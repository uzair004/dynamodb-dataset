[
  {
    "title": "DynamoDB transactions example - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-example.html",
    "html": "DynamoDB transactions example\nPDF\nRSS\n\nAs an example of a situation in which Amazon DynamoDB transactions can be useful, consider this sample Java application for an online marketplace.\n\nThe application has three DynamoDB tables in the backend:\n\nCustomers — This table stores details about the marketplace customers. Its primary key is a CustomerId unique identifier.\n\nProductCatalog — This table stores details such as price and availability about the products for sale in the marketplace. Its primary key is a ProductId unique identifier.\n\nOrders — This table stores details about orders from the marketplace. Its primary key is an OrderId unique identifier.\n\nMaking an order\n\nThe following code snippets illustrate how to use DynamoDB transactions to coordinate the multiple steps that are required to create and process an order. Using a single all-or-nothing operation ensures that if any part of the transaction fails, no actions in the transaction are run and no changes are made.\n\nIn this example, you set up an order from a customer whose customerId is 09e8e9c8-ec48. You then run it as a single transaction using the following simple order-processing workflow:\n\nDetermine that the customer ID is valid.\n\nMake sure that the product is IN_STOCK, and update the product status to SOLD.\n\nMake sure that the order does not already exist, and create the order.\n\nValidate the customer\n\nFirst, define an action to verify that a customer with customerId equal to 09e8e9c8-ec48 exists in the customer table.\n\nfinal String CUSTOMER_TABLE_NAME = \"Customers\";\nfinal String CUSTOMER_PARTITION_KEY = \"CustomerId\";\nfinal String customerId = \"09e8e9c8-ec48\";\nfinal HashMap<String, AttributeValue> customerItemKey = new HashMap<>();\ncustomerItemKey.put(CUSTOMER_PARTITION_KEY, new AttributeValue(customerId));\n\nConditionCheck checkCustomerValid = new ConditionCheck()\n    .withTableName(CUSTOMER_TABLE_NAME)\n    .withKey(customerItemKey)\n    .withConditionExpression(\"attribute_exists(\" + CUSTOMER_PARTITION_KEY + \")\");\nUpdate the product status\n\nNext, define an action to update the product status to SOLD if the condition that the product status is currently set to IN_STOCK is true. Setting the ReturnValuesOnConditionCheckFailure parameter returns the item if the item's product status attribute was not equal to IN_STOCK.\n\nfinal String PRODUCT_TABLE_NAME = \"ProductCatalog\";\nfinal String PRODUCT_PARTITION_KEY = \"ProductId\";\nHashMap<String, AttributeValue> productItemKey = new HashMap<>();\nproductItemKey.put(PRODUCT_PARTITION_KEY, new AttributeValue(productKey));\n\nMap<String, AttributeValue> expressionAttributeValues = new HashMap<>();\nexpressionAttributeValues.put(\":new_status\", new AttributeValue(\"SOLD\"));\nexpressionAttributeValues.put(\":expected_status\", new AttributeValue(\"IN_STOCK\"));\n\nUpdate markItemSold = new Update()\n    .withTableName(PRODUCT_TABLE_NAME)\n    .withKey(productItemKey)\n    .withUpdateExpression(\"SET ProductStatus = :new_status\")\n    .withExpressionAttributeValues(expressionAttributeValues)\n    .withConditionExpression(\"ProductStatus = :expected_status\")\n    .withReturnValuesOnConditionCheckFailure(ReturnValuesOnConditionCheckFailure.ALL_OLD);\nCreate the order\n\nLastly, create the order as long as an order with that OrderId does not already exist.\n\nfinal String ORDER_PARTITION_KEY = \"OrderId\";\nfinal String ORDER_TABLE_NAME = \"Orders\";\n\nHashMap<String, AttributeValue> orderItem = new HashMap<>();\norderItem.put(ORDER_PARTITION_KEY, new AttributeValue(orderId));\norderItem.put(PRODUCT_PARTITION_KEY, new AttributeValue(productKey));\norderItem.put(CUSTOMER_PARTITION_KEY, new AttributeValue(customerId));\norderItem.put(\"OrderStatus\", new AttributeValue(\"CONFIRMED\"));\norderItem.put(\"OrderTotal\", new AttributeValue(\"100\"));\n\nPut createOrder = new Put()\n    .withTableName(ORDER_TABLE_NAME)\n    .withItem(orderItem)\n    .withReturnValuesOnConditionCheckFailure(ReturnValuesOnConditionCheckFailure.ALL_OLD)\n    .withConditionExpression(\"attribute_not_exists(\" + ORDER_PARTITION_KEY + \")\");\nRun the transaction\n\nThe following example illustrates how to run the actions defined previously as a single all-or-nothing operation.\n\n    Collection<TransactWriteItem> actions = Arrays.asList(\n        new TransactWriteItem().withConditionCheck(checkCustomerValid),\n        new TransactWriteItem().withUpdate(markItemSold),\n        new TransactWriteItem().withPut(createOrder));\n\n    TransactWriteItemsRequest placeOrderTransaction = new TransactWriteItemsRequest()\n        .withTransactItems(actions)\n        .withReturnConsumedCapacity(ReturnConsumedCapacity.TOTAL);\n\n    // Run the transaction and process the result.\n    try {\n        client.transactWriteItems(placeOrderTransaction);\n        System.out.println(\"Transaction Successful\");\n\n    } catch (ResourceNotFoundException rnf) {\n        System.err.println(\"One of the table involved in the transaction is not found\" + rnf.getMessage());\n    } catch (InternalServerErrorException ise) {\n        System.err.println(\"Internal Server Error\" + ise.getMessage());\n    } catch (TransactionCanceledException tce) {\n        System.out.println(\"Transaction Canceled \" + tce.getMessage());\n    }\nReading the order details\n\nThe following example shows how to read the completed order transactionally across the Orders and ProductCatalog tables.\n\nHashMap<String, AttributeValue> productItemKey = new HashMap<>();\nproductItemKey.put(PRODUCT_PARTITION_KEY, new AttributeValue(productKey));\n\nHashMap<String, AttributeValue> orderKey = new HashMap<>();\norderKey.put(ORDER_PARTITION_KEY, new AttributeValue(orderId));\n\nGet readProductSold = new Get()\n    .withTableName(PRODUCT_TABLE_NAME)\n    .withKey(productItemKey);\nGet readCreatedOrder = new Get()\n    .withTableName(ORDER_TABLE_NAME)\n    .withKey(orderKey);\n\nCollection<TransactGetItem> getActions = Arrays.asList(\n    new TransactGetItem().withGet(readProductSold),\n    new TransactGetItem().withGet(readCreatedOrder));\n\nTransactGetItemsRequest readCompletedOrder = new TransactGetItemsRequest()\n    .withTransactItems(getActions)\n    .withReturnConsumedCapacity(ReturnConsumedCapacity.TOTAL);\n\n// Run the transaction and process the result.\ntry {\n    TransactGetItemsResult result = client.transactGetItems(readCompletedOrder);\n    System.out.println(result.getResponses());\n} catch (ResourceNotFoundException rnf) {\n    System.err.println(\"One of the table involved in the transaction is not found\" + rnf.getMessage());\n} catch (InternalServerErrorException ise) {\n    System.err.println(\"Internal Server Error\" + ise.getMessage());\n} catch (TransactionCanceledException tce) {\n    System.err.println(\"Transaction Canceled\" + tce.getMessage());\n}\nAdditional examples\n\nUsing transactions from DynamoDBMapper"
  },
  {
    "title": "Using IAM with DynamoDB transactions - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis-iam.html",
    "html": "Using IAM with DynamoDB transactions\nPDF\nRSS\n\nYou can use AWS Identity and Access Management (IAM) to restrict the actions that transactional operations can perform in Amazon DynamoDB. For more information about using IAM policies in DynamoDB, see Identity-based policies for DynamoDB.\n\nPermissions for Put, Update, Delete, and Get actions are governed by the permissions used for the underlying PutItem, UpdateItem, DeleteItem, and GetItem operations. For the ConditionCheck action, you can use the dynamodb:ConditionCheck permission in IAM policies.\n\nThe following are examples of IAM policies that you can use to configure the DynamoDB transactions.\n\nExample 1: Allow transactional operations\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"dynamodb:ConditionCheckItem\",\n                \"dynamodb:PutItem\",\n                \"dynamodb:UpdateItem\",\n                \"dynamodb:DeleteItem\",\n                \"dynamodb:GetItem\"\n            ],\n            \"Resource\": [\n                \"arn:aws:dynamodb:*:*:table/table04\"\n            ]\n        }\n    ]\n}\nExample 2: Allow only transactional operations\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"dynamodb:ConditionCheckItem\",\n                \"dynamodb:PutItem\",\n                \"dynamodb:UpdateItem\",\n                \"dynamodb:DeleteItem\",\n                \"dynamodb:GetItem\"\n            ],\n            \"Resource\": [\n                \"arn:aws:dynamodb:*:*:table/table04\"\n            ],\n            \"Condition\": {\n                \"ForAnyValue:StringEquals\": {\n                    \"dynamodb:EnclosingOperation\": [\n                        \"TransactWriteItems\",\n                        \"TransactGetItems\"\n                    ]\n                }\n            }\n        }\n    ]\n}\nExample 3: Allow nontransactional reads and writes, and block transactional reads and writes\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Deny\",\n            \"Action\": [\n                \"dynamodb:ConditionCheckItem\",\n                \"dynamodb:PutItem\",\n                \"dynamodb:UpdateItem\",\n                \"dynamodb:DeleteItem\",\n                \"dynamodb:GetItem\"\n            ],\n            \"Resource\": [\n                \"arn:aws:dynamodb:*:*:table/table04\"\n            ],\n            \"Condition\": {\n                \"ForAnyValue:StringEquals\": {\n                    \"dynamodb:EnclosingOperation\": [\n                        \"TransactWriteItems\",\n                        \"TransactGetItems\"\n                    ]\n                }\n            }\n        },\n        {\n            \"Effect\": \"Allow\",\n             \"Action\": [\n                 \"dynamodb:PutItem\",\n                 \"dynamodb:DeleteItem\",\n                 \"dynamodb:GetItem\",\n                 \"dynamodb:UpdateItem\"\n             ],\n             \"Resource\": [\n                 \"arn:aws:dynamodb:*:*:table/table04\"\n             ]\n         }\n    ]\n}\nExample 4: Prevent information from being returned on a ConditionCheck failure\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"dynamodb:ConditionCheckItem\",\n                \"dynamodb:PutItem\",\n                \"dynamodb:UpdateItem\",\n                \"dynamodb:DeleteItem\",\n                \"dynamodb:GetItem\"\n            ],\n            \"Resource\": \"arn:aws:dynamodb:*:*:table/table01\",\n            \"Condition\": {\n                \"StringEqualsIfExists\": {\n                    \"dynamodb:ReturnValues\": \"NONE\"\n                }\n            }\n        }\n    ]\n}"
  },
  {
    "title": "Amazon DynamoDB Transactions: How it works - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html",
    "html": "Amazon DynamoDB Transactions: How it works\nPDF\nRSS\n\nWith Amazon DynamoDB transactions, you can group multiple actions together and submit them as a single all-or-nothing TransactWriteItems or TransactGetItems operation. The following sections describe API operations, capacity management, best practices, and other details about using transactional operations in DynamoDB.\n\nTopics\nTransactWriteItems API\nTransactGetItems API\nIsolation levels for DynamoDB transactions\nTransaction conflict handling in DynamoDB\nUsing transactional APIs in DynamoDB Accelerator (DAX)\nCapacity management for transactions\nBest practices for transactions\nUsing transactional APIs with global tables\nDynamoDB Transactions vs. the AWSLabs transactions client library\nTransactWriteItems API\n\nTransactWriteItems is a synchronous and idempotent write operation that groups up to 100 write actions in a single all-or-nothing operation. These actions can target up to 100 distinct items in one or more DynamoDB tables within the same AWS account and in the same Region. The aggregate size of the items in the transaction cannot exceed 4 MB. The actions are completed atomically so that either all of them succeed or none of them succeeds.\n\nNote\n\nA TransactWriteItems operation differs from a BatchWriteItem operation in that all the actions it contains must be completed successfully, or no changes are made at all. With a BatchWriteItem operation, it is possible that only some of the actions in the batch succeed while the others do not.\n\nTransactions cannot be performed using indexes.\n\nYou can't target the same item with multiple operations within the same transaction. For example, you can't perform a ConditionCheck and also an Update action on the same item in the same transaction.\n\nYou can add the following types of actions to a transaction:\n\nPut — Initiates a PutItem operation to create a new item or replace an old item with a new item, conditionally or without specifying any condition.\n\nUpdate — Initiates an UpdateItem operation to edit an existing item's attributes or add a new item to the table if it does not already exist. Use this action to add, delete, or update attributes on an existing item conditionally or without a condition.\n\nDelete — Initiates a DeleteItem operation to delete a single item in a table identified by its primary key.\n\nConditionCheck — Checks that an item exists or checks the condition of specific attributes of the item.\n\nOnce a transaction completes, the changes made within that transaction are propagated to global secondary indexes (GSIs), streams, and backups. Since propagation is not immediate or instantaneous, if a table is restored from backup (RestoreTableFromBackup) or exported to a point in time (ExportTableToPointInTime) mid-propagation, it might contain some but not all of the changes made during a recent transaction.\n\nIdempotency\n\nYou can optionally include a client token when you make a TransactWriteItems call to ensure that the request is idempotent. Making your transactions idempotent helps prevent application errors if the same operation is submitted multiple times due to a connection time-out or other connectivity issue.\n\nIf the original TransactWriteItems call was successful, then subsequent TransactWriteItems calls with the same client token return successfully without making any changes. If the ReturnConsumedCapacity parameter is set, the initial TransactWriteItems call returns the number of write capacity units consumed in making the changes. Subsequent TransactWriteItems calls with the same client token return the number of read capacity units consumed in reading the item.\n\nImportant points about idempotency\n\nA client token is valid for 10 minutes after the request that uses it finishes. After 10 minutes, any request that uses the same client token is treated as a new request. You should not reuse the same client token for the same request after 10 minutes.\n\nIf you repeat a request with the same client token within the 10-minute idempotency window but change some other request parameter, DynamoDB returns an IdempotentParameterMismatch exception.\n\nError handling for writing\n\nWrite transactions don't succeed under the following circumstances:\n\nWhen a condition in one of the condition expressions is not met.\n\nWhen a transaction validation error occurs because more than one action in the same TransactWriteItems operation targets the same item.\n\nWhen a TransactWriteItems request conflicts with an ongoing TransactWriteItems operation on one or more items in the TransactWriteItems request. In this case, the request fails with a TransactionCanceledException.\n\nWhen there is insufficient provisioned capacity for the transaction to be completed.\n\nWhen an item size becomes too large (larger than 400 KB), or a local secondary index (LSI) becomes too large, or a similar validation error occurs because of changes made by the transaction.\n\nWhen there is a user error, such as an invalid data format.\n\nFor more information about how conflicts with TransactWriteItems operations are handled, see Transaction conflict handling in DynamoDB.\n\nTransactGetItems API\n\nTransactGetItems is a synchronous read operation that groups up to 100 Get actions together. These actions can target up to 100 distinct items in one or more DynamoDB tables within the same AWS account and Region. The aggregate size of the items in the transaction can't exceed 4 MB.\n\nThe Get actions are performed atomically so that either all of them succeed or all of them fail:\n\nGet — Initiates a GetItem operation to retrieve a set of attributes for the item with the given primary key. If no matching item is found, Get does not return any data.\n\nError handling for reading\n\nRead transactions don't succeed under the following circumstances:\n\nWhen a TransactGetItems request conflicts with an ongoing TransactWriteItems operation on one or more items in the TransactGetItems request. In this case, the request fails with a TransactionCanceledException.\n\nWhen there is insufficient provisioned capacity for the transaction to be completed.\n\nWhen there is a user error, such as an invalid data format.\n\nFor more information about how conflicts with TransactGetItems operations are handled, see Transaction conflict handling in DynamoDB.\n\nIsolation levels for DynamoDB transactions\n\nThe isolation levels of transactional operations (TransactWriteItems or TransactGetItems) and other operations are as follows.\n\nSERIALIZABLE\n\nSerializable isolation ensures that the results of multiple concurrent operations are the same as if no operation begins until the previous one has finished.\n\nThere is serializable isolation between the following types of operation:\n\nBetween any transactional operation and any standard write operation (PutItem, UpdateItem, or DeleteItem).\n\nBetween any transactional operation and any standard read operation (GetItem).\n\nBetween a TransactWriteItems operation and a TransactGetItems operation.\n\nAlthough there is serializable isolation between transactional operations, and each individual standard write in a BatchWriteItem operation, there is no serializable isolation between the transaction and the BatchWriteItem operation as a unit.\n\nSimilarly, the isolation level between a transactional operation and individual GetItems in a BatchGetItem operation is serializable. But the isolation level between the transaction and the BatchGetItem operation as a unit is read-committed.\n\nA single GetItem request is serializable with respect to a TransactWriteItems request in one of two ways, either before or after the TransactWriteItems request. Multiple GetItem requests, against keys in a concurrent TransactWriteItems requests can be run in any order, and therefore the results are read-committed.\n\nFor example, if GetItem requests for item A and item B are run concurrently with a TransactWriteItems request that modifies both item A and item B, there are four possibilities:\n\nBoth GetItem requests are run before the TransactWriteItems request.\n\nBoth GetItem requests are run after the TransactWriteItems request.\n\nGetItem request for item A is run before the TransactWriteItems request. For item B the GetItem is run after TransactWriteItems.\n\nGetItem request for item B is run before the TransactWriteItems request. For item A the GetItem is run after TransactWriteItems.\n\nYou should use TransactGetItems if you prefer serializable isolation level for multiple GetItem requests.\n\nIf a non-transactional read is made on multiple items that were part of the same transaction write request in-flight, it is possible that you'll be able to read new state of some of the items and old state of the other items. You'll be able to read new state of all items that were part of the transaction write request only when a successful response is received for the transactional write.\n\nREAD-COMMITTED\n\nRead-committed isolation ensures that read operations always return committed values for an item - the read will never present a view to the item representing a state from a transactional write which did not ultimately succeed. Read-committed isolation does not prevent modifications of the item immediately after the read operation.\n\nThe isolation level is read-committed between any transactional operation and any read operation that involves multiple standard reads (BatchGetItem, Query, or Scan). If a transactional write updates an item in the middle of a BatchGetItem, Query, or Scan operation, the subsequent part of the read operation returns the newly committed value (with ConsistentRead) or possibly a prior committed value (eventually consistent reads).\n\nOperation summary\n\nTo summarize, the following table shows the isolation levels between a transaction operation (TransactWriteItems or TransactGetItems) and other operations.\n\nOperation\tIsolation Level\n\n\nDeleteItem\n\n\t\n\nSerializable\n\n\n\n\nPutItem\n\n\t\n\nSerializable\n\n\n\n\nUpdateItem\n\n\t\n\nSerializable\n\n\n\n\nGetItem\n\n\t\n\nSerializable\n\n\n\n\nBatchGetItem\n\n\t\n\nRead-committed*\n\n\n\n\nBatchWriteItem\n\n\t\n\nNOT Serializable*\n\n\n\n\nQuery\n\n\t\n\nRead-committed\n\n\n\n\nScan\n\n\t\n\nRead-committed\n\n\n\n\nOther transactional operation\n\n\t\n\nSerializable\n\nLevels marked with an asterisk (*) apply to the operation as a unit. However, individual actions within those operations have a serializable isolation level.\n\nTransaction conflict handling in DynamoDB\n\nA transactional conflict can occur during concurrent item-level requests on an item within a transaction. Transaction conflicts can occur in the following scenarios:\n\nA PutItem, UpdateItem, or DeleteItem request for an item conflicts with an ongoing TransactWriteItems request that includes the same item.\n\nAn item within a TransactWriteItems request is part of another ongoing TransactWriteItems request.\n\nAn item within a TransactGetItems request is part of an ongoing TransactWriteItems, BatchWriteItem, PutItem, UpdateItem, or DeleteItem request.\n\nNote\n\nWhen a PutItem, UpdateItem, or DeleteItem request is rejected, the request fails with a TransactionConflictException.\n\nIf any item-level request within TransactWriteItems or TransactGetItems is rejected, the request fails with a TransactionCanceledException. If that request fails, AWS SDKs do not retry the request.\n\nIf you are using the AWS SDK for Java, the exception contains the list of CancellationReasons, ordered according to the list of items in the TransactItems request parameter. For other languages, a string representation of the list is included in the exception’s error message.\n\nIf an ongoing TransactWriteItems or TransactGetItems operation conflicts with a concurrent GetItem request, both operations can succeed.\n\nThe TransactionConflict CloudWatch metric is incremented for each failed item-level request.\n\nUsing transactional APIs in DynamoDB Accelerator (DAX)\n\nTransactWriteItems and TransactGetItems are both supported in DynamoDB Accelerator (DAX) with the same isolation levels as in DynamoDB.\n\nTransactWriteItems writes through DAX. DAX passes a TransactWriteItems call to DynamoDB and returns the response. To populate the cache after the write, DAX calls TransactGetItems in the background for each item in the TransactWriteItems operation, which consumes additional read capacity units. (For more information, see Capacity management for transactions.) This functionality enables you to keep your application logic simple and use DAX for both transactional operations and nontransactional ones.\n\nTransactGetItems calls are passed through DAX without the items being cached locally. This is the same behavior as for strongly consistent read APIs in DAX.\n\nCapacity management for transactions\n\nThere is no additional cost to enable transactions for your DynamoDB tables. You pay only for the reads or writes that are part of your transaction. DynamoDB performs two underlying reads or writes of every item in the transaction: one to prepare the transaction and one to commit the transaction. The two underlying read/write operations are visible in your Amazon CloudWatch metrics.\n\nPlan for the additional reads and writes that are required by transactional APIs when you are provisioning capacity to your tables. For example, suppose that your application runs one transaction per second, and each transaction writes three 500-byte items in your table. Each item requires two write capacity units (WCUs): one to prepare the transaction and one to commit the transaction. Therefore, you would need to provision six WCUs to the table.\n\nIf you were using DynamoDB Accelerator (DAX) in the previous example, you would also use two read capacity units (RCUs) for each item in the TransactWriteItems call. So you would need to provision six additional RCUs to the table.\n\nSimilarly, if your application runs one read transaction per second, and each transaction reads three 500-byte items in your table, you would need to provision six read capacity units (RCUs) to the table. Reading each item requires two RCUs: one to prepare the transaction and one to commit the transaction.\n\nAlso, default SDK behavior is to retry transactions in case of a TransactionInProgressException exception. Plan for the additional read-capacity units (RCUs) that these retries consume. The same is true if you are retrying transactions in your own code using a ClientRequestToken.\n\nBest practices for transactions\n\nConsider the following recommended practices when using DynamoDB transactions.\n\nEnable automatic scaling on your tables, or ensure that you have provisioned enough throughput capacity to perform the two read or write operations for every item in your transaction.\n\nIf you are not using an AWS provided SDK, include a ClientRequestToken attribute when you make a TransactWriteItems call to ensure that the request is idempotent.\n\nDon't group operations together in a transaction if it's not necessary. For example, if a single transaction with 10 operations can be broken up into multiple transactions without compromising the application correctness, we recommend splitting up the transaction. Simpler transactions improve throughput and are more likely to succeed.\n\nMultiple transactions updating the same items simultaneously can cause conflicts that cancel the transactions. We recommend following DynamoDB best practices for data modeling to minimize such conflicts.\n\nIf a set of attributes is often updated across multiple items as part of a single transaction, consider grouping the attributes into a single item to reduce the scope of the transaction.\n\nAvoid using transactions for ingesting data in bulk. For bulk writes, it is better to use BatchWriteItem.\n\nUsing transactional APIs with global tables\n\nOperations contained within a DynamoDB transaction are only guaranteed transactional in the region where the transaction is originally executed. Transactionality is not preserved when changes applied within a transaction are replicated across Regions to global tables replicas.\n\nDynamoDB Transactions vs. the AWSLabs transactions client library\n\nDynamoDB transactions provide a more cost-effective, robust, and performant replacement for the AWSLabs transactions client library. We suggest that you update your applications to use the native, server-side transaction APIs."
  },
  {
    "title": "Managing complex workflows with DynamoDB transactions - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transactions.html",
    "html": "Managing complex workflows with DynamoDB transactions\nPDF\nRSS\n\nAmazon DynamoDB transactions simplify the developer experience of making coordinated, all-or-nothing changes to multiple items both within and across tables. Transactions provide atomicity, consistency, isolation, and durability (ACID) in DynamoDB, helping you to maintain data correctness in your applications.\n\nYou can use the DynamoDB transactional read and write APIs to manage complex business workflows that require adding, updating, or deleting multiple items as a single, all-or-nothing operation. For example, a video game developer can ensure that players’ profiles are updated correctly when they exchange items in a game or make in-game purchases.\n\nWith the transaction write API, you can group multiple Put, Update, Delete, and ConditionCheck actions. You can then submit the actions as a single TransactWriteItems operation that either succeeds or fails as a unit. The same is true for multiple Get actions, which you can group and submit as a single TransactGetItems operation.\n\nThere is no additional cost to enable transactions for your DynamoDB tables. You pay only for the reads or writes that are part of your transaction. DynamoDB performs two underlying reads or writes of every item in the transaction: one to prepare the transaction and one to commit the transaction. These two underlying read/write operations are visible in your Amazon CloudWatch metrics.\n\nTo get started with DynamoDB transactions, download the latest AWS SDK or the AWS Command Line Interface (AWS CLI). Then follow the DynamoDB transactions example.\n\nThe following sections provide a detailed overview of the transaction APIs and how you can use them in DynamoDB.\n\nTopics\nHow it works\nUsing IAM with transactions\nExample code"
  },
  {
    "title": "Example: Local Secondary Indexes using the AWS SDK for .NET low-level API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LSILowLevelDotNet.Example.html",
    "html": "Example: Local Secondary Indexes using the AWS SDK for .NET low-level API\nPDF\nRSS\n\nThe following C# code example shows how to work with local secondary indexes in Amazon DynamoDB. The example creates a table named CustomerOrders with a partition key of CustomerId and a sort key of OrderId. There are two local secondary indexes on this table:\n\nOrderCreationDateIndex — The sort key is OrderCreationDate, and the following attributes are projected into the index:\n\nProductCategory\n\nProductName\n\nOrderStatus\n\nShipmentTrackingId\n\nIsOpenIndex — The sort key is IsOpen, and all of the table attributes are projected into the index.\n\nAfter the CustomerOrders table is created, the program loads the table with data representing customer orders. It then queries the data using the local secondary indexes. Finally, the program deletes the CustomerOrders table.\n\nFor step-by-step instructions for testing the following example, see .NET code examples.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.DataModel;\nusing Amazon.DynamoDBv2.DocumentModel;\nusing Amazon.DynamoDBv2.Model;\nusing Amazon.Runtime;\nusing Amazon.SecurityToken;\n\nnamespace com.amazonaws.codesamples\n{\n    class LowLevelLocalSecondaryIndexExample\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n        private static string tableName = \"CustomerOrders\";\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                CreateTable();\n                LoadData();\n\n                Query(null);\n                Query(\"IsOpenIndex\");\n                Query(\"OrderCreationDateIndex\");\n\n                DeleteTable(tableName);\n\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (AmazonDynamoDBException e) { Console.WriteLine(e.Message); }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n        }\n\n        private static void CreateTable()\n        {\n            var createTableRequest =\n                new CreateTableRequest()\n                {\n                    TableName = tableName,\n                    ProvisionedThroughput =\n                    new ProvisionedThroughput()\n                    {\n                        ReadCapacityUnits = (long)1,\n                        WriteCapacityUnits = (long)1\n                    }\n                };\n\n            var attributeDefinitions = new List<AttributeDefinition>()\n        {\n            // Attribute definitions for table primary key\n            { new AttributeDefinition() {\n                  AttributeName = \"CustomerId\", AttributeType = \"S\"\n              } },\n            { new AttributeDefinition() {\n                  AttributeName = \"OrderId\", AttributeType = \"N\"\n              } },\n            // Attribute definitions for index primary key\n            { new AttributeDefinition() {\n                  AttributeName = \"OrderCreationDate\", AttributeType = \"N\"\n              } },\n            { new AttributeDefinition() {\n                  AttributeName = \"IsOpen\", AttributeType = \"N\"\n              }}\n        };\n\n            createTableRequest.AttributeDefinitions = attributeDefinitions;\n\n            // Key schema for table\n            var tableKeySchema = new List<KeySchemaElement>()\n        {\n            { new KeySchemaElement() {\n                  AttributeName = \"CustomerId\", KeyType = \"HASH\"\n              } },                                                  //Partition key\n            { new KeySchemaElement() {\n                  AttributeName = \"OrderId\", KeyType = \"RANGE\"\n              } }                                                //Sort key\n        };\n\n            createTableRequest.KeySchema = tableKeySchema;\n\n            var localSecondaryIndexes = new List<LocalSecondaryIndex>();\n\n            // OrderCreationDateIndex\n            LocalSecondaryIndex orderCreationDateIndex = new LocalSecondaryIndex()\n            {\n                IndexName = \"OrderCreationDateIndex\"\n            };\n\n            // Key schema for OrderCreationDateIndex\n            var indexKeySchema = new List<KeySchemaElement>()\n        {\n            { new KeySchemaElement() {\n                  AttributeName = \"CustomerId\", KeyType = \"HASH\"\n              } },                                                    //Partition key\n            { new KeySchemaElement() {\n                  AttributeName = \"OrderCreationDate\", KeyType = \"RANGE\"\n              } }                                                            //Sort key\n        };\n\n            orderCreationDateIndex.KeySchema = indexKeySchema;\n\n            // Projection (with list of projected attributes) for\n            // OrderCreationDateIndex\n            var projection = new Projection()\n            {\n                ProjectionType = \"INCLUDE\"\n            };\n\n            var nonKeyAttributes = new List<string>()\n        {\n            \"ProductCategory\",\n            \"ProductName\"\n        };\n            projection.NonKeyAttributes = nonKeyAttributes;\n\n            orderCreationDateIndex.Projection = projection;\n\n            localSecondaryIndexes.Add(orderCreationDateIndex);\n\n            // IsOpenIndex\n            LocalSecondaryIndex isOpenIndex\n                = new LocalSecondaryIndex()\n                {\n                    IndexName = \"IsOpenIndex\"\n                };\n\n            // Key schema for IsOpenIndex\n            indexKeySchema = new List<KeySchemaElement>()\n        {\n            { new KeySchemaElement() {\n                  AttributeName = \"CustomerId\", KeyType = \"HASH\"\n              }},                                                     //Partition key\n            { new KeySchemaElement() {\n                  AttributeName = \"IsOpen\", KeyType = \"RANGE\"\n              }}                                                  //Sort key\n        };\n\n            // Projection (all attributes) for IsOpenIndex\n            projection = new Projection()\n            {\n                ProjectionType = \"ALL\"\n            };\n\n            isOpenIndex.KeySchema = indexKeySchema;\n            isOpenIndex.Projection = projection;\n\n            localSecondaryIndexes.Add(isOpenIndex);\n\n            // Add index definitions to CreateTable request\n            createTableRequest.LocalSecondaryIndexes = localSecondaryIndexes;\n\n            Console.WriteLine(\"Creating table \" + tableName + \"...\");\n            client.CreateTable(createTableRequest);\n            WaitUntilTableReady(tableName);\n        }\n\n        public static void Query(string indexName)\n        {\n            Console.WriteLine(\"\\n***********************************************************\\n\");\n            Console.WriteLine(\"Querying table \" + tableName + \"...\");\n\n            QueryRequest queryRequest = new QueryRequest()\n            {\n                TableName = tableName,\n                ConsistentRead = true,\n                ScanIndexForward = true,\n                ReturnConsumedCapacity = \"TOTAL\"\n            };\n\n\n            String keyConditionExpression = \"CustomerId = :v_customerId\";\n            Dictionary<string, AttributeValue> expressionAttributeValues = new Dictionary<string, AttributeValue> {\n            {\":v_customerId\", new AttributeValue {\n                 S = \"bob@example.com\"\n             }}\n        };\n\n\n            if (indexName == \"IsOpenIndex\")\n            {\n                Console.WriteLine(\"\\nUsing index: '\" + indexName\n                          + \"': Bob's orders that are open.\");\n                Console.WriteLine(\"Only a user-specified list of attributes are returned\\n\");\n                queryRequest.IndexName = indexName;\n\n                keyConditionExpression += \" and IsOpen = :v_isOpen\";\n                expressionAttributeValues.Add(\":v_isOpen\", new AttributeValue\n                {\n                    N = \"1\"\n                });\n\n                // ProjectionExpression\n                queryRequest.ProjectionExpression = \"OrderCreationDate, ProductCategory, ProductName, OrderStatus\";\n            }\n            else if (indexName == \"OrderCreationDateIndex\")\n            {\n                Console.WriteLine(\"\\nUsing index: '\" + indexName\n                          + \"': Bob's orders that were placed after 01/31/2013.\");\n                Console.WriteLine(\"Only the projected attributes are returned\\n\");\n                queryRequest.IndexName = indexName;\n\n                keyConditionExpression += \" and OrderCreationDate > :v_Date\";\n                expressionAttributeValues.Add(\":v_Date\", new AttributeValue\n                {\n                    N = \"20130131\"\n                });\n\n                // Select\n                queryRequest.Select = \"ALL_PROJECTED_ATTRIBUTES\";\n            }\n            else\n            {\n                Console.WriteLine(\"\\nNo index: All of Bob's orders, by OrderId:\\n\");\n            }\n            queryRequest.KeyConditionExpression = keyConditionExpression;\n            queryRequest.ExpressionAttributeValues = expressionAttributeValues;\n\n            var result = client.Query(queryRequest);\n            var items = result.Items;\n            foreach (var currentItem in items)\n            {\n                foreach (string attr in currentItem.Keys)\n                {\n                    if (attr == \"OrderId\" || attr == \"IsOpen\"\n                        || attr == \"OrderCreationDate\")\n                    {\n                        Console.WriteLine(attr + \"---> \" + currentItem[attr].N);\n                    }\n                    else\n                    {\n                        Console.WriteLine(attr + \"---> \" + currentItem[attr].S);\n                    }\n                }\n                Console.WriteLine();\n            }\n            Console.WriteLine(\"\\nConsumed capacity: \" + result.ConsumedCapacity.CapacityUnits + \"\\n\");\n        }\n\n        private static void DeleteTable(string tableName)\n        {\n            Console.WriteLine(\"Deleting table \" + tableName + \"...\");\n            client.DeleteTable(new DeleteTableRequest()\n            {\n                TableName = tableName\n            });\n            WaitForTableToBeDeleted(tableName);\n        }\n\n        public static void LoadData()\n        {\n            Console.WriteLine(\"Loading data into table \" + tableName + \"...\");\n\n            Dictionary<string, AttributeValue> item = new Dictionary<string, AttributeValue>();\n\n            item[\"CustomerId\"] = new AttributeValue\n            {\n                S = \"alice@example.com\"\n            };\n            item[\"OrderId\"] = new AttributeValue\n            {\n                N = \"1\"\n            };\n            item[\"IsOpen\"] = new AttributeValue\n            {\n                N = \"1\"\n            };\n            item[\"OrderCreationDate\"] = new AttributeValue\n            {\n                N = \"20130101\"\n            };\n            item[\"ProductCategory\"] = new AttributeValue\n            {\n                S = \"Book\"\n            };\n            item[\"ProductName\"] = new AttributeValue\n            {\n                S = \"The Great Outdoors\"\n            };\n            item[\"OrderStatus\"] = new AttributeValue\n            {\n                S = \"PACKING ITEMS\"\n            };\n            /* no ShipmentTrackingId attribute */\n            PutItemRequest putItemRequest = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n                ReturnItemCollectionMetrics = \"SIZE\"\n            };\n            client.PutItem(putItemRequest);\n\n            item = new Dictionary<string, AttributeValue>();\n            item[\"CustomerId\"] = new AttributeValue\n            {\n                S = \"alice@example.com\"\n            };\n            item[\"OrderId\"] = new AttributeValue\n            {\n                N = \"2\"\n            };\n            item[\"IsOpen\"] = new AttributeValue\n            {\n                N = \"1\"\n            };\n            item[\"OrderCreationDate\"] = new AttributeValue\n            {\n                N = \"20130221\"\n            };\n            item[\"ProductCategory\"] = new AttributeValue\n            {\n                S = \"Bike\"\n            };\n            item[\"ProductName\"] = new AttributeValue\n            {\n                S = \"Super Mountain\"\n            };\n            item[\"OrderStatus\"] = new AttributeValue\n            {\n                S = \"ORDER RECEIVED\"\n            };\n            /* no ShipmentTrackingId attribute */\n            putItemRequest = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n                ReturnItemCollectionMetrics = \"SIZE\"\n            };\n            client.PutItem(putItemRequest);\n\n            item = new Dictionary<string, AttributeValue>();\n            item[\"CustomerId\"] = new AttributeValue\n            {\n                S = \"alice@example.com\"\n            };\n            item[\"OrderId\"] = new AttributeValue\n            {\n                N = \"3\"\n            };\n            /* no IsOpen attribute */\n            item[\"OrderCreationDate\"] = new AttributeValue\n            {\n                N = \"20130304\"\n            };\n            item[\"ProductCategory\"] = new AttributeValue\n            {\n                S = \"Music\"\n            };\n            item[\"ProductName\"] = new AttributeValue\n            {\n                S = \"A Quiet Interlude\"\n            };\n            item[\"OrderStatus\"] = new AttributeValue\n            {\n                S = \"IN TRANSIT\"\n            };\n            item[\"ShipmentTrackingId\"] = new AttributeValue\n            {\n                S = \"176493\"\n            };\n            putItemRequest = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n                ReturnItemCollectionMetrics = \"SIZE\"\n            };\n            client.PutItem(putItemRequest);\n\n            item = new Dictionary<string, AttributeValue>();\n            item[\"CustomerId\"] = new AttributeValue\n            {\n                S = \"bob@example.com\"\n            };\n            item[\"OrderId\"] = new AttributeValue\n            {\n                N = \"1\"\n            };\n            /* no IsOpen attribute */\n            item[\"OrderCreationDate\"] = new AttributeValue\n            {\n                N = \"20130111\"\n            };\n            item[\"ProductCategory\"] = new AttributeValue\n            {\n                S = \"Movie\"\n            };\n            item[\"ProductName\"] = new AttributeValue\n            {\n                S = \"Calm Before The Storm\"\n            };\n            item[\"OrderStatus\"] = new AttributeValue\n            {\n                S = \"SHIPPING DELAY\"\n            };\n            item[\"ShipmentTrackingId\"] = new AttributeValue\n            {\n                S = \"859323\"\n            };\n            putItemRequest = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n                ReturnItemCollectionMetrics = \"SIZE\"\n            };\n            client.PutItem(putItemRequest);\n\n            item = new Dictionary<string, AttributeValue>();\n            item[\"CustomerId\"] = new AttributeValue\n            {\n                S = \"bob@example.com\"\n            };\n            item[\"OrderId\"] = new AttributeValue\n            {\n                N = \"2\"\n            };\n            /* no IsOpen attribute */\n            item[\"OrderCreationDate\"] = new AttributeValue\n            {\n                N = \"20130124\"\n            };\n            item[\"ProductCategory\"] = new AttributeValue\n            {\n                S = \"Music\"\n            };\n            item[\"ProductName\"] = new AttributeValue\n            {\n                S = \"E-Z Listening\"\n            };\n            item[\"OrderStatus\"] = new AttributeValue\n            {\n                S = \"DELIVERED\"\n            };\n            item[\"ShipmentTrackingId\"] = new AttributeValue\n            {\n                S = \"756943\"\n            };\n            putItemRequest = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n                ReturnItemCollectionMetrics = \"SIZE\"\n            };\n            client.PutItem(putItemRequest);\n\n            item = new Dictionary<string, AttributeValue>();\n            item[\"CustomerId\"] = new AttributeValue\n            {\n                S = \"bob@example.com\"\n            };\n            item[\"OrderId\"] = new AttributeValue\n            {\n                N = \"3\"\n            };\n            /* no IsOpen attribute */\n            item[\"OrderCreationDate\"] = new AttributeValue\n            {\n                N = \"20130221\"\n            };\n            item[\"ProductCategory\"] = new AttributeValue\n            {\n                S = \"Music\"\n            };\n            item[\"ProductName\"] = new AttributeValue\n            {\n                S = \"Symphony 9\"\n            };\n            item[\"OrderStatus\"] = new AttributeValue\n            {\n                S = \"DELIVERED\"\n            };\n            item[\"ShipmentTrackingId\"] = new AttributeValue\n            {\n                S = \"645193\"\n            };\n            putItemRequest = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n                ReturnItemCollectionMetrics = \"SIZE\"\n            };\n            client.PutItem(putItemRequest);\n\n            item = new Dictionary<string, AttributeValue>();\n            item[\"CustomerId\"] = new AttributeValue\n            {\n                S = \"bob@example.com\"\n            };\n            item[\"OrderId\"] = new AttributeValue\n            {\n                N = \"4\"\n            };\n            item[\"IsOpen\"] = new AttributeValue\n            {\n                N = \"1\"\n            };\n            item[\"OrderCreationDate\"] = new AttributeValue\n            {\n                N = \"20130222\"\n            };\n            item[\"ProductCategory\"] = new AttributeValue\n            {\n                S = \"Hardware\"\n            };\n            item[\"ProductName\"] = new AttributeValue\n            {\n                S = \"Extra Heavy Hammer\"\n            };\n            item[\"OrderStatus\"] = new AttributeValue\n            {\n                S = \"PACKING ITEMS\"\n            };\n            /* no ShipmentTrackingId attribute */\n            putItemRequest = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n                ReturnItemCollectionMetrics = \"SIZE\"\n            };\n            client.PutItem(putItemRequest);\n\n            item = new Dictionary<string, AttributeValue>();\n            item[\"CustomerId\"] = new AttributeValue\n            {\n                S = \"bob@example.com\"\n            };\n            item[\"OrderId\"] = new AttributeValue\n            {\n                N = \"5\"\n            };\n            /* no IsOpen attribute */\n            item[\"OrderCreationDate\"] = new AttributeValue\n            {\n                N = \"20130309\"\n            };\n            item[\"ProductCategory\"] = new AttributeValue\n            {\n                S = \"Book\"\n            };\n            item[\"ProductName\"] = new AttributeValue\n            {\n                S = \"How To Cook\"\n            };\n            item[\"OrderStatus\"] = new AttributeValue\n            {\n                S = \"IN TRANSIT\"\n            };\n            item[\"ShipmentTrackingId\"] = new AttributeValue\n            {\n                S = \"440185\"\n            };\n            putItemRequest = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n                ReturnItemCollectionMetrics = \"SIZE\"\n            };\n            client.PutItem(putItemRequest);\n\n            item = new Dictionary<string, AttributeValue>();\n            item[\"CustomerId\"] = new AttributeValue\n            {\n                S = \"bob@example.com\"\n            };\n            item[\"OrderId\"] = new AttributeValue\n            {\n                N = \"6\"\n            };\n            /* no IsOpen attribute */\n            item[\"OrderCreationDate\"] = new AttributeValue\n            {\n                N = \"20130318\"\n            };\n            item[\"ProductCategory\"] = new AttributeValue\n            {\n                S = \"Luggage\"\n            };\n            item[\"ProductName\"] = new AttributeValue\n            {\n                S = \"Really Big Suitcase\"\n            };\n            item[\"OrderStatus\"] = new AttributeValue\n            {\n                S = \"DELIVERED\"\n            };\n            item[\"ShipmentTrackingId\"] = new AttributeValue\n            {\n                S = \"893927\"\n            };\n            putItemRequest = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n                ReturnItemCollectionMetrics = \"SIZE\"\n            };\n            client.PutItem(putItemRequest);\n\n            item = new Dictionary<string, AttributeValue>();\n            item[\"CustomerId\"] = new AttributeValue\n            {\n                S = \"bob@example.com\"\n            };\n            item[\"OrderId\"] = new AttributeValue\n            {\n                N = \"7\"\n            };\n            /* no IsOpen attribute */\n            item[\"OrderCreationDate\"] = new AttributeValue\n            {\n                N = \"20130324\"\n            };\n            item[\"ProductCategory\"] = new AttributeValue\n            {\n                S = \"Golf\"\n            };\n            item[\"ProductName\"] = new AttributeValue\n            {\n                S = \"PGA Pro II\"\n            };\n            item[\"OrderStatus\"] = new AttributeValue\n            {\n                S = \"OUT FOR DELIVERY\"\n            };\n            item[\"ShipmentTrackingId\"] = new AttributeValue\n            {\n                S = \"383283\"\n            };\n            putItemRequest = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n                ReturnItemCollectionMetrics = \"SIZE\"\n            };\n            client.PutItem(putItemRequest);\n        }\n\n        private static void WaitUntilTableReady(string tableName)\n        {\n            string status = null;\n            // Let us wait until table is created. Call DescribeTable.\n            do\n            {\n                System.Threading.Thread.Sleep(5000); // Wait 5 seconds.\n                try\n                {\n                    var res = client.DescribeTable(new DescribeTableRequest\n                    {\n                        TableName = tableName\n                    });\n\n                    Console.WriteLine(\"Table name: {0}, status: {1}\",\n                              res.Table.TableName,\n                              res.Table.TableStatus);\n                    status = res.Table.TableStatus;\n                }\n                catch (ResourceNotFoundException)\n                {\n                    // DescribeTable is eventually consistent. So you might\n                    // get resource not found. So we handle the potential exception.\n                }\n            } while (status != \"ACTIVE\");\n        }\n\n        private static void WaitForTableToBeDeleted(string tableName)\n        {\n            bool tablePresent = true;\n\n            while (tablePresent)\n            {\n                System.Threading.Thread.Sleep(5000); // Wait 5 seconds.\n                try\n                {\n                    var res = client.DescribeTable(new DescribeTableRequest\n                    {\n                        TableName = tableName\n                    });\n\n                    Console.WriteLine(\"Table name: {0}, status: {1}\",\n                              res.Table.TableName,\n                              res.Table.TableStatus);\n                }\n                catch (ResourceNotFoundException)\n                {\n                    tablePresent = false;\n                }\n            }\n        }\n    }\n}\n"
  },
  {
    "title": "Working with Local Secondary Indexes: .NET - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LSILowLevelDotNet.html",
    "html": "Working with Local Secondary Indexes: .NET\nPDF\nRSS\nTopics\nCreate a table with a Local Secondary Index\nDescribe a table with a Local Secondary Index\nQuery a Local Secondary Index\nExample: Local Secondary Indexes using the AWS SDK for .NET low-level API\n\nYou can use the AWS SDK for .NET low-level API to create an Amazon DynamoDB table with one or more local secondary indexes, describe the indexes on the table, and perform queries using the indexes. These operations map to the corresponding low-level DynamoDB API actions. For more information, see .NET code examples.\n\nThe following are the common steps for table operations using the .NET low-level API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nProvide the required and optional parameters for the operation by creating the corresponding request objects.\n\nFor example, create a CreateTableRequest object to create a table and an QueryRequest object to query a table or an index.\n\nRun the appropriate method provided by the client that you created in the preceding step.\n\nCreate a table with a Local Secondary Index\n\nLocal secondary indexes must be created at the same time that you create a table. To do this, use CreateTable and provide your specifications for one or more local secondary indexes. The following C# code example creates a table to hold information about songs in a music collection. The partition key is Artist and the sort key is SongTitle. A secondary index, AlbumTitleIndex, facilitates queries by album title.\n\nThe following are the steps to create a table with a local secondary index, using the .NET low-level API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nCreate an instance of the CreateTableRequest class to provide the request information.\n\nYou must provide the table name, its primary key, and the provisioned throughput values. For the local secondary index, you must provide the index name, the name and data type of the index sort key, the key schema for the index, and the attribute projection.\n\nRun the CreateTable method by providing the request object as a parameter.\n\nThe following C# code example demonstrates the preceding steps. The code creates a table (Music) with a secondary index on the AlbumTitle attribute. The table partition key and sort key, plus the index sort key, are the only attributes projected into the index.\n\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"Music\";\n\nCreateTableRequest createTableRequest = new CreateTableRequest()\n{\n    TableName = tableName\n};\n\n//ProvisionedThroughput\ncreateTableRequest.ProvisionedThroughput = new ProvisionedThroughput()\n{\n    ReadCapacityUnits = (long)5,\n    WriteCapacityUnits = (long)5\n};\n\n//AttributeDefinitions\nList<AttributeDefinition> attributeDefinitions = new List<AttributeDefinition>();\n\nattributeDefinitions.Add(new AttributeDefinition()\n{\n    AttributeName = \"Artist\",\n    AttributeType = \"S\"\n});\n\nattributeDefinitions.Add(new AttributeDefinition()\n {\n     AttributeName = \"SongTitle\",\n     AttributeType = \"S\"\n });\n\nattributeDefinitions.Add(new AttributeDefinition()\n {\n     AttributeName = \"AlbumTitle\",\n     AttributeType = \"S\"\n });\n\ncreateTableRequest.AttributeDefinitions = attributeDefinitions;\n\n//KeySchema\nList<KeySchemaElement> tableKeySchema = new List<KeySchemaElement>();\n\ntableKeySchema.Add(new KeySchemaElement() { AttributeName = \"Artist\", KeyType = \"HASH\" });  //Partition key\ntableKeySchema.Add(new KeySchemaElement() { AttributeName = \"SongTitle\", KeyType = \"RANGE\" });  //Sort key\n\ncreateTableRequest.KeySchema = tableKeySchema;\n\nList<KeySchemaElement> indexKeySchema = new List<KeySchemaElement>();\nindexKeySchema.Add(new KeySchemaElement() { AttributeName = \"Artist\", KeyType = \"HASH\" });  //Partition key\nindexKeySchema.Add(new KeySchemaElement() { AttributeName = \"AlbumTitle\", KeyType = \"RANGE\" });  //Sort key\n\nProjection projection = new Projection() { ProjectionType = \"INCLUDE\" };\n\nList<string> nonKeyAttributes = new List<string>();\nnonKeyAttributes.Add(\"Genre\");\nnonKeyAttributes.Add(\"Year\");\nprojection.NonKeyAttributes = nonKeyAttributes;\n\nLocalSecondaryIndex localSecondaryIndex = new LocalSecondaryIndex()\n{\n    IndexName = \"AlbumTitleIndex\",\n    KeySchema = indexKeySchema,\n    Projection = projection\n};\n\nList<LocalSecondaryIndex> localSecondaryIndexes = new List<LocalSecondaryIndex>();\nlocalSecondaryIndexes.Add(localSecondaryIndex);\ncreateTableRequest.LocalSecondaryIndexes = localSecondaryIndexes;\n\nCreateTableResponse result = client.CreateTable(createTableRequest);\nConsole.WriteLine(result.CreateTableResult.TableDescription.TableName);\nConsole.WriteLine(result.CreateTableResult.TableDescription.TableStatus);\n\nYou must wait until DynamoDB creates the table and sets the table status to ACTIVE. After that, you can begin putting data items into the table.\n\nDescribe a table with a Local Secondary Index\n\nTo get information about local secondary indexes on a table, use the DescribeTable API. For each index, you can access its name, key schema, and projected attributes.\n\nThe following are the steps to access local secondary index information a table using the .NET low-level API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nCreate an instance of the DescribeTableRequest class to provide the request information. You must provide the table name.\n\nRun the describeTable method by providing the request object as a parameter.\n\nThe following C# code example demonstrates the preceding steps.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"Music\";\n\nDescribeTableResponse response = client.DescribeTable(new DescribeTableRequest() { TableName = tableName });\nList<LocalSecondaryIndexDescription> localSecondaryIndexes =\n    response.DescribeTableResult.Table.LocalSecondaryIndexes;\n\n// This code snippet will work for multiple indexes, even though\n// there is only one index in this example.\nforeach (LocalSecondaryIndexDescription lsiDescription in localSecondaryIndexes)\n{\n    Console.WriteLine(\"Info for index \" + lsiDescription.IndexName + \":\");\n\n    foreach (KeySchemaElement kse in lsiDescription.KeySchema)\n    {\n        Console.WriteLine(\"\\t\" + kse.AttributeName + \": key type is \" + kse.KeyType);\n    }\n\n    Projection projection = lsiDescription.Projection;\n\n    Console.WriteLine(\"\\tThe projection type is: \" + projection.ProjectionType);\n\n    if (projection.ProjectionType.ToString().Equals(\"INCLUDE\"))\n    {\n        Console.WriteLine(\"\\t\\tThe non-key projected attributes are:\");\n\n        foreach (String s in projection.NonKeyAttributes)\n        {\n            Console.WriteLine(\"\\t\\t\" + s);\n        }\n\n    }\n}\nQuery a Local Secondary Index\n\nYou can use Query on a local secondary index in much the same way you Query a table. You must specify the index name, the query criteria for the index sort key, and the attributes that you want to return. In this example, the index is AlbumTitleIndex, and the index sort key is AlbumTitle.\n\nThe only attributes returned are those that have been projected into the index. You could modify this query to select non-key attributes too, but this would require table fetch activity that is relatively expensive. For more information about table fetches, see Attribute projections\n\nThe following are the steps to query a local secondary index using the .NET low-level API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nCreate an instance of the QueryRequest class to provide the request information.\n\nRun the query method by providing the request object as a parameter.\n\nThe following C# code example demonstrates the preceding steps.\n\nExample\n\nQueryRequest queryRequest = new QueryRequest\n{\n    TableName = \"Music\",\n    IndexName = \"AlbumTitleIndex\",\n    Select = \"ALL_ATTRIBUTES\",\n    ScanIndexForward = true,\n    KeyConditionExpression = \"Artist = :v_artist and AlbumTitle = :v_title\",\n    ExpressionAttributeValues = new Dictionary<string, AttributeValue>()\n    {\n        {\":v_artist\",new AttributeValue {S = \"Acme Band\"}},\n        {\":v_title\",new AttributeValue {S = \"Songs About Life\"}}\n    },\n};\n\nQueryResponse response = client.Query(queryRequest);\n\nforeach (var attribs in response.Items)\n{\n    foreach (var attrib in attribs)\n    {\n        Console.WriteLine(attrib.Key + \" ---> \" + attrib.Value.S);\n    }\n    Console.WriteLine();\n}\n"
  },
  {
    "title": "Example: Local Secondary Indexes using the Java document API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LSIJavaDocumentAPI.Example.html",
    "html": "Example: Local Secondary Indexes using the Java document API\nPDF\nRSS\n\nThe following Java code example shows how to work with local secondary indexes in Amazon DynamoDB. The example creates a table named CustomerOrders with a partition key of CustomerId and a sort key of OrderId. There are two local secondary indexes on this table:\n\nOrderCreationDateIndex — The sort key is OrderCreationDate, and the following attributes are projected into the index:\n\nProductCategory\n\nProductName\n\nOrderStatus\n\nShipmentTrackingId\n\nIsOpenIndex — The sort key is IsOpen, and all of the table attributes are projected into the index.\n\nAfter the CustomerOrders table is created, the program loads the table with data representing customer orders. It then queries the data using the local secondary indexes. Finally, the program deletes the CustomerOrders table.\n\nFor step-by-step instructions for testing the following sample, see Java code examples.\n\nExample\n\npackage com.amazonaws.codesamples.document;\n\nimport java.util.ArrayList;\nimport java.util.Iterator;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.document.DynamoDB;\nimport com.amazonaws.services.dynamodbv2.document.Index;\nimport com.amazonaws.services.dynamodbv2.document.Item;\nimport com.amazonaws.services.dynamodbv2.document.ItemCollection;\nimport com.amazonaws.services.dynamodbv2.document.PutItemOutcome;\nimport com.amazonaws.services.dynamodbv2.document.QueryOutcome;\nimport com.amazonaws.services.dynamodbv2.document.Table;\nimport com.amazonaws.services.dynamodbv2.document.spec.QuerySpec;\nimport com.amazonaws.services.dynamodbv2.document.utils.ValueMap;\nimport com.amazonaws.services.dynamodbv2.model.AttributeDefinition;\nimport com.amazonaws.services.dynamodbv2.model.CreateTableRequest;\nimport com.amazonaws.services.dynamodbv2.model.KeySchemaElement;\nimport com.amazonaws.services.dynamodbv2.model.KeyType;\nimport com.amazonaws.services.dynamodbv2.model.LocalSecondaryIndex;\nimport com.amazonaws.services.dynamodbv2.model.Projection;\nimport com.amazonaws.services.dynamodbv2.model.ProjectionType;\nimport com.amazonaws.services.dynamodbv2.model.ProvisionedThroughput;\nimport com.amazonaws.services.dynamodbv2.model.ReturnConsumedCapacity;\nimport com.amazonaws.services.dynamodbv2.model.Select;\n\npublic class DocumentAPILocalSecondaryIndexExample {\n\n        static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n        static DynamoDB dynamoDB = new DynamoDB(client);\n\n        public static String tableName = \"CustomerOrders\";\n\n        public static void main(String[] args) throws Exception {\n\n                createTable();\n                loadData();\n\n                query(null);\n                query(\"IsOpenIndex\");\n                query(\"OrderCreationDateIndex\");\n\n                deleteTable(tableName);\n\n        }\n\n        public static void createTable() {\n\n                CreateTableRequest createTableRequest = new CreateTableRequest().withTableName(tableName)\n                                .withProvisionedThroughput(\n                                                new ProvisionedThroughput().withReadCapacityUnits((long) 1)\n                                                                .withWriteCapacityUnits((long) 1));\n\n                // Attribute definitions for table partition and sort keys\n                ArrayList<AttributeDefinition> attributeDefinitions = new ArrayList<AttributeDefinition>();\n                attributeDefinitions\n                                .add(new AttributeDefinition().withAttributeName(\"CustomerId\").withAttributeType(\"S\"));\n                attributeDefinitions.add(new AttributeDefinition().withAttributeName(\"OrderId\").withAttributeType(\"N\"));\n\n                // Attribute definition for index primary key attributes\n                attributeDefinitions\n                                .add(new AttributeDefinition().withAttributeName(\"OrderCreationDate\")\n                                                .withAttributeType(\"N\"));\n                attributeDefinitions.add(new AttributeDefinition().withAttributeName(\"IsOpen\").withAttributeType(\"N\"));\n\n                createTableRequest.setAttributeDefinitions(attributeDefinitions);\n\n                // Key schema for table\n                ArrayList<KeySchemaElement> tableKeySchema = new ArrayList<KeySchemaElement>();\n                tableKeySchema.add(new KeySchemaElement().withAttributeName(\"CustomerId\").withKeyType(KeyType.HASH)); // Partition\n                                                                                                                      // key\n                tableKeySchema.add(new KeySchemaElement().withAttributeName(\"OrderId\").withKeyType(KeyType.RANGE)); // Sort\n                                                                                                                    // key\n\n                createTableRequest.setKeySchema(tableKeySchema);\n\n                ArrayList<LocalSecondaryIndex> localSecondaryIndexes = new ArrayList<LocalSecondaryIndex>();\n\n                // OrderCreationDateIndex\n                LocalSecondaryIndex orderCreationDateIndex = new LocalSecondaryIndex()\n                                .withIndexName(\"OrderCreationDateIndex\");\n\n                // Key schema for OrderCreationDateIndex\n                ArrayList<KeySchemaElement> indexKeySchema = new ArrayList<KeySchemaElement>();\n                indexKeySchema.add(new KeySchemaElement().withAttributeName(\"CustomerId\").withKeyType(KeyType.HASH)); // Partition\n                                                                                                                      // key\n                indexKeySchema.add(new KeySchemaElement().withAttributeName(\"OrderCreationDate\")\n                                .withKeyType(KeyType.RANGE)); // Sort\n                                                              // key\n\n                orderCreationDateIndex.setKeySchema(indexKeySchema);\n\n                // Projection (with list of projected attributes) for\n                // OrderCreationDateIndex\n                Projection projection = new Projection().withProjectionType(ProjectionType.INCLUDE);\n                ArrayList<String> nonKeyAttributes = new ArrayList<String>();\n                nonKeyAttributes.add(\"ProductCategory\");\n                nonKeyAttributes.add(\"ProductName\");\n                projection.setNonKeyAttributes(nonKeyAttributes);\n\n                orderCreationDateIndex.setProjection(projection);\n\n                localSecondaryIndexes.add(orderCreationDateIndex);\n\n                // IsOpenIndex\n                LocalSecondaryIndex isOpenIndex = new LocalSecondaryIndex().withIndexName(\"IsOpenIndex\");\n\n                // Key schema for IsOpenIndex\n                indexKeySchema = new ArrayList<KeySchemaElement>();\n                indexKeySchema.add(new KeySchemaElement().withAttributeName(\"CustomerId\").withKeyType(KeyType.HASH)); // Partition\n                                                                                                                      // key\n                indexKeySchema.add(new KeySchemaElement().withAttributeName(\"IsOpen\").withKeyType(KeyType.RANGE)); // Sort\n                                                                                                                   // key\n\n                // Projection (all attributes) for IsOpenIndex\n                projection = new Projection().withProjectionType(ProjectionType.ALL);\n\n                isOpenIndex.setKeySchema(indexKeySchema);\n                isOpenIndex.setProjection(projection);\n\n                localSecondaryIndexes.add(isOpenIndex);\n\n                // Add index definitions to CreateTable request\n                createTableRequest.setLocalSecondaryIndexes(localSecondaryIndexes);\n\n                System.out.println(\"Creating table \" + tableName + \"...\");\n                System.out.println(dynamoDB.createTable(createTableRequest));\n\n                // Wait for table to become active\n                System.out.println(\"Waiting for \" + tableName + \" to become ACTIVE...\");\n                try {\n                        Table table = dynamoDB.getTable(tableName);\n                        table.waitForActive();\n                } catch (InterruptedException e) {\n                        e.printStackTrace();\n                }\n        }\n\n        public static void query(String indexName) {\n\n                Table table = dynamoDB.getTable(tableName);\n\n                System.out.println(\"\\n***********************************************************\\n\");\n                System.out.println(\"Querying table \" + tableName + \"...\");\n\n                QuerySpec querySpec = new QuerySpec().withConsistentRead(true).withScanIndexForward(true)\n                                .withReturnConsumedCapacity(ReturnConsumedCapacity.TOTAL);\n\n                if (indexName == \"IsOpenIndex\") {\n\n                        System.out.println(\"\\nUsing index: '\" + indexName + \"': Bob's orders that are open.\");\n                        System.out.println(\"Only a user-specified list of attributes are returned\\n\");\n                        Index index = table.getIndex(indexName);\n\n                        querySpec.withKeyConditionExpression(\"CustomerId = :v_custid and IsOpen = :v_isopen\")\n                                        .withValueMap(new ValueMap().withString(\":v_custid\", \"bob@example.com\")\n                                                        .withNumber(\":v_isopen\", 1));\n\n                        querySpec.withProjectionExpression(\n                                        \"OrderCreationDate, ProductCategory, ProductName, OrderStatus\");\n\n                        ItemCollection<QueryOutcome> items = index.query(querySpec);\n                        Iterator<Item> iterator = items.iterator();\n\n                        System.out.println(\"Query: printing results...\");\n\n                        while (iterator.hasNext()) {\n                                System.out.println(iterator.next().toJSONPretty());\n                        }\n\n                } else if (indexName == \"OrderCreationDateIndex\") {\n                        System.out.println(\"\\nUsing index: '\" + indexName\n                                        + \"': Bob's orders that were placed after 01/31/2015.\");\n                        System.out.println(\"Only the projected attributes are returned\\n\");\n                        Index index = table.getIndex(indexName);\n\n                        querySpec.withKeyConditionExpression(\n                                        \"CustomerId = :v_custid and OrderCreationDate >= :v_orddate\")\n                                        .withValueMap(\n                                                        new ValueMap().withString(\":v_custid\", \"bob@example.com\")\n                                                                        .withNumber(\":v_orddate\",\n                                                                                        20150131));\n\n                        querySpec.withSelect(Select.ALL_PROJECTED_ATTRIBUTES);\n\n                        ItemCollection<QueryOutcome> items = index.query(querySpec);\n                        Iterator<Item> iterator = items.iterator();\n\n                        System.out.println(\"Query: printing results...\");\n\n                        while (iterator.hasNext()) {\n                                System.out.println(iterator.next().toJSONPretty());\n                        }\n\n                } else {\n                        System.out.println(\"\\nNo index: All of Bob's orders, by OrderId:\\n\");\n\n                        querySpec.withKeyConditionExpression(\"CustomerId = :v_custid\")\n                                        .withValueMap(new ValueMap().withString(\":v_custid\", \"bob@example.com\"));\n\n                        ItemCollection<QueryOutcome> items = table.query(querySpec);\n                        Iterator<Item> iterator = items.iterator();\n\n                        System.out.println(\"Query: printing results...\");\n\n                        while (iterator.hasNext()) {\n                                System.out.println(iterator.next().toJSONPretty());\n                        }\n\n                }\n\n        }\n\n        public static void deleteTable(String tableName) {\n\n                Table table = dynamoDB.getTable(tableName);\n                System.out.println(\"Deleting table \" + tableName + \"...\");\n                table.delete();\n\n                // Wait for table to be deleted\n                System.out.println(\"Waiting for \" + tableName + \" to be deleted...\");\n                try {\n                        table.waitForDelete();\n                } catch (InterruptedException e) {\n                        e.printStackTrace();\n                }\n        }\n\n        public static void loadData() {\n\n                Table table = dynamoDB.getTable(tableName);\n\n                System.out.println(\"Loading data into table \" + tableName + \"...\");\n\n                Item item = new Item().withPrimaryKey(\"CustomerId\", \"alice@example.com\").withNumber(\"OrderId\", 1)\n                                .withNumber(\"IsOpen\", 1).withNumber(\"OrderCreationDate\", 20150101)\n                                .withString(\"ProductCategory\", \"Book\")\n                                .withString(\"ProductName\", \"The Great Outdoors\")\n                                .withString(\"OrderStatus\", \"PACKING ITEMS\");\n                // no ShipmentTrackingId attribute\n\n                PutItemOutcome putItemOutcome = table.putItem(item);\n\n                item = new Item().withPrimaryKey(\"CustomerId\", \"alice@example.com\").withNumber(\"OrderId\", 2)\n                                .withNumber(\"IsOpen\", 1).withNumber(\"OrderCreationDate\", 20150221)\n                                .withString(\"ProductCategory\", \"Bike\")\n                                .withString(\"ProductName\", \"Super Mountain\")\n                                .withString(\"OrderStatus\", \"ORDER RECEIVED\");\n                // no ShipmentTrackingId attribute\n\n                putItemOutcome = table.putItem(item);\n\n                item = new Item().withPrimaryKey(\"CustomerId\", \"alice@example.com\").withNumber(\"OrderId\", 3)\n                                // no IsOpen attribute\n                                .withNumber(\"OrderCreationDate\", 20150304).withString(\"ProductCategory\", \"Music\")\n                                .withString(\"ProductName\", \"A Quiet Interlude\").withString(\"OrderStatus\", \"IN TRANSIT\")\n                                .withString(\"ShipmentTrackingId\", \"176493\");\n\n                putItemOutcome = table.putItem(item);\n\n                item = new Item().withPrimaryKey(\"CustomerId\", \"bob@example.com\").withNumber(\"OrderId\", 1)\n                                // no IsOpen attribute\n                                .withNumber(\"OrderCreationDate\", 20150111).withString(\"ProductCategory\", \"Movie\")\n                                .withString(\"ProductName\", \"Calm Before The Storm\")\n                                .withString(\"OrderStatus\", \"SHIPPING DELAY\")\n                                .withString(\"ShipmentTrackingId\", \"859323\");\n\n                putItemOutcome = table.putItem(item);\n\n                item = new Item().withPrimaryKey(\"CustomerId\", \"bob@example.com\").withNumber(\"OrderId\", 2)\n                                // no IsOpen attribute\n                                .withNumber(\"OrderCreationDate\", 20150124).withString(\"ProductCategory\", \"Music\")\n                                .withString(\"ProductName\", \"E-Z Listening\").withString(\"OrderStatus\", \"DELIVERED\")\n                                .withString(\"ShipmentTrackingId\", \"756943\");\n\n                putItemOutcome = table.putItem(item);\n\n                item = new Item().withPrimaryKey(\"CustomerId\", \"bob@example.com\").withNumber(\"OrderId\", 3)\n                                // no IsOpen attribute\n                                .withNumber(\"OrderCreationDate\", 20150221).withString(\"ProductCategory\", \"Music\")\n                                .withString(\"ProductName\", \"Symphony 9\").withString(\"OrderStatus\", \"DELIVERED\")\n                                .withString(\"ShipmentTrackingId\", \"645193\");\n\n                putItemOutcome = table.putItem(item);\n\n                item = new Item().withPrimaryKey(\"CustomerId\", \"bob@example.com\").withNumber(\"OrderId\", 4)\n                                .withNumber(\"IsOpen\", 1).withNumber(\"OrderCreationDate\", 20150222)\n                                .withString(\"ProductCategory\", \"Hardware\")\n                                .withString(\"ProductName\", \"Extra Heavy Hammer\")\n                                .withString(\"OrderStatus\", \"PACKING ITEMS\");\n                // no ShipmentTrackingId attribute\n\n                putItemOutcome = table.putItem(item);\n\n                item = new Item().withPrimaryKey(\"CustomerId\", \"bob@example.com\").withNumber(\"OrderId\", 5)\n                                /* no IsOpen attribute */\n                                .withNumber(\"OrderCreationDate\", 20150309).withString(\"ProductCategory\", \"Book\")\n                                .withString(\"ProductName\", \"How To Cook\").withString(\"OrderStatus\", \"IN TRANSIT\")\n                                .withString(\"ShipmentTrackingId\", \"440185\");\n\n                putItemOutcome = table.putItem(item);\n\n                item = new Item().withPrimaryKey(\"CustomerId\", \"bob@example.com\").withNumber(\"OrderId\", 6)\n                                // no IsOpen attribute\n                                .withNumber(\"OrderCreationDate\", 20150318).withString(\"ProductCategory\", \"Luggage\")\n                                .withString(\"ProductName\", \"Really Big Suitcase\").withString(\"OrderStatus\", \"DELIVERED\")\n                                .withString(\"ShipmentTrackingId\", \"893927\");\n\n                putItemOutcome = table.putItem(item);\n\n                item = new Item().withPrimaryKey(\"CustomerId\", \"bob@example.com\").withNumber(\"OrderId\", 7)\n                                /* no IsOpen attribute */\n                                .withNumber(\"OrderCreationDate\", 20150324).withString(\"ProductCategory\", \"Golf\")\n                                .withString(\"ProductName\", \"PGA Pro II\").withString(\"OrderStatus\", \"OUT FOR DELIVERY\")\n                                .withString(\"ShipmentTrackingId\", \"383283\");\n\n                putItemOutcome = table.putItem(item);\n                assert putItemOutcome != null;\n        }\n\n}\n\n"
  },
  {
    "title": "Local Secondary Indexes - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LSI.html",
    "html": "Local Secondary Indexes\nPDF\nRSS\n\nSome applications only need to query data using the base table's primary key. However, there might be situations where an alternative sort key would be helpful. To give your application a choice of sort keys, you can create one or more local secondary indexes on an Amazon DynamoDB table and issue Query or Scan requests against these indexes.\n\nTopics\nScenario: Using a Local Secondary Index\nAttribute projections\nCreating a Local Secondary Index\nReading data from a Local Secondary Index\nItem writes and Local Secondary Indexes\nProvisioned throughput considerations for Local Secondary Indexes\nStorage considerations for Local Secondary Indexes\nItem collections in Local Secondary Indexes\nWorking with Local Secondary Indexes: Java\nWorking with Local Secondary Indexes: .NET\nWorking with Local Secondary Indexes: AWS CLI\nScenario: Using a Local Secondary Index\n\nAs an example, consider the Thread table that is defined in Creating tables and loading data for code examples in DynamoDB. This table is useful for an application such as the AWS discussion forums. The following diagram shows how the items in the table would be organized. (Not all of the attributes are shown.)\n\nDynamoDB stores all of the items with the same partition key value continuously. In this example, given a particular ForumName, a Query operation could immediately locate all of the threads for that forum. Within a group of items with the same partition key value, the items are sorted by sort key value. If the sort key (Subject) is also provided in the query, DynamoDB can narrow down the results that are returned—for example, returning all of the threads in the \"S3\" forum that have a Subject beginning with the letter \"a\".\n\nSome requests might require more complex data access patterns. For example:\n\nWhich forum threads get the most views and replies?\n\nWhich thread in a particular forum has the largest number of messages?\n\nHow many threads were posted in a particular forum within a particular time period?\n\nTo answer these questions, the Query action would not be sufficient. Instead, you would have to Scan the entire table. For a table with millions of items, this would consume a large amount of provisioned read throughput and take a long time to complete.\n\nHowever, you can specify one or more local secondary indexes on non-key attributes, such as Replies or LastPostDateTime.\n\nA local secondary index maintains an alternate sort key for a given partition key value. A local secondary index also contains a copy of some or all of the attributes from its base table. You specify which attributes are projected into the local secondary index when you create the table. The data in a local secondary index is organized by the same partition key as the base table, but with a different sort key. This lets you access data items efficiently across this different dimension. For greater query or scan flexibility, you can create up to five local secondary indexes per table.\n\nSuppose that an application needs to find all of the threads that have been posted within the last three months in a particular forum. Without a local secondary index, the application would have to Scan the entire Thread table and discard any posts that were not within the specified time frame. With a local secondary index, a Query operation could use LastPostDateTime as a sort key and find the data quickly.\n\nThe following diagram shows a local secondary index named LastPostIndex. Note that the partition key is the same as that of the Thread table, but the sort key is LastPostDateTime.\n\nEvery local secondary index must meet the following conditions:\n\nThe partition key is the same as that of its base table.\n\nThe sort key consists of exactly one scalar attribute.\n\nThe sort key of the base table is projected into the index, where it acts as a non-key attribute.\n\nIn this example, the partition key is ForumName and the sort key of the local secondary index is LastPostDateTime. In addition, the sort key value from the base table (in this example, Subject) is projected into the index, but it is not a part of the index key. If an application needs a list that is based on ForumName and LastPostDateTime, it can issue a Query request against LastPostIndex. The query results are sorted by LastPostDateTime, and can be returned in ascending or descending order. The query can also apply key conditions, such as returning only items that have a LastPostDateTime within a particular time span.\n\nEvery local secondary index automatically contains the partition and sort keys from its base table; you can optionally project non-key attributes into the index. When you query the index, DynamoDB can retrieve these projected attributes efficiently. When you query a local secondary index, the query can also retrieve attributes that are not projected into the index. DynamoDB automatically fetches these attributes from the base table, but at a greater latency and with higher provisioned throughput costs.\n\nFor any local secondary index, you can store up to 10 GB of data per distinct partition key value. This figure includes all of the items in the base table, plus all of the items in the indexes, that have the same partition key value. For more information, see Item collections in Local Secondary Indexes.\n\nAttribute projections\n\nWith LastPostIndex, an application could use ForumName and LastPostDateTime as query criteria. However, to retrieve any additional attributes, DynamoDB must perform additional read operations against the Thread table. These extra reads are known as fetches, and they can increase the total amount of provisioned throughput required for a query.\n\nSuppose that you wanted to populate a webpage with a list of all the threads in \"S3\" and the number of replies for each thread, sorted by the last reply date/time beginning with the most recent reply. To populate this list, you would need the following attributes:\n\nSubject\n\nReplies\n\nLastPostDateTime\n\nThe most efficient way to query this data and to avoid fetch operations would be to project the Replies attribute from the table into the local secondary index, as shown in this diagram.\n\nA projection is the set of attributes that is copied from a table into a secondary index. The partition key and sort key of the table are always projected into the index; you can project other attributes to support your application's query requirements. When you query an index, Amazon DynamoDB can access any attribute in the projection as if those attributes were in a table of their own.\n\nWhen you create a secondary index, you need to specify the attributes that will be projected into the index. DynamoDB provides three different options for this:\n\nKEYS_ONLY – Each item in the index consists only of the table partition key and sort key values, plus the index key values. The KEYS_ONLY option results in the smallest possible secondary index.\n\nINCLUDE – In addition to the attributes described in KEYS_ONLY, the secondary index will include other non-key attributes that you specify.\n\nALL – The secondary index includes all of the attributes from the source table. Because all of the table data is duplicated in the index, an ALL projection results in the largest possible secondary index.\n\nIn the previous diagram, the non-key attribute Replies is projected into LastPostIndex. An application can query LastPostIndex instead of the full Thread table to populate a webpage with Subject, Replies, and LastPostDateTime. If any other non-key attributes are requested, DynamoDB would need to fetch those attributes from the Thread table.\n\nFrom an application's point of view, fetching additional attributes from the base table is automatic and transparent, so there is no need to rewrite any application logic. However, such fetching can greatly reduce the performance advantage of using a local secondary index.\n\nWhen you choose the attributes to project into a local secondary index, you must consider the tradeoff between provisioned throughput costs and storage costs:\n\nIf you need to access just a few attributes with the lowest possible latency, consider projecting only those attributes into a local secondary index. The smaller the index, the less that it costs to store it, and the less your write costs are. If there are attributes that you occasionally need to fetch, the cost for provisioned throughput may well outweigh the longer-term cost of storing those attributes.\n\nIf your application frequently accesses some non-key attributes, you should consider projecting those attributes into a local secondary index. The additional storage costs for the local secondary index offset the cost of performing frequent table scans.\n\nIf you need to access most of the non-key attributes on a frequent basis, you can project these attributes—or even the entire base table— into a local secondary index. This gives you maximum flexibility and lowest provisioned throughput consumption, because no fetching would be required. However, your storage cost would increase, or even double if you are projecting all attributes.\n\nIf your application needs to query a table infrequently, but must perform many writes or updates against the data in the table, consider projecting KEYS_ONLY. The local secondary index would be of minimal size, but would still be available when needed for query activity.\n\nCreating a Local Secondary Index\n\nTo create one or more local secondary indexes on a table, use the LocalSecondaryIndexes parameter of the CreateTable operation. Local secondary indexes on a table are created when the table is created. When you delete a table, any local secondary indexes on that table are also deleted.\n\nYou must specify one non-key attribute to act as the sort key of the local secondary index. The attribute that you choose must be a scalar String, Number, or Binary. Other scalar types, document types, and set types are not allowed. For a complete list of data types, see Data types.\n\nImportant\n\nFor tables with local secondary indexes, there is a 10 GB size limit per partition key value. A table with local secondary indexes can store any number of items, as long as the total size for any one partition key value does not exceed 10 GB. For more information, see Item collection size limit.\n\nYou can project attributes of any data type into a local secondary index. This includes scalars, documents, and sets. For a complete list of data types, see Data types.\n\nReading data from a Local Secondary Index\n\nYou can retrieve items from a local secondary index using the Query and Scan operations. The GetItem and BatchGetItem operations can't be used on a local secondary index.\n\nQuerying a Local Secondary Index\n\nIn a DynamoDB table, the combined partition key value and sort key value for each item must be unique. However, in a local secondary index, the sort key value does not need to be unique for a given partition key value. If there are multiple items in the local secondary index that have the same sort key value, a Query operation returns all of the items that have the same partition key value. In the response, the matching items are not returned in any particular order.\n\nYou can query a local secondary index using either eventually consistent or strongly consistent reads. To specify which type of consistency you want, use the ConsistentRead parameter of the Query operation. A strongly consistent read from a local secondary index always returns the latest updated values. If the query needs to fetch additional attributes from the base table, those attributes will be consistent with respect to the index.\n\nExample\n\nConsider the following data returned from a Query that requests data from the discussion threads in a particular forum.\n\n{\n    \"TableName\": \"Thread\",\n    \"IndexName\": \"LastPostIndex\",\n    \"ConsistentRead\": false,\n    \"ProjectionExpression\": \"Subject, LastPostDateTime, Replies, Tags\",\n    \"KeyConditionExpression\": \n        \"ForumName = :v_forum and LastPostDateTime between :v_start and :v_end\",\n    \"ExpressionAttributeValues\": {\n        \":v_start\": {\"S\": \"2015-08-31T00:00:00.000Z\"},\n        \":v_end\": {\"S\": \"2015-11-31T00:00:00.000Z\"},\n        \":v_forum\": {\"S\": \"EC2\"}\n    }\n}\n\nIn this query:\n\nDynamoDB accesses LastPostIndex, using the ForumName partition key to locate the index items for \"EC2\". All of the index items with this key are stored adjacent to each other for rapid retrieval.\n\nWithin this forum, DynamoDB uses the index to look up the keys that match the specified LastPostDateTime condition.\n\nBecause the Replies attribute is projected into the index, DynamoDB can retrieve this attribute without consuming any additional provisioned throughput.\n\nThe Tags attribute is not projected into the index, so DynamoDB must access the Thread table and fetch this attribute.\n\nThe results are returned, sorted by LastPostDateTime. The index entries are sorted by partition key value and then by sort key value, and Query returns them in the order they are stored. (You can use the ScanIndexForward parameter to return the results in descending order.)\n\nBecause the Tags attribute is not projected into the local secondary index, DynamoDB must consume additional read capacity units to fetch this attribute from the base table. If you need to run this query often, you should project Tags into LastPostIndex to avoid fetching from the base table. However, if you needed to access Tags only occasionally, the additional storage cost for projecting Tags into the index might not be worthwhile.\n\nScanning a Local Secondary Index\n\nYou can use Scan to retrieve all of the data from a local secondary index. You must provide the base table name and the index name in the request. With a Scan, DynamoDB reads all of the data in the index and returns it to the application. You can also request that only some of the data be returned, and that the remaining data should be discarded. To do this, use the FilterExpression parameter of the Scan API. For more information, see Filter expressions for scan.\n\nItem writes and Local Secondary Indexes\n\nDynamoDB automatically keeps all local secondary indexes synchronized with their respective base tables. Applications never write directly to an index. However, it is important that you understand the implications of how DynamoDB maintains these indexes.\n\nWhen you create a local secondary index, you specify an attribute to serve as the sort key for the index. You also specify a data type for that attribute. This means that whenever you write an item to the base table, if the item defines an index key attribute, its type must match the index key schema's data type. In the case of LastPostIndex, the LastPostDateTime sort key in the index is defined as a String data type. If you try to add an item to the Thread table and specify a different data type for LastPostDateTime (such as Number), DynamoDB returns a ValidationException because of the data type mismatch.\n\nThere is no requirement for a one-to-one relationship between the items in a base table and the items in a local secondary index. In fact, this behavior can be advantageous for many applications.\n\nA table with many local secondary indexes incurs higher costs for write activity than tables with fewer indexes. For more information, see Provisioned throughput considerations for Local Secondary Indexes.\n\nImportant\n\nFor tables with local secondary indexes, there is a 10 GB size limit per partition key value. A table with local secondary indexes can store any number of items, as long as the total size for any one partition key value does not exceed 10 GB. For more information, see Item collection size limit.\n\nProvisioned throughput considerations for Local Secondary Indexes\n\nWhen you create a table in DynamoDB, you provision read and write capacity units for the table's expected workload. That workload includes read and write activity on the table's local secondary indexes.\n\nTo view the current rates for provisioned throughput capacity, see Amazon DynamoDB pricing.\n\nRead capacity units\n\nWhen you query a local secondary index, the number of read capacity units consumed depends on how the data is accessed.\n\nAs with table queries, an index query can use either eventually consistent or strongly consistent reads depending on the value of ConsistentRead. One strongly consistent read consumes one read capacity unit; an eventually consistent read consumes only half of that. Thus, by choosing eventually consistent reads, you can reduce your read capacity unit charges.\n\nFor index queries that request only index keys and projected attributes, DynamoDB calculates the provisioned read activity in the same way as it does for queries against tables. The only difference is that the calculation is based on the sizes of the index entries, rather than the size of the item in the base table. The number of read capacity units is the sum of all projected attribute sizes across all of the items returned; the result is then rounded up to the next 4 KB boundary. For more information about how DynamoDB calculates provisioned throughput usage, see Provisioned capacity mode.\n\nFor index queries that read attributes that are not projected into the local secondary index, DynamoDB needs to fetch those attributes from the base table, in addition to reading the projected attributes from the index. These fetches occur when you include any non-projected attributes in the Select or ProjectionExpression parameters of the Query operation. Fetching causes additional latency in query responses, and it also incurs a higher provisioned throughput cost: In addition to the reads from the local secondary index described previously, you are charged for read capacity units for every base table item fetched. This charge is for reading each entire item from the table, not just the requested attributes.\n\nThe maximum size of the results returned by a Query operation is 1 MB. This includes the sizes of all the attribute names and values across all of the items returned. However, if a Query against a local secondary index causes DynamoDB to fetch item attributes from the base table, the maximum size of the data in the results might be lower. In this case, the result size is the sum of:\n\nThe size of the matching items in the index, rounded up to the next 4 KB.\n\nThe size of each matching item in the base table, with each item individually rounded up to the next 4 KB.\n\nUsing this formula, the maximum size of the results returned by a Query operation is still 1 MB.\n\nFor example, consider a table where the size of each item is 300 bytes. There is a local secondary index on that table, but only 200 bytes of each item is projected into the index. Now suppose that you Query this index, that the query requires table fetches for each item, and that the query returns 4 items. DynamoDB sums up the following:\n\nThe size of the matching items in the index: 200 bytes × 4 items = 800 bytes; this is then rounded up to 4 KB.\n\nThe size of each matching item in the base table: (300 bytes, rounded up to 4 KB) × 4 items = 16 KB.\n\nThe total size of the data in the result is therefore 20 KB.\n\nWrite capacity units\n\nWhen an item in a table is added, updated, or deleted, updating the local secondary indexes consumes provisioned write capacity units for the table. The total provisioned throughput cost for a write is the sum of write capacity units consumed by writing to the table and those consumed by updating the local secondary indexes.\n\nThe cost of writing an item to a local secondary index depends on several factors:\n\nIf you write a new item to the table that defines an indexed attribute, or you update an existing item to define a previously undefined indexed attribute, one write operation is required to put the item into the index.\n\nIf an update to the table changes the value of an indexed key attribute (from A to B), two writes are required: one to delete the previous item from the index and another write to put the new item into the index. \n\nIf an item was present in the index, but a write to the table caused the indexed attribute to be deleted, one write is required to delete the old item projection from the index.\n\nIf an item is not present in the index before or after the item is updated, there is no additional write cost for the index.\n\nAll of these factors assume that the size of each item in the index is less than or equal to the 1 KB item size for calculating write capacity units. Larger index entries require additional write capacity units. You can minimize your write costs by considering which attributes your queries need to return and projecting only those attributes into the index.\n\nStorage considerations for Local Secondary Indexes\n\nWhen an application writes an item to a table, DynamoDB automatically copies the correct subset of attributes to any local secondary indexes in which those attributes should appear. Your AWS account is charged for storage of the item in the base table and also for storage of attributes in any local secondary indexes on that table.\n\nThe amount of space used by an index item is the sum of the following:\n\nThe size in bytes of the base table primary key (partition key and sort key)\n\nThe size in bytes of the index key attribute\n\nThe size in bytes of the projected attributes (if any)\n\n100 bytes of overhead per index item\n\nTo estimate the storage requirements for a local secondary index, you can estimate the average size of an item in the index and then multiply by the number of items in the index.\n\nIf a table contains an item where a particular attribute is not defined, but that attribute is defined as an index sort key, then DynamoDB does not write any data for that item to the index.\n\nItem collections in Local Secondary Indexes\nNote\n\nThis section pertains only to tables that have local secondary indexes.\n\nIn DynamoDB, an item collection is any group of items that have the same partition key value in a table and all of its local secondary indexes. In the examples used throughout this section, the partition key for the Thread table is ForumName, and the partition key for LastPostIndex is also ForumName. All the table and index items with the same ForumName are part of the same item collection. For example, in the Thread table and the LastPostIndex local secondary index, there is an item collection for forum EC2 and a different item collection for forum RDS.\n\nThe following diagram shows the item collection for forum S3.\n\nIn this diagram, the item collection consists of all the items in Thread and LastPostIndex where the ForumName partition key value is \"S3\". If there were other local secondary indexes on the table, any items in those indexes with ForumName equal to \"S3\" would also be part of the item collection.\n\nYou can use any of the following operations in DynamoDB to return information about item collections:\n\nBatchWriteItem\n\nDeleteItem\n\nPutItem\n\nUpdateItem\n\nTransactWriteItems\n\nEach of these operations supports the ReturnItemCollectionMetrics parameter. When you set this parameter to SIZE, you can view information about the size of each item collection in the index.\n\nExample\n\nThe following is an example from the output of an UpdateItem operation on the Thread table, with ReturnItemCollectionMetrics set to SIZE. The item that was updated had a ForumName value of \"EC2\", so the output includes information about that item collection.\n\n{\n    ItemCollectionMetrics: {\n        ItemCollectionKey: {\n            ForumName: \"EC2\"\n        },\n        SizeEstimateRangeGB: [0.0, 1.0]\n    }\n}\n\nThe SizeEstimateRangeGB object shows that the size of this item collection is between 0 and 1 GB. DynamoDB periodically updates this size estimate, so the numbers might be different next time the item is modified.\n\nItem collection size limit\n\nThe maximum size of any item collection for a table which has one or more local secondary indexes is 10 GB. This does not apply to item collections in tables without local secondary indexes, and also does not apply to item collections in global secondary indexes. Only tables that have one or more local secondary indexes are affected.\n\nIf an item collection exceeds the 10 GB limit, DynamoDB returns an ItemCollectionSizeLimitExceededException, and you won't be able to add more items to the item collection or increase the sizes of items that are in the item collection. (Read and write operations that shrink the size of the item collection are still allowed.) You can still add items to other item collections.\n\nTo reduce the size of an item collection, you can do one of the following:\n\nDelete any unnecessary items with the partition key value in question. When you delete these items from the base table, DynamoDB also removes any index entries that have the same partition key value.\n\nUpdate the items by removing attributes or by reducing the size of the attributes. If these attributes are projected into any local secondary indexes, DynamoDB also reduces the size of the corresponding index entries.\n\nCreate a new table with the same partition key and sort key, and then move items from the old table to the new table. This might be a good approach if a table has historical data that is infrequently accessed. You might also consider archiving this historical data to Amazon Simple Storage Service (Amazon S3).\n\nWhen the total size of the item collection drops below 10 GB, you can once again add items with the same partition key value.\n\nWe recommend as a best practice that you instrument your application to monitor the sizes of your item collections. One way to do so is to set the ReturnItemCollectionMetrics parameter to SIZE whenever you use BatchWriteItem, DeleteItem, PutItem, or UpdateItem. Your application should examine the ReturnItemCollectionMetrics object in the output and log an error message whenever an item collection exceeds a user-defined limit (8 GB, for example). Setting a limit that is less than 10 GB would provide an early warning system so you know that an item collection is approaching the limit in time to do something about it.\n\nItem collections and partitions\n\nIn a table with one or more local secondary indexes, each item collection is stored in one partition. The total size of such an item collection is limited to the capability of that partition: 10 GB. For an application where the data model includes item collections which are unbounded in size, or where you might reasonably expect some item collections to grow beyond 10 GB in the future, you should consider using a global secondary index instead.\n\nYou should design your applications so that table data is evenly distributed across distinct partition key values. For tables with local secondary indexes, your applications should not create \"hot spots\" of read and write activity within a single item collection on a single partition."
  },
  {
    "title": "Example: Global Secondary Indexes using the AWS SDK for .NET low-level API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSILowLevelDotNet.Example.html",
    "html": "Example: Global Secondary Indexes using the AWS SDK for .NET low-level API\nPDF\nRSS\n\nThe following C# code example shows how to work with global secondary indexes. The example creates a table named Issues, which might be used in a simple bug tracking system for software development. The partition key is IssueId and the sort key is Title. There are three global secondary indexes on this table:\n\nCreateDateIndex — The partition key is CreateDate and the sort key is IssueId. In addition to the table keys, the attributes Description and Status are projected into the index.\n\nTitleIndex — The partition key is Title and the sort key is IssueId. No attributes other than the table keys are projected into the index.\n\nDueDateIndex — The partition key is DueDate, and there is no sort key. All of the table attributes are projected into the index.\n\nAfter the Issues table is created, the program loads the table with data representing software bug reports. It then queries the data using the global secondary indexes. Finally, the program deletes the Issues table.\n\nFor step-by-step instructions for testing the following sample, see .NET code examples.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.DataModel;\nusing Amazon.DynamoDBv2.DocumentModel;\nusing Amazon.DynamoDBv2.Model;\nusing Amazon.Runtime;\nusing Amazon.SecurityToken;\n\nnamespace com.amazonaws.codesamples\n{\n    class LowLevelGlobalSecondaryIndexExample\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n        public static String tableName = \"Issues\";\n\n        public static void Main(string[] args)\n        {\n            CreateTable();\n            LoadData();\n\n            QueryIndex(\"CreateDateIndex\");\n            QueryIndex(\"TitleIndex\");\n            QueryIndex(\"DueDateIndex\");\n\n            DeleteTable(tableName);\n\n            Console.WriteLine(\"To continue, press enter\");\n            Console.Read();\n        }\n\n        private static void CreateTable()\n        {\n            // Attribute definitions\n            var attributeDefinitions = new List<AttributeDefinition>()\n        {\n            {new AttributeDefinition {\n                 AttributeName = \"IssueId\", AttributeType = \"S\"\n             }},\n            {new AttributeDefinition {\n                 AttributeName = \"Title\", AttributeType = \"S\"\n             }},\n            {new AttributeDefinition {\n                 AttributeName = \"CreateDate\", AttributeType = \"S\"\n             }},\n            {new AttributeDefinition {\n                 AttributeName = \"DueDate\", AttributeType = \"S\"\n             }}\n        };\n\n            // Key schema for table\n            var tableKeySchema = new List<KeySchemaElement>() {\n            {\n                new KeySchemaElement {\n                    AttributeName= \"IssueId\",\n                    KeyType = \"HASH\" //Partition key\n                }\n            },\n            {\n                new KeySchemaElement {\n                    AttributeName = \"Title\",\n                    KeyType = \"RANGE\" //Sort key\n                }\n            }\n        };\n\n            // Initial provisioned throughput settings for the indexes\n            var ptIndex = new ProvisionedThroughput\n            {\n                ReadCapacityUnits = 1L,\n                WriteCapacityUnits = 1L\n            };\n\n            // CreateDateIndex\n            var createDateIndex = new GlobalSecondaryIndex()\n            {\n                IndexName = \"CreateDateIndex\",\n                ProvisionedThroughput = ptIndex,\n                KeySchema = {\n                new KeySchemaElement {\n                    AttributeName = \"CreateDate\", KeyType = \"HASH\" //Partition key\n                },\n                new KeySchemaElement {\n                    AttributeName = \"IssueId\", KeyType = \"RANGE\" //Sort key\n                }\n            },\n                Projection = new Projection\n                {\n                    ProjectionType = \"INCLUDE\",\n                    NonKeyAttributes = {\n                    \"Description\", \"Status\"\n                }\n                }\n            };\n\n            // TitleIndex\n            var titleIndex = new GlobalSecondaryIndex()\n            {\n                IndexName = \"TitleIndex\",\n                ProvisionedThroughput = ptIndex,\n                KeySchema = {\n                new KeySchemaElement {\n                    AttributeName = \"Title\", KeyType = \"HASH\" //Partition key\n                },\n                new KeySchemaElement {\n                    AttributeName = \"IssueId\", KeyType = \"RANGE\" //Sort key\n                }\n            },\n                Projection = new Projection\n                {\n                    ProjectionType = \"KEYS_ONLY\"\n                }\n            };\n\n            // DueDateIndex\n            var dueDateIndex = new GlobalSecondaryIndex()\n            {\n                IndexName = \"DueDateIndex\",\n                ProvisionedThroughput = ptIndex,\n                KeySchema = {\n                new KeySchemaElement {\n                    AttributeName = \"DueDate\",\n                    KeyType = \"HASH\" //Partition key\n                }\n            },\n                Projection = new Projection\n                {\n                    ProjectionType = \"ALL\"\n                }\n            };\n\n\n\n            var createTableRequest = new CreateTableRequest\n            {\n                TableName = tableName,\n                ProvisionedThroughput = new ProvisionedThroughput\n                {\n                    ReadCapacityUnits = (long)1,\n                    WriteCapacityUnits = (long)1\n                },\n                AttributeDefinitions = attributeDefinitions,\n                KeySchema = tableKeySchema,\n                GlobalSecondaryIndexes = {\n                createDateIndex, titleIndex, dueDateIndex\n            }\n            };\n\n            Console.WriteLine(\"Creating table \" + tableName + \"...\");\n            client.CreateTable(createTableRequest);\n\n            WaitUntilTableReady(tableName);\n        }\n\n        private static void LoadData()\n        {\n            Console.WriteLine(\"Loading data into table \" + tableName + \"...\");\n\n            // IssueId, Title,\n            // Description,\n            // CreateDate, LastUpdateDate, DueDate,\n            // Priority, Status\n\n            putItem(\"A-101\", \"Compilation error\",\n                \"Can't compile Project X - bad version number. What does this mean?\",\n                \"2013-11-01\", \"2013-11-02\", \"2013-11-10\",\n                1, \"Assigned\");\n\n            putItem(\"A-102\", \"Can't read data file\",\n                \"The main data file is missing, or the permissions are incorrect\",\n                \"2013-11-01\", \"2013-11-04\", \"2013-11-30\",\n                2, \"In progress\");\n\n            putItem(\"A-103\", \"Test failure\",\n                \"Functional test of Project X produces errors\",\n                \"2013-11-01\", \"2013-11-02\", \"2013-11-10\",\n                1, \"In progress\");\n\n            putItem(\"A-104\", \"Compilation error\",\n                \"Variable 'messageCount' was not initialized.\",\n                \"2013-11-15\", \"2013-11-16\", \"2013-11-30\",\n                3, \"Assigned\");\n\n            putItem(\"A-105\", \"Network issue\",\n                \"Can't ping IP address 127.0.0.1. Please fix this.\",\n                \"2013-11-15\", \"2013-11-16\", \"2013-11-19\",\n                5, \"Assigned\");\n        }\n\n        private static void putItem(\n            String issueId, String title,\n            String description,\n            String createDate, String lastUpdateDate, String dueDate,\n            Int32 priority, String status)\n        {\n            Dictionary<String, AttributeValue> item = new Dictionary<string, AttributeValue>();\n\n            item.Add(\"IssueId\", new AttributeValue\n            {\n                S = issueId\n            });\n            item.Add(\"Title\", new AttributeValue\n            {\n                S = title\n            });\n            item.Add(\"Description\", new AttributeValue\n            {\n                S = description\n            });\n            item.Add(\"CreateDate\", new AttributeValue\n            {\n                S = createDate\n            });\n            item.Add(\"LastUpdateDate\", new AttributeValue\n            {\n                S = lastUpdateDate\n            });\n            item.Add(\"DueDate\", new AttributeValue\n            {\n                S = dueDate\n            });\n            item.Add(\"Priority\", new AttributeValue\n            {\n                N = priority.ToString()\n            });\n            item.Add(\"Status\", new AttributeValue\n            {\n                S = status\n            });\n\n            try\n            {\n                client.PutItem(new PutItemRequest\n                {\n                    TableName = tableName,\n                    Item = item\n                });\n            }\n            catch (Exception e)\n            {\n                Console.WriteLine(e.ToString());\n            }\n        }\n\n        private static void QueryIndex(string indexName)\n        {\n            Console.WriteLine\n                (\"\\n***********************************************************\\n\");\n            Console.WriteLine(\"Querying index \" + indexName + \"...\");\n\n            QueryRequest queryRequest = new QueryRequest\n            {\n                TableName = tableName,\n                IndexName = indexName,\n                ScanIndexForward = true\n            };\n\n\n            String keyConditionExpression;\n            Dictionary<string, AttributeValue> expressionAttributeValues = new Dictionary<string, AttributeValue>();\n\n            if (indexName == \"CreateDateIndex\")\n            {\n                Console.WriteLine(\"Issues filed on 2013-11-01\\n\");\n\n                keyConditionExpression = \"CreateDate = :v_date and begins_with(IssueId, :v_issue)\";\n                expressionAttributeValues.Add(\":v_date\", new AttributeValue\n                {\n                    S = \"2013-11-01\"\n                });\n                expressionAttributeValues.Add(\":v_issue\", new AttributeValue\n                {\n                    S = \"A-\"\n                });\n            }\n            else if (indexName == \"TitleIndex\")\n            {\n                Console.WriteLine(\"Compilation errors\\n\");\n\n                keyConditionExpression = \"Title = :v_title and begins_with(IssueId, :v_issue)\";\n                expressionAttributeValues.Add(\":v_title\", new AttributeValue\n                {\n                    S = \"Compilation error\"\n                });\n                expressionAttributeValues.Add(\":v_issue\", new AttributeValue\n                {\n                    S = \"A-\"\n                });\n\n                // Select\n                queryRequest.Select = \"ALL_PROJECTED_ATTRIBUTES\";\n            }\n            else if (indexName == \"DueDateIndex\")\n            {\n                Console.WriteLine(\"Items that are due on 2013-11-30\\n\");\n\n                keyConditionExpression = \"DueDate = :v_date\";\n                expressionAttributeValues.Add(\":v_date\", new AttributeValue\n                {\n                    S = \"2013-11-30\"\n                });\n\n                // Select\n                queryRequest.Select = \"ALL_PROJECTED_ATTRIBUTES\";\n            }\n            else\n            {\n                Console.WriteLine(\"\\nNo valid index name provided\");\n                return;\n            }\n\n            queryRequest.KeyConditionExpression = keyConditionExpression;\n            queryRequest.ExpressionAttributeValues = expressionAttributeValues;\n\n            var result = client.Query(queryRequest);\n            var items = result.Items;\n            foreach (var currentItem in items)\n            {\n                foreach (string attr in currentItem.Keys)\n                {\n                    if (attr == \"Priority\")\n                    {\n                        Console.WriteLine(attr + \"---> \" + currentItem[attr].N);\n                    }\n                    else\n                    {\n                        Console.WriteLine(attr + \"---> \" + currentItem[attr].S);\n                    }\n                }\n                Console.WriteLine();\n            }\n        }\n\n        private static void DeleteTable(string tableName)\n        {\n            Console.WriteLine(\"Deleting table \" + tableName + \"...\");\n            client.DeleteTable(new DeleteTableRequest\n            {\n                TableName = tableName\n            });\n            WaitForTableToBeDeleted(tableName);\n        }\n\n        private static void WaitUntilTableReady(string tableName)\n        {\n            string status = null;\n            // Let us wait until table is created. Call DescribeTable.\n            do\n            {\n                System.Threading.Thread.Sleep(5000); // Wait 5 seconds.\n                try\n                {\n                    var res = client.DescribeTable(new DescribeTableRequest\n                    {\n                        TableName = tableName\n                    });\n\n                    Console.WriteLine(\"Table name: {0}, status: {1}\",\n                              res.Table.TableName,\n                              res.Table.TableStatus);\n                    status = res.Table.TableStatus;\n                }\n                catch (ResourceNotFoundException)\n                {\n                    // DescribeTable is eventually consistent. So you might\n                    // get resource not found. So we handle the potential exception.\n                }\n            } while (status != \"ACTIVE\");\n        }\n\n        private static void WaitForTableToBeDeleted(string tableName)\n        {\n            bool tablePresent = true;\n\n            while (tablePresent)\n            {\n                System.Threading.Thread.Sleep(5000); // Wait 5 seconds.\n                try\n                {\n                    var res = client.DescribeTable(new DescribeTableRequest\n                    {\n                        TableName = tableName\n                    });\n\n                    Console.WriteLine(\"Table name: {0}, status: {1}\",\n                              res.Table.TableName,\n                              res.Table.TableStatus);\n                }\n                catch (ResourceNotFoundException)\n                {\n                    tablePresent = false;\n                }\n            }\n        }\n    }\n}\n\n"
  },
  {
    "title": "Working with Global Secondary Indexes: AWS CLI - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GCICli.html",
    "html": "Working with Global Secondary Indexes: AWS CLI\nPDF\nRSS\n\nYou can use the AWS CLI to create an Amazon DynamoDB table with one or more global secondary indexes, describe the indexes on the table, and perform queries using the indexes.\n\nTopics\nCreate a table with a Global Secondary Index\nAdd a Global Secondary Index to an existing table\nDescribe a table with a Global Secondary Index\nQuery a Global Secondary Index\nCreate a table with a Global Secondary Index\n\nGlobal secondary indexes may be created at the same time you create a table. To do this, use the create-table parameter and provide your specifications for one or more global secondary indexes. The following example creates a table named GameScores with a global secondary index called GameTitleIndex. The base table has a partition key of UserId and a sort key of GameTitle, allowing you to find an individual user's best score for a specific game efficiently, whereas the GSI has a partition key of GameTitle and a sort key of TopScore, allowing you to quickly find the overall highest score for a particular game.\n\naws dynamodb create-table \\\n    --table-name GameScores \\\n    --attribute-definitions AttributeName=UserId,AttributeType=S \\\n                            AttributeName=GameTitle,AttributeType=S \\\n                            AttributeName=TopScore,AttributeType=N  \\\n    --key-schema AttributeName=UserId,KeyType=HASH \\\n                 AttributeName=GameTitle,KeyType=RANGE \\\n    --provisioned-throughput ReadCapacityUnits=10,WriteCapacityUnits=5 \\\n    --global-secondary-indexes \\\n        \"[\n            {\n                \\\"IndexName\\\": \\\"GameTitleIndex\\\",\n                \\\"KeySchema\\\": [{\\\"AttributeName\\\":\\\"GameTitle\\\",\\\"KeyType\\\":\\\"HASH\\\"},\n                                {\\\"AttributeName\\\":\\\"TopScore\\\",\\\"KeyType\\\":\\\"RANGE\\\"}],\n                \\\"Projection\\\":{\n                    \\\"ProjectionType\\\":\\\"INCLUDE\\\",\n                    \\\"NonKeyAttributes\\\":[\\\"UserId\\\"]\n                },\n                \\\"ProvisionedThroughput\\\": {\n                    \\\"ReadCapacityUnits\\\": 10,\n                    \\\"WriteCapacityUnits\\\": 5\n                }\n            }\n        ]\"\n\nYou must wait until DynamoDB creates the table and sets the table status to ACTIVE. After that, you can begin putting data items into the table. You can use describe-table to determine the status of the table creation.\n\nAdd a Global Secondary Index to an existing table\n\nGlobal secondary indexes may also be added or modified after table creation. To do this, use the update-table parameter and provide your specifications for one or more global secondary indexes. The following example uses the same schema as the previous example, but assumes that the table has already been created and we're adding the GSI later.\n\naws dynamodb update-table \\\n    --table-name GameScores \\\n    --attribute-definitions AttributeName=TopScore,AttributeType=N  \\\n    --global-secondary-index-updates \\\n        \"[\n            {\n                \\\"Create\\\": {\n                    \\\"IndexName\\\": \\\"GameTitleIndex\\\",\n                    \\\"KeySchema\\\": [{\\\"AttributeName\\\":\\\"GameTitle\\\",\\\"KeyType\\\":\\\"HASH\\\"},\n                                    {\\\"AttributeName\\\":\\\"TopScore\\\",\\\"KeyType\\\":\\\"RANGE\\\"}],\n                    \\\"Projection\\\":{\n                        \\\"ProjectionType\\\":\\\"INCLUDE\\\",\n                        \\\"NonKeyAttributes\\\":[\\\"UserId\\\"]\n                    }\n                }\n            }\n        ]\"\nDescribe a table with a Global Secondary Index\n\nTo get information about Global Secondary Indexes on a table, use the describe-table parameter. For each index, you can access its name, key schema, and projected attributes.\n\naws dynamodb describe-table --table-name GameScores\nQuery a Global Secondary Index\n\nYou can use the query operation on a global secondary index in much the same way that you query a table. You must specify the index name, the query criteria for the index sort key, and the attributes that you want to return. In this example, the index is GameTitleIndex and the index sort key is GameTitle.\n\nThe only attributes returned are those that have been projected into the index. You could modify this query to select non-key attributes too, but this would require table fetch activity that is relatively expensive. For more information about table fetches, see Attribute projections.\n\naws dynamodb query --table-name GameScores\\\n    --index-name GameTitleIndex \\\n    --key-condition-expression \"GameTitle = :v_game\" \\\n    --expression-attribute-values '{\":v_game\":{\"S\":\"Alien Adventure\"} }'"
  },
  {
    "title": "Working with Global Secondary Indexes: .NET - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSILowLevelDotNet.html",
    "html": "Working with Global Secondary Indexes: .NET\nPDF\nRSS\n\nYou can use the AWS SDK for .NET low-level API to create an Amazon DynamoDB table with one or more global secondary indexes, describe the indexes on the table, and perform queries using the indexes. These operations map to the corresponding DynamoDB operations. For more information, see the Amazon DynamoDB API Reference.\n\nThe following are the common steps for table operations using the .NET low-level API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nProvide the required and optional parameters for the operation by creating the corresponding request objects.\n\nFor example, create a CreateTableRequest object to create a table and QueryRequest object to query a table or an index.\n\nRun the appropriate method provided by the client that you created in the preceding step.\n\nTopics\nCreate a table with a Global Secondary Index\nDescribe a table with a Global Secondary Index\nQuery a Global Secondary Index\nExample: Global Secondary Indexes using the AWS SDK for .NET low-level API\nCreate a table with a Global Secondary Index\n\nYou can create global secondary indexes at the same time that you create a table. To do this, use CreateTable and provide your specifications for one or more global secondary indexes. The following C# code example creates a table to hold information about weather data. The partition key is Location and the sort key is Date. A global secondary index named PrecipIndex allows fast access to precipitation data for various locations.\n\nThe following are the steps to create a table with a global secondary index, using the .NET low-level API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nCreate an instance of the CreateTableRequest class to provide the request information.\n\nYou must provide the table name, its primary key, and the provisioned throughput values. For the global secondary index, you must provide the index name, its provisioned throughput settings, the attribute definitions for the index sort key, the key schema for the index, and the attribute projection.\n\nRun the CreateTable method by providing the request object as a parameter.\n\nThe following C# code example demonstrates the preceding steps. The code creates a table (WeatherData) with a global secondary index (PrecipIndex). The index partition key is Date and its sort key is Precipitation. All of the table attributes are projected into the index. Users can query this index to obtain weather data for a particular date, optionally sorting the data by precipitation amount.\n\nBecause Precipitation is not a key attribute for the table, it is not required. However, WeatherData items without Precipitation do not appear in PrecipIndex.\n\nclient = new AmazonDynamoDBClient();\nstring tableName = \"WeatherData\";\n\n// Attribute definitions\nvar attributeDefinitions = new List<AttributeDefinition>()\n{\n    {new AttributeDefinition{\n        AttributeName = \"Location\",\n        AttributeType = \"S\"}},\n    {new AttributeDefinition{\n        AttributeName = \"Date\",\n        AttributeType = \"S\"}},\n    {new AttributeDefinition(){\n        AttributeName = \"Precipitation\",\n        AttributeType = \"N\"}\n    }\n};\n\n// Table key schema\nvar tableKeySchema = new List<KeySchemaElement>()\n{\n    {new KeySchemaElement {\n        AttributeName = \"Location\",\n        KeyType = \"HASH\"}},  //Partition key\n    {new KeySchemaElement {\n        AttributeName = \"Date\",\n        KeyType = \"RANGE\"}  //Sort key\n    }\n};\n\n// PrecipIndex\nvar precipIndex = new GlobalSecondaryIndex\n{\n    IndexName = \"PrecipIndex\",\n    ProvisionedThroughput = new ProvisionedThroughput\n    {\n        ReadCapacityUnits = (long)10,\n        WriteCapacityUnits = (long)1\n    },\n    Projection = new Projection { ProjectionType = \"ALL\" }\n};\n\nvar indexKeySchema = new List<KeySchemaElement> {\n    {new KeySchemaElement { AttributeName = \"Date\", KeyType = \"HASH\"}},  //Partition key\n    {new KeySchemaElement{AttributeName = \"Precipitation\",KeyType = \"RANGE\"}}  //Sort key\n};\n\nprecipIndex.KeySchema = indexKeySchema;\n\nCreateTableRequest createTableRequest = new CreateTableRequest\n{\n    TableName = tableName,\n    ProvisionedThroughput = new ProvisionedThroughput\n    {\n        ReadCapacityUnits = (long)5,\n        WriteCapacityUnits = (long)1\n    },\n    AttributeDefinitions = attributeDefinitions,\n    KeySchema = tableKeySchema,\n    GlobalSecondaryIndexes = { precipIndex }\n};\n\nCreateTableResponse response = client.CreateTable(createTableRequest);\nConsole.WriteLine(response.CreateTableResult.TableDescription.TableName);\nConsole.WriteLine(response.CreateTableResult.TableDescription.TableStatus);\n\nYou must wait until DynamoDB creates the table and sets the table status to ACTIVE. After that, you can begin putting data items into the table.\n\nDescribe a table with a Global Secondary Index\n\nTo get information about global secondary indexes on a table, use DescribeTable. For each index, you can access its name, key schema, and projected attributes.\n\nThe following are the steps to access global secondary index information for a table using the .NET low-level API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nRun the describeTable method by providing the request object as a parameter.\n\nCreate an instance of the DescribeTableRequest class to provide the request information. You must provide the table name.\n\nThe following C# code example demonstrates the preceding steps.\n\nExample\nclient = new AmazonDynamoDBClient();\nstring tableName = \"WeatherData\";\n\nDescribeTableResponse response = client.DescribeTable(new DescribeTableRequest { TableName = tableName});\n\nList<GlobalSecondaryIndexDescription> globalSecondaryIndexes =\nresponse.DescribeTableResult.Table.GlobalSecondaryIndexes;\n\n// This code snippet will work for multiple indexes, even though\n// there is only one index in this example.\n\nforeach (GlobalSecondaryIndexDescription gsiDescription in globalSecondaryIndexes) {\n     Console.WriteLine(\"Info for index \" + gsiDescription.IndexName + \":\");\n\n     foreach (KeySchemaElement kse in gsiDescription.KeySchema) {\n          Console.WriteLine(\"\\t\" + kse.AttributeName + \": key type is \" + kse.KeyType);\n     }\n\n      Projection projection = gsiDescription.Projection;\n      Console.WriteLine(\"\\tThe projection type is: \" + projection.ProjectionType);\n\n      if (projection.ProjectionType.ToString().Equals(\"INCLUDE\")) {\n           Console.WriteLine(\"\\t\\tThe non-key projected attributes are: \"\n                + projection.NonKeyAttributes);\n      }\n}\nQuery a Global Secondary Index\n\nYou can use Query on a global secondary index, in much the same way you Query a table. You need to specify the index name, the query criteria for the index partition key and sort key (if present), and the attributes that you want to return. In this example, the index is PrecipIndex, which has a partition key of Date and a sort key of Precipitation. The index query returns all of the weather data for a particular date, where the precipitation is greater than zero.\n\nThe following are the steps to query a global secondary index using the .NET low-level API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nCreate an instance of the QueryRequest class to provide the request information.\n\nRun the query method by providing the request object as a parameter.\n\nThe attribute name Date is a DynamoDB reserved word. Therefore, you must use an expression attribute name as a placeholder in the KeyConditionExpression.\n\nThe following C# code example demonstrates the preceding steps.\n\nExample\nclient = new AmazonDynamoDBClient();\n\nQueryRequest queryRequest = new QueryRequest\n{\n    TableName = \"WeatherData\",\n    IndexName = \"PrecipIndex\",\n    KeyConditionExpression = \"#dt = :v_date and Precipitation > :v_precip\",\n    ExpressionAttributeNames = new Dictionary<String, String> {\n        {\"#dt\", \"Date\"}\n    },\n    ExpressionAttributeValues = new Dictionary<string, AttributeValue> {\n        {\":v_date\", new AttributeValue { S =  \"2013-08-01\" }},\n        {\":v_precip\", new AttributeValue { N =  \"0\" }}\n    },\n    ScanIndexForward = true\n};\n\nvar result = client.Query(queryRequest);\n\nvar items = result.Items;\nforeach (var currentItem in items)\n{\n    foreach (string attr in currentItem.Keys)\n    {\n        Console.Write(attr + \"---> \");\n        if (attr == \"Precipitation\")\n        {\n            Console.WriteLine(currentItem[attr].N);\n    }\n    else\n    {\n        Console.WriteLine(currentItem[attr].S);\n    }\n\n         }\n     Console.WriteLine();\n}"
  },
  {
    "title": "Using Global Secondary Indexes in DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html",
    "html": "Using Global Secondary Indexes in DynamoDB\nPDF\nRSS\n\nSome applications might need to perform many kinds of queries, using a variety of different attributes as query criteria. To support these requirements, you can create one or more global secondary indexes and issue Query requests against these indexes in Amazon DynamoDB.\n\nTopics\nScenario: Using a Global Secondary Index\nAttribute projections\nReading data from a Global Secondary Index\nData synchronization between tables and Global Secondary Indexes\nTable classes with Global Secondary Index\nProvisioned throughput considerations for Global Secondary Indexes\nStorage considerations for Global Secondary Indexes\nManaging Global Secondary Indexes\nWorking with Global Secondary Indexes: Java\nWorking with Global Secondary Indexes: .NET\nWorking with Global Secondary Indexes: AWS CLI\nScenario: Using a Global Secondary Index\n\nTo illustrate, consider a table named GameScores that tracks users and scores for a mobile gaming application. Each item in GameScores is identified by a partition key (UserId) and a sort key (GameTitle). The following diagram shows how the items in the table would be organized. (Not all of the attributes are shown.)\n\nNow suppose that you wanted to write a leaderboard application to display top scores for each game. A query that specified the key attributes (UserId and GameTitle) would be very efficient. However, if the application needed to retrieve data from GameScores based on GameTitle only, it would need to use a Scan operation. As more items are added to the table, scans of all the data would become slow and inefficient. This makes it difficult to answer questions such as the following:\n\nWhat is the top score ever recorded for the game Meteor Blasters?\n\nWhich user had the highest score for Galaxy Invaders?\n\nWhat was the highest ratio of wins vs. losses?\n\nTo speed up queries on non-key attributes, you can create a global secondary index. A global secondary index contains a selection of attributes from the base table, but they are organized by a primary key that is different from that of the table. The index key does not need to have any of the key attributes from the table. It doesn't even need to have the same key schema as a table.\n\nFor example, you could create a global secondary index named GameTitleIndex, with a partition key of GameTitle and a sort key of TopScore. The base table's primary key attributes are always projected into an index, so the UserId attribute is also present. The following diagram shows what GameTitleIndex index would look like.\n\nNow you can query GameTitleIndex and easily obtain the scores for Meteor Blasters. The results are ordered by the sort key values, TopScore. If you set the ScanIndexForward parameter to false, the results are returned in descending order, so the highest score is returned first.\n\nEvery global secondary index must have a partition key, and can have an optional sort key. The index key schema can be different from the base table schema. You could have a table with a simple primary key (partition key), and create a global secondary index with a composite primary key (partition key and sort key)—or vice versa. The index key attributes can consist of any top-level String, Number, or Binary attributes from the base table. Other scalar types, document types, and set types are not allowed.\n\nYou can project other base table attributes into the index if you want. When you query the index, DynamoDB can retrieve these projected attributes efficiently. However, global secondary index queries cannot fetch attributes from the base table. For example, if you query GameTitleIndex as shown in the previous diagram, the query could not access any non-key attributes other than TopScore (although the key attributes GameTitle and UserId would automatically be projected).\n\nIn a DynamoDB table, each key value must be unique. However, the key values in a global secondary index do not need to be unique. To illustrate, suppose that a game named Comet Quest is especially difficult, with many new users trying but failing to get a score above zero. The following is some data that could represent this.\n\nUserId\tGameTitle\tTopScore\n123\tComet Quest\t0\n201\tComet Quest\t0\n301\tComet Quest\t0\n\nWhen this data is added to the GameScores table, DynamoDB propagates it to GameTitleIndex. If we then query the index using Comet Quest for GameTitle and 0 for TopScore, the following data is returned.\n\nOnly the items with the specified key values appear in the response. Within that set of data, the items are in no particular order.\n\nA global secondary index only tracks data items where its key attributes actually exist. For example, suppose that you added another new item to the GameScores table, but only provided the required primary key attributes.\n\nUserId\tGameTitle\n400\tComet Quest\n\nBecause you didn't specify the TopScore attribute, DynamoDB would not propagate this item to GameTitleIndex. Thus, if you queried GameScores for all the Comet Quest items, you would get the following four items.\n\nA similar query on GameTitleIndex would still return three items, rather than four. This is because the item with the nonexistent TopScore is not propagated to the index.\n\nAttribute projections\n\nA projection is the set of attributes that is copied from a table into a secondary index. The partition key and sort key of the table are always projected into the index; you can project other attributes to support your application's query requirements. When you query an index, Amazon DynamoDB can access any attribute in the projection as if those attributes were in a table of their own.\n\nWhen you create a secondary index, you need to specify the attributes that will be projected into the index. DynamoDB provides three different options for this:\n\nKEYS_ONLY – Each item in the index consists only of the table partition key and sort key values, plus the index key values. The KEYS_ONLY option results in the smallest possible secondary index.\n\nINCLUDE – In addition to the attributes described in KEYS_ONLY, the secondary index will include other non-key attributes that you specify.\n\nALL – The secondary index includes all of the attributes from the source table. Because all of the table data is duplicated in the index, an ALL projection results in the largest possible secondary index.\n\nIn the previous diagram, GameTitleIndex has only one projected attribute: UserId. So while an application can efficiently determine the UserId of the top scorers for each game using GameTitle and TopScore in queries, it can't efficiently determine the highest ratio of wins vs. losses for the top scorers. To do so, it would have to perform an additional query on the base table to fetch the wins and losses for each of the top scorers. A more efficient way to support queries on this data would be to project these attributes from the base table into the global secondary index, as shown in this diagram.\n\nBecause the non-key attributes Wins and Losses are projected into the index, an application can determine the wins vs. losses ratio for any game, or for any combination of game and user ID.\n\nWhen you choose the attributes to project into a global secondary index, you must consider the tradeoff between provisioned throughput costs and storage costs:\n\nIf you need to access just a few attributes with the lowest possible latency, consider projecting only those attributes into a global secondary index. The smaller the index, the less that it costs to store it, and the less your write costs are.\n\nIf your application frequently accesses some non-key attributes, you should consider projecting those attributes into a global secondary index. The additional storage costs for the global secondary index offset the cost of performing frequent table scans.\n\nIf you need to access most of the non-key attributes on a frequent basis, you can project these attributes—or even the entire base table— into a global secondary index. This gives you maximum flexibility. However, your storage cost would increase, or even double.\n\nIf your application needs to query a table infrequently, but must perform many writes or updates against the data in the table, consider projecting KEYS_ONLY. The global secondary index would be of minimal size, but would still be available when needed for query activity.\n\nReading data from a Global Secondary Index\n\nYou can retrieve items from a global secondary index using the Query and Scan operations. The GetItem and BatchGetItem operations can't be used on a global secondary index.\n\nQuerying a Global Secondary Index\n\nYou can use the Query operation to access one or more items in a global secondary index. The query must specify the name of the base table and the name of the index that you want to use, the attributes to be returned in the query results, and any query conditions that you want to apply. DynamoDB can return the results in ascending or descending order.\n\nConsider the following data returned from a Query that requests gaming data for a leaderboard application.\n\n{\n    \"TableName\": \"GameScores\",\n    \"IndexName\": \"GameTitleIndex\",\n    \"KeyConditionExpression\": \"GameTitle = :v_title\",\n    \"ExpressionAttributeValues\": {\n        \":v_title\": {\"S\": \"Meteor Blasters\"}\n    },\n    \"ProjectionExpression\": \"UserId, TopScore\",\n    \"ScanIndexForward\": false\n}\n\nIn this query:\n\nDynamoDB accesses GameTitleIndex, using the GameTitle partition key to locate the index items for Meteor Blasters. All of the index items with this key are stored adjacent to each other for rapid retrieval.\n\nWithin this game, DynamoDB uses the index to access all of the user IDs and top scores for this game.\n\nThe results are returned, sorted in descending order because the ScanIndexForward parameter is set to false.\n\nScanning a Global Secondary Index\n\nYou can use the Scan operation to retrieve all of the data from a global secondary index. You must provide the base table name and the index name in the request. With a Scan, DynamoDB reads all of the data in the index and returns it to the application. You can also request that only some of the data be returned, and that the remaining data should be discarded. To do this, use the FilterExpression parameter of the Scan operation. For more information, see Filter expressions for scan.\n\nData synchronization between tables and Global Secondary Indexes\n\nDynamoDB automatically synchronizes each global secondary index with its base table. When an application writes or deletes items in a table, any global secondary indexes on that table are updated asynchronously, using an eventually consistent model. Applications never write directly to an index. However, it is important that you understand the implications of how DynamoDB maintains these indexes.\n\nGlobal secondary indexes inherit the read/write capacity mode from the base table. For more information, see Considerations when switching capacity modes.\n\nWhen you create a global secondary index, you specify one or more index key attributes and their data types. This means that whenever you write an item to the base table, the data types for those attributes must match the index key schema's data types. In the case of GameTitleIndex, the GameTitle partition key in the index is defined as a String data type. The TopScore sort key in the index is of type Number. If you try to add an item to the GameScores table and specify a different data type for either GameTitle or TopScore, DynamoDB returns a ValidationException because of the data type mismatch.\n\nWhen you put or delete items in a table, the global secondary indexes on that table are updated in an eventually consistent fashion. Changes to the table data are propagated to the global secondary indexes within a fraction of a second, under normal conditions. However, in some unlikely failure scenarios, longer propagation delays might occur. Because of this, your applications need to anticipate and handle situations where a query on a global secondary index returns results that are not up to date.\n\nIf you write an item to a table, you don't have to specify the attributes for any global secondary index sort key. Using GameTitleIndex as an example, you would not need to specify a value for the TopScore attribute to write a new item to the GameScores table. In this case, DynamoDB does not write any data to the index for this particular item.\n\nA table with many global secondary indexes incurs higher costs for write activity than tables with fewer indexes. For more information, see Provisioned throughput considerations for Global Secondary Indexes.\n\nTable classes with Global Secondary Index\n\nA global secondary index will always use the same table class as its base table. Any time a new global secondary index is added for a table, the new index will use the same table class as its base table. When a table's table class is updated, all associated global secondary indexes are updated as well.\n\nProvisioned throughput considerations for Global Secondary Indexes\n\nWhen you create a global secondary index on a provisioned mode table, you must specify read and write capacity units for the expected workload on that index. The provisioned throughput settings of a global secondary index are separate from those of its base table. A Query operation on a global secondary index consumes read capacity units from the index, not the base table. When you put, update or delete items in a table, the global secondary indexes on that table are also updated. These index updates consume write capacity units from the index, not from the base table.\n\nFor example, if you Query a global secondary index and exceed its provisioned read capacity, your request will be throttled. If you perform heavy write activity on the table, but a global secondary index on that table has insufficient write capacity, the write activity on the table will be throttled.\n\nImportant\n\nTo avoid potential throttling, the provisioned write capacity for a global secondary index should be equal or greater than the write capacity of the base table because new updates write to both the base table and global secondary index.\n\nTo view the provisioned throughput settings for a global secondary index, use the DescribeTable operation. Detailed information about all of the table's global secondary indexes is returned.\n\nRead capacity units\n\nGlobal secondary indexes support eventually consistent reads, each of which consume one half of a read capacity unit. This means that a single global secondary index query can retrieve up to 2 × 4 KB = 8 KB per read capacity unit.\n\nFor global secondary index queries, DynamoDB calculates the provisioned read activity in the same way as it does for queries against tables. The only difference is that the calculation is based on the sizes of the index entries, rather than the size of the item in the base table. The number of read capacity units is the sum of all projected attribute sizes across all of the items returned. The result is then rounded up to the next 4 KB boundary. For more information about how DynamoDB calculates provisioned throughput usage, see Provisioned capacity mode.\n\nThe maximum size of the results returned by a Query operation is 1 MB. This includes the sizes of all the attribute names and values across all of the items returned.\n\nFor example, consider a global secondary index where each item contains 2,000 bytes of data. Now suppose that you Query this index and that the query's KeyConditionExpression matches eight items. The total size of the matching items is 2,000 bytes × 8 items = 16,000 bytes. This result is then rounded up to the nearest 4 KB boundary. Because global secondary index queries are eventually consistent, the total cost is 0.5 × (16 KB / 4 KB), or 2 read capacity units.\n\nWrite capacity units\n\nWhen an item in a table is added, updated, or deleted, and a global secondary index is affected by this, the global secondary index consumes provisioned write capacity units for the operation. The total provisioned throughput cost for a write consists of the sum of write capacity units consumed by writing to the base table and those consumed by updating the global secondary indexes. If a write to a table does not require a global secondary index update, no write capacity is consumed from the index.\n\nFor a table write to succeed, the provisioned throughput settings for the table and all of its global secondary indexes must have enough write capacity to accommodate the write. Otherwise, the write to the table is throttled.\n\nThe cost of writing an item to a global secondary index depends on several factors:\n\nIf you write a new item to the table that defines an indexed attribute, or you update an existing item to define a previously undefined indexed attribute, one write operation is required to put the item into the index.\n\nIf an update to the table changes the value of an indexed key attribute (from A to B), two writes are required, one to delete the previous item from the index and another write to put the new item into the index. \n\nIf an item was present in the index, but a write to the table caused the indexed attribute to be deleted, one write is required to delete the old item projection from the index.\n\nIf an item is not present in the index before or after the item is updated, there is no additional write cost for the index.\n\nIf an update to the table only changes the value of projected attributes in the index key schema, but does not change the value of any indexed key attribute, one write is required to update the values of the projected attributes into the index.\n\nAll of these factors assume that the size of each item in the index is less than or equal to the 1 KB item size for calculating write capacity units. Larger index entries require additional write capacity units. You can minimize your write costs by considering which attributes your queries will need to return and projecting only those attributes into the index.\n\nStorage considerations for Global Secondary Indexes\n\nWhen an application writes an item to a table, DynamoDB automatically copies the correct subset of attributes to any global secondary indexes in which those attributes should appear. Your AWS account is charged for storage of the item in the base table and also for storage of attributes in any global secondary indexes on that table.\n\nThe amount of space used by an index item is the sum of the following:\n\nThe size in bytes of the base table primary key (partition key and sort key)\n\nThe size in bytes of the index key attribute\n\nThe size in bytes of the projected attributes (if any)\n\n100 bytes of overhead per index item\n\nTo estimate the storage requirements for a global secondary index, you can estimate the average size of an item in the index and then multiply by the number of items in the base table that have the global secondary index key attributes.\n\nIf a table contains an item where a particular attribute is not defined, but that attribute is defined as an index partition key or sort key, DynamoDB doesn't write any data for that item to the index."
  },
  {
    "title": "Detecting and correcting index key violations - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.OnlineOps.ViolationDetection.html",
    "html": "Detecting and correcting index key violations\nPDF\nRSS\n\nDuring the backfill phase of global secondary index creation, Amazon DynamoDB examines each item in the table to determine whether it is eligible for inclusion in the index. Some items might not be eligible because they would cause index key violations. In these cases, the items remain in the table, but the index doesn't have a corresponding entry for that item.\n\nAn index key violation occurs in the following situations:\n\nThere is a data type mismatch between an attribute value and the index key schema data type. For example, suppose that one of the items in the GameScores table had a TopScore value of type String. If you added a global secondary index with a partition key of TopScore, of type Number, the item from the table would violate the index key.\n\nAn attribute value from the table exceeds the maximum length for an index key attribute. The maximum length of a partition key is 2048 bytes, and the maximum length of a sort key is 1024 bytes. If any of the corresponding attribute values in the table exceed these limits, the item from the table would violate the index key.\n\nNote\n\nIf a String or Binary attribute value is set for an attribute that is used as an index key, then the attribute value must have a length greater than zero;, otherwise, the item from the table would violate the index key.\n\nThis tool does not flag this index key violation, at this time.\n\nIf an index key violation occurs, the backfill phase continues without interruption. However, any violating items are not included in the index. After the backfill phase completes, all writes to items that violate the new index's key schema will be rejected.\n\nTo identify and fix attribute values in a table that violate an index key, use the Violation Detector tool. To run Violation Detector, you create a configuration file that specifies the name of a table to be scanned, the names and data types of the global secondary index partition key and sort key, and what actions to take if any index key violations are found. Violation Detector can run in one of two different modes:\n\nDetection mode — Detect index key violations. Use detection mode to report the items in the table that would cause key violations in a global secondary index. (You can optionally request that these violating table items be deleted immediately when they are found.) The output from detection mode is written to a file, which you can use for further analysis.\n\nCorrection mode — Correct index key violations. In correction mode, Violation Detector reads an input file with the same format as the output file from detection mode. Correction mode reads the records from the input file and, for each record, it either deletes or updates the corresponding items in the table. (Note that if you choose to update the items, you must edit the input file and set appropriate values for these updates.)\n\nDownloading and running Violation Detector\n\nViolation Detector is available as an executable Java Archive (.jar file), and runs on Windows, macOS, or Linux computers. Violation Detector requires Java 1.7 (or later) and Apache Maven.\n\nDownload violation detector from GitHub\n\nFollow the instructions in the README.md file to download and install Violation Detector using Maven.\n\nTo start Violation Detector, go to the directory where you have built ViolationDetector.java and enter the following command.\n\njava -jar ViolationDetector.jar [options]\n\nThe Violation Detector command line accepts the following options:\n\n-h | --help — Prints a usage summary and options for Violation Detector.\n\n-p | --configFilePath value — The fully qualified name of a Violation Detector configuration file. For more information, see The Violation Detector configuration file.\n\n-t | --detect value — Detect index key violations in the table, and write them to the Violation Detector output file. If the value of this parameter is set to keep, items with key violations are not modified. If the value is set to delete, items with key violations are deleted from the table.\n\n-c | --correct value — Read index key violations from an input file, and take corrective actions on the items in the table. If the value of this parameter is set to update, items with key violations are updated with new, non-violating values. If the value is set to delete, items with key violations are deleted from the table.\n\nThe Violation Detector configuration file\n\nAt runtime, the Violation Detector tool requires a configuration file. The parameters in this file determine which DynamoDB resources that Violation Detector can access, and how much provisioned throughput it can consume. The following table describes these parameters.\n\nParameter name\tDescription\tRequired?\n\n\nawsCredentialsFile\n\n\t\n\nThe fully qualified name of a file containing your AWS credentials. The credentials file must be in the following format:\n\naccessKey = access_key_id_goes_here\nsecretKey = secret_key_goes_here \n\t\n\nYes\n\n\n\n\ndynamoDBRegion\n\n\t\n\nThe AWS Region in which the table resides. For example: us-west-2.\n\n\t\n\nYes\n\n\n\n\ntableName\n\n\tThe name of the DynamoDB table to be scanned.\t\n\nYes\n\n\n\n\ngsiHashKeyName\n\n\t\n\nThe name of the index partition key.\n\n\t\n\nYes\n\n\n\n\ngsiHashKeyType\n\n\t\n\nThe data type of the index partition key—String, Number, or Binary:\n\nS | N | B\n\n\t\n\nYes\n\n\n\n\ngsiRangeKeyName\n\n\t\n\nThe name of the index sort key. Do not specify this parameter if the index only has a simple primary key (partition key).\n\n\t\n\nNo\n\n\n\n\ngsiRangeKeyType\n\n\t\n\nThe data type of the index sort key—String, Number, or Binary:\n\nS | N | B\n\nDo not specify this parameter if the index only has a simple primary key (partition key).\n\n\t\n\nNo\n\n\n\n\nrecordDetails\n\n\t\n\nWhether to write the full details of index key violations to the output file. If set to true (the default), full information about the violating items is reported. If set to false, only the number of violations is reported.\n\n\t\n\nNo\n\n\n\n\nrecordGsiValueInViolationRecord\n\n\t\n\nWhether to write the values of the violating index keys to the output file. If set to true (default), the key values are reported. If set to false, the key values are not reported.\n\n\t\n\nNo\n\n\n\n\ndetectionOutputPath\n\n\t\n\nThe full path of the Violation Detector output file. This parameter supports writing to a local directory or to Amazon Simple Storage Service (Amazon S3). The following are examples:\n\ndetectionOutputPath = //local/path/filename.csv\n\ndetectionOutputPath = s3://bucket/filename.csv\n\nInformation in the output file appears in comma-separated values (CSV) format. If you don't set detectionOutputPath, the output file is named violation_detection.csv and is written to your current working directory.\n\n\t\n\nNo\n\n\n\n\nnumOfSegments\n\n\t\n\nThe number of parallel scan segments to be used when Violation Detector scans the table. The default value is 1, meaning that the table is scanned in a sequential manner. If the value is 2 or higher, then Violation Detector divides the table into that many logical segments and an equal number of scan threads.\n\nThe maximum setting for numOfSegments is 4096.\n\nFor larger tables, a parallel scan is generally faster than a sequential scan. In addition, if the table is large enough to span multiple partitions, a parallel scan distributes its read activity evenly across multiple partitions.\n\nFor more information about parallel scans in DynamoDB, see Parallel scan.\t\n\nNo\n\n\n\n\nnumOfViolations\n\n\t\n\nThe upper limit of index key violations to write to the output file. If set to -1 (the default), the entire table is scanned. If set to a positive integer, then Violation Detector stops after it encounters that number of violations.\n\n\t\n\nNo\n\n\n\n\nnumOfRecords\n\n\t\n\nThe number of items in the table to be scanned. If set to -1 (the default), the entire table is scanned. If set to a positive integer, Violation Detector stops after it scans that many items in the table.\n\n\t\n\nNo\n\n\n\n\nreadWriteIOPSPercent\n\n\t\n\nRegulates the percentage of provisioned read capacity units that are consumed during the table scan. Valid values range from 1 to 100. The default value (25) means that Violation Detector will consume no more than 25% of the table's provisioned read throughput.\n\n\t\n\nNo\n\n\n\n\ncorrectionInputPath\n\n\t\n\nThe full path of the Violation Detector correction input file. If you run Violation Detector in correction mode, the contents of this file are used to modify or delete data items in the table that violate the global secondary index.\n\nThe format of the correctionInputPath file is the same as that of the detectionOutputPath file. This lets you process the output from detection mode as input in correction mode.\n\n\t\n\nNo\n\n\n\n\ncorrectionOutputPath\n\n\t\n\nThe full path of the Violation Detector correction output file. This file is created only if there are update errors.\n\nThis parameter supports writing to a local directory or to Amazon S3. The following are examples:\n\ncorrectionOutputPath = //local/path/filename.csv\n\ncorrectionOutputPath = s3://bucket/filename.csv\n\nInformation in the output file appears in CSV format. If you don't set correctionOutputPath, the output file is named violation_update_errors.csv and is written to your current working directory.\n\n\t\n\nNo\n\nDetection\n\nTo detect index key violations, use Violation Detector with the --detect command line option. To show how this option works, consider the ProductCatalog table shown in Creating tables and loading data for code examples in DynamoDB. The following is a list of items in the table. Only the primary key (Id) and the Price attribute are shown.\n\nId (primary key)\tPrice\n101\t5\n102\t20\n103\t200\n201\t100\n202\t200\n203\t300\n204\t400\n205\t500\n\nAll of the values for Price are of type Number. However, because DynamoDB is schemaless, it is possible to add an item with a non-numeric Price. For example, suppose that you add another item to the ProductCatalog table.\n\nId (primary key)\tPrice\n999\t\"Hello\"\n\nThe table now has a total of nine items.\n\nNow you add a new global secondary index to the table: PriceIndex. The primary key for this index is a partition key, Price, which is of type Number. After the index has been built, it will contain eight items—but the ProductCatalog table has nine items. The reason for this discrepancy is that the value \"Hello\" is of type String, but PriceIndex has a primary key of type Number. The String value violates the global secondary index key, so it is not present in the index.\n\nTo use Violation Detector in this scenario, you first create a configuration file such as the following.\n\n\n# Properties file for violation detection tool configuration.\n# Parameters that are not specified will use default values.\n\nawsCredentialsFile = /home/alice/credentials.txt\ndynamoDBRegion = us-west-2\ntableName = ProductCatalog\ngsiHashKeyName = Price\ngsiHashKeyType = N\nrecordDetails = true\nrecordGsiValueInViolationRecord = true\ndetectionOutputPath = ./gsi_violation_check.csv\ncorrectionInputPath = ./gsi_violation_check.csv\nnumOfSegments = 1\nreadWriteIOPSPercent = 40\n\n\nNext, you run Violation Detector as in the following example.\n\n$  java -jar ViolationDetector.jar --configFilePath config.txt --detect keep\n\nViolation detection started: sequential scan, Table name: ProductCatalog, GSI name: PriceIndex\nProgress: Items scanned in total: 9,    Items scanned by this thread: 9,    Violations found by this thread: 1, Violations deleted by this thread: 0\nViolation detection finished: Records scanned: 9, Violations found: 1, Violations deleted: 0, see results at: ./gsi_violation_check.csv\n\nIf the recordDetails config parameter is set to true, Violation Detector writes details of each violation to the output file, as in the following example.\n\nTable Hash Key,GSI Hash Key Value,GSI Hash Key Violation Type,GSI Hash Key Violation Description,GSI Hash Key Update Value(FOR USER),Delete Blank Attributes When Updating?(Y/N) \n\n999,\"{\"\"S\"\":\"\"Hello\"\"}\",Type Violation,Expected: N Found: S,, \n\nThe output file is in CSV format. The first line in the file is a header, followed by one record per item that violates the index key. The fields of these violation records are as follows:\n\nTable hash key — The partition key value of the item in the table.\n\nTable range key — The sort key value of the item in the table.\n\nGSI hash key value — The partition key value of the global secondary index.\n\nGSI hash key violation type — Either Type Violation or Size Violation.\n\nGSI hash key violation description — The cause of the violation.\n\nGSI hash key update Value(FOR USER) — In correction mode, a new user-supplied value for the attribute.\n\nGSI range key value — The sort key value of the global secondary index.\n\nGSI range key violation type — Either Type Violation or Size Violation.\n\nGSI range key violation description — The cause of the violation.\n\nGSI range key update Value(FOR USER) — In correction mode, a new user-supplied value for the attribute.\n\nDelete blank attribute when Updating(Y/N) — In correction mode, determines whether to delete (Y) or keep (N) the violating item in the table—but only if either of the following fields are blank:\n\nGSI Hash Key Update Value(FOR USER)\n\nGSI Range Key Update Value(FOR USER)\n\nIf either of these fields are non-blank, then Delete Blank Attribute When Updating(Y/N) has no effect.\n\nNote\n\nThe output format might vary, depending on the configuration file and command line options. For example, if the table has a simple primary key (without a sort key), no sort key fields will be present in the output.\n\nThe violation records in the file might not be in sorted order.\n\nCorrection\n\nTo correct index key violations, use Violation Detector with the --correct command line option. In correction mode, Violation Detector reads the input file specified by the correctionInputPath parameter. This file has the same format as the detectionOutputPath file, so that you can use the output from detection as input for correction.\n\nViolation Detector provides two different ways to correct index key violations:\n\nDelete violations — Delete the table items that have violating attribute values.\n\nUpdate violations — Update the table items, replacing the violating attributes with non-violating values.\n\nIn either case, you can use the output file from detection mode as input for correction mode.\n\nContinuing with the ProductCatalog example, suppose that you want to delete the violating item from the table. To do this, you use the following command line.\n\n$  java -jar ViolationDetector.jar --configFilePath config.txt --correct delete\n\nAt this point, you are asked to confirm whether you want to delete the violating items.\n\nAre you sure to delete all violations on the table?y/n\ny\nConfirmed, will delete violations on the table...\nViolation correction from file started: Reading records from file: ./gsi_violation_check.csv, will delete these records from table.\nViolation correction from file finished: Violations delete: 1, Violations Update: 0\n\nNow both ProductCatalog and PriceIndex have the same number of items."
  },
  {
    "title": "Managing Global Secondary Indexes - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.OnlineOps.html",
    "html": "Managing Global Secondary Indexes\nPDF\nRSS\n\nThis section describes how to create, modify, and delete global secondary indexes in Amazon DynamoDB.\n\nTopics\nCreating a table with Global Secondary Indexes\nDescribing the Global Secondary Indexes on a table\nAdding a Global Secondary Index to an existing table\nDeleting a Global Secondary Index\nModifying a Global Secondary Index during creation\nDetecting and correcting index key violations\nCreating a table with Global Secondary Indexes\n\nTo create a table with one or more global secondary indexes, use the CreateTable operation with the GlobalSecondaryIndexes parameter. For maximum query flexibility, you can create up to 20 global secondary indexes (default quota) per table.\n\nYou must specify one attribute to act as the index partition key. You can optionally specify another attribute for the index sort key. It is not necessary for either of these key attributes to be the same as a key attribute in the table. For example, in the GameScores table (see Using Global Secondary Indexes in DynamoDB), neither TopScore nor TopScoreDateTime are key attributes. You could create a global secondary index with a partition key of TopScore and a sort key of TopScoreDateTime. You might use such an index to determine whether there is a correlation between high scores and the time of day a game is played.\n\nEach index key attribute must be a scalar of type String, Number, or Binary. (It cannot be a document or a set.) You can project attributes of any data type into a global secondary index. This includes scalars, documents, and sets. For a complete list of data types, see Data types.\n\nIf using provisioned mode, you must provide ProvisionedThroughput settings for the index, consisting of ReadCapacityUnits and WriteCapacityUnits. These provisioned throughput settings are separate from those of the table, but behave in similar ways. For more information, see Provisioned throughput considerations for Global Secondary Indexes.\n\nGlobal secondary indexes inherit the read/write capacity mode from the base table. For more information, see Considerations when switching capacity modes.\n\nNote\n\nBackfill operations and ongoing write operations share write throughput within the global secondary index. When creating a new GSI, it can be important to check if your choice of partition key is producing uneven or narrowed distribution of data or traffic across the new index’s partition key values. If this occurs, you could be seeing backfill and write operations occurring at the same time and throttling writes to the base table. The service takes measures to minimize the potential for this scenario, but has no insight into the shape of customer data with respect to the index partition key, the chosen projection, or the sparseness of the index primary key.\n\nIf you suspect that your new global secondary index might have narrow or skewed data or traffic distribution across partition key values, consider the following before adding new indexes to operationally important tables.\n\nIt might be safest to add the index at a time when your application is driving the least amount of traffic.\n\nConsider enabling CloudWatch Contributor Insights on your base table and indexes. This will give you valuable insight into your traffic distribution.\n\nFor provisioned capacity mode base tables and indexes, set the provisioned write capacity of your new index to at least double that of your base table. Watch WriteThrottleEvents, ThrottledRequests, OnlineIndexPercentageProgress, OnlineIndexConsumedWriteCapacity and OnlineIndexThrottleEvents CloudWatch metrics throughout the process. Adjust the provisioned write capacity as required to complete the backfill in a reasonable time without any significant throttling effects on your ongoing operations.\n\nBe prepared to cancel the index creation if you experience operational impact due to write throttling, and increasing the provisioned write capacity in your new GSI does not resolve it.\n\nDescribing the Global Secondary Indexes on a table\n\nTo view the status of all the global secondary indexes on a table, use the DescribeTable operation. The GlobalSecondaryIndexes portion of the response shows all of the indexes on the table, along with the current status of each ( IndexStatus).\n\nThe IndexStatus for a global secondary index will be one of the following:\n\nCREATING — The index is currently being created, and is not yet available for use.\n\nACTIVE — The index is ready for use, and applications can perform Query operations on the index.\n\nUPDATING — The provisioned throughput settings of the index are being changed.\n\nDELETING — The index is currently being deleted, and can no longer be used.\n\nWhen DynamoDB has finished building a global secondary index, the index status changes from CREATING to ACTIVE.\n\nAdding a Global Secondary Index to an existing table\n\nTo add a global secondary index to an existing table, use the UpdateTable operation with the GlobalSecondaryIndexUpdates parameter. You must provide the following:\n\nAn index name. The name must be unique among all the indexes on the table.\n\nThe key schema of the index. You must specify one attribute for the index partition key; you can optionally specify another attribute for the index sort key. It is not necessary for either of these key attributes to be the same as a key attribute in the table. The data types for each schema attribute must be scalar: String, Number, or Binary.\n\nThe attributes to be projected from the table into the index:\n\nKEYS_ONLY — Each item in the index consists only of the table partition key and sort key values, plus the index key values.\n\nINCLUDE — In addition to the attributes described in KEYS_ONLY, the secondary index includes other non-key attributes that you specify.\n\nALL — The index includes all of the attributes from the source table.\n\nThe provisioned throughput settings for the index, consisting of ReadCapacityUnits and WriteCapacityUnits. These provisioned throughput settings are separate from those of the table.\n\nYou can only create one global secondary index per UpdateTable operation.\n\nPhases of index creation\n\nWhen you add a new global secondary index to an existing table, the table continues to be available while the index is being built. However, the new index is not available for Query operations until its status changes from CREATING to ACTIVE.\n\nNote\n\nGlobal secondary index creation does not use Application Auto Scaling. Increasing the MIN Application Auto Scaling capacity will not decrease the creation time of the global secondary index.\n\nBehind the scenes, DynamoDB builds the index in two phases:\n\nResource Allocation\n\nDynamoDB allocates the compute and storage resources that are needed for building the index.\n\nDuring the resource allocation phase, the IndexStatus attribute is CREATING and the Backfilling attribute is false. Use the DescribeTable operation to retrieve the status of a table and all of its secondary indexes.\n\nWhile the index is in the resource allocation phase, you can't delete the index or delete its parent table. You also can't modify the provisioned throughput of the index or the table. You cannot add or delete other indexes on the table. However, you can modify the provisioned throughput of these other indexes.\n\nBackfilling\n\nFor each item in the table, DynamoDB determines which set of attributes to write to the index based on its projection (KEYS_ONLY, INCLUDE, or ALL). It then writes these attributes to the index. During the backfill phase, DynamoDB tracks the items that are being added, deleted, or updated in the table. The attributes from these items are also added, deleted, or updated in the index as appropriate.\n\nDuring the backfilling phase, the IndexStatus attribute is set to CREATING, and the Backfilling attribute is true. Use the DescribeTable operation to retrieve the status of a table and all of its secondary indexes.\n\nWhile the index is backfilling, you cannot delete its parent table. However, you can still delete the index or modify the provisioned throughput of the table and any of its global secondary indexes.\n\nNote\n\nDuring the backfilling phase, some writes of violating items might succeed while others are rejected. After backfilling, all writes to items that violate the new index's key schema are rejected. We recommend that you run the Violation Detector tool after the backfill phase finishes to detect and resolve any key violations that might have occurred. For more information, see Detecting and correcting index key violations.\n\nWhile the resource allocation and backfilling phases are in progress, the index is in the CREATING state. During this time, DynamoDB performs read operations on the table. You are not charged for read operations from the base table to populate the global secondary index. However, you are charged for write operations to populate the newly created global secondary index.\n\nWhen the index build is complete, its status changes to ACTIVE. You can't Query or Scan the index until it is ACTIVE.\n\nNote\n\nIn some cases, DynamoDB can't write data from the table to the index because of index key violations. This can occur if:\n\nThe data type of an attribute value does not match the data type of an index key schema data type.\n\nThe size of an attribute exceeds the maximum length for an index key attribute.\n\nAn index key attribute has an empty String or empty Binary attribute value.\n\nIndex key violations do not interfere with global secondary index creation. However, when the index becomes ACTIVE, the violating keys are not present in the index.\n\nDynamoDB provides a standalone tool for finding and resolving these issues. For more information, see Detecting and correcting index key violations.\n\nAdding a Global Secondary Index to a large table\n\nThe time required for building a global secondary index depends on several factors, such as the following:\n\nThe size of the table\n\nThe number of items in the table that qualify for inclusion in the index\n\nThe number of attributes projected into the index\n\nThe provisioned write capacity of the index\n\nWrite activity on the main table during index builds\n\nIf you are adding a global secondary index to a very large table, it might take a long time for the creation process to complete. To monitor progress and determine whether the index has sufficient write capacity, consult the following Amazon CloudWatch metrics:\n\nOnlineIndexPercentageProgress\n\nOnlineIndexConsumedWriteCapacity\n\nOnlineIndexThrottleEvents\n\nNote\n\nFor more information about CloudWatch metrics related to DynamoDB, see DynamoDB metrics.\n\nIf the provisioned write throughput setting on the index is too low, the index build will take longer to complete. To shorten the time it takes to build a new global secondary index, you can increase its provisioned write capacity temporarily.\n\nNote\n\nAs a general rule, we recommend setting the provisioned write capacity of the index to 1.5 times the write capacity of the table. This is a good setting for many use cases. However, your actual requirements might be higher or lower.\n\nWhile an index is being backfilled, DynamoDB uses internal system capacity to read from the table. This is to minimize the impact of the index creation and to assure that your table does not run out of read capacity.\n\nHowever, it is possible that the volume of incoming write activity might exceed the provisioned write capacity of the index. This is a bottleneck scenario, in which the index creation takes more time because the write activity to the index is throttled. During the index build, we recommend that you monitor the Amazon CloudWatch metrics for the index to determine whether its consumed write capacity is exceeding its provisioned capacity. In a bottleneck scenario, you should increase the provisioned write capacity on the index to avoid write throttling during the backfill phase.\n\nAfter the index has been created, you should set its provisioned write capacity to reflect the normal usage of your application.\n\nDeleting a Global Secondary Index\n\nIf you no longer need a global secondary index, you can delete it using the UpdateTable operation.\n\nYou can delete only one global secondary index per UpdateTable operation.\n\nWhile the global secondary index is being deleted, there is no effect on any read or write activity in the parent table. While the deletion is in progress, you can still modify the provisioned throughput on other indexes.\n\nNote\n\nWhen you delete a table using the DeleteTable action, all of the global secondary indexes on that table are also deleted.\n\nYour account will not be charged for the delete operation of the global secondary index.\n\nModifying a Global Secondary Index during creation\n\nWhile an index is being built, you can use the DescribeTable operation to determine what phase it is in. The description for the index includes a Boolean attribute, Backfilling, to indicate whether DynamoDB is currently loading the index with items from the table. If Backfilling is true, the resource allocation phase is complete and the index is now backfilling.\n\nWhile the backfill is proceeding, you can update the provisioned throughput parameters for the index. You might decide to do this in order to speed up the index build: You can increase the write capacity of the index while it is being built, and then decrease it afterward. To modify the provisioned throughput settings of the index, use the UpdateTable operation. The index status changes to UPDATING, and Backfilling is true until the index is ready for use.\n\nDuring the backfilling phase, you can delete the index that is being created. During this phase, you can't add or delete other indexes on the table.\n\nNote\n\nFor indexes that were created as part of a CreateTable operation, the Backfilling attribute does not appear in the DescribeTable output. For more information, see Phases of index creation."
  },
  {
    "title": "Improving data access with secondary indexes - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SecondaryIndexes.html",
    "html": "Improving data access with secondary indexes\nPDF\nRSS\nTopics\nUsing Global Secondary Indexes in DynamoDB\nLocal Secondary Indexes\n\nAmazon DynamoDB provides fast access to items in a table by specifying primary key values. However, many applications might benefit from having one or more secondary (or alternate) keys available, to allow efficient access to data with attributes other than the primary key. To address this, you can create one or more secondary indexes on a table and issue Query or Scan requests against these indexes.\n\nA secondary index is a data structure that contains a subset of attributes from a table, along with an alternate key to support Query operations. You can retrieve data from the index using a Query, in much the same way as you use Query with a table. A table can have multiple secondary indexes, which give your applications access to many different query patterns.\n\nNote\n\nYou can also Scan an index, in much the same way as you would Scan a table.\n\nEvery secondary index is associated with exactly one table, from which it obtains its data. This is called the base table for the index. When you create an index, you define an alternate key for the index (partition key and sort key). You also define the attributes that you want to be projected, or copied, from the base table into the index. DynamoDB copies these attributes into the index, along with the primary key attributes from the base table. You can then query or scan the index just as you would query or scan a table.\n\nEvery secondary index is automatically maintained by DynamoDB. When you add, modify, or delete items in the base table, any indexes on that table are also updated to reflect these changes.\n\nDynamoDB supports two types of secondary indexes:\n\nGlobal secondary index — An index with a partition key and a sort key that can be different from those on the base table. A global secondary index is considered \"global\" because queries on the index can span all of the data in the base table, across all partitions. A global secondary index is stored in its own partition space away from the base table and scales separately from the base table.\n\nLocal secondary index — An index that has the same partition key as the base table, but a different sort key. A local secondary index is \"local\" in the sense that every partition of a local secondary index is scoped to a base table partition that has the same partition key value.\n\nFor a comparison of global secondary indexes and local secondary indexes, see this video.\n\nYou should consider your application's requirements when you determine which type of index to use. The following table shows the main differences between a global secondary index and a local secondary index.\n\nCharacteristic\tGlobal secondary index\tLocal secondary index\nKey Schema\tThe primary key of a global secondary index can be either simple (partition key) or composite (partition key and sort key).\tThe primary key of a local secondary index must be composite (partition key and sort key).\nKey Attributes\tThe index partition key and sort key (if present) can be any base table attributes of type string, number, or binary.\tThe partition key of the index is the same attribute as the partition key of the base table. The sort key can be any base table attribute of type string, number, or binary.\nSize Restrictions Per Partition Key Value\tThere are no size restrictions for global secondary indexes.\tFor each partition key value, the total size of all indexed items must be 10 GB or less.\nOnline Index Operations\tGlobal secondary indexes can be created at the same time that you create a table. You can also add a new global secondary index to an existing table, or delete an existing global secondary index. For more information, see Managing Global Secondary Indexes.\tLocal secondary indexes are created at the same time that you create a table. You cannot add a local secondary index to an existing table, nor can you delete any local secondary indexes that currently exist.\nQueries and Partitions\tA global secondary index lets you query over the entire table, across all partitions.\tA local secondary index lets you query over a single partition, as specified by the partition key value in the query.\nRead Consistency\tQueries on global secondary indexes support eventual consistency only.\tWhen you query a local secondary index, you can choose either eventual consistency or strong consistency.\nProvisioned Throughput Consumption\tEvery global secondary index has its own provisioned throughput settings for read and write activity. Queries or scans on a global secondary index consume capacity units from the index, not from the base table. The same holds true for global secondary index updates due to table writes. A global secondary index associated with global tables consumes write capacity units.\tQueries or scans on a local secondary index consume read capacity units from the base table. When you write to a table its local secondary indexes are also updated, and these updates consume write capacity units from the base table. A local secondary index associated with global tables consumes replicated write capacity units.\nProjected Attributes\tWith global secondary index queries or scans, you can only request the attributes that are projected into the index. DynamoDB does not fetch any attributes from the table.\tIf you query or scan a local secondary index, you can request attributes that are not projected in to the index. DynamoDB automatically fetches those attributes from the table.\n\nIf you want to create more than one table with secondary indexes, you must do so sequentially. For example, you would create the first table and wait for it to become ACTIVE, create the next table and wait for it to become ACTIVE, and so on. If you try to concurrently create more than one table with a secondary index, DynamoDB returns a LimitExceededException.\n\nEach secondary index uses the same table class and capacity mode as the base table it is associated with. For each secondary index, you must specify the following:\n\nThe type of index to be created – either a global secondary index or a local secondary index.\n\nA name for the index. The naming rules for indexes are the same as those for tables, as listed in Service, account, and table quotas in Amazon DynamoDB. The name must be unique for the base table it is associated with, but you can use the same name for indexes that are associated with different base tables.\n\nThe key schema for the index. Every attribute in the index key schema must be a top-level attribute of type String, Number, or Binary. Other data types, including documents and sets, are not allowed. Other requirements for the key schema depend on the type of index:\n\nFor a global secondary index, the partition key can be any scalar attribute of the base table. A sort key is optional, and it too can be any scalar attribute of the base table.\n\nFor a local secondary index, the partition key must be the same as the base table's partition key, and the sort key must be a non-key base table attribute.\n\nAdditional attributes, if any, to project from the base table into the index. These attributes are in addition to the table's key attributes, which are automatically projected into every index. You can project attributes of any data type, including scalars, documents, and sets.\n\nThe provisioned throughput settings for the index, if necessary:\n\nFor a global secondary index, you must specify read and write capacity unit settings. These provisioned throughput settings are independent of the base table's settings.\n\nFor a local secondary index, you do not need to specify read and write capacity unit settings. Any read and write operations on a local secondary index draw from the provisioned throughput settings of its base table.\n\nFor maximum query flexibility, you can create up to 20 global secondary indexes (default quota) and up to 5 local secondary indexes per table.\n\nThe quota of global secondary indexes per table is five for the following AWS Regions:\n\nAWS GovCloud (US-East)\n\nAWS GovCloud (US-West)\n\nEurope (Stockholm)\n\nTo get a detailed listing of secondary indexes on a table, use the DescribeTable operation. DescribeTable returns the name, storage size, and item counts for every secondary index on the table. These values are not updated in real time, but they are refreshed approximately every six hours.\n\nYou can access the data in a secondary index using either the Query or Scan operation. You must specify the name of the base table and the name of the index that you want to use, the attributes to be returned in the results, and any condition expressions or filters that you want to apply. DynamoDB can return the results in ascending or descending order.\n\nWhen you delete a table, all of the indexes associated with that table are also deleted.\n\nFor best practices, see Best practices for using secondary indexes in DynamoDB."
  },
  {
    "title": "IAM security policies with PartiQL for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-iam.html",
    "html": "IAM security policies with PartiQL for DynamoDB\nPDF\nRSS\n\nThe following permissions are required:\n\nTo read items using PartiQL for DynamoDB, you must have dynamodb:PartiQLSelect permission on the table or index.\n\nTo insert items using PartiQL for DynamoDB, you must have dynamodb:PartiQLInsert permission on the table or index.\n\nTo update items using PartiQL for DynamoDB, you must have dynamodb:PartiQLUpdate permission on the table or index.\n\nTo delete items using PartiQL for DynamoDB, you must have dynamodb:PartiQLDelete permission on the table or index.\n\nExample: Allow all PartiQL for DynamoDB statements (Select/Insert/Update/Delete) on a table\n\nThe following IAM policy grants permissions to run all PartiQL for DynamoDB statements on a table.\n\n{\n   \"Version\":\"2012-10-17\",\n   \"Statement\":[\n      {\n         \"Effect\":\"Allow\",\n         \"Action\":[\n            \"dynamodb:PartiQLInsert\",\n            \"dynamodb:PartiQLUpdate\",\n            \"dynamodb:PartiQLDelete\",\n            \"dynamodb:PartiQLSelect\"\n         ],\n         \"Resource\":[\n            \"arn:aws:dynamodb:us-west-2:123456789012:table/Music\"\n         ]\n      }\n   ]\n}\nExample: Allow PartiQL for DynamoDB select statements on a table\n\nThe following IAM policy grants permissions to run the select statement on a specific table.\n\n{\n   \"Version\":\"2012-10-17\",\n   \"Statement\":[\n      {\n         \"Effect\":\"Allow\",\n         \"Action\":[\n            \"dynamodb:PartiQLSelect\"\n         ],\n         \"Resource\":[\n            \"arn:aws:dynamodb:us-west-2:123456789012:table/Music\"\n         ]\n      }\n   ]\n}\nExample: Allow PartiQL for DynamoDB insert statements on an index\n\nThe following IAM policy grants permissions to run the insert statement on a specific index.\n\n{\n   \"Version\":\"2012-10-17\",\n   \"Statement\":[\n      {\n         \"Effect\":\"Allow\",\n         \"Action\":[\n            \"dynamodb:PartiQLInsert\"\n         ],\n         \"Resource\":[\n            \"arn:aws:dynamodb:us-west-2:123456789012:table/Music/index/index1\"\n         ]\n      }\n   ]\n}\nExample: Allow PartiQL for DynamoDB transactional statements only on a table\n\nThe following IAM policy grants permissions to run only transactional statements on a specific table.\n\n{\n   \"Version\":\"2012-10-17\",\n   \"Statement\":[\n      {\n         \"Effect\":\"Allow\",\n         \"Action\":[\n            \"dynamodb:PartiQLInsert\",\n            \"dynamodb:PartiQLUpdate\",\n            \"dynamodb:PartiQLDelete\",\n            \"dynamodb:PartiQLSelect\"\n         ],\n         \"Resource\":[\n            \"arn:aws:dynamodb:us-west-2:123456789012:table/Music\"\n         ],\n         \"Condition\":{\n            \"StringEquals\":{\n               \"dynamodb:EnclosingOperation\":[\n                  \"ExecuteTransaction\"\n               ]\n            }\n         }\n      }\n   ]\n}\nExample: Allow PartiQL for DynamoDB non-transactional reads and writes and block PartiQL transactional reads and writes transactional statements on a table.\n\nThe following IAM policy grants permissions to run PartiQL for DynamoDB non-transactional reads and writes while blocking PartiQL for DynamoDB transactional reads and writes.\n\n{\n   \"Version\":\"2012-10-17\",\n   \"Statement\":[\n      {\n         \"Effect\":\"Deny\",\n         \"Action\":[\n            \"dynamodb:PartiQLInsert\",\n            \"dynamodb:PartiQLUpdate\",\n            \"dynamodb:PartiQLDelete\",\n            \"dynamodb:PartiQLSelect\"\n         ],\n         \"Resource\":[\n            \"arn:aws:dynamodb:us-west-2:123456789012:table/Music\"\n         ],\n         \"Condition\":{\n            \"StringEquals\":{\n               \"dynamodb:EnclosingOperation\":[\n                  \"ExecuteTransaction\"\n               ]\n            }\n         }\n      },\n      {\n         \"Effect\":\"Allow\",\n         \"Action\":[\n            \"dynamodb:PartiQLInsert\",\n            \"dynamodb:PartiQLUpdate\",\n            \"dynamodb:PartiQLDelete\",\n            \"dynamodb:PartiQLSelect\"\n         ],\n         \"Resource\":[\n            \"arn:aws:dynamodb:us-west-2:123456789012:table/Music\"\n         ]\n      }\n   ]\n}\nExample: Allow select statements and deny full table scan statements in PartiQL for DynamoDB\n\nThe following IAM policy grants permissions to run the select statement on a specific table while blocking select statements that result in a full table scan.\n\n{\n   \"Version\":\"2012-10-17\",\n   \"Statement\":[\n      {\n         \"Effect\":\"Deny\",\n         \"Action\":[\n            \"dynamodb:PartiQLSelect\"\n         ],\n         \"Resource\":[\n            \"arn:aws:dynamodb:us-west-2:123456789012:table/WatchList\"\n         ],\n         \"Condition\":{\n            \"Bool\":{\n               \"dynamodb:FullTableScan\":[\n                  \"true\"\n               ]\n            }\n         }\n      },\n      {\n         \"Effect\":\"Allow\",\n         \"Action\":[\n            \"dynamodb:PartiQLSelect\"\n         ],\n         \"Resource\":[\n            \"arn:aws:dynamodb:us-west-2:123456789012:table/WatchList\"\n         ]\n      }\n   ]\n}"
  },
  {
    "title": "Running batch operations with PartiQL for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-reference.multiplestatements.batching.html",
    "html": "Running batch operations with PartiQL for DynamoDB\nPDF\nRSS\n\nThis section describes how to use batch statements with PartiQL for DynamoDB.\n\nNote\n\nThe entire batch must consist of either read statements or write statements; you cannot mix both in one batch.\n\nBatchExecuteStatement and BatchWriteItem can perform no more than 25 statements per batch.\n\nTopics\nSyntax\nParameters\nExamples\nSyntax\n[\n   {\n      \"Statement\":\" statement \",\n      \"Parameters\":[\n         {\n            \" parametertype \" : \" parametervalue \"\n         }, ...]\n   } , ...\n]\nParameters\nstatement\n\n(Required) A PartiQL for DynamoDB supported statement.\n\nNote\n\nThe entire batch must consist of either read statements or write statements; you cannot mix both in one batch.\n\nBatchExecuteStatement and BatchWriteItem can perform no more than 25 statements per batch.\n\nparametertype\n\n(Optional) A DynamoDB type, if parameters were used when specifying the PartiQL statement.\n\nparametervalue\n\n(Optional) A parameter value if parameters were used when specifying the PartiQL statement.\n\nExamples\nAWS CLI\nJava\n\nSave the following json to a file called partiql.json\n\n[\n   {\n\t \"Statement\": \"INSERT INTO Music value {'Artist':'?','SongTitle':'?'}\",\n\t  \"Parameters\": [{\"S\": \"Acme Band\"}, {\"S\": \"Best Song\"}]\n\t},\n\t{\n\t \"Statement\": \"UPDATE Music SET AwardsWon=1 SET AwardDetail={'Grammys':[2020, 2018]} where Artist='Acme Band' and SongTitle='PartiQL Rocks'\"\n    }\n]\n\nRun the following command in a command prompt.\n\naws dynamodb batch-execute-statement  --statements  file://partiql.json"
  },
  {
    "title": "Performing transactions with PartiQL for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-reference.multiplestatements.transactions.html",
    "html": "Performing transactions with PartiQL for DynamoDB\nPDF\nRSS\n\nThis section describes how to use transactions with PartiQL for DynamoDB. PartiQL transactions are limited to 100 total statements (actions).\n\nFor more information on DynamoDB transactions, see Managing complex workflows with DynamoDB transactions.\n\nNote\n\nThe entire transaction must consist of either read statements or write statements. You can't mix both in one transaction. The EXISTS function is an exception. You can use it to check the condition of specific attributes of the item in a similar manner to ConditionCheck in the TransactWriteItems API operation.\n\nTopics\nSyntax\nParameters\nReturn values\nExamples\nSyntax\n[\n   {\n      \"Statement\":\" statement \",\n      \"Parameters\":[\n         {\n            \" parametertype \" : \" parametervalue \"\n         }, ...]\n   } , ...\n]\nParameters\nstatement\n\n(Required) A PartiQL for DynamoDB supported statement.\n\nNote\n\nThe entire transaction must consist of either read statements or write statements. You can't mix both in one transaction.\n\nparametertype\n\n(Optional) A DynamoDB type, if parameters were used when specifying the PartiQL statement.\n\nparametervalue\n\n(Optional) A parameter value if parameters were used when specifying the PartiQL statement.\n\nReturn values\n\nThis statement doesn't return any values for Write operations (INSERT, UPDATE, or DELETE). However, it returns different values for Read operations (SELECT) based on the conditions specified in the WHERE clause.\n\nNote\n\nIf any of the singleton INSERT, UPDATE, or DELETE operations return an error, the transactions are canceled with the TransactionCanceledException exception, and the cancellation reason code includes the errors from the individual singleton operations.\n\nExamples\n\nThe following example runs multiple statements as a transaction.\n\nAWS CLI\nJava\n\nSave the following JSON code to a file called partiql.json.\n\n[\n    {\n        \"Statement\": \"EXISTS(SELECT * FROM \\\"Music\\\" where Artist='No One You Know' and SongTitle='Call Me Today' and Awards is  MISSING)\"\n    },\n    {\n        \"Statement\": \"INSERT INTO Music value {'Artist':?,'SongTitle':'?'}\",\n        \"Parameters\": [{\\\"S\\\": \\\"Acme Band\\\"}, {\\\"S\\\": \\\"Best Song\\\"}]\n    },\n    {\n        \"Statement\": \"UPDATE \\\"Music\\\" SET AwardsWon=1 SET AwardDetail={'Grammys':[2020, 2018]}  where Artist='Acme Band' and SongTitle='PartiQL Rocks'\"\n    }\n]\n\nRun the following command in a command prompt.\n\naws dynamodb execute-transaction --transact-statements  file://partiql.json\n\nThe following example shows the different return values when DynamoDB reads items with different conditions specified in the WHERE clause.\n\nAWS CLI\n\nSave the following JSON code to a file called partiql.json.\n\n[\n    // Item exists and projected attribute exists\n    {\n        \"Statement\": \"SELECT * FROM \"Music\" WHERE Artist='No One You Know' and SongTitle='Call Me Today'\"\n    },\n    // Item exists but projected attributes do not exist\n    {\n        \"Statement\": \"SELECT non_existent_projected_attribute FROM \"Music\" WHERE Artist='No One You Know' and SongTitle='Call Me Today'\"\n    },\n    // Item does not exist\n    {\n        \"Statement\": \"SELECT * FROM \"Music\" WHERE Artist='No One I Know' and SongTitle='Call You Today'\"\n    }\n]\n\nfollowing command in a command prompt.\n\naws dynamodb execute-transaction --transact-statements  file://partiql.json\n\nThe following response is returned:\n\n{\n    \"Responses\": [\n        // Item exists and projected attribute exists\n        {\n            \"Item\": {\n                \"Artist\":{\n                    \"S\": \"No One You Know\"\n                },\n                \"SongTitle\":{\n                    \"S\": \"Call Me Today\"\n                }    \n            }\n        },\n        // Item exists but projected attributes do not exist\n        {\n            \"Item\": {}\n        },\n        // Item does not exist\n        {}\n    ]\n}"
  },
  {
    "title": "PartiQL arithmetic, comparison, and logical operators for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-operators.html",
    "html": "PartiQL arithmetic, comparison, and logical operators for DynamoDB\nPDF\nRSS\n\nPartiQL in Amazon DynamoDB supports the following SQL standard operators.\n\nNote\n\nAny SQL operators that are not included in this list are not currently supported in DynamoDB.\n\nArithmetic operators\nOperator\tDescription\n+\tAdd\n-\tSubtract\nComparison operators\nOperator\tDescription\n=\tEqual to\n<>\tNot Equal to\n!=\tNot Equal to\n>\tGreater than\n<\tLess than\n>=\tGreater than or equal to\n<=\tLess than or equal to\nLogical operators\nOperator\tDescription\nAND\tTRUE if all the conditions separated by AND are TRUE\nBETWEEN\t\n\nTRUE if the operand is within the range of comparisons.\n\nThis operator is inclusive of the lower and upper bound of the operands on which you apply it.\n\n\nIN\tTRUE if the operand is equal to one of a list of expressions (at max 50 hash attribute values or at max 100 non-key attribute values)\nIS\tTRUE if the operand is a given, PartiQL data type, including NULL or MISSING\nNOT\tReverses the value of a given Boolean expression\nOR\tTRUE if any of the conditions separated by OR are TRUE\n\nFor more information about using logical operators, see Making comparisons and Logical evaluations."
  },
  {
    "title": "Using the SIZE function with PartiQL for amazon DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-functions.size.html",
    "html": "Using the SIZE function with PartiQL for amazon DynamoDB\nPDF\nRSS\n\nReturns a number representing an attribute's size in bytes. The following are valid data types for use with size. For more information, see the DynamoDB size function.\n\nSyntax\nsize( path)\nArguments\npath\n\n(Required) The attribute name or document path.\n\nFor supported types, see DynamoDB size function.\n\nReturn type\n\nint\n\nExamples\n SELECT * FROM \"Orders\" WHERE \"OrderID\"=1 AND size(\"Image\") >300"
  },
  {
    "title": "Using the CONTAINS function with PartiQL for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-functions.contains.html",
    "html": "Using the CONTAINS function with PartiQL for DynamoDB\nPDF\nRSS\n\nReturns TRUE if the attribute specified by the path is one of the following:\n\nA String that contains a particular substring.\n\nA Set that contains a particular element within the set.\n\nFor more information, see the DynamoDB contains function.\n\nSyntax\ncontains( path, substring )\nArguments\npath\n\n(Required) The attribute name or document path to use.\n\nsubstring\n\n(Required) The attribute substring or set member to check for. For more information, see the DynamoDB contains function.\n\nReturn type\n\nbool\n\nExamples\nSELECT * FROM \"Orders\" WHERE \"OrderID\"=1 AND contains(\"Address\", 'Kirkland')"
  },
  {
    "title": "Using the MISSING function with PartiQL for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-functions.missing.html",
    "html": "Using the MISSING function with PartiQL for DynamoDB\nPDF\nRSS\n\nReturns TRUE if the item does not contain the attribute specified. Only equality and inequality operators can be used with this function.\n\nSyntax\n attributename IS | IS NOT  MISSING \nArguments\nattributename\n\n(Required) The attribute name to look for.\n\nReturn type\n\nbool\n\nExamples\nSELECT * FROM Music WHERE \"Awards\" is MISSING"
  },
  {
    "title": "Using the BEGINS_WITH function with PartiQL for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-functions.beginswith.html",
    "html": "Using the BEGINS_WITH function with PartiQL for DynamoDB\nPDF\nRSS\n\nReturns TRUE if the attribute specified begins with a particular substring.\n\nSyntax\nbegins_with(path, value )\nArguments\npath\n\n(Required) The attribute name or document path to use.\n\nvalue\n\n(Required) The string to search for.\n\nReturn type\n\nbool\n\nExamples\nSELECT * FROM \"Orders\" WHERE \"OrderID\"=1 AND begins_with(\"Address\", '7834 24th')"
  },
  {
    "title": "Using the EXISTS function with PartiQL for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-functions.exists.html",
    "html": "Using the EXISTS function with PartiQL for DynamoDB\nPDF\nRSS\n\nYou can use EXISTS to perform the same function as ConditionCheck does in the TransactWriteItems API. The EXISTS function can only be used in transactions.\n\nGiven a value, returns TRUE if the value is a non-empty collection. Otherwise, returns FALSE.\n\nNote\n\nThis function can only be used in transactional operations.\n\nSyntax\nEXISTS ( statement )\nArguments\nstatement\n\n(Required) The SELECT statement that the function evaluates.\n\nNote\n\nThe SELECT statement must specify a full primary key and one other condition.\n\nReturn type\n\nbool\n\nExamples\nEXISTS(\n    SELECT * FROM \"Music\" \n    WHERE \"Artist\" = 'Acme Band' AND \"SongTitle\" = 'PartiQL Rocks')"
  },
  {
    "title": "PartiQL insert statements for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-reference.insert.html",
    "html": "PartiQL insert statements for DynamoDB\nPDF\nRSS\n\nUse the INSERT statement to add an item to a table in Amazon DynamoDB.\n\nNote\n\nYou can only insert one item at a time; you cannot issue a single DynamoDB PartiQL statement that inserts multiple items. For information on inserting multiple items, see Performing transactions with PartiQL for DynamoDB or Running batch operations with PartiQL for DynamoDB.\n\nTopics\nSyntax\nParameters\nReturn value\nExamples\nSyntax\n\nInsert a single item.\n\nINSERT INTO table VALUE item\nParameters\ntable\n\n(Required) The table where you want to insert the data. The table must already exist.\n\nitem\n\n(Required) A valid DynamoDB item represented as a PartiQL tuple. You must specify only one item and each attribute name in the item is case-sensitive and can be denoted with single quotation marks ('...') in PartiQL.\n\nString values are also denoted with single quotation marks ('...') in PartiQL.\n\nReturn value\n\nThis statement does not return any values.\n\nNote\n\nIf the DynamoDB table already has an item with the same primary key as the primary key of the item being inserted, DuplicateItemException is returned.\n\nExamples\nINSERT INTO \"Music\" value {'Artist' : 'Acme Band','SongTitle' : 'PartiQL Rocks'}"
  },
  {
    "title": "Use PartiQL functions with amazon DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-functions.html",
    "html": "Use PartiQL functions with amazon DynamoDB\nPDF\nRSS\n\nPartiQL in Amazon DynamoDB supports the following built-in variants of SQL standard functions.\n\nNote\n\nAny SQL functions that are not included in this list are not currently supported in DynamoDB.\n\nAggregate functions\n\nUsing the SIZE function with PartiQL for amazon DynamoDB\n\nConditional functions\n\nUsing the EXISTS function with PartiQL for DynamoDB\n\nUsing the ATTRIBUTE_TYPE function with PartiQL for DynamoDB\n\nUsing the BEGINS_WITH function with PartiQL for DynamoDB\n\nUsing the CONTAINS function with PartiQL for DynamoDB\n\nUsing the MISSING function with PartiQL for DynamoDB"
  },
  {
    "title": "PartiQL delete statements for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-reference.delete.html",
    "html": "PartiQL delete statements for DynamoDB\nPDF\nRSS\n\nUse the DELETE statement to delete an existing item from your Amazon DynamoDB table.\n\nNote\n\nYou can only delete one item at a time. You cannot issue a single DynamoDB PartiQL statement that deletes multiple items. For information on deleting multiple items, see Performing transactions with PartiQL for DynamoDB or Running batch operations with PartiQL for DynamoDB.\n\nTopics\nSyntax\nParameters\nReturn value\nExamples\nSyntax\nDELETE FROM table \n WHERE condition [RETURNING returnvalues]\n <returnvalues>  ::= ALL OLD *\nParameters\ntable\n\n(Required) The DynamoDB table containing the item to be deleted.\n\ncondition\n\n(Required) The selection criteria for the item to be deleted; this condition must resolve to a single primary key value.\n\nreturnvalues\n\n(Optional) Use returnvalues if you want to get the item attributes as they appeared before they were deleted. The valid values are:\n\nALL OLD *- The content of the old item is returned.\n\nReturn value\n\nThis statement does not return a value unless returnvalues parameter is specified.\n\nNote\n\nIf the DynamoDB table does not have any item with the same primary key as that of the item for which the DELETE is issued, SUCCESS is returned with 0 items deleted. If the table has an item with same primary key, but the condition in the WHERE clause of the DELETE statement evaluates to false, ConditionalCheckFailedException is returned.\n\nExamples\n\nThe following query deletes an item in the \"Music\" table.\n\nDELETE FROM \"Music\" WHERE \"Artist\" = 'Acme Band' AND \"SongTitle\" = 'PartiQL Rocks'\n\nYou can add the parameter RETURNING ALL OLD * to return the data that was deleted.\n\nDELETE FROM \"Music\" WHERE \"Artist\" = 'Acme Band' AND \"SongTitle\" = 'PartiQL Rocks' RETURNING ALL OLD *\n\nThe Delete statement now returns the following:\n\n{\n    \"Items\": [\n        {\n            \"Artist\": {\n                \"S\": \"Acme Band\"\n            },\n            \"SongTitle\": {\n                \"S\": \"PartiQL Rocks\"\n            }\n        }\n    ]\n}"
  },
  {
    "title": "PartiQL update statements for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-reference.update.html",
    "html": "PartiQL update statements for DynamoDB\nPDF\nRSS\n\nUse the UPDATE statement to modify the value of one or more attributes within an item in an Amazon DynamoDB table.\n\nNote\n\nYou can only update one item at a time; you cannot issue a single DynamoDB PartiQL statement that updates multiple items. For information on updating multiple items, see Performing transactions with PartiQL for DynamoDB or Running batch operations with PartiQL for DynamoDB.\n\nTopics\nSyntax\nParameters\nReturn value\nExamples\nSyntax\nUPDATE  table  \n[SET | REMOVE]  path  [=  data] […]\nWHERE condition [RETURNING returnvalues]\n<returnvalues>  ::= [ALL OLD | MODIFIED OLD | ALL NEW | MODIFIED NEW] *\nParameters\ntable\n\n(Required) The table containing the data to be modified.\n\npath\n\n(Required) An attribute name or document path to be created or modified.\n\ndata\n\n(Required) An attribute value or the result of an operation.\n\nThe supported operations to use with SET:\n\nLIST_APPEND: adds a value to a list type.\n\nSET_ADD: adds a value to a number or string set.\n\nSET_DELETE: removes a value from a number or string set.\n\ncondition\n\n(Required) The selection criteria for the item to be modified. This condition must resolve to a single primary key value.\n\nreturnvalues\n\n(Optional) Use returnvalues if you want to get the item attributes as they appear before or after they are updated. The valid values are:\n\nALL OLD *- Returns all of the attributes of the item, as they appeared before the update operation.\n\nMODIFIED OLD *- Returns only the updated attributes, as they appeared before the update operation.\n\nALL NEW *- Returns all of the attributes of the item, as they appear after the update operation.\n\nMODIFIED NEW *- Returns only the updated attributes, as they appear after the UpdateItem operation.\n\nReturn value\n\nThis statement does not return a value unless returnvalues parameter is specified.\n\nNote\n\nIf the WHERE clause of the UPDATE statement does not evaluate to true for any item in the DynamoDB table, ConditionalCheckFailedException is returned.\n\nExamples\n\nUpdate an attribute value in an existing item. If the attribute does not exist, it is created.\n\nThe following query updates an item in the \"Music\" table by adding an attribute of type number (AwardsWon) and an attribute of type map (AwardDetail).\n\nUPDATE \"Music\" \nSET AwardsWon=1 \nSET AwardDetail={'Grammys':[2020, 2018]}  \nWHERE Artist='Acme Band' AND SongTitle='PartiQL Rocks'\n\nYou can add RETURNING ALL OLD * to return the attributes as they appeared before the Update operation.\n\nUPDATE \"Music\" \nSET AwardsWon=1 \nSET AwardDetail={'Grammys':[2020, 2018]}  \nWHERE Artist='Acme Band' AND SongTitle='PartiQL Rocks'\nRETURNING ALL OLD *\n\nThis returns the following:\n\n{\n    \"Items\": [\n        {\n            \"Artist\": {\n                \"S\": \"Acme Band\"\n            },\n            \"SongTitle\": {\n                \"S\": \"PartiQL Rocks\"\n            }\n        }\n    ]\n}\n\nYou can add RETURNING ALL NEW * to return the attributes as they appeared after the Update operation.\n\nUPDATE \"Music\" \nSET AwardsWon=1 \nSET AwardDetail={'Grammys':[2020, 2018]}  \nWHERE Artist='Acme Band' AND SongTitle='PartiQL Rocks'\nRETURNING ALL NEW *\n\nThis returns the following:\n\n{\n    \"Items\": [\n        {\n            \"AwardDetail\": {\n                \"M\": {\n                    \"Grammys\": {\n                        \"L\": [\n                            {\n                                \"N\": \"2020\"\n                            },\n                            {\n                                \"N\": \"2018\"\n                            }\n                        ]\n                    }\n                }\n            },\n            \"AwardsWon\": {\n                \"N\": \"1\"\n            }\n        }\n    ]\n}\n\nThe following query updates an item in the \"Music\" table by appending to a list AwardDetail.Grammys.\n\nUPDATE \"Music\" \nSET AwardDetail.Grammys =list_append(AwardDetail.Grammys,[2016])  \nWHERE Artist='Acme Band' AND SongTitle='PartiQL Rocks'\n\nThe following query updates an item in the \"Music\" table by removing from a list AwardDetail.Grammys.\n\nUPDATE \"Music\" \nREMOVE AwardDetail.Grammys[2]   \nWHERE Artist='Acme Band' AND SongTitle='PartiQL Rocks'\n\nThe following query updates an item in the \"Music\" table by adding BillBoard to the map AwardDetail.\n\nUPDATE \"Music\" \nSET AwardDetail.BillBoard=[2020] \nWHERE Artist='Acme Band' AND SongTitle='PartiQL Rocks'\n\nThe following query updates an item in the \"Music\" table by adding the string set attribute BandMembers.\n\nUPDATE \"Music\" \nSET BandMembers =<<'member1', 'member2'>> \nWHERE Artist='Acme Band' AND SongTitle='PartiQL Rocks'\n\nThe following query updates an item in the \"Music\" table by adding newbandmember to the string set BandMembers.\n\nUPDATE \"Music\" \nSET BandMembers =set_add(BandMembers, <<'newbandmember'>>) \nWHERE Artist='Acme Band' AND SongTitle='PartiQL Rocks'"
  },
  {
    "title": "PartiQL select statements for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-reference.select.html",
    "html": "PartiQL select statements for DynamoDB\nPDF\nRSS\n\nUse the SELECT statement to retrieve data from a table in Amazon DynamoDB.\n\nUsing the SELECT statement can result in a full table scan if an equality or IN condition with a partition key is not provided in the WHERE clause. A scan operation examines every item for the requested values and can use up the provisioned throughput for a large table or index in a single operation.\n\nIf you want to avoid full table scan in PartiQL, you can:\n\nAuthor your SELECT statements to not result in full table scans by making sure your WHERE clause condition is configured accordingly.\n\nDisable full table scans using the IAM policy specified at Example: Allow select statements and deny full table scan statements in PartiQL for DynamoDB, in the DynamoDB developer guide.\n\nFor more information see Best practices for querying and scanning data, in the DynamoDB developer guide.\n\nTopics\nSyntax\nParameters\nExamples\nSyntax\nSELECT expression  [, ...] \nFROM table[.index]\n[ WHERE condition ] [ [ORDER BY key [DESC|ASC] , ...]\nParameters\nexpression\n\n(Required) A projection formed from the * wildcard or a projection list of one or more attribute names or document paths from the result set. An expression can consist of calls to Use PartiQL functions with amazon DynamoDB or fields that are modified by PartiQL arithmetic, comparison, and logical operators for DynamoDB .\n\ntable\n\n(Required) The table name to query.\n\nindex\n\n(Optional) The name of the index to query.\n\nNote\n\nYou must add double quotation marks to the table name and index name when querying an index.\n\nSELECT * \nFROM \"TableName\".\"IndexName\" \n\ncondition\n\n(Optional) The selection criteria for the query.\n\nImportant\n\nTo ensure that a SELECT statement does not result in a full table scan, the WHERE clause condition must specify a partition key. Use the equality or IN operator.\n\nFor example, if you have an Orders table with an OrderID partition key and other non-key attributes, including an Address, the following statements would not result in a full table scan:\n\nSELECT * \nFROM \"Orders\" \nWHERE OrderID = 100\n\nSELECT * \nFROM \"Orders\" \nWHERE OrderID = 100 and Address='some address'\n\nSELECT * \nFROM \"Orders\" \nWHERE OrderID = 100 or pk = 200\n\nSELECT * \nFROM \"Orders\" \nWHERE OrderID IN [100, 300, 234]\n\nThe following SELECT statements, however, will result in a full table scan:\n\nSELECT * \nFROM \"Orders\" \nWHERE OrderID > 1\n\nSELECT * \nFROM \"Orders\" \nWHERE Address='some address'\n\nSELECT * \nFROM \"Orders\" \nWHERE OrderID = 100 OR Address='some address'\nkey\n\n(Optional) A hash key or a sort key to use to order returned results. The default order is ascending (ASC) specify DESC if you want the results retuned in descending order.\n\nNote\n\nIf you omit the WHERE clause, then all of the items in the table are retrieved.\n\nExamples\n\nThe following query returns one item, if one exists, from the Orders table by specifying the partition key, OrderID, and using the equality operator.\n\nSELECT OrderID, Total\nFROM \"Orders\"\nWHERE OrderID = 1\n\nThe following query returns all items in the Orders table that have a specific partition key, OrderID, values using the OR operator.\n\nSELECT OrderID, Total\nFROM \"Orders\"\nWHERE OrderID = 1 OR OrderID = 2\n\nThe following query returns all items in the Orders table that have a specific partition key, OrderID, values using the IN operator. The returned results are in descending order, based on the OrderID key attribute value.\n\nSELECT OrderID, Total\nFROM \"Orders\"\nWHERE OrderID IN [1, 2, 3] ORDER BY OrderID DESC\n\nThe following query shows a full table scan that returns all items from the Orders table that have a Total greater than 500, where Total is a non-key attribute.\n\nSELECT OrderID, Total \nFROM \"Orders\"\nWHERE Total > 500\n\nThe following query shows a full table scan that returns all items from the Orders table within a specific Total order range, using the IN operator and a non-key attribute Total.\n\nSELECT OrderID, Total \nFROM \"Orders\"\nWHERE Total IN [500, 600]\n\nThe following query shows a full table scan that returns all items from the Orders table within a specific Total order range, using the BETWEEN operator and a non-key attribute Total.\n\nSELECT OrderID, Total \nFROM \"Orders\" \nWHERE Total BETWEEN 500 AND 600\n\nThe following query returns the first date a firestick device was used to watch by specifying the partition key CustomerID and sort key MovieID in the WHERE clause condition and using document paths in the SELECT clause.\n\nSELECT Devices.FireStick.DateWatched[0] \nFROM WatchList \nWHERE CustomerID= 'C1' AND MovieID= 'M1'\n\nThe following query shows a full table scan that returns the list of items where a firestick device was first used after 12/24/19 using document paths in the WHERE clause condition.\n\nSELECT Devices \nFROM WatchList \nWHERE Devices.FireStick.DateWatched[0] >= '12/24/19'"
  },
  {
    "title": "PartiQL statements for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-reference.statements.html",
    "html": "PartiQL statements for DynamoDB\nPDF\nRSS\n\nAmazon DynamoDB supports the following PartiQL statements.\n\nNote\n\nDynamoDB does not support all PartiQL statements.\n\nThis reference provides basic syntax and usage examples of PartiQL statements that you manually run using the AWS CLI or APIs.\n\nData manipulation language (DML) is the set of PartiQL statements that you use to manage data in DynamoDB tables. You use DML statements to add, modify, or delete data in a table.\n\nThe following DML and query language statements are supported:\n\nPartiQL select statements for DynamoDB\n\nPartiQL update statements for DynamoDB\n\nPartiQL insert statements for DynamoDB\n\nPartiQL delete statements for DynamoDB\n\nPerforming transactions with PartiQL for DynamoDB and Running batch operations with PartiQL for DynamoDB are also supported by PartiQL for DynamoDB."
  },
  {
    "title": "Getting started with PartiQL for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-gettingstarted.html",
    "html": "Getting started with PartiQL for DynamoDB\nPDF\nRSS\n\nThis section describes how to use PartiQL for DynamoDB from the Amazon DynamoDB console, the AWS Command Line Interface (AWS CLI), and DynamoDB APIs.\n\nIn the following examples, the DynamoDB table that is defined in the Getting started with DynamoDB tutorial is a pre-requisite.\n\nFor information about using the DynamoDB console, AWS Command Line Interface, or DynamoDB APIs to access DynamoDB, see Accessing DynamoDB.\n\nTo download and use the NoSQL workbench to build PartiQL for DynamoDB statements choose PartiQL operations at the top right corner of the NoSQL Workbench for DynamoDB Operation builder.\n\nConsole\nNoSQL workbench\nAWS CLI\nJava\nNote\n\nPartiQL for DynamoDB is only available in the new DynamoDB console. To use the new DynamoDB console, choose Try the Preview of the new console in the navigation pane on the left side of the console.\n\nSign in to the AWS Management Console and open the DynamoDB console at https://console.aws.amazon.com/dynamodb/.\n\nIn the navigation pane on the left side of the console, choose PartiQL editor.\n\nChoose the Music table.\n\nChoose Query table. This action generates a query that will not result in a full table scan.\n\nReplace partitionKeyValue with the string value Acme Band. Replace sortKeyValue with the string value Happy Day.\n\nChoose the Run button.\n\nYou can view the results of the query by choosing the Table view or the JSON view buttons."
  },
  {
    "title": "PartiQL - a SQL-compatible query language for Amazon DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-reference.html",
    "html": "PartiQL - a SQL-compatible query language for Amazon DynamoDB\nPDF\nRSS\n\nAmazon DynamoDB supports PartiQL, a SQL-compatible query language, to select, insert, update, and delete data in Amazon DynamoDB. Using PartiQL, you can easily interact with DynamoDB tables and run ad hoc queries using the AWS Management Console, NoSQL Workbench, AWS Command Line Interface, and DynamoDB APIs for PartiQL.\n\nPartiQL operations provide the same availability, latency, and performance as the other DynamoDB data plane operations.\n\nThe following sections describe the DynamoDB implementation of PartiQL.\n\nTopics\nWhat is PartiQL?\nPartiQL in Amazon DynamoDB\nGetting started\nData types\nStatements\nFunctions\nOperators\nTransactions\nBatch operations\nIAM policies\nWhat is PartiQL?\n\nPartiQL provides SQL-compatible query access across multiple data stores containing structured data, semistructured data, and nested data. It is widely used within Amazon and is now available as part of many AWS services, including DynamoDB.\n\nFor the PartiQL specification and a tutorial on the core query language, see the PartiQL documentation.\n\nNote\n\nAmazon DynamoDB supports a subset of the PartiQL query language.\n\nAmazon DynamoDB does not support the Amazon ion data format or Amazon Ion literals.\n\nPartiQL in Amazon DynamoDB\n\nTo run PartiQL queries in DynamoDB, you can use:\n\nThe DynamoDB console\n\nThe NoSQL Workbench\n\nThe AWS Command Line Interface (AWS CLI)\n\nThe DynamoDB APIs\n\nFor information about using these methods to access DynamoDB, see Accessing DynamoDB."
  },
  {
    "title": "Scanning tables and indexes: .NET - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LowLevelDotNetScanning.html",
    "html": "Scanning tables and indexes: .NET\nPDF\nRSS\n\nThe Scan operation reads all of the items in a table or index in Amazon DynamoDB.\n\nThe following are the steps to scan a table using the AWS SDK for .NET low-level API:\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nCreate an instance of the ScanRequest class and provide scan operation parameters.\n\nThe only required parameter is the table name.\n\nRun the Scan method and provide the ScanRequest object that you created in the preceding step.\n\nThe following Reply table stores replies for forum threads.\n\nExample\n>Reply ( <emphasis role=\"underline\">Id</emphasis>, <emphasis role=\"underline\">ReplyDateTime</emphasis>, Message, PostedBy )\n\nThe table maintains all the replies for various forum threads. Therefore, the primary key is composed of both the Id (partition key) and ReplyDateTime (sort key). The following C# code example scans the entire table. The ScanRequest instance specifies the name of the table to scan.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\nvar request = new ScanRequest\n{\n    TableName = \"Reply\",\n};\n\nvar response = client.Scan(request);\nvar result = response.ScanResult;\n\nforeach (Dictionary<string, AttributeValue> item in response.ScanResult.Items)\n{\n  // Process the result.\n  PrintItem(item);\n}\nSpecifying optional parameters\n\nThe Scan method supports several optional parameters. For example, you can optionally use a scan filter to filter the scan result. In a scan filter, you can specify a condition and an attribute name on which you want the condition evaluated. For more information, see Scan.\n\nThe following C# code scans the ProductCatalog table to find items that are priced less than 0. The sample specifies the following optional parameters:\n\nA FilterExpression parameter to retrieve only the items priced less than 0 (error condition).\n\nA ProjectionExpression parameter to specify the attributes to retrieve for items in the query results.\n\nThe following C# example scans the ProductCatalog table to find all items priced less than 0.\n\nExample\nvar forumScanRequest = new ScanRequest\n {\n   TableName = \"ProductCatalog\",\n   // Optional parameters.\n   ExpressionAttributeValues = new Dictionary<string,AttributeValue> {\n        {\":val\", new AttributeValue { N = \"0\" }}\n   },\n   FilterExpression = \"Price < :val\",\n   ProjectionExpression = \"Id\"\n };\n\nYou can also optionally limit the page size or the number of items per page, by adding the optional Limit parameter. Each time you run the Scan method, you get one page of results that has the specified number of items. To fetch the next page, you run the Scan method again by providing the primary key value of the last item in the previous page so that the Scan method can return the next set of items. You provide this information in the request by setting the ExclusiveStartKey property. Initially, this property can be null. To retrieve subsequent pages, you must update this property value to the primary key of the last item in the preceding page.\n\nThe following C# code example scans the ProductCatalog table. In the request, it specifies the Limit and ExclusiveStartKey optional parameters. The do/while loop continues to scan one page at time until the LastEvaluatedKey returns a null value.\n\nExample\nDictionary<string, AttributeValue> lastKeyEvaluated = null;\ndo\n{\n    var request = new ScanRequest\n    {\n        TableName = \"ProductCatalog\",\n        Limit = 10,\n        ExclusiveStartKey = lastKeyEvaluated\n    };\n\n    var response = client.Scan(request);\n\n    foreach (Dictionary<string, AttributeValue> item\n      in response.Items)\n    {\n        PrintItem(item);\n    }\n    lastKeyEvaluated = response.LastEvaluatedKey;\n\n} while (lastKeyEvaluated != null && lastKeyEvaluated.Count != 0);\nExample - scan using .NET\n\nThe following C# code provides a working example that scans the ProductCatalog table to find items priced less than 0.\n\nFor step-by-step instructions for testing the following sample, see .NET code examples.\n\nusing System;\nusing System.Collections.Generic;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.Model;\nusing Amazon.Runtime;\n\nnamespace com.amazonaws.codesamples\n{\n    class LowLevelScan\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                FindProductsForPriceLessThanZero();\n\n                Console.WriteLine(\"Example complete. To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (Exception e)\n            {\n                Console.WriteLine(e.Message);\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n        }\n\n        private static void FindProductsForPriceLessThanZero()\n        {\n            Dictionary<string, AttributeValue> lastKeyEvaluated = null;\n            do\n            {\n                var request = new ScanRequest\n                {\n                    TableName = \"ProductCatalog\",\n                    Limit = 2,\n                    ExclusiveStartKey = lastKeyEvaluated,\n                    ExpressionAttributeValues = new Dictionary<string, AttributeValue> {\n                    {\":val\", new AttributeValue {\n                         N = \"0\"\n                     }}\n                },\n                    FilterExpression = \"Price < :val\",\n\n                    ProjectionExpression = \"Id, Title, Price\"\n                };\n\n                var response = client.Scan(request);\n\n                foreach (Dictionary<string, AttributeValue> item\n                     in response.Items)\n                {\n                    Console.WriteLine(\"\\nScanThreadTableUsePaging - printing.....\");\n                    PrintItem(item);\n                }\n                lastKeyEvaluated = response.LastEvaluatedKey;\n            } while (lastKeyEvaluated != null && lastKeyEvaluated.Count != 0);\n\n            Console.WriteLine(\"To continue, press Enter\");\n            Console.ReadLine();\n        }\n\n        private static void PrintItem(\n            Dictionary<string, AttributeValue> attributeList)\n        {\n            foreach (KeyValuePair<string, AttributeValue> kvp in attributeList)\n            {\n                string attributeName = kvp.Key;\n                AttributeValue value = kvp.Value;\n\n                Console.WriteLine(\n                    attributeName + \" \" +\n                    (value.S == null ? \"\" : \"S=[\" + value.S + \"]\") +\n                    (value.N == null ? \"\" : \"N=[\" + value.N + \"]\") +\n                    (value.SS == null ? \"\" : \"SS=[\" + string.Join(\",\", value.SS.ToArray()) + \"]\") +\n                    (value.NS == null ? \"\" : \"NS=[\" + string.Join(\",\", value.NS.ToArray()) + \"]\")\n                    );\n            }\n            Console.WriteLine(\"************************************************\");\n        }\n    }\n}\n\nExample - parallel scan using .NET\n\nThe following C# code example demonstrates a parallel scan. The program deletes and then re-creates the ProductCatalog table and then loads the table with data. When the data load is finished, the program spawns multiple threads and issues parallel Scan requests. Finally, the program prints a summary of runtime statistics.\n\nFor step-by-step instructions for testing the following sample, see .NET code examples.\n\nusing System;\nusing System.Collections.Generic;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.Model;\nusing Amazon.Runtime;\n\nnamespace com.amazonaws.codesamples\n{\n    class LowLevelParallelScan\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n        private static string tableName = \"ProductCatalog\";\n        private static int exampleItemCount = 100;\n        private static int scanItemLimit = 10;\n        private static int totalSegments = 5;\n\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                DeleteExampleTable();\n                CreateExampleTable();\n                UploadExampleData();\n                ParallelScanExampleTable();\n            }\n            catch (AmazonDynamoDBException e) { Console.WriteLine(e.Message); }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n\n            Console.WriteLine(\"To continue, press Enter\");\n            Console.ReadLine();\n        }\n\n        private static void ParallelScanExampleTable()\n        {\n            Console.WriteLine(\"\\n*** Creating {0} Parallel Scan Tasks to scan {1}\", totalSegments, tableName);\n            Task[] tasks = new Task[totalSegments];\n            for (int segment = 0; segment < totalSegments; segment++)\n            {\n                int tmpSegment = segment;\n                Task task = Task.Factory.StartNew(() =>\n                                  {\n                                      ScanSegment(totalSegments, tmpSegment);\n                                  });\n\n                tasks[segment] = task;\n            }\n\n            Console.WriteLine(\"All scan tasks are created, waiting for them to complete.\");\n            Task.WaitAll(tasks);\n\n            Console.WriteLine(\"All scan tasks are completed.\");\n        }\n\n        private static void ScanSegment(int totalSegments, int segment)\n        {\n            Console.WriteLine(\"*** Starting to Scan Segment {0} of {1} out of {2} total segments ***\", segment, tableName, totalSegments);\n            Dictionary<string, AttributeValue> lastEvaluatedKey = null;\n            int totalScannedItemCount = 0;\n            int totalScanRequestCount = 0;\n            do\n            {\n                var request = new ScanRequest\n                {\n                    TableName = tableName,\n                    Limit = scanItemLimit,\n                    ExclusiveStartKey = lastEvaluatedKey,\n                    Segment = segment,\n                    TotalSegments = totalSegments\n                };\n\n                var response = client.Scan(request);\n                lastEvaluatedKey = response.LastEvaluatedKey;\n                totalScanRequestCount++;\n                totalScannedItemCount += response.ScannedCount;\n                foreach (var item in response.Items)\n                {\n                    Console.WriteLine(\"Segment: {0}, Scanned Item with Title: {1}\", segment, item[\"Title\"].S);\n                }\n            } while (lastEvaluatedKey.Count != 0);\n\n            Console.WriteLine(\"*** Completed Scan Segment {0} of {1}. TotalScanRequestCount: {2}, TotalScannedItemCount: {3} ***\", segment, tableName, totalScanRequestCount, totalScannedItemCount);\n        }\n\n        private static void UploadExampleData()\n        {\n            Console.WriteLine(\"\\n*** Uploading {0} Example Items to {1} Table***\", exampleItemCount, tableName);\n            Console.Write(\"Uploading Items: \");\n            for (int itemIndex = 0; itemIndex < exampleItemCount; itemIndex++)\n            {\n                Console.Write(\"{0}, \", itemIndex);\n                CreateItem(itemIndex.ToString());\n            }\n            Console.WriteLine();\n        }\n\n        private static void CreateItem(string itemIndex)\n        {\n            var request = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = new Dictionary<string, AttributeValue>()\n            {\n                { \"Id\", new AttributeValue {\n                      N = itemIndex\n                  }},\n                { \"Title\", new AttributeValue {\n                      S = \"Book \" + itemIndex + \" Title\"\n                  }},\n                { \"ISBN\", new AttributeValue {\n                      S = \"11-11-11-11\"\n                  }},\n                { \"Authors\", new AttributeValue {\n                      SS = new List<string>{\"Author1\", \"Author2\" }\n                  }},\n                { \"Price\", new AttributeValue {\n                      N = \"20.00\"\n                  }},\n                { \"Dimensions\", new AttributeValue {\n                      S = \"8.5x11.0x.75\"\n                  }},\n                { \"InPublication\", new AttributeValue {\n                      BOOL = false\n                  } }\n            }\n            };\n            client.PutItem(request);\n        }\n\n        private static void CreateExampleTable()\n        {\n            Console.WriteLine(\"\\n*** Creating {0} Table ***\", tableName);\n            var request = new CreateTableRequest\n            {\n                AttributeDefinitions = new List<AttributeDefinition>()\n            {\n                new AttributeDefinition\n                {\n                    AttributeName = \"Id\",\n                    AttributeType = \"N\"\n                }\n            },\n                KeySchema = new List<KeySchemaElement>\n            {\n                new KeySchemaElement\n                {\n                    AttributeName = \"Id\",\n                    KeyType = \"HASH\" //Partition key\n                }\n            },\n                ProvisionedThroughput = new ProvisionedThroughput\n                {\n                    ReadCapacityUnits = 5,\n                    WriteCapacityUnits = 6\n                },\n                TableName = tableName\n            };\n\n            var response = client.CreateTable(request);\n\n            var result = response;\n            var tableDescription = result.TableDescription;\n            Console.WriteLine(\"{1}: {0} \\t ReadsPerSec: {2} \\t WritesPerSec: {3}\",\n                      tableDescription.TableStatus,\n                      tableDescription.TableName,\n                      tableDescription.ProvisionedThroughput.ReadCapacityUnits,\n                      tableDescription.ProvisionedThroughput.WriteCapacityUnits);\n\n            string status = tableDescription.TableStatus;\n            Console.WriteLine(tableName + \" - \" + status);\n\n            WaitUntilTableReady(tableName);\n        }\n\n        private static void DeleteExampleTable()\n        {\n            try\n            {\n                Console.WriteLine(\"\\n*** Deleting {0} Table ***\", tableName);\n                var request = new DeleteTableRequest\n                {\n                    TableName = tableName\n                };\n\n                var response = client.DeleteTable(request);\n                var result = response;\n                Console.WriteLine(\"{0} is being deleted...\", tableName);\n                WaitUntilTableDeleted(tableName);\n            }\n            catch (ResourceNotFoundException)\n            {\n                Console.WriteLine(\"{0} Table delete failed: Table does not exist\", tableName);\n            }\n        }\n\n        private static void WaitUntilTableReady(string tableName)\n        {\n            string status = null;\n            // Let us wait until table is created. Call DescribeTable.\n            do\n            {\n                System.Threading.Thread.Sleep(5000); // Wait 5 seconds.\n                try\n                {\n                    var res = client.DescribeTable(new DescribeTableRequest\n                    {\n                        TableName = tableName\n                    });\n\n                    Console.WriteLine(\"Table name: {0}, status: {1}\",\n                              res.Table.TableName,\n                              res.Table.TableStatus);\n                    status = res.Table.TableStatus;\n                }\n                catch (ResourceNotFoundException)\n                {\n                    // DescribeTable is eventually consistent. So you might\n                    // get resource not found. So we handle the potential exception.\n                }\n            } while (status != \"ACTIVE\");\n        }\n\n        private static void WaitUntilTableDeleted(string tableName)\n        {\n            string status = null;\n            // Let us wait until table is deleted. Call DescribeTable.\n            do\n            {\n                System.Threading.Thread.Sleep(5000); // Wait 5 seconds.\n                try\n                {\n                    var res = client.DescribeTable(new DescribeTableRequest\n                    {\n                        TableName = tableName\n                    });\n\n                    Console.WriteLine(\"Table name: {0}, status: {1}\",\n                              res.Table.TableName,\n                              res.Table.TableStatus);\n                    status = res.Table.TableStatus;\n                }\n                catch (ResourceNotFoundException)\n                {\n                    Console.WriteLine(\"Table name: {0} is not found. It is deleted\", tableName);\n                    return;\n                }\n            } while (status == \"DELETING\");\n        }\n    }\n}\n"
  },
  {
    "title": "Scanning tables and indexes: Java - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ScanJavaDocumentAPI.html",
    "html": "Scanning tables and indexes: Java\nPDF\nRSS\n\nThe Scan operation reads all of the items in a table or index in Amazon DynamoDB.\n\nThe following are the steps to scan a table using the AWS SDK for Java Document API.\n\nCreate an instance of the AmazonDynamoDB class.\n\nCreate an instance of the ScanRequest class and provide scan parameter.\n\nThe only required parameter is the table name.\n\nRun the scan method and provide the ScanRequest object that you created in the preceding step.\n\nThe following Reply table stores replies for forum threads.\n\nExample\nReply ( Id, ReplyDateTime, Message, PostedBy )\n\nThe table maintains all the replies for various forum threads. Therefore, the primary key is composed of both the Id (partition key) and ReplyDateTime (sort key). The following Java code example scans the entire table. The ScanRequest instance specifies the name of the table to scan.\n\nExample\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n\nScanRequest scanRequest = new ScanRequest()\n    .withTableName(\"Reply\");\n\nScanResponse result = client.scan(scanRequest);\nfor (Map<String, AttributeValue> item : result.getItems()){\n    printItem(item);\n}\nSpecifying optional parameters\n\nThe scan method supports several optional parameters. For example, you can optionally use a filter expression to filter the scan result. In a filter expression, you can specify a condition and attribute names and values on which you want the condition evaluated. For more information, see Scan.\n\nThe following Java example scans the ProductCatalog table to find items that are priced less than 0. The example specifies the following optional parameters:\n\nA filter expression to retrieve only the items priced less than 0 (error condition).\n\nA list of attributes to retrieve for items in the query results.\n\nExample\nMap<String, AttributeValue> expressionAttributeValues =\n    new HashMap<String, AttributeValue>();\nexpressionAttributeValues.put(\":val\", new AttributeValue().withN(\"0\"));\n\nScanRequest scanRequest = new ScanRequest()\n    .withTableName(\"ProductCatalog\")\n    .withFilterExpression(\"Price < :val\")\n    .withProjectionExpression(\"Id\")\n    .withExpressionAttributeValues(expressionAttributeValues);\n\n\nScanResponse result = client.scan(scanRequest);\nfor (Map<String, AttributeValue> item : result.getItems()) {\n    printItem(item);\n}\n\nYou can also optionally limit the page size, or the number of items per page, by using the withLimit method of the scan request. Each time you run the scan method, you get one page of results that has the specified number of items. To fetch the next page, you run the scan method again by providing the primary key value of the last item in the previous page so that the scan method can return the next set of items. You provide this information in the request by using the withExclusiveStartKey method. Initially, the parameter of this method can be null. To retrieve subsequent pages, you must update this property value to the primary key of the last item in the preceding page.\n\nThe following Java code example scans the ProductCatalog table. In the request, the withLimit and withExclusiveStartKey methods are used. The do/while loop continues to scan one page at time until the getLastEvaluatedKey method of the result returns a value of null.\n\nExample\nMap<String, AttributeValue> lastKeyEvaluated = null;\ndo {\n    ScanRequest scanRequest = new ScanRequest()\n        .withTableName(\"ProductCatalog\")\n        .withLimit(10)\n        .withExclusiveStartKey(lastKeyEvaluated);\n\n    ScanResponse result = client.scan(scanRequest);\n    for (Map<String, AttributeValue> item : result.getItems()){\n        printItem(item);\n    }\n    lastKeyEvaluated = result.getLastEvaluatedKey();\n} while (lastKeyEvaluated != null);\nExample - scan using Java\n\nThe following Java code example provides a working sample that scans the ProductCatalog table to find items that are priced less than 100.\n\nNote\n\nThe SDK for Java also provides an object persistence model, enabling you to map your client-side classes to DynamoDB tables. This approach can reduce the amount of code that you have to write. For more information, see Java 1.x: DynamoDBMapper.\n\nNote\n\nThis code example assumes that you have already loaded data into DynamoDB for your account by following the instructions in the Creating tables and loading data for code examples in DynamoDB section.\n\nFor step-by-step instructions to run the following example, see Java code examples.\n\n\npackage com.amazonaws.codesamples.document;\n\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.Map;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.document.DynamoDB;\nimport com.amazonaws.services.dynamodbv2.document.Item;\nimport com.amazonaws.services.dynamodbv2.document.ItemCollection;\nimport com.amazonaws.services.dynamodbv2.document.ScanOutcome;\nimport com.amazonaws.services.dynamodbv2.document.Table;\n\npublic class DocumentAPIScan {\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n    static DynamoDB dynamoDB = new DynamoDB(client);\n    static String tableName = \"ProductCatalog\";\n\n    public static void main(String[] args) throws Exception {\n\n        findProductsForPriceLessThanOneHundred();\n    }\n\n    private static void findProductsForPriceLessThanOneHundred() {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        Map<String, Object> expressionAttributeValues = new HashMap<String, Object>();\n        expressionAttributeValues.put(\":pr\", 100);\n\n        ItemCollection<ScanOutcome> items = table.scan(\"Price < :pr\", // FilterExpression\n                \"Id, Title, ProductCategory, Price\", // ProjectionExpression\n                null, // ExpressionAttributeNames - not used in this example\n                expressionAttributeValues);\n\n        System.out.println(\"Scan of \" + tableName + \" for items with a price less than 100.\");\n        Iterator<Item> iterator = items.iterator();\n        while (iterator.hasNext()) {\n            System.out.println(iterator.next().toJSONPretty());\n        }\n    }\n\n}\n\n\nExample - parallel scan using Java\n\nThe following Java code example demonstrates a parallel scan. The program deletes and re-creates a table named ParallelScanTest, and then loads the table with data. When the data load is finished, the program spawns multiple threads and issues parallel Scan requests. The program prints runtime statistics for each parallel request.\n\nNote\n\nThe SDK for Java also provides an object persistence model, enabling you to map your client-side classes to DynamoDB tables. This approach can reduce the amount of code that you have to write. For more information, see Java 1.x: DynamoDBMapper.\n\nNote\n\nThis code example assumes that you have already loaded data into DynamoDB for your account by following the instructions in the Creating tables and loading data for code examples in DynamoDB section.\n\nFor step-by-step instructions to run the following example, see Java code examples.\n\n\npackage com.amazonaws.codesamples.document;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashSet;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\n\nimport com.amazonaws.AmazonServiceException;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.document.DynamoDB;\nimport com.amazonaws.services.dynamodbv2.document.Item;\nimport com.amazonaws.services.dynamodbv2.document.ItemCollection;\nimport com.amazonaws.services.dynamodbv2.document.ScanOutcome;\nimport com.amazonaws.services.dynamodbv2.document.Table;\nimport com.amazonaws.services.dynamodbv2.document.spec.ScanSpec;\nimport com.amazonaws.services.dynamodbv2.model.AttributeDefinition;\nimport com.amazonaws.services.dynamodbv2.model.KeySchemaElement;\nimport com.amazonaws.services.dynamodbv2.model.KeyType;\nimport com.amazonaws.services.dynamodbv2.model.ProvisionedThroughput;\n\npublic class DocumentAPIParallelScan {\n\n    // total number of sample items\n    static int scanItemCount = 300;\n\n    // number of items each scan request should return\n    static int scanItemLimit = 10;\n\n    // number of logical segments for parallel scan\n    static int parallelScanThreads = 16;\n\n    // table that will be used for scanning\n    static String parallelScanTestTableName = \"ParallelScanTest\";\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n    static DynamoDB dynamoDB = new DynamoDB(client);\n\n    public static void main(String[] args) throws Exception {\n        try {\n\n            // Clean up the table\n            deleteTable(parallelScanTestTableName);\n            createTable(parallelScanTestTableName, 10L, 5L, \"Id\", \"N\");\n\n            // Upload sample data for scan\n            uploadSampleProducts(parallelScanTestTableName, scanItemCount);\n\n            // Scan the table using multiple threads\n            parallelScan(parallelScanTestTableName, scanItemLimit, parallelScanThreads);\n        } catch (AmazonServiceException ase) {\n            System.err.println(ase.getMessage());\n        }\n    }\n\n    private static void parallelScan(String tableName, int itemLimit, int numberOfThreads) {\n        System.out.println(\n                \"Scanning \" + tableName + \" using \" + numberOfThreads + \" threads \" + itemLimit + \" items at a time\");\n        ExecutorService executor = Executors.newFixedThreadPool(numberOfThreads);\n\n        // Divide DynamoDB table into logical segments\n        // Create one task for scanning each segment\n        // Each thread will be scanning one segment\n        int totalSegments = numberOfThreads;\n        for (int segment = 0; segment < totalSegments; segment++) {\n            // Runnable task that will only scan one segment\n            ScanSegmentTask task = new ScanSegmentTask(tableName, itemLimit, totalSegments, segment);\n\n            // Execute the task\n            executor.execute(task);\n        }\n\n        shutDownExecutorService(executor);\n    }\n\n    // Runnable task for scanning a single segment of a DynamoDB table\n    private static class ScanSegmentTask implements Runnable {\n\n        // DynamoDB table to scan\n        private String tableName;\n\n        // number of items each scan request should return\n        private int itemLimit;\n\n        // Total number of segments\n        // Equals to total number of threads scanning the table in parallel\n        private int totalSegments;\n\n        // Segment that will be scanned with by this task\n        private int segment;\n\n        public ScanSegmentTask(String tableName, int itemLimit, int totalSegments, int segment) {\n            this.tableName = tableName;\n            this.itemLimit = itemLimit;\n            this.totalSegments = totalSegments;\n            this.segment = segment;\n        }\n\n        @Override\n        public void run() {\n            System.out.println(\"Scanning \" + tableName + \" segment \" + segment + \" out of \" + totalSegments\n                    + \" segments \" + itemLimit + \" items at a time...\");\n            int totalScannedItemCount = 0;\n\n            Table table = dynamoDB.getTable(tableName);\n\n            try {\n                ScanSpec spec = new ScanSpec().withMaxResultSize(itemLimit).withTotalSegments(totalSegments)\n                        .withSegment(segment);\n\n                ItemCollection<ScanOutcome> items = table.scan(spec);\n                Iterator<Item> iterator = items.iterator();\n\n                Item currentItem = null;\n                while (iterator.hasNext()) {\n                    totalScannedItemCount++;\n                    currentItem = iterator.next();\n                    System.out.println(currentItem.toString());\n                }\n\n            } catch (Exception e) {\n                System.err.println(e.getMessage());\n            } finally {\n                System.out.println(\"Scanned \" + totalScannedItemCount + \" items from segment \" + segment + \" out of \"\n                        + totalSegments + \" of \" + tableName);\n            }\n        }\n    }\n\n    private static void uploadSampleProducts(String tableName, int itemCount) {\n        System.out.println(\"Adding \" + itemCount + \" sample items to \" + tableName);\n        for (int productIndex = 0; productIndex < itemCount; productIndex++) {\n            uploadProduct(tableName, productIndex);\n        }\n    }\n\n    private static void uploadProduct(String tableName, int productIndex) {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        try {\n            System.out.println(\"Processing record #\" + productIndex);\n\n            Item item = new Item().withPrimaryKey(\"Id\", productIndex)\n                    .withString(\"Title\", \"Book \" + productIndex + \" Title\").withString(\"ISBN\", \"111-1111111111\")\n                    .withStringSet(\"Authors\", new HashSet<String>(Arrays.asList(\"Author1\"))).withNumber(\"Price\", 2)\n                    .withString(\"Dimensions\", \"8.5 x 11.0 x 0.5\").withNumber(\"PageCount\", 500)\n                    .withBoolean(\"InPublication\", true).withString(\"ProductCategory\", \"Book\");\n            table.putItem(item);\n\n        } catch (Exception e) {\n            System.err.println(\"Failed to create item \" + productIndex + \" in \" + tableName);\n            System.err.println(e.getMessage());\n        }\n    }\n\n    private static void deleteTable(String tableName) {\n        try {\n\n            Table table = dynamoDB.getTable(tableName);\n            table.delete();\n            System.out.println(\"Waiting for \" + tableName + \" to be deleted...this may take a while...\");\n            table.waitForDelete();\n\n        } catch (Exception e) {\n            System.err.println(\"Failed to delete table \" + tableName);\n            e.printStackTrace(System.err);\n        }\n    }\n\n    private static void createTable(String tableName, long readCapacityUnits, long writeCapacityUnits,\n            String partitionKeyName, String partitionKeyType) {\n\n        createTable(tableName, readCapacityUnits, writeCapacityUnits, partitionKeyName, partitionKeyType, null, null);\n    }\n\n    private static void createTable(String tableName, long readCapacityUnits, long writeCapacityUnits,\n            String partitionKeyName, String partitionKeyType, String sortKeyName, String sortKeyType) {\n\n        try {\n            System.out.println(\"Creating table \" + tableName);\n\n            List<KeySchemaElement> keySchema = new ArrayList<KeySchemaElement>();\n            keySchema.add(new KeySchemaElement().withAttributeName(partitionKeyName).withKeyType(KeyType.HASH)); // Partition\n                                                                                                                 // key\n\n            List<AttributeDefinition> attributeDefinitions = new ArrayList<AttributeDefinition>();\n            attributeDefinitions\n                    .add(new AttributeDefinition().withAttributeName(partitionKeyName)\n                            .withAttributeType(partitionKeyType));\n\n            if (sortKeyName != null) {\n                keySchema.add(new KeySchemaElement().withAttributeName(sortKeyName).withKeyType(KeyType.RANGE)); // Sort\n                                                                                                                 // key\n                attributeDefinitions\n                        .add(new AttributeDefinition().withAttributeName(sortKeyName).withAttributeType(sortKeyType));\n            }\n\n            Table table = dynamoDB.createTable(tableName, keySchema, attributeDefinitions, new ProvisionedThroughput()\n                    .withReadCapacityUnits(readCapacityUnits).withWriteCapacityUnits(writeCapacityUnits));\n            System.out.println(\"Waiting for \" + tableName + \" to be created...this may take a while...\");\n            table.waitForActive();\n\n        } catch (Exception e) {\n            System.err.println(\"Failed to create table \" + tableName);\n            e.printStackTrace(System.err);\n        }\n    }\n\n    private static void shutDownExecutorService(ExecutorService executor) {\n        executor.shutdown();\n        try {\n            if (!executor.awaitTermination(10, TimeUnit.SECONDS)) {\n                executor.shutdownNow();\n            }\n        } catch (InterruptedException e) {\n            executor.shutdownNow();\n\n            // Preserve interrupt status\n            Thread.currentThread().interrupt();\n        }\n    }\n}\n\n"
  },
  {
    "title": "Querying tables and indexes: .NET - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LowLevelDotNetQuerying.html",
    "html": "Querying tables and indexes: .NET\nPDF\nRSS\n\nThe Query operation enables you to query a table or a secondary index in Amazon DynamoDB. You must provide a partition key value and an equality condition. If the table or index has a sort key, you can refine the results by providing a sort key value and a condition.\n\nThe following are the steps to query a table using the low-level AWS SDK for .NET API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nCreate an instance of the QueryRequest class and provide query operation parameters.\n\nRun the Query method and provide the QueryRequest object that you created in the preceding step.\n\nThe response includes the QueryResult object that provides all items returned by the query.\n\nThe following C# code example demonstrates the preceding tasks. The code assumes that you have a Reply table that stores replies for forum threads. For more information, see Creating tables and loading data for code examples in DynamoDB.\n\nExample\nReply Id, ReplyDateTime, ... )\n\nEach forum thread has a unique ID and can have zero or more replies. Therefore, the primary key is composed of both the Id (partition key) and ReplyDateTime (sort key).\n\nThe following query retrieves all replies for a specific thread subject. The query requires both the table name and the Subject value.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\nvar request = new QueryRequest\n{\n    TableName = \"Reply\",\n    KeyConditionExpression = \"Id = :v_Id\",\n    ExpressionAttributeValues = new Dictionary<string, AttributeValue> {\n        {\":v_Id\", new AttributeValue { S =  \"Amazon DynamoDB#DynamoDB Thread 1\" }}}\n};\n\nvar response = client.Query(request);\n\nforeach (Dictionary<string, AttributeValue> item in response.Items)\n{\n    // Process the result.\n    PrintItem(item);\n} \nSpecifying optional parameters\n\nThe Query method supports several optional parameters. For example, you can optionally narrow the query result in the preceding query to return replies in the past two weeks by specifying a condition. The condition is called a sort key condition, because DynamoDB evaluates the query condition that you specify against the sort key of the primary key. You can specify other optional parameters to retrieve only a specific list of attributes from items in the query result. For more information, see Query.\n\nThe following C# code example retrieves forum thread replies posted in the past 15 days. The example specifies the following optional parameters:\n\nA KeyConditionExpression to retrieve only the replies in the past 15 days.\n\nA ProjectionExpression parameter to specify a list of attributes to retrieve for items in the query result.\n\nA ConsistentRead parameter to perform a strongly consistent read.\n\nExample\nDateTime twoWeeksAgoDate = DateTime.UtcNow - TimeSpan.FromDays(15);\nstring twoWeeksAgoString = twoWeeksAgoDate.ToString(AWSSDKUtils.ISO8601DateFormat);\n\nvar request = new QueryRequest\n{\n    TableName = \"Reply\",\n    KeyConditionExpression = \"Id = :v_Id and ReplyDateTime > :v_twoWeeksAgo\",\n    ExpressionAttributeValues = new Dictionary<string, AttributeValue> {\n        {\":v_Id\", new AttributeValue { S =  \"Amazon DynamoDB#DynamoDB Thread 2\" }},\n        {\":v_twoWeeksAgo\", new AttributeValue { S =  twoWeeksAgoString }}\n    },\n    ProjectionExpression = \"Subject, ReplyDateTime, PostedBy\",\n    ConsistentRead = true\n};\n\nvar response = client.Query(request);\n\nforeach (Dictionary<string, AttributeValue> item in response.Items)\n{\n    // Process the result.\n    PrintItem(item);\n}\n\n\nYou can also optionally limit the page size, or the number of items per page, by adding the optional Limit parameter. Each time you run the Query method, you get one page of results that has the specified number of items. To fetch the next page, you run the Query method again by providing the primary key value of the last item in the previous page so that the method can return the next set of items. You provide this information in the request by setting the ExclusiveStartKey property. Initially, this property can be null. To retrieve subsequent pages, you must update this property value to the primary key of the last item in the preceding page.\n\nThe following C# example queries the Reply table. In the request, it specifies the Limit and ExclusiveStartKey optional parameters. The do/while loop continues to scan one page at time until the LastEvaluatedKey returns a null value.\n\nExample\n\nDictionary<string,AttributeValue> lastKeyEvaluated = null;\n\ndo\n{\n    var request = new QueryRequest\n    {\n        TableName = \"Reply\",\n        KeyConditionExpression = \"Id = :v_Id\",\n        ExpressionAttributeValues = new Dictionary<string, AttributeValue> {\n            {\":v_Id\", new AttributeValue { S =  \"Amazon DynamoDB#DynamoDB Thread 2\" }}\n        },\n\n        // Optional parameters.\n        Limit = 1,\n        ExclusiveStartKey = lastKeyEvaluated\n    };\n\n    var response = client.Query(request);\n\n    // Process the query result.\n    foreach (Dictionary<string, AttributeValue> item in response.Items)\n    {\n         PrintItem(item);\n    }\n\n    lastKeyEvaluated = response.LastEvaluatedKey;\n\n} while (lastKeyEvaluated != null && lastKeyEvaluated.Count != 0);\n\nExample - querying using the AWS SDK for .NET\n\nThe following tables store information about a collection of forums. For more information, see Creating tables and loading data for code examples in DynamoDB.\n\nExample\nForum ( Name, ... )\nThread ( ForumName, Subject, Message, LastPostedBy, LastPostDateTime, ...)\nReply ( Id, ReplyDateTime, Message, PostedBy, ...)\n\nIn this example, you run variations of \"Find replies for a thread \"DynamoDB Thread 1\" in forum \"DynamoDB\".\n\nFind replies for a thread.\n\nFind replies for a thread. Specify the Limit query parameter to set page size.\n\nThis function illustrates the use of pagination to process multipage result. DynamoDB has a page size limit and if your result exceeds the page size, you get only the first page of results. This coding pattern ensures your code processes all the pages in the query result.\n\nFind replies in the last 15 days.\n\nFind replies in a specific date range.\n\nThe preceding two queries show how you can specify sort key conditions to narrow query results and use other optional query parameters.\n\nFor step-by-step instructions for testing the following example, see .NET code examples.\n\nusing System;\nusing System.Collections.Generic;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.Model;\nusing Amazon.Runtime;\nusing Amazon.Util;\n\nnamespace com.amazonaws.codesamples\n{\n    class LowLevelQuery\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                // Query a specific forum and thread.\n                string forumName = \"Amazon DynamoDB\";\n                string threadSubject = \"DynamoDB Thread 1\";\n\n                FindRepliesForAThread(forumName, threadSubject);\n                FindRepliesForAThreadSpecifyOptionalLimit(forumName, threadSubject);\n                FindRepliesInLast15DaysWithConfig(forumName, threadSubject);\n                FindRepliesPostedWithinTimePeriod(forumName, threadSubject);\n\n                Console.WriteLine(\"Example complete. To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (AmazonDynamoDBException e) { Console.WriteLine(e.Message); Console.ReadLine(); }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); Console.ReadLine(); }\n            catch (Exception e) { Console.WriteLine(e.Message); Console.ReadLine(); }\n        }\n\n        private static void FindRepliesPostedWithinTimePeriod(string forumName, string threadSubject)\n        {\n            Console.WriteLine(\"*** Executing FindRepliesPostedWithinTimePeriod() ***\");\n            string replyId = forumName + \"#\" + threadSubject;\n            // You must provide date value based on your test data.\n            DateTime startDate = DateTime.UtcNow - TimeSpan.FromDays(21);\n            string start = startDate.ToString(AWSSDKUtils.ISO8601DateFormat);\n\n            // You provide date value based on your test data.\n            DateTime endDate = DateTime.UtcNow - TimeSpan.FromDays(5);\n            string end = endDate.ToString(AWSSDKUtils.ISO8601DateFormat);\n\n            var request = new QueryRequest\n            {\n                TableName = \"Reply\",\n                ReturnConsumedCapacity = \"TOTAL\",\n                KeyConditionExpression = \"Id = :v_replyId and ReplyDateTime between :v_start and :v_end\",\n                ExpressionAttributeValues = new Dictionary<string, AttributeValue> {\n                {\":v_replyId\", new AttributeValue {\n                     S = replyId\n                 }},\n                {\":v_start\", new AttributeValue {\n                     S = start\n                 }},\n                {\":v_end\", new AttributeValue {\n                     S = end\n                 }}\n            }\n            };\n\n            var response = client.Query(request);\n\n            Console.WriteLine(\"\\nNo. of reads used (by query in FindRepliesPostedWithinTimePeriod) {0}\",\n                      response.ConsumedCapacity.CapacityUnits);\n            foreach (Dictionary<string, AttributeValue> item\n                 in response.Items)\n            {\n                PrintItem(item);\n            }\n            Console.WriteLine(\"To continue, press Enter\");\n            Console.ReadLine();\n        }\n\n        private static void FindRepliesInLast15DaysWithConfig(string forumName, string threadSubject)\n        {\n            Console.WriteLine(\"*** Executing FindRepliesInLast15DaysWithConfig() ***\");\n            string replyId = forumName + \"#\" + threadSubject;\n\n            DateTime twoWeeksAgoDate = DateTime.UtcNow - TimeSpan.FromDays(15);\n            string twoWeeksAgoString =\n                twoWeeksAgoDate.ToString(AWSSDKUtils.ISO8601DateFormat);\n\n            var request = new QueryRequest\n            {\n                TableName = \"Reply\",\n                ReturnConsumedCapacity = \"TOTAL\",\n                KeyConditionExpression = \"Id = :v_replyId and ReplyDateTime > :v_interval\",\n                ExpressionAttributeValues = new Dictionary<string, AttributeValue> {\n                {\":v_replyId\", new AttributeValue {\n                     S = replyId\n                 }},\n                {\":v_interval\", new AttributeValue {\n                     S = twoWeeksAgoString\n                 }}\n            },\n\n                // Optional parameter.\n                ProjectionExpression = \"Id, ReplyDateTime, PostedBy\",\n                // Optional parameter.\n                ConsistentRead = true\n            };\n\n            var response = client.Query(request);\n\n            Console.WriteLine(\"No. of reads used (by query in FindRepliesInLast15DaysWithConfig) {0}\",\n                      response.ConsumedCapacity.CapacityUnits);\n            foreach (Dictionary<string, AttributeValue> item\n                 in response.Items)\n            {\n                PrintItem(item);\n            }\n            Console.WriteLine(\"To continue, press Enter\");\n            Console.ReadLine();\n        }\n\n        private static void FindRepliesForAThreadSpecifyOptionalLimit(string forumName, string threadSubject)\n        {\n            Console.WriteLine(\"*** Executing FindRepliesForAThreadSpecifyOptionalLimit() ***\");\n            string replyId = forumName + \"#\" + threadSubject;\n\n            Dictionary<string, AttributeValue> lastKeyEvaluated = null;\n            do\n            {\n                var request = new QueryRequest\n                {\n                    TableName = \"Reply\",\n                    ReturnConsumedCapacity = \"TOTAL\",\n                    KeyConditionExpression = \"Id = :v_replyId\",\n                    ExpressionAttributeValues = new Dictionary<string, AttributeValue> {\n                    {\":v_replyId\", new AttributeValue {\n                         S = replyId\n                     }}\n                },\n                    Limit = 2, // The Reply table has only a few sample items. So the page size is smaller.\n                    ExclusiveStartKey = lastKeyEvaluated\n                };\n\n                var response = client.Query(request);\n\n                Console.WriteLine(\"No. of reads used (by query in FindRepliesForAThreadSpecifyLimit) {0}\\n\",\n                          response.ConsumedCapacity.CapacityUnits);\n                foreach (Dictionary<string, AttributeValue> item\n                     in response.Items)\n                {\n                    PrintItem(item);\n                }\n                lastKeyEvaluated = response.LastEvaluatedKey;\n            } while (lastKeyEvaluated != null && lastKeyEvaluated.Count != 0);\n\n            Console.WriteLine(\"To continue, press Enter\");\n\n\n            Console.ReadLine();\n        }\n\n        private static void FindRepliesForAThread(string forumName, string threadSubject)\n        {\n            Console.WriteLine(\"*** Executing FindRepliesForAThread() ***\");\n            string replyId = forumName + \"#\" + threadSubject;\n\n            var request = new QueryRequest\n            {\n                TableName = \"Reply\",\n                ReturnConsumedCapacity = \"TOTAL\",\n                KeyConditionExpression = \"Id = :v_replyId\",\n                ExpressionAttributeValues = new Dictionary<string, AttributeValue> {\n                {\":v_replyId\", new AttributeValue {\n                     S = replyId\n                 }}\n            }\n            };\n\n            var response = client.Query(request);\n            Console.WriteLine(\"No. of reads used (by query in FindRepliesForAThread) {0}\\n\",\n                      response.ConsumedCapacity.CapacityUnits);\n            foreach (Dictionary<string, AttributeValue> item in response.Items)\n            {\n                PrintItem(item);\n            }\n            Console.WriteLine(\"To continue, press Enter\");\n            Console.ReadLine();\n        }\n\n        private static void PrintItem(\n            Dictionary<string, AttributeValue> attributeList)\n        {\n            foreach (KeyValuePair<string, AttributeValue> kvp in attributeList)\n            {\n                string attributeName = kvp.Key;\n                AttributeValue value = kvp.Value;\n\n                Console.WriteLine(\n                    attributeName + \" \" +\n                    (value.S == null ? \"\" : \"S=[\" + value.S + \"]\") +\n                    (value.N == null ? \"\" : \"N=[\" + value.N + \"]\") +\n                    (value.SS == null ? \"\" : \"SS=[\" + string.Join(\",\", value.SS.ToArray()) + \"]\") +\n                    (value.NS == null ? \"\" : \"NS=[\" + string.Join(\",\", value.NS.ToArray()) + \"]\")\n                    );\n            }\n            Console.WriteLine(\"************************************************\");\n        }\n    }\n}\n\n"
  },
  {
    "title": "Working with scans in DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Scan.html",
    "html": "Working with scans in DynamoDB\nPDF\nRSS\n\nA Scan operation in Amazon DynamoDB reads every item in a table or a secondary index. By default, a Scan operation returns all of the data attributes for every item in the table or index. You can use the ProjectionExpression parameter so that Scan only returns some of the attributes, rather than all of them.\n\nScan always returns a result set. If no matching items are found, the result set is empty.\n\nA single Scan request can retrieve a maximum of 1 MB of data. Optionally, DynamoDB can apply a filter expression to this data, narrowing the results before they are returned to the user.\n\nTopics\nFilter expressions for scan\nLimiting the number of items in the result set\nPaginating the results\nCounting the items in the results\nCapacity units consumed by scan\nRead consistency for scan\nParallel scan\nScanning tables and indexes: Java\nScanning tables and indexes: .NET\nFilter expressions for scan\n\nIf you need to further refine the Scan results, you can optionally provide a filter expression. A filter expression determines which items within the Scan results should be returned to you. All of the other results are discarded.\n\nA filter expression is applied after a Scan finishes but before the results are returned. Therefore, a Scan consumes the same amount of read capacity, regardless of whether a filter expression is present.\n\nA Scan operation can retrieve a maximum of 1 MB of data. This limit applies before the filter expression is evaluated.\n\nWith Scan, you can specify any attributes in a filter expression—including partition key and sort key attributes.\n\nThe syntax for a filter expression is identical to that of a condition expression. Filter expressions can use the same comparators, functions, and logical operators as a condition expression. See Comparison operator and function reference for more information about logical operators.\n\nExample\n\nThe following AWS Command Line Interface (AWS CLI) example scans the Thread table and returns only the items that were last posted to by a particular user.\n\naws dynamodb scan \\\n     --table-name Thread \\\n     --filter-expression \"LastPostedBy = :name\" \\\n     --expression-attribute-values '{\":name\":{\"S\":\"User A\"}}'\nLimiting the number of items in the result set\n\nThe Scan operation enables you to limit the number of items that it returns in the result. To do this, set the Limit parameter to the maximum number of items that you want the Scan operation to return, prior to filter expression evaluation.\n\nFor example, suppose that you Scan a table with a Limit value of 6 and without a filter expression. The Scan result contains the first six items from the table.\n\nNow suppose that you add a filter expression to the Scan. In this case, DynamoDB applies the filter expression to the six items that were returned, discarding those that do not match. The final Scan result contains six items or fewer, depending on the number of items that were filtered.\n\nPaginating the results\n\nDynamoDB paginates the results from Scan operations. With pagination, the Scan results are divided into \"pages\" of data that are 1 MB in size (or less). An application can process the first page of results, then the second page, and so on.\n\nA single Scan only returns a result set that fits within the 1 MB size limit.\n\nTo determine whether there are more results and to retrieve them one page at a time, applications should do the following:\n\nExamine the low-level Scan result:\n\nIf the result contains a LastEvaluatedKey element, proceed to step 2.\n\nIf there is not a LastEvaluatedKey in the result, then there are no more items to be retrieved.\n\nConstruct a new Scan request, with the same parameters as the previous one. However, this time, take the LastEvaluatedKey value from step 1 and use it as the ExclusiveStartKey parameter in the new Scan request.\n\nRun the new Scan request.\n\nGo to step 1.\n\nIn other words, the LastEvaluatedKey from a Scan response should be used as the ExclusiveStartKey for the next Scan request. If there is not a LastEvaluatedKey element in a Scan response, you have retrieved the final page of results. (The absence of LastEvaluatedKey is the only way to know that you have reached the end of the result set.)\n\nYou can use the AWS CLI to view this behavior. The AWS CLI sends low-level Scan requests to DynamoDB, repeatedly, until LastEvaluatedKey is no longer present in the results. Consider the following AWS CLI example that scans the entire Movies table but returns only the movies from a particular genre.\n\naws dynamodb scan \\\n    --table-name Movies \\\n    --projection-expression \"title\" \\\n    --filter-expression 'contains(info.genres,:gen)' \\\n    --expression-attribute-values '{\":gen\":{\"S\":\"Sci-Fi\"}}' \\\n    --page-size 100  \\\n    --debug\n\nOrdinarily, the AWS CLI handles pagination automatically. However, in this example, the AWS CLI --page-size parameter limits the number of items per page. The --debug parameter prints low-level information about requests and responses.\n\nNote\n\nYour pagination results will also differ based on the input parameters you pass.\n\nUsing aws dynamodb scan --table-name Prices --max-items 1 returns a NextToken\n\nUsing aws dynamodb scan --table-name Prices --limit 1 returns a LastEvaluatedKey.\n\nAlso be aware that using --starting-token in particular requires the NextToken value.\n\nIf you run the example, the first response from DynamoDB looks similar to the following.\n\n2017-07-07 12:19:14,389 - MainThread - botocore.parsers - DEBUG - Response body:\nb'{\"Count\":7,\"Items\":[{\"title\":{\"S\":\"Monster on the Campus\"}},{\"title\":{\"S\":\"+1\"}},\n{\"title\":{\"S\":\"100 Degrees Below Zero\"}},{\"title\":{\"S\":\"About Time\"}},{\"title\":{\"S\":\"After Earth\"}},\n{\"title\":{\"S\":\"Age of Dinosaurs\"}},{\"title\":{\"S\":\"Cloudy with a Chance of Meatballs 2\"}}],\n\"LastEvaluatedKey\":{\"year\":{\"N\":\"2013\"},\"title\":{\"S\":\"Curse of Chucky\"}},\"ScannedCount\":100}'\n\nThe LastEvaluatedKey in the response indicates that not all of the items have been retrieved. The AWS CLI then issues another Scan request to DynamoDB. This request and response pattern continues, until the final response.\n\n2017-07-07 12:19:17,830 - MainThread - botocore.parsers - DEBUG - Response body:\nb'{\"Count\":1,\"Items\":[{\"title\":{\"S\":\"WarGames\"}}],\"ScannedCount\":6}'\n\nThe absence of LastEvaluatedKey indicates that there are no more items to retrieve.\n\nNote\n\nThe AWS SDKs handle the low-level DynamoDB responses (including the presence or absence of LastEvaluatedKey) and provide various abstractions for paginating Scan results. For example, the SDK for Java document interface provides java.util.Iterator support so that you can walk through the results one at a time.\n\nFor code examples in various programming languages, see the Amazon DynamoDB Getting Started Guide and the AWS SDK documentation for your language.\n\nCounting the items in the results\n\nIn addition to the items that match your criteria, the Scan response contains the following elements:\n\nScannedCount — The number of items evaluated, before any ScanFilter is applied. A high ScannedCount value with few, or no, Count results indicates an inefficient Scan operation. If you did not use a filter in the request, ScannedCount is the same as Count.\n\nCount — The number of items that remain, after a filter expression (if present) was applied.\n\nNote\n\nIf you do not use a filter expression, ScannedCount and Count have the same value.\n\nIf the size of the Scan result set is larger than 1 MB, ScannedCount and Count represent only a partial count of the total items. You need to perform multiple Scan operations to retrieve all the results (see Paginating the results).\n\nEach Scan response contains the ScannedCount and Count for the items that were processed by that particular Scan request. To get grand totals for all of the Scan requests, you could keep a running tally of both ScannedCount and Count.\n\nCapacity units consumed by scan\n\nYou can Scan any table or secondary index. Scan operations consume read capacity units, as follows.\n\nIf you Scan a...\tDynamoDB consumes read capacity units from...\nTable\tThe table's provisioned read capacity.\nGlobal secondary index\tThe index's provisioned read capacity.\nLocal secondary index\tThe base table's provisioned read capacity.\n\nBy default, a Scan operation does not return any data on how much read capacity it consumes. However, you can specify the ReturnConsumedCapacity parameter in a Scan request to obtain this information. The following are the valid settings for ReturnConsumedCapacity:\n\nNONE — No consumed capacity data is returned. (This is the default.)\n\nTOTAL — The response includes the aggregate number of read capacity units consumed.\n\nINDEXES — The response shows the aggregate number of read capacity units consumed, together with the consumed capacity for each table and index that was accessed.\n\nDynamoDB calculates the number of read capacity units consumed based on the number of items and the size of those items, not on the amount of data that is returned to an application. For this reason, the number of capacity units consumed is the same whether you request all of the attributes (the default behavior) or just some of them (using a projection expression). The number is also the same whether or not you use a filter expression. Scan consumes a minimum read capacity unit to perform one strongly consistent read per second, or two eventually consistent reads per second for an item up to 4 KB. If you need to read an item that is larger than 4 KB, DynamoDB needs additional read request units. Empty tables and very large tables which have a sparse amount of partition keys might see some additional RCUs charged beyond the amount of data scanned. This covers the cost of serving the Scan request, even if no data exists.\n\nRead consistency for scan\n\nA Scan operation performs eventually consistent reads, by default. This means that the Scan results might not reflect changes due to recently completed PutItem or UpdateItem operations. For more information, see Read consistency.\n\nIf you require strongly consistent reads, as of the time that the Scan begins, set the ConsistentRead parameter to true in the Scan request. This ensures that all of the write operations that completed before the Scan began are included in the Scan response.\n\nSetting ConsistentRead to true can be useful in table backup or replication scenarios, in conjunction with DynamoDB Streams. You first use Scan with ConsistentRead set to true to obtain a consistent copy of the data in the table. During the Scan, DynamoDB Streams records any additional write activity that occurs on the table. After the Scan is complete, you can apply the write activity from the stream to the table.\n\nNote\n\nA Scan operation with ConsistentRead set to true consumes twice as many read capacity units as compared to leaving ConsistentRead at its default value (false).\n\nParallel scan\n\nBy default, the Scan operation processes data sequentially. Amazon DynamoDB returns data to the application in 1 MB increments, and an application performs additional Scan operations to retrieve the next 1 MB of data.\n\nThe larger the table or index being scanned, the more time the Scan takes to complete. In addition, a sequential Scan might not always be able to fully use the provisioned read throughput capacity: Even though DynamoDB distributes a large table's data across multiple physical partitions, a Scan operation can only read one partition at a time. For this reason, the throughput of a Scan is constrained by the maximum throughput of a single partition.\n\nTo address these issues, the Scan operation can logically divide a table or secondary index into multiple segments, with multiple application workers scanning the segments in parallel. Each worker can be a thread (in programming languages that support multithreading) or an operating system process. To perform a parallel scan, each worker issues its own Scan request with the following parameters:\n\nSegment — A segment to be scanned by a particular worker. Each worker should use a different value for Segment.\n\nTotalSegments — The total number of segments for the parallel scan. This value must be the same as the number of workers that your application will use.\n\nThe following diagram shows how a multithreaded application performs a parallel Scan with three degrees of parallelism.\n\nIn this diagram, the application spawns three threads and assigns each thread a number. (Segments are zero-based, so the first number is always 0.) Each thread issues a Scan request, setting Segment to its designated number and setting TotalSegments to 3. Each thread scans its designated segment, retrieving data 1 MB at a time, and returns the data to the application's main thread.\n\nThe values for Segment and TotalSegments apply to individual Scan requests, and you can use different values at any time. You might need to experiment with these values, and the number of workers you use, until your application achieves its best performance.\n\nNote\n\nA parallel scan with a large number of workers can easily consume all of the provisioned throughput for the table or index being scanned. It is best to avoid such scans if the table or index is also incurring heavy read or write activity from other applications.\n\nTo control the amount of data returned per request, use the Limit parameter. This can help prevent situations where one worker consumes all of the provisioned throughput, at the expense of all other workers."
  },
  {
    "title": "Querying tables and indexes: Java - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/QueryingJavaDocumentAPI.html",
    "html": "Querying tables and indexes: Java\nPDF\nRSS\n\nThe Query operation enables you to query a table or a secondary index in Amazon DynamoDB. You must provide a partition key value and an equality condition. If the table or index has a sort key, you can refine the results by providing a sort key value and a condition.\n\nNote\n\nThe AWS SDK for Java also provides an object persistence model, enabling you to map your client-side classes to DynamoDB tables. This approach can reduce the amount of code you have to write. For more information, see Java 1.x: DynamoDBMapper.\n\nThe following are the steps to retrieve an item using the AWS SDK for Java Document API.\n\nCreate an instance of the DynamoDB class.\n\nCreate an instance of the Table class to represent the table you want to work with.\n\nCall the query method of the Table instance. You must specify the partition key value of the items that you want to retrieve, along with any optional query parameters.\n\nThe response includes an ItemCollection object that provides all items returned by the query.\n\nThe following Java code example demonstrates the preceding tasks. The example assumes that you have a Reply table that stores replies for forum threads. For more information, see Creating tables and loading data for code examples in DynamoDB.\n\nReply ( Id, ReplyDateTime, ... )\n\nEach forum thread has a unique ID and can have zero or more replies. Therefore, the Id attribute of the Reply table is composed of both the forum name and forum subject. Id (partition key) and ReplyDateTime (sort key) make up the composite primary key for the table.\n\nThe following query retrieves all replies for a specific thread subject. The query requires both the table name and the Subject value.\n\nExample\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()\n.withRegion(Regions.US_WEST_2).build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\nTable table = dynamoDB.getTable(\"Reply\");\n\nQuerySpec spec = new QuerySpec()\n    .withKeyConditionExpression(\"Id = :v_id\")\n    .withValueMap(new ValueMap()\n        .withString(\":v_id\", \"Amazon DynamoDB#DynamoDB Thread 1\"));\n\nItemCollection<QueryOutcome> items = table.query(spec);\n\nIterator<Item> iterator = items.iterator();\nItem item = null;\nwhile (iterator.hasNext()) {\n    item = iterator.next();\n    System.out.println(item.toJSONPretty());\n}\n\nSpecifying optional parameters\n\nThe query method supports several optional parameters. For example, you can optionally narrow the results from the preceding query to return replies in the past two weeks by specifying a condition. The condition is called a sort key condition, because DynamoDB evaluates the query condition that you specify against the sort key of the primary key. You can specify other optional parameters to retrieve only a specific list of attributes from items in the query result.\n\nThe following Java code example retrieves forum thread replies posted in the past 15 days. The example specifies optional parameters using the following:\n\nA KeyConditionExpression to retrieve the replies from a specific discussion forum (partition key) and, within that set of items, replies that were posted within the last 15 days (sort key).\n\nA FilterExpression to return only the replies from a specific user. The filter is applied after the query is processed, but before the results are returned to the user.\n\nA ValueMap to define the actual values for the KeyConditionExpression placeholders.\n\nA ConsistentRead setting of true, to request a strongly consistent read.\n\nThis example uses a QuerySpec object that gives access to all of the low-level Query input parameters.\n\nExample\n\nTable table = dynamoDB.getTable(\"Reply\");\n\nlong twoWeeksAgoMilli = (new Date()).getTime() - (15L*24L*60L*60L*1000L);\nDate twoWeeksAgo = new Date();\ntwoWeeksAgo.setTime(twoWeeksAgoMilli);\nSimpleDateFormat df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\nString twoWeeksAgoStr = df.format(twoWeeksAgo);\n\nQuerySpec spec = new QuerySpec()\n    .withKeyConditionExpression(\"Id = :v_id and ReplyDateTime > :v_reply_dt_tm\")\n    .withFilterExpression(\"PostedBy = :v_posted_by\")\n    .withValueMap(new ValueMap()\n        .withString(\":v_id\", \"Amazon DynamoDB#DynamoDB Thread 1\")\n        .withString(\":v_reply_dt_tm\", twoWeeksAgoStr)\n        .withString(\":v_posted_by\", \"User B\"))\n    .withConsistentRead(true);\n\nItemCollection<QueryOutcome> items = table.query(spec);\n\nIterator<Item> iterator = items.iterator();\nwhile (iterator.hasNext()) {\n    System.out.println(iterator.next().toJSONPretty());\n}\n\n\nYou can also optionally limit the number of items per page by using the withMaxPageSize method. When you call the query method, you get an ItemCollection that contains the resulting items. You can then step through the results, processing one page at a time, until there are no more pages.\n\nThe following Java code example modifies the query specification shown previously. This time, the query spec uses the withMaxPageSize method. The Page class provides an iterator that allows the code to process the items on each page.\n\nExample\n\nspec.withMaxPageSize(10);\n\nItemCollection<QueryOutcome> items = table.query(spec);\n\n// Process each page of results\nint pageNum = 0;\nfor (Page<Item, QueryOutcome> page : items.pages()) {\n\n    System.out.println(\"\\nPage: \" + ++pageNum);\n\n    // Process each item on the current page\n    Iterator<Item> item = page.iterator();\n    while (item.hasNext()) {\n        System.out.println(item.next().toJSONPretty());\n    }\n}\n\nExample - query using Java\n\nThe following tables store information about a collection of forums. For more information, see Creating tables and loading data for code examples in DynamoDB.\n\nNote\n\nThe SDK for Java also provides an object persistence model, enabling you to map your client-side classes to DynamoDB tables. This approach can reduce the amount of code you have to write. For more information, see Java 1.x: DynamoDBMapper.\n\nExample\nForum ( Name, ... )\nThread ( ForumName, Subject, Message, LastPostedBy, LastPostDateTime, ...)\nReply ( Id, ReplyDateTime, Message, PostedBy, ...)\n\nIn this Java code example, you run variations of finding replies for a thread \"DynamoDB Thread 1\" in forum \"DynamoDB\".\n\nFind replies for a thread.\n\nFind replies for a thread, specifying a limit on the number of items per page of results. If the number of items in the result set exceeds the page size, you get only the first page of results. This coding pattern ensures that your code processes all the pages in the query result.\n\nFind replies in the last 15 days.\n\nFind replies in a specific date range.\n\nThe preceding two queries show how you can specify sort key conditions to narrow the query results and use other optional query parameters.\n\nNote\n\nThis code example assumes that you have already loaded data into DynamoDB for your account by following the instructions in the Creating tables and loading data for code examples in DynamoDB section.\n\nFor step-by-step instructions to run the following example, see Java code examples.\n\n\npackage com.amazonaws.codesamples.document;\n\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\nimport java.util.Iterator;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.document.DynamoDB;\nimport com.amazonaws.services.dynamodbv2.document.Item;\nimport com.amazonaws.services.dynamodbv2.document.ItemCollection;\nimport com.amazonaws.services.dynamodbv2.document.Page;\nimport com.amazonaws.services.dynamodbv2.document.QueryOutcome;\nimport com.amazonaws.services.dynamodbv2.document.Table;\nimport com.amazonaws.services.dynamodbv2.document.spec.QuerySpec;\nimport com.amazonaws.services.dynamodbv2.document.utils.ValueMap;\n\npublic class DocumentAPIQuery {\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n    static DynamoDB dynamoDB = new DynamoDB(client);\n\n    static String tableName = \"Reply\";\n\n    public static void main(String[] args) throws Exception {\n\n        String forumName = \"Amazon DynamoDB\";\n        String threadSubject = \"DynamoDB Thread 1\";\n\n        findRepliesForAThread(forumName, threadSubject);\n        findRepliesForAThreadSpecifyOptionalLimit(forumName, threadSubject);\n        findRepliesInLast15DaysWithConfig(forumName, threadSubject);\n        findRepliesPostedWithinTimePeriod(forumName, threadSubject);\n        findRepliesUsingAFilterExpression(forumName, threadSubject);\n    }\n\n    private static void findRepliesForAThread(String forumName, String threadSubject) {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        String replyId = forumName + \"#\" + threadSubject;\n\n        QuerySpec spec = new QuerySpec().withKeyConditionExpression(\"Id = :v_id\")\n                .withValueMap(new ValueMap().withString(\":v_id\", replyId));\n\n        ItemCollection<QueryOutcome> items = table.query(spec);\n\n        System.out.println(\"\\nfindRepliesForAThread results:\");\n\n        Iterator<Item> iterator = items.iterator();\n        while (iterator.hasNext()) {\n            System.out.println(iterator.next().toJSONPretty());\n        }\n\n    }\n\n    private static void findRepliesForAThreadSpecifyOptionalLimit(String forumName, String threadSubject) {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        String replyId = forumName + \"#\" + threadSubject;\n\n        QuerySpec spec = new QuerySpec().withKeyConditionExpression(\"Id = :v_id\")\n                .withValueMap(new ValueMap().withString(\":v_id\", replyId)).withMaxPageSize(1);\n\n        ItemCollection<QueryOutcome> items = table.query(spec);\n\n        System.out.println(\"\\nfindRepliesForAThreadSpecifyOptionalLimit results:\");\n\n        // Process each page of results\n        int pageNum = 0;\n        for (Page<Item, QueryOutcome> page : items.pages()) {\n\n            System.out.println(\"\\nPage: \" + ++pageNum);\n\n            // Process each item on the current page\n            Iterator<Item> item = page.iterator();\n            while (item.hasNext()) {\n                System.out.println(item.next().toJSONPretty());\n            }\n        }\n    }\n\n    private static void findRepliesInLast15DaysWithConfig(String forumName, String threadSubject) {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        long twoWeeksAgoMilli = (new Date()).getTime() - (15L * 24L * 60L * 60L * 1000L);\n        Date twoWeeksAgo = new Date();\n        twoWeeksAgo.setTime(twoWeeksAgoMilli);\n        SimpleDateFormat df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\n        String twoWeeksAgoStr = df.format(twoWeeksAgo);\n\n        String replyId = forumName + \"#\" + threadSubject;\n\n        QuerySpec spec = new QuerySpec().withProjectionExpression(\"Message, ReplyDateTime, PostedBy\")\n                .withKeyConditionExpression(\"Id = :v_id and ReplyDateTime <= :v_reply_dt_tm\")\n                .withValueMap(new ValueMap().withString(\":v_id\", replyId).withString(\":v_reply_dt_tm\", twoWeeksAgoStr));\n\n        ItemCollection<QueryOutcome> items = table.query(spec);\n\n        System.out.println(\"\\nfindRepliesInLast15DaysWithConfig results:\");\n        Iterator<Item> iterator = items.iterator();\n        while (iterator.hasNext()) {\n            System.out.println(iterator.next().toJSONPretty());\n        }\n\n    }\n\n    private static void findRepliesPostedWithinTimePeriod(String forumName, String threadSubject) {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        long startDateMilli = (new Date()).getTime() - (15L * 24L * 60L * 60L * 1000L);\n        long endDateMilli = (new Date()).getTime() - (5L * 24L * 60L * 60L * 1000L);\n        java.text.SimpleDateFormat df = new java.text.SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\n        String startDate = df.format(startDateMilli);\n        String endDate = df.format(endDateMilli);\n\n        String replyId = forumName + \"#\" + threadSubject;\n\n        QuerySpec spec = new QuerySpec().withProjectionExpression(\"Message, ReplyDateTime, PostedBy\")\n                .withKeyConditionExpression(\"Id = :v_id and ReplyDateTime between :v_start_dt and :v_end_dt\")\n                .withValueMap(new ValueMap().withString(\":v_id\", replyId).withString(\":v_start_dt\", startDate)\n                        .withString(\":v_end_dt\", endDate));\n\n        ItemCollection<QueryOutcome> items = table.query(spec);\n\n        System.out.println(\"\\nfindRepliesPostedWithinTimePeriod results:\");\n        Iterator<Item> iterator = items.iterator();\n        while (iterator.hasNext()) {\n            System.out.println(iterator.next().toJSONPretty());\n        }\n    }\n\n    private static void findRepliesUsingAFilterExpression(String forumName, String threadSubject) {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        String replyId = forumName + \"#\" + threadSubject;\n\n        QuerySpec spec = new QuerySpec().withProjectionExpression(\"Message, ReplyDateTime, PostedBy\")\n                .withKeyConditionExpression(\"Id = :v_id\").withFilterExpression(\"PostedBy = :v_postedby\")\n                .withValueMap(new ValueMap().withString(\":v_id\", replyId).withString(\":v_postedby\", \"User B\"));\n\n        ItemCollection<QueryOutcome> items = table.query(spec);\n\n        System.out.println(\"\\nfindRepliesUsingAFilterExpression results:\");\n        Iterator<Item> iterator = items.iterator();\n        while (iterator.hasNext()) {\n            System.out.println(iterator.next().toJSONPretty());\n        }\n    }\n\n}\n\n"
  },
  {
    "title": "Object persistence interface - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.SDKs.Interfaces.Mapper.html",
    "html": "Object persistence interface\nPDF\nRSS\n\nSome AWS SDKs provide an object persistence interface where you do not directly perform data plane operations. Instead, you create objects that represent items in Amazon DynamoDB tables and indexes, and interact only with those objects. This allows you to write object-centric code, rather than database-centric code.\n\nNote\n\nObject persistence interfaces are available in the AWS SDKs for Java and .NET. For more information, see Higher-level programming interfaces for DynamoDB for DynamoDB.\n\nimport com.example.dynamodb.Customer;\nimport software.amazon.awssdk.enhanced.dynamodb.DynamoDbEnhancedClient;\nimport software.amazon.awssdk.enhanced.dynamodb.DynamoDbTable;\nimport software.amazon.awssdk.enhanced.dynamodb.Key;\nimport software.amazon.awssdk.enhanced.dynamodb.TableSchema;\nimport software.amazon.awssdk.enhanced.dynamodb.model.GetItemEnhancedRequest;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.dynamodb.DynamoDbClient;\nimport software.amazon.awssdk.services.dynamodb.model.DynamoDbException;\n\nimport com.example.dynamodb.Customer;\nimport software.amazon.awssdk.enhanced.dynamodb.DynamoDbEnhancedClient;\nimport software.amazon.awssdk.enhanced.dynamodb.DynamoDbTable;\nimport software.amazon.awssdk.enhanced.dynamodb.Key;\nimport software.amazon.awssdk.enhanced.dynamodb.TableSchema;\nimport software.amazon.awssdk.enhanced.dynamodb.model.GetItemEnhancedRequest;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.dynamodb.DynamoDbClient;\nimport software.amazon.awssdk.services.dynamodb.model.DynamoDbException;\n\n/*\n * Before running this code example, create an Amazon DynamoDB table named Customer with these columns:\n *   - id - the id of the record that is the key. Be sure one of the id values is `id101`\n *   - custName - the customer name\n *   - email - the email value\n *   - registrationDate - an instant value when the item was added to the table. These values\n *                        need to be in the form of `YYYY-MM-DDTHH:mm:ssZ`, such as 2022-07-11T00:00:00Z\n *\n * Also, ensure that you have set up your development environment, including your credentials.\n *\n * For information, see this documentation topic:\n *\n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-started.html\n */\n\npublic class EnhancedGetItem {\n    public static void main(String[] args) {\n        Region region = Region.US_EAST_1;\n        DynamoDbClient ddb = DynamoDbClient.builder()\n                .region(region)\n                .build();\n\n        DynamoDbEnhancedClient enhancedClient = DynamoDbEnhancedClient.builder()\n                .dynamoDbClient(ddb)\n                .build();\n\n        getItem(enhancedClient);\n        ddb.close();\n    }\n\n    public static String getItem(DynamoDbEnhancedClient enhancedClient) {\n        Customer result = null;\n        try {\n            DynamoDbTable<Customer> table = enhancedClient.table(\"Customer\", TableSchema.fromBean(Customer.class));\n            Key key = Key.builder()\n                    .partitionValue(\"id101\").sortValue(\"tred@noserver.com\")\n                    .build();\n\n            // Get the item by using the key.\n            result = table.getItem(\n                    (GetItemEnhancedRequest.Builder requestBuilder) -> requestBuilder.key(key));\n            System.out.println(\"******* The description value is \" + result.getCustName());\n\n        } catch (DynamoDbException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n        return result.getCustName();\n    }\n}\n"
  },
  {
    "title": "Programmatic interfaces - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.SDKs.Interfaces.html",
    "html": "Programmatic interfaces\nPDF\nRSS\n\nEvery AWS SDK provides one or more programmatic interfaces for working with Amazon DynamoDB. These interfaces range from simple low-level DynamoDB wrappers to object-oriented persistence layers. The available interfaces vary depending on the AWS SDK and programming language that you use.\n\nThe following section highlights some of the interfaces available, using the AWS SDK for Java as an example. (Not all interfaces are available in all AWS SDKs.)\n\nTopics\nLow-level interfaces\nDocument interfaces\nObject persistence interface"
  },
  {
    "title": "Programming with DynamoDB and the AWS SDKs - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.html",
    "html": "Programming with DynamoDB and the AWS SDKs\nPDF\nRSS\n\nThis section covers developer-related topics. If you want to run code examples instead, see Running the code examples in this Developer Guide.\n\nNote\n\nIn December 2017, AWS began the process of migrating all Amazon DynamoDB endpoints to use secure certificates issued by Amazon Trust Services (ATS). For more information, see Troubleshooting SSL/TLS connection establishment issues.\n\nTopics\nOverview of AWS SDK support for DynamoDB\nHigher-level programming interfaces for DynamoDB\nRunning the code examples in this Developer Guide\nProgramming Amazon DynamoDB with Python and Boto3\nProgramming Amazon DynamoDB with JavaScript\nProgramming DynamoDB with the AWS SDK for Java 2.x"
  },
  {
    "title": "Getting started with DynamoDB: Next steps - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/getting-started-NextSteps.html",
    "html": "Getting started with DynamoDB: Next steps\nPDF\nRSS\n\nFor more information about using Amazon DynamoDB, see the following topics:\n\nWorking with tables and data in DynamoDB\n\nWorking with items and attributes\n\nQuery operations in DynamoDB\n\nUsing Global Secondary Indexes in DynamoDB\n\nWorking with transactions\n\nIn-memory acceleration with DynamoDB Accelerator (DAX)\n\nGetting started with DynamoDB and the AWS SDKs\n\nProgramming with DynamoDB and the AWS SDKs"
  },
  {
    "title": "Step 8: (Optional) clean up resources - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/getting-started-step-8.html",
    "html": "Step 8: (Optional) clean up resources\nPDF\nRSS\n\nIf you no longer need the Amazon DynamoDB table that you created for the tutorial, you can delete it. This step helps ensure that you aren't charged for resources that you aren't using. You can use the DynamoDB console or the AWS CLI to delete the Music table that you created in Step 1: Create a table.\n\nFor more information about table operations in DynamoDB, see Working with tables and data in DynamoDB.\n\nAWS Management Console\nAWS CLI"
  },
  {
    "title": "IP address ranges - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Using.IPRanges.html",
    "html": "IP address ranges\nPDF\nRSS\n\nAmazon Web Services (AWS) publishes its current IP address ranges in JSON format. To view the current ranges, download ip-ranges.json. For more information, see AWS IP address ranges in the AWS General Reference.\n\nTo find the IP address ranges that you can use to access to DynamoDB tables and indexes, search the ip-ranges.json file for the following string: \"service\": \"DYNAMODB\".\n\nNote\n\nThe IP address ranges do not apply to DynamoDB Streams or DynamoDB Accelerator (DAX)."
  },
  {
    "title": "Overview of AWS SDK support for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.SDKOverview.html",
    "html": "Overview of AWS SDK support for DynamoDB\nPDF\nRSS\n\nThe following diagram provides a high-level overview of Amazon DynamoDB application programming using the AWS SDKs.\n\nYou write an application using an AWS SDK for your programming language.\n\nEach AWS SDK provides one or more programmatic interfaces for working with DynamoDB. The specific interfaces available depend on which programming language and AWS SDK you use. Options include:\n\nLow-level interfaces\n\nDocument interfaces\n\nObject persistence interface\n\nHigh Level Interfaces\n\nThe AWS SDK constructs HTTP(S) requests for use with the low-level DynamoDB API.\n\nThe AWS SDK sends the request to the DynamoDB endpoint.\n\nDynamoDB runs the request. If the request is successful, DynamoDB returns an HTTP 200 response code (OK). If the request is unsuccessful, DynamoDB returns an HTTP error code and an error message.\n\nThe AWS SDK processes the response and propagates it back to your application.\n\nEach of the AWS SDKs provides important services to your application, including the following:\n\nFormatting HTTP(S) requests and serializing request parameters.\n\nGenerating a cryptographic signature for each request.\n\nForwarding requests to a DynamoDB endpoint and receiving responses from DynamoDB.\n\nExtracting the results from those responses.\n\nImplementing basic retry logic in case of errors.\n\nYou do not need to write code for any of these tasks.\n\nNote\n\nFor more information about AWS SDKs, including installation instructions and documentation, see Tools for Amazon Web Services."
  },
  {
    "title": "Using the console - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ConsoleDynamoDB.html",
    "html": "Using the console\nPDF\nRSS\n\nYou can access the AWS Management Console for Amazon DynamoDB at https://console.aws.amazon.com/dynamodb/home.\n\nYou can use the console to do the following in DynamoDB:\n\nMonitor recent alerts, total capacity, service health, and the latest DynamoDB news on the DynamoDB dashboard.\n\nCreate, update, and delete tables. The capacity calculator provides estimates of how many capacity units to request based on the usage information you provide.\n\nManage streams.\n\nView, add, update, and delete items that are stored in tables. Manage Time to Live (TTL) to define when items in a table expire so that they can be automatically deleted from the database.\n\nQuery and scan a table.\n\nSet up and view alarms to monitor your table's capacity usage. View your table's top monitoring metrics on real-time graphs from CloudWatch.\n\nModify a table's provisioned capacity.\n\nModify a table's table class.\n\nCreate and delete global secondary indexes.\n\nCreate triggers to connect DynamoDB streams to AWS Lambda functions.\n\nApply tags to your resources to help organize and identify them.\n\nPurchase reserved capacity.\n\nThe console displays an introductory screen that prompts you to create your first table. To view your tables, in the navigation pane on the left side of the console, choose Tables.\n\nHere's a high-level overview of the actions available per table within each navigation tab:\n\nOverview – View table details, including item count and metrics.\n\nIndexes – Manage global and local secondary indexes.\n\nMonitor – View alarms, CloudWatch Contributor Insights, and Cloudwatch metrics.\n\nGlobal tables – Manage table replicas.\n\nBackups – Manage point-in-time recovery and on-demand backups.\n\nExports and streams – Export your table to Amazon S3 and manage DynamoDB Streams and Kinesis Data Streams.\n\nAdditional settings – Manage read/write capacity, Time to Live settings, encryption, and tags."
  },
  {
    "title": "Burst and adaptive capacity - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/burst-adaptive-capacity.html",
    "html": "Burst and adaptive capacity\nPDF\nRSS\n\nTo minimize throttling because of throughput exceptions, DynamoDB uses burst capacity to handle usage spikes. DynamoDB uses adaptive capacity to help accommodate uneven access patterns.\n\nBurst capacity\n\nDynamoDB provides some flexibility for your throughput provisioning with burst capacity. Whenever you aren't fully using your available throughput, DynamoDB reserves a portion of that unused capacity for later bursts of throughput to handle usage spikes. With burst capacity, unexpected read or write requests can succeed where they otherwise would be throttled.\n\nDynamoDB currently retains up to five minutes (300 seconds) of unused read and write capacity. During an occasional burst of read or write activity, these extra capacity units can be consumed quickly — even faster than the per-second provisioned throughput capacity that you've defined for your table.\n\nDynamoDB can also consume burst capacity for background maintenance and other tasks without prior notice.\n\nNote that these burst capacity details might change in the future.\n\nAdaptive capacity\n\nDynamoDB automatically distributes your data across partitions, which are stored on multiple servers in the AWS Cloud. It's not always possible to evenly distribute read and write activity all the time. When data access is imbalanced, a \"hot\" partition can receive a higher volume of read and write traffic compared to other partitions. Because read and write operations on a partition are managed independently, throttling will occur if a single partition receives more than 3000 read operation or more than 1000 write operations. Adaptive capacity works by automatically increasing throughput capacity for partitions that receive more traffic.\n\nTo better accommodate uneven access patterns, DynamoDB adaptive capacity enables your application to continue reading and writing to hot partitions without being throttled, provided that traffic does not exceed your table’s total provisioned capacity or the partition maximum capacity. Adaptive capacity works by automatically and instantly increasing throughput capacity for partitions that receive more traffic.\n\nThe following diagram illustrates how adaptive capacity works. The example table is provisioned with 400 WCUs evenly shared across four partitions, allowing each partition to sustain up to 100 WCUs per second. Partitions 1, 2, and 3 each receives write traffic of 50 WCU/sec. Partition 4 receives 150 WCU/sec. This hot partition can accept write traffic while it still has unused burst capacity, but eventually it throttles traffic that exceeds 100 WCU/sec.\n\nDynamoDB adaptive capacity responds by increasing the capacity of partition 4 so that it can sustain the higher workload of 150 WCU/sec without being throttled.\n\nAdaptive capacity is enabled automatically for every DynamoDB table, at no additional cost. You don't need to explicitly enable or disable it.\n\nIsolate frequently accessed items\n\nIf your application drives disproportionately high traffic to one or more items, adaptive capacity rebalances your partitions such that frequently accessed items don't reside on the same partition. This isolation of frequently accessed items reduces the likelihood of request throttling due to your workload exceeding the throughput quota on a single partition. You can also break up an item collection into segments by sort key, as long as the item collection isn't traffic that is tracked by a monotonic increase or decrease of the sort key.\n\nIf your application drives consistently high traffic to a single item, adaptive capacity might rebalance your data so that a partition contains only that single, frequently accessed item. In this case, DynamoDB can deliver throughput up to the partition maximum of 3,000 RCUs and 1,000 WCUs to that single item’s primary key. Adaptive capacity will not split item collections across multiple partitions of the table when there is a local secondary index on the table."
  },
  {
    "title": "Blog posts, repositories, and guides - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AdditionalResources.Guides.html",
    "html": "Blog posts, repositories, and guides\nPDF\nRSS\n\nIn addition to the DynamoDB Developer Guide, there are many useful resources for working with DynamoDB. Here are some selected blog posts, repositories, and guides for working with DynamoDB:\n\nAWS repository of DynamoDB code examples in various AWS SDK languages: Node.js, Java, Python, .Net, Go, and Rust.\n\nThe DynamoDB Book – A comprehensive guide from Alex DeBrie that teaches a strategy-driven approach to data modeling with DynamoDB.\n\nDynamoDB guide – An open guide from Alex DeBrie that walks through the basic concepts and advanced features of the DynamoDB NoSQL database.\n\nHow to switch from RDBMS to DynamoDB in 20 easy steps – A list of useful steps for learning data modeling from Jeremy Daly.\n\nDynamoDB JavaScript DocumentClient cheat sheet – A cheat sheet to help you get started building applications with DynamoDB in a Node.js or JavaScript environment.\n\nDynamoDB Core Concept Videos – This playlist covers many of the core concepts of DynamoDB."
  },
  {
    "title": "Modifying data in a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.UpdateData.html",
    "html": "Modifying data in a table\nPDF\nRSS\n\nThe SQL language provides the UPDATE statement for modifying data. Amazon DynamoDB uses the UpdateItem operation to accomplish similar tasks.\n\nTopics\nModifying data in a table with SQL\nModifying data in a table in DynamoDB\nModifying data in a table with SQL\n\nIn SQL, you would use the UPDATE statement to modify one or more rows. The SET clause specifies new values for one or more columns, and the WHERE clause determines which rows are modified. The following is an example.\n\nUPDATE Music\nSET RecordLabel = 'Global Records'\nWHERE Artist = 'No One You Know' AND SongTitle = 'Call Me Today';\n\nIf no rows match the WHERE clause, the UPDATE statement has no effect.\n\nModifying data in a table in DynamoDB\n\nIn DynamoDB, you can use either the DynamoDB API or PartiQL (a SQL-compatible query language) to modify a single item. If you want to modify multiple items, you must use multiple operations.\n\nDynamoDB API\nPartiQL for DynamoDB\n\nWith the DynamoDB API, you use the UpdateItem operation to modify a single item.\n\n{\n    TableName: \"Music\",\n    Key: {\n        \"Artist\":\"No One You Know\",\n        \"SongTitle\":\"Call Me Today\"\n    },\n    UpdateExpression: \"SET RecordLabel = :label\",\n    ExpressionAttributeValues: {\n        \":label\": \"Global Records\"\n    }\n}\n\nYou must specify the Key attributes of the item to be modified and an UpdateExpression to specify attribute values. UpdateItem behaves like an \"upsert\" operation. The item is updated if it exists in the table, but if not, a new item is added (inserted).\n\nUpdateItem supports conditional writes, where the operation succeeds only if a specific ConditionExpression evaluates to true. For example, the following UpdateItem operation does not perform the update unless the price of the song is greater than or equal to 2.00.\n\n{\n    TableName: \"Music\",\n    Key: {\n        \"Artist\":\"No One You Know\",\n        \"SongTitle\":\"Call Me Today\"\n    },\n    UpdateExpression: \"SET RecordLabel = :label\",\n    ConditionExpression: \"Price >= :p\",\n    ExpressionAttributeValues: {\n        \":label\": \"Global Records\",\n        \":p\": 2.00\n    }\n}\n\nUpdateItem also supports atomic counters, or attributes of type Number that can be incremented or decremented. Atomic counters are similar in many ways to sequence generators, identity columns, or autoincrement fields in SQL databases.\n\nThe following is an example of an UpdateItem operation to initialize a new attribute (Plays) to keep track of the number of times a song has been played.\n\n{\n    TableName: \"Music\",\n    Key: {\n        \"Artist\":\"No One You Know\",\n        \"SongTitle\":\"Call Me Today\"\n    },\n    UpdateExpression: \"SET Plays = :val\",\n    ExpressionAttributeValues: {\n        \":val\": 0\n    },\n    ReturnValues: \"UPDATED_NEW\"\n}\n\nThe ReturnValues parameter is set to UPDATED_NEW, which returns the new values of any attributes that were updated. In this case, it returns 0 (zero).\n\nWhenever someone plays this song, we can use the following UpdateItem operation to increment Plays by one.\n\n{\n    TableName: \"Music\",\n    Key: {\n        \"Artist\":\"No One You Know\",\n        \"SongTitle\":\"Call Me Today\"\n    },\n    UpdateExpression: \"SET Plays = Plays + :incr\",\n    ExpressionAttributeValues: {\n        \":incr\": 1\n    },\n    ReturnValues: \"UPDATED_NEW\"\n}\nNote\n\nFor code examples that use UpdateItem, see Getting started with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Querying and scanning an index - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.Indexes.QueryAndScan.html",
    "html": "Querying and scanning an index\nPDF\nRSS\n\nCompare querying and scanning an index using the SELECT statement in SQL with the Query and Scan operations in Amazon DynamoDB.\n\nTopics\nQuerying and scanning an index with SQL\nQuerying and scanning an index in DynamoDB\nQuerying and scanning an index with SQL\n\nIn a relational database, you do not work directly with indexes. Instead, you query tables by issuing SELECT statements, and the query optimizer can make use of any indexes.\n\nA query optimizer is a relational database management system (RDBMS) component that evaluates the available indexes and determines whether they can be used to speed up a query. If the indexes can be used to speed up a query, the RDBMS accesses the index first and then uses it to locate the data in the table.\n\nHere are some SQL statements that can use GenreAndPriceIndex to improve performance. We assume that the Music table has enough data in it that the query optimizer decides to use this index, rather than simply scanning the entire table.\n\n/* All of the rock songs */\n\nSELECT * FROM Music\nWHERE Genre = 'Rock';\n/* All of the cheap country songs */\n\nSELECT Artist, SongTitle, Price FROM Music\nWHERE Genre = 'Country' AND Price < 0.50;\nQuerying and scanning an index in DynamoDB\n\nIn DynamoDB, you perform Query and Scan operations directly on the index, in the same way that you would on a table. You can use either the DynamoDB API or PartiQL (a SQL-compatible query language) to query or scan the index. You must specify both TableName and IndexName.\n\nThe following are some queries on GenreAndPriceIndex in DynamoDB. (The key schema for this index consists of Genre and Price.)\n\nDynamoDB API\nPartiQL for DynamoDB\n// All of the rock songs\n\n{\n    TableName: \"Music\",\n    IndexName: \"GenreAndPriceIndex\",\n    KeyConditionExpression: \"Genre = :genre\",\n    ExpressionAttributeValues: {\n        \":genre\": \"Rock\"\n    },\n};\n\nThis example uses a ProjectionExpression to indicate that you only want some of the attributes, rather than all of them, to appear in the results.\n\n// All of the cheap country songs\n\n{\n    TableName: \"Music\",\n    IndexName: \"GenreAndPriceIndex\",\n    KeyConditionExpression: \"Genre = :genre and Price < :price\",\n    ExpressionAttributeValues: {\n        \":genre\": \"Country\",\n        \":price\": 0.50\n    },\n    ProjectionExpression: \"Artist, SongTitle, Price\"\n};\n\nThe following is a scan on GenreAndPriceIndex.\n\n// Return all of the data in the index\n\n{\n    TableName:  \"Music\",\n    IndexName: \"GenreAndPriceIndex\"\n}"
  },
  {
    "title": "Scanning a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.ReadData.Scan.html",
    "html": "Scanning a table\nPDF\nRSS\n\nIn SQL, a SELECT statement without a WHERE clause will return every row in a table. In Amazon DynamoDB, the Scan operation does the same thing. In both cases, you can retrieve all of the items or just some of them.\n\nWhether you are using a SQL or a NoSQL database, scans should be used sparingly because they can consume large amounts of system resources. Sometimes a scan is appropriate (such as scanning a small table) or unavoidable (such as performing a bulk export of data). However, as a general rule, you should design your applications to avoid performing scans. For more information, see Query operations in DynamoDB.\n\nNote\n\nDoing a bulk export also creates at least 1 file per partition. All of the items in each file are from that particular partition's hashed keyspace.\n\nTopics\nScanning a table with SQL\nScanning a table in DynamoDB\nScanning a table with SQL\n\nWhen using SQL you can scan a table and retrieve all of its data by using a SELECT statement without specifying a WHERE clause. You can request one or more columns in the result. Or you can request all of them if you use the wildcard character (*).\n\nThe following are examples of using a SELECT statement.\n\n/* Return all of the data in the table */\nSELECT * FROM Music;\n/* Return all of the values for Artist and Title */\nSELECT Artist, Title FROM Music;\nScanning a table in DynamoDB\n\nIn Amazon DynamoDB, you can use either the DynamoDB API or PartiQL (a SQL-compatible query language) to perform a scan on a table.\n\nDynamoDB API\nPartiQL for DynamoDB\n\nWith the DynamoDB API, you use the Scan operation to return one or more items and item attributes by accessing every item in a table or a secondary index.\n\n// Return all of the data in the table\n{\n    TableName:  \"Music\"\n}\n// Return all of the values for Artist and Title\n{\n    TableName:  \"Music\",\n    ProjectionExpression: \"Artist, Title\"\n}\n\nThe Scan operation also provides a FilterExpression parameter, which you can use to discard items that you do not want to appear in the results. A FilterExpression is applied after the scan is performed, but before the results are returned to you. (This is not recommended with large tables. You are still charged for the entire Scan, even if only a few matching items are returned.)\n\nNote\n\nFor code examples that use Scan, see Getting started with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Reading an item using its primary key - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.ReadData.SingleItem.html",
    "html": "Reading an item using its primary key\nPDF\nRSS\n\nOne common access pattern for databases is to read a single item from a table. You have to specify the primary key of the item you want.\n\nTopics\nReading an item using its primary key with SQL\nReading an item using its primary key in DynamoDB\nReading an item using its primary key with SQL\n\nIn SQL, you would use the SELECT statement to retrieve data from a table. You can request one or more columns in the result (or all of them, if you use the * operator). The WHERE clause determines which rows to return.\n\nThe following is a SELECT statement to retrieve a single row from the Music table. The WHERE clause specifies the primary key values.\n\nSELECT *\nFROM Music\nWHERE Artist='No One You Know' AND SongTitle = 'Call Me Today'\n\nYou can modify this query to retrieve only a subset of the columns.\n\nSELECT AlbumTitle, Year, Price\nFROM Music\nWHERE Artist='No One You Know' AND SongTitle = 'Call Me Today'\n\nNote that the primary key for this table consists of Artist and SongTitle.\n\nReading an item using its primary key in DynamoDB\n\nIn Amazon DynamoDB, you can use either the DynamoDB API or PartiQL (a SQL-compatible query language) to read an item from a table.\n\nDynamoDB API\nPartiQL for DynamoDB\n\nWith the DynamoDB API, you use the PutItem operation to add an item to a table.\n\nDynamoDB provides the GetItem operation for retrieving an item by its primary key. GetItem is highly efficient because it provides direct access to the physical location of the item. (For more information, see Partitions and data distribution.)\n\nBy default, GetItem returns the entire item with all of its attributes.\n\n{\n    TableName: \"Music\",\n    Key: {\n        \"Artist\": \"No One You Know\",\n        \"SongTitle\": \"Call Me Today\"\n    }\n}\n\nYou can add a ProjectionExpression parameter to return only some of the attributes.\n\n{\n    TableName: \"Music\",\n    Key: {\n        \"Artist\": \"No One You Know\",\n        \"SongTitle\": \"Call Me Today\"\n    },\n    \"ProjectionExpression\": \"AlbumTitle, Year, Price\"\n}\n\nNote that the primary key for this table consists of Artist and SongTitle.\n\nThe DynamoDB GetItem operation is very efficient. It uses the primary key values to determine the exact storage location of the item in question, and retrieves it directly from there. The SQL SELECT statement is similarly efficient, in the case of retrieving items by primary key values.\n\nThe SQL SELECT statement supports many kinds of queries and table scans. DynamoDB provides similar functionality with its Query and Scan operations, which are described in Querying a table and Scanning a table.\n\nThe SQL SELECT statement can perform table joins, allowing you to retrieve data from multiple tables at the same time. Joins are most effective where the database tables are normalized and the relationships among the tables are clear. However, if you join too many tables in one SELECT statement application performance can be affected. You can work around such issues by using database replication, materialized views, or query rewrites.\n\nDynamoDB is a nonrelational database and doesn't support table joins. If you are migrating an existing application from a relational database to DynamoDB, you need to denormalize your data model to eliminate the need for joins.\n\nNote\n\nFor code examples that use GetItem, see Getting started with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Querying a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.ReadData.Query.html",
    "html": "Querying a table\nPDF\nRSS\n\nAnother common access pattern is reading multiple items from a table, based on your query criteria.\n\nTopics\nQuerying a table with SQL\nQuerying a table in DynamoDB\nQuerying a table with SQL\n\nWhen using SQL the SELECT statement lets you query on key columns, non-key columns, or any combination. The WHERE clause determines which rows are returned, as shown in the following examples.\n\n/* Return a single song, by primary key */\n\nSELECT * FROM Music\nWHERE Artist='No One You Know' AND SongTitle = 'Call Me Today';\n/* Return all of the songs by an artist */\n\nSELECT * FROM Music\nWHERE Artist='No One You Know';\n/* Return all of the songs by an artist, matching first part of title */\n\nSELECT * FROM Music\nWHERE Artist='No One You Know' AND SongTitle LIKE 'Call%';\n/* Return all of the songs by an artist, with a particular word in the title...\n...but only if the price is less than 1.00 */\n\nSELECT * FROM Music\nWHERE Artist='No One You Know' AND SongTitle LIKE '%Today%'\nAND Price < 1.00;\n\nNote that the primary key for this table consists of Artist and SongTitle.\n\nQuerying a table in DynamoDB\n\nIn Amazon DynamoDB, you can use either the DynamoDB API or PartiQL (a SQL-compatible query language) to query an item from a table.\n\nDynamoDB API\nPartiQL for DynamoDB\n\nWith Amazon DynamoDB, you can use the Query operation to retrieve data in a similar fashion. The Query operation provides quick, efficient access to the physical locations where the data is stored. For more information, see Partitions and data distribution.\n\nYou can use Query with any table or secondary index. You must specify an equality condition for the partition key's value, and you can optionally provide another condition for the sort key attribute if it is defined.\n\nThe KeyConditionExpression parameter specifies the key values that you want to query. You can use an optional FilterExpression to remove certain items from the results before they are returned to you.\n\nIn DynamoDB, you must use ExpressionAttributeValues as placeholders in expression parameters (such as KeyConditionExpression and FilterExpression). This is analogous to the use of bind variables in relational databases, where you substitute the actual values into the SELECT statement at runtime.\n\nNote that the primary key for this table consists of Artist and SongTitle.\n\nThe following are some DynamoDB Query examples.\n\n// Return a single song, by primary key\n\n{\n    TableName: \"Music\",\n    KeyConditionExpression: \"Artist = :a and SongTitle = :t\",\n    ExpressionAttributeValues: {\n        \":a\": \"No One You Know\",\n        \":t\": \"Call Me Today\"\n    }\n}\n// Return all of the songs by an artist\n\n{\n    TableName: \"Music\",\n    KeyConditionExpression: \"Artist = :a\",\n    ExpressionAttributeValues: {\n        \":a\": \"No One You Know\"\n    }\n}\n// Return all of the songs by an artist, matching first part of title\n\n{\n    TableName: \"Music\",\n    KeyConditionExpression: \"Artist = :a and begins_with(SongTitle, :t)\",\n    ExpressionAttributeValues: {\n        \":a\": \"No One You Know\",\n        \":t\": \"Call\"\n    }\n}\nNote\n\nFor code examples that use Query, see Getting started with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Paginating table query results - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.Pagination.html",
    "html": "Paginating table query results\nPDF\nRSS\n\nDynamoDB paginates the results from Query operations. With pagination, the Query results are divided into \"pages\" of data that are 1 MB in size (or less). An application can process the first page of results, then the second page, and so on.\n\nA single Query only returns a result set that fits within the 1 MB size limit. To determine whether there are more results, and to retrieve them one page at a time, applications should do the following:\n\nExamine the low-level Query result:\n\nIf the result contains a LastEvaluatedKey element and it's non-null, proceed to step 2.\n\nIf there is not a LastEvaluatedKey in the result, there are no more items to be retrieved.\n\nConstruct a new Query request, with the same parameters as the previous one. However, this time, take the LastEvaluatedKey value from step 1 and use it as the ExclusiveStartKey parameter in the new Query request.\n\nRun the new Query request.\n\nGo to step 1.\n\nIn other words, the LastEvaluatedKey from a Query response should be used as the ExclusiveStartKey for the next Query request. If there is not a LastEvaluatedKey element in a Query response, then you have retrieved the final page of results. If LastEvaluatedKey is not empty, it does not necessarily mean that there is more data in the result set. The only way to know when you have reached the end of the result set is when LastEvaluatedKey is empty.\n\nYou can use the AWS CLI to view this behavior. The AWS CLI sends low-level Query requests to DynamoDB repeatedly, until LastEvaluatedKey is no longer present in the results. Consider the following AWS CLI example that retrieves movie titles from a particular year.\n\naws dynamodb query --table-name Movies \\\n    --projection-expression \"title\" \\\n    --key-condition-expression \"#y = :yyyy\" \\\n    --expression-attribute-names '{\"#y\":\"year\"}' \\\n    --expression-attribute-values '{\":yyyy\":{\"N\":\"1993\"}}' \\\n    --page-size 5 \\\n    --debug\n\nOrdinarily, the AWS CLI handles pagination automatically. However, in this example, the AWS CLI --page-size parameter limits the number of items per page. The --debug parameter prints low-level information about requests and responses.\n\nIf you run the example, the first response from DynamoDB looks similar to the following.\n\n2017-07-07 11:13:15,603 - MainThread - botocore.parsers - DEBUG - Response body:\nb'{\"Count\":5,\"Items\":[{\"title\":{\"S\":\"A Bronx Tale\"}},\n{\"title\":{\"S\":\"A Perfect World\"}},{\"title\":{\"S\":\"Addams Family Values\"}},\n{\"title\":{\"S\":\"Alive\"}},{\"title\":{\"S\":\"Benny & Joon\"}}],\n\"LastEvaluatedKey\":{\"year\":{\"N\":\"1993\"},\"title\":{\"S\":\"Benny & Joon\"}},\n\"ScannedCount\":5}'\n\nThe LastEvaluatedKey in the response indicates that not all of the items have been retrieved. The AWS CLI then issues another Query request to DynamoDB. This request and response pattern continues, until the final response.\n\n2017-07-07 11:13:16,291 - MainThread - botocore.parsers - DEBUG - Response body:\nb'{\"Count\":1,\"Items\":[{\"title\":{\"S\":\"What\\'s Eating Gilbert Grape\"}}],\"ScannedCount\":1}'\n\nThe absence of LastEvaluatedKey indicates that there are no more items to retrieve.\n\nNote\n\nThe AWS SDKs handle the low-level DynamoDB responses (including the presence or absence of LastEvaluatedKey) and provide various abstractions for paginating Query results. For example, the SDK for Java document interface provides java.util.Iterator support so that you can walk through the results one at a time.\n\nFor code examples in various programming languages, see the Amazon DynamoDB Getting Started Guide and the AWS SDK documentation for your language.\n\nYou can also reduce page size by limiting the number of items in the result set, with the Limit parameter of the Query operation.\n\nFor more information about querying with DynamoDB, see Query operations in DynamoDB."
  },
  {
    "title": "Filter expressions for the Query operation - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.FilterExpression.html",
    "html": "Filter expressions for the Query operation\nPDF\nRSS\n\nIf you need to further refine the Query results, you can optionally provide a filter expression. A filter expression determines which items within the Query results should be returned to you. All of the other results are discarded.\n\nA filter expression is applied after a Query finishes, but before the results are returned. Therefore, a Query consumes the same amount of read capacity, regardless of whether a filter expression is present.\n\nA Query operation can retrieve a maximum of 1 MB of data. This limit applies before the filter expression is evaluated.\n\nA filter expression cannot contain partition key or sort key attributes. You need to specify those attributes in the key condition expression, not the filter expression.\n\nThe syntax for a filter expression is similar to that of a key condition expression. Filter expressions can use the same comparators, functions, and logical operators as a key condition expression. In addition, filter expressions can use the not-equals operator (<>), the OR operator, the CONTAINS operator, the IN operator, the BEGINS_WITH operator, the BETWEEN operator, the EXISTS operator, and the SIZE operator. For more information, see Key condition expressions for the Query operation and Syntax for filter and condition expressions.\n\nExample\n\nThe following AWS CLI example queries the Thread table for a particular ForumName (partition key) and Subject (sort key). Of the items that are found, only the most popular discussion threads are returned—in other words, only those threads with more than a certain number of Views.\n\naws dynamodb query \\\n    --table-name Thread \\\n    --key-condition-expression \"ForumName = :fn and Subject = :sub\" \\\n    --filter-expression \"#v >= :num\" \\\n    --expression-attribute-names '{\"#v\": \"Views\"}' \\\n    --expression-attribute-values file://values.json\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":fn\":{\"S\":\"Amazon DynamoDB\"},\n    \":sub\":{\"S\":\"DynamoDB Thread 1\"},\n    \":num\":{\"N\":\"3\"}\n}\n\nNote that Views is a reserved word in DynamoDB (see Reserved words in DynamoDB), so this example uses #v as a placeholder. For more information, see Expression attribute names in DynamoDB.\n\nNote\n\nA filter expression removes items from the Query result set. If possible, avoid using Query where you expect to retrieve a large number of items but also need to discard most of those items."
  },
  {
    "title": "Query operations in DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.html",
    "html": "Query operations in DynamoDB\nPDF\nRSS\n\nYou can use the Query API operation in Amazon DynamoDB to find items based on primary key values.\n\nYou must provide the name of the partition key attribute and a single value for that attribute. Query returns all items with that partition key value. Optionally, you can provide a sort key attribute and use a comparison operator to refine the search results.\n\nFor more information on how to use Query, such as the request syntax, response parameters, and additional examples, see Query in the Amazon DynamoDB API Reference.\n\nTopics\nKey condition expressions for the Query operation\nFilter expressions for the Query operation\nPaginating table query results\nOther aspects of working with the Query operation\nQuerying tables and indexes: Java\nQuerying tables and indexes: .NET"
  },
  {
    "title": "Key condition expressions for the Query operation - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.KeyConditionExpressions.html",
    "html": "Key condition expressions for the Query operation\nPDF\nRSS\n\nTo specify the search criteria, you use a key condition expression—a string that determines the items to be read from the table or index.\n\nYou must specify the partition key name and value as an equality condition. You cannot use a non-key attribute in a key condition expression.\n\nYou can optionally provide a second condition for the sort key (if present). The sort key condition must use one of the following comparison operators:\n\na = b — true if the attribute a is equal to the value b\n\na < b — true if a is less than b\n\na <= b — true if a is less than or equal to b\n\na > b — true if a is greater than b\n\na >= b — true if a is greater than or equal to b\n\na BETWEEN b AND c — true if a is greater than or equal to b, and less than or equal to c.\n\nThe following function is also supported:\n\nbegins_with (a, substr)— true if the value of attribute a begins with a particular substring.\n\nThe following AWS Command Line Interface (AWS CLI) examples demonstrate the use of key condition expressions. These expressions use placeholders (such as :name and :sub) instead of actual values. For more information, see Expression attribute names in DynamoDB and Expression attribute values.\n\nExample\n\nQuery the Thread table for a particular ForumName (partition key). All of the items with that ForumName value are read by the query because the sort key (Subject) is not included in KeyConditionExpression.\n\naws dynamodb query \\\n    --table-name Thread \\\n    --key-condition-expression \"ForumName = :name\" \\\n    --expression-attribute-values  '{\":name\":{\"S\":\"Amazon DynamoDB\"}}'\nExample\n\nQuery the Thread table for a particular ForumName (partition key), but this time return only the items with a given Subject (sort key).\n\naws dynamodb query \\\n    --table-name Thread \\\n    --key-condition-expression \"ForumName = :name and Subject = :sub\" \\\n    --expression-attribute-values  file://values.json\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":name\":{\"S\":\"Amazon DynamoDB\"},\n    \":sub\":{\"S\":\"DynamoDB Thread 1\"}\n}\nExample\n\nQuery the Reply table for a particular Id (partition key), but return only those items whose ReplyDateTime (sort key) begins with certain characters.\n\naws dynamodb query \\\n    --table-name Reply \\\n    --key-condition-expression \"Id = :id and begins_with(ReplyDateTime, :dt)\" \\\n    --expression-attribute-values  file://values.json\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":id\":{\"S\":\"Amazon DynamoDB#DynamoDB Thread 1\"},\n    \":dt\":{\"S\":\"2015-09\"}\n}\n\nYou can use any attribute name in a key condition expression, provided that the first character is a-z or A-Z and the rest of the characters (starting from the second character, if present) are a-z, A-Z, or 0-9. In addition, the attribute name must not be a DynamoDB reserved word. (For a complete list of these, see Reserved words in DynamoDB.) If an attribute name does not meet these requirements, you must define an expression attribute name as a placeholder. For more information, see Expression attribute names in DynamoDB.\n\nFor items with a given partition key value, DynamoDB stores these items close together, in sorted order by sort key value. In a Query operation, DynamoDB retrieves the items in sorted order, and then processes the items using KeyConditionExpression and any FilterExpression that might be present. Only then are the Query results sent back to the client.\n\nA Query operation always returns a result set. If no matching items are found, the result set is empty.\n\nQuery results are always sorted by the sort key value. If the data type of the sort key is Number, the results are returned in numeric order. Otherwise, the results are returned in order of UTF-8 bytes. By default, the sort order is ascending. To reverse the order, set the ScanIndexForward parameter to false.\n\nA single Query operation can retrieve a maximum of 1 MB of data. This limit applies before any FilterExpression or ProjectionExpression is applied to the results. If LastEvaluatedKey is present in the response and is non-null, you must paginate the result set (see Paginating table query results)."
  },
  {
    "title": "Example: Handling binary type attributes using the AWS SDK for .NET low-level API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LowLevelDotNetBinaryTypeExample.html",
    "html": "Example: Handling binary type attributes using the AWS SDK for .NET low-level API\nPDF\nRSS\n\nThe following C# code example illustrates the handling of binary type attributes. The example adds an item to the Reply table. The item includes a binary type attribute (ExtendedMessage) that stores compressed data. The example then retrieves the item and prints all the attribute values. For illustration, the example uses the GZipStream class to compress a sample stream and assigns it to the ExtendedMessage attribute, and decompresses it when printing the attribute value.\n\nIf you followed the steps in Creating tables and loading data for code examples in DynamoDB, you already have the Reply table created. You can also create these sample tables programmatically. For more information, see Creating example tables and uploading data using the AWS SDK for .NET.\n\nFor step-by-step instructions for testing the following example, see .NET code examples.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing System.IO;\nusing System.IO.Compression;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.Model;\nusing Amazon.Runtime;\n\nnamespace com.amazonaws.codesamples\n{\n    class LowLevelItemBinaryExample\n    {\n        private static string tableName = \"Reply\";\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            // Reply table primary key.\n            string replyIdPartitionKey = \"Amazon DynamoDB#DynamoDB Thread 1\";\n            string replyDateTimeSortKey = Convert.ToString(DateTime.UtcNow);\n\n            try\n            {\n                CreateItem(replyIdPartitionKey, replyDateTimeSortKey);\n                RetrieveItem(replyIdPartitionKey, replyDateTimeSortKey);\n                // Delete item.\n                DeleteItem(replyIdPartitionKey, replyDateTimeSortKey);\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (AmazonDynamoDBException e) { Console.WriteLine(e.Message); }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n        }\n\n        private static void CreateItem(string partitionKey, string sortKey)\n        {\n            MemoryStream compressedMessage = ToGzipMemoryStream(\"Some long extended message to compress.\");\n            var request = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = new Dictionary<string, AttributeValue>()\n            {\n                { \"Id\", new AttributeValue {\n                      S = partitionKey\n                  }},\n                { \"ReplyDateTime\", new AttributeValue {\n                      S = sortKey\n                  }},\n                { \"Subject\", new AttributeValue {\n                      S = \"Binary type \"\n                  }},\n                { \"Message\", new AttributeValue {\n                      S = \"Some message about the binary type\"\n                  }},\n                { \"ExtendedMessage\", new AttributeValue {\n                      B = compressedMessage\n                  }}\n            }\n            };\n            client.PutItem(request);\n        }\n\n        private static void RetrieveItem(string partitionKey, string sortKey)\n        {\n            var request = new GetItemRequest\n            {\n                TableName = tableName,\n                Key = new Dictionary<string, AttributeValue>()\n            {\n                { \"Id\", new AttributeValue {\n                      S = partitionKey\n                  } },\n                { \"ReplyDateTime\", new AttributeValue {\n                      S = sortKey\n                  } }\n            },\n                ConsistentRead = true\n            };\n            var response = client.GetItem(request);\n\n            // Check the response.\n            var attributeList = response.Item; // attribute list in the response.\n            Console.WriteLine(\"\\nPrinting item after retrieving it ............\");\n\n            PrintItem(attributeList);\n        }\n\n        private static void DeleteItem(string partitionKey, string sortKey)\n        {\n            var request = new DeleteItemRequest\n            {\n                TableName = tableName,\n                Key = new Dictionary<string, AttributeValue>()\n            {\n                { \"Id\", new AttributeValue {\n                      S = partitionKey\n                  } },\n                { \"ReplyDateTime\", new AttributeValue {\n                      S = sortKey\n                  } }\n            }\n            };\n            var response = client.DeleteItem(request);\n        }\n\n        private static void PrintItem(Dictionary<string, AttributeValue> attributeList)\n        {\n            foreach (KeyValuePair<string, AttributeValue> kvp in attributeList)\n            {\n                string attributeName = kvp.Key;\n                AttributeValue value = kvp.Value;\n\n                Console.WriteLine(\n                    attributeName + \" \" +\n                    (value.S == null ? \"\" : \"S=[\" + value.S + \"]\") +\n                    (value.N == null ? \"\" : \"N=[\" + value.N + \"]\") +\n                    (value.SS == null ? \"\" : \"SS=[\" + string.Join(\",\", value.SS.ToArray()) + \"]\") +\n                    (value.NS == null ? \"\" : \"NS=[\" + string.Join(\",\", value.NS.ToArray()) + \"]\") +\n                    (value.B == null ? \"\" : \"B=[\" + FromGzipMemoryStream(value.B) + \"]\")\n                    );\n            }\n            Console.WriteLine(\"************************************************\");\n        }\n\n        private static MemoryStream ToGzipMemoryStream(string value)\n        {\n            MemoryStream output = new MemoryStream();\n            using (GZipStream zipStream = new GZipStream(output, CompressionMode.Compress, true))\n            using (StreamWriter writer = new StreamWriter(zipStream))\n            {\n                writer.Write(value);\n            }\n            return output;\n        }\n\n        private static string FromGzipMemoryStream(MemoryStream stream)\n        {\n            using (GZipStream zipStream = new GZipStream(stream, CompressionMode.Decompress))\n            using (StreamReader reader = new StreamReader(zipStream))\n            {\n                return reader.ReadToEnd();\n            }\n        }\n    }\n}\n"
  },
  {
    "title": "Item collections - how to model one-to-many relationships in DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItemCollections.html",
    "html": "Item collections - how to model one-to-many relationships in DynamoDB\nPDF\nRSS\n\nIn DynamoDB, an item collection is a group of items that share the same partition key value, which means the items are related. Item collections are the primary mechanism to model one-to-many relationships in DynamoDB. Item collections can only exist on tables or indexes configured to use a composite primary key.\n\nNote\n\nItem collections can exist either in a base table or a secondary index. For more information specifically about how item collections interact with indexes, see Item collections in Local Secondary Indexes.\n\nConsider the following table showing three different users and their in-game inventories:\n\nFor some items in each collection, the sort key is a concatenation made up of information used to group data, such as inventory::armor, inventory::weapon or info. Each item collection can have a different combination of these attributes as the sort key. User account1234 has an inventory::weapons item, while user account1387 does not (because they have not found any yet). User account1138 only uses two items for their sort key (since they have no inventory yet) while the other users use three.\n\nDynamoDB lets you selectively retrieve items from these item collections to do the following:\n\nRetrieve all items from a particular user\n\nRetrieve only one item from a particular user\n\nRetrieve all the items of a specific type belonging to a particular user\n\nSpeed up queries by organizing your data with item collections\n\nIn this example, each of the items in these three item collections represents a player and the data model we have chosen, based off the game’s and player’s access patterns. What data does the game need? When does it need it? How frequently does it need it? What’s the cost of doing it this way? These data modeling decisions were made based off the answers to these questions.\n\nIn this game, there is a different page presented to the player for their inventory for weapons and another page for armor. When the player opens their inventory, weapons are shown first because we want that page to load extremely fast, while subsequent inventory pages can load after that. Since each of these item types can be quite large as the player acquires more in-game items, we decided that each inventory page would be its own item in the player’s item collection in the database.\n\nThe following section talks more about how you can interact with item collections through the Query operation.\n\nTopics\nQuery operations in DynamoDB"
  },
  {
    "title": "Example: Batch operations using the AWS SDK for .NET low-level API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/batch-operation-lowlevel-dotnet.html",
    "html": "Example: Batch operations using the AWS SDK for .NET low-level API\nPDF\nRSS\nTopics\nExample: Batch write operation using the AWS SDK for .NET low-level API\nExample: Batch get operation using the AWS SDK for .NET low-level API\n\nThis section provides examples of batch operations, batch write and batch get, that Amazon DynamoDB supports.\n\nExample: Batch write operation using the AWS SDK for .NET low-level API\n\nThe following C# code example uses the BatchWriteItem method to perform the following put and delete operations:\n\nPut one item in the Forum table.\n\nPut one item and delete one item from the Thread table.\n\nYou can specify any number of put and delete requests against one or more tables when creating your batch write request. However, DynamoDB BatchWriteItem limits the size of a batch write request and the number of put and delete operations in a single batch write operation. For more information, see BatchWriteItem. If your request exceeds these limits, your request is rejected. If your table does not have sufficient provisioned throughput to serve this request, the unprocessed request items are returned in the response.\n\nThe following example checks the response to see if it has any unprocessed request items. If it does, it loops back and resends the BatchWriteItem request with unprocessed items in the request. If you followed the steps in Creating tables and loading data for code examples in DynamoDB, you already have the Forum and Thread tables created. You can also create these sample tables and upload sample data programmatically. For more information, see Creating example tables and uploading data using the AWS SDK for .NET.\n\nFor step-by-step instructions for testing the following sample, see .NET code examples.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.Model;\nusing Amazon.Runtime;\n\nnamespace com.amazonaws.codesamples\n{\n    class LowLevelBatchWrite\n    {\n        private static string table1Name = \"Forum\";\n        private static string table2Name = \"Thread\";\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                TestBatchWrite();\n            }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n\n            Console.WriteLine(\"To continue, press Enter\");\n            Console.ReadLine();\n        }\n\n        private static void TestBatchWrite()\n        {\n            var request = new BatchWriteItemRequest\n            {\n                ReturnConsumedCapacity = \"TOTAL\",\n                RequestItems = new Dictionary<string, List<WriteRequest>>\n            {\n                {\n                    table1Name, new List<WriteRequest>\n                    {\n                        new WriteRequest\n                        {\n                            PutRequest = new PutRequest\n                            {\n                                Item = new Dictionary<string, AttributeValue>\n                                {\n                                    { \"Name\", new AttributeValue {\n                                          S = \"S3 forum\"\n                                      } },\n                                    { \"Threads\", new AttributeValue {\n                                          N = \"0\"\n                                      }}\n                                }\n                            }\n                        }\n                    }\n                },\n                {\n                    table2Name, new List<WriteRequest>\n                    {\n                        new WriteRequest\n                        {\n                            PutRequest = new PutRequest\n                            {\n                                Item = new Dictionary<string, AttributeValue>\n                                {\n                                    { \"ForumName\", new AttributeValue {\n                                          S = \"S3 forum\"\n                                      } },\n                                    { \"Subject\", new AttributeValue {\n                                          S = \"My sample question\"\n                                      } },\n                                    { \"Message\", new AttributeValue {\n                                          S = \"Message Text.\"\n                                      } },\n                                    { \"KeywordTags\", new AttributeValue {\n                                          SS = new List<string> { \"S3\", \"Bucket\" }\n                                      } }\n                                }\n                            }\n                        },\n                        new WriteRequest\n                        {\n                            // For the operation to delete an item, if you provide a primary key value\n                            // that does not exist in the table, there is no error, it is just a no-op.\n                            DeleteRequest = new DeleteRequest\n                            {\n                                Key = new Dictionary<string, AttributeValue>()\n                                {\n                                    { \"ForumName\",  new AttributeValue {\n                                          S = \"Some partition key value\"\n                                      } },\n                                    { \"Subject\", new AttributeValue {\n                                          S = \"Some sort key value\"\n                                      } }\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n            };\n\n            CallBatchWriteTillCompletion(request);\n        }\n\n        private static void CallBatchWriteTillCompletion(BatchWriteItemRequest request)\n        {\n            BatchWriteItemResponse response;\n\n            int callCount = 0;\n            do\n            {\n                Console.WriteLine(\"Making request\");\n                response = client.BatchWriteItem(request);\n                callCount++;\n\n                // Check the response.\n\n                var tableConsumedCapacities = response.ConsumedCapacity;\n                var unprocessed = response.UnprocessedItems;\n\n                Console.WriteLine(\"Per-table consumed capacity\");\n                foreach (var tableConsumedCapacity in tableConsumedCapacities)\n                {\n                    Console.WriteLine(\"{0} - {1}\", tableConsumedCapacity.TableName, tableConsumedCapacity.CapacityUnits);\n                }\n\n                Console.WriteLine(\"Unprocessed\");\n                foreach (var unp in unprocessed)\n                {\n                    Console.WriteLine(\"{0} - {1}\", unp.Key, unp.Value.Count);\n                }\n                Console.WriteLine();\n\n                // For the next iteration, the request will have unprocessed items.\n                request.RequestItems = unprocessed;\n            } while (response.UnprocessedItems.Count > 0);\n\n            Console.WriteLine(\"Total # of batch write API calls made: {0}\", callCount);\n        }\n    }\n}\n\nExample: Batch get operation using the AWS SDK for .NET low-level API\n\nThe following C# code example uses the BatchGetItem method to retrieve multiple items from the Forum and the Thread tables in Amazon DynamoDB. The BatchGetItemRequest specifies the table names and a list of primary keys for each table. The example processes the response by printing the items retrieved.\n\nIf you followed the steps in Creating tables and loading data for code examples in DynamoDB, you already have these tables created with sample data. You can also create these sample tables and upload sample data programmatically. For more information, see Creating example tables and uploading data using the AWS SDK for .NET.\n\nFor step-by-step instructions for testing the following sample, see .NET code examples.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.Model;\nusing Amazon.Runtime;\n\nnamespace com.amazonaws.codesamples\n{\n    class LowLevelBatchGet\n    {\n        private static string table1Name = \"Forum\";\n        private static string table2Name = \"Thread\";\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                RetrieveMultipleItemsBatchGet();\n\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n        }\n\n        private static void RetrieveMultipleItemsBatchGet()\n        {\n            var request = new BatchGetItemRequest\n            {\n                RequestItems = new Dictionary<string, KeysAndAttributes>()\n            {\n                { table1Name,\n                  new KeysAndAttributes\n                  {\n                      Keys = new List<Dictionary<string, AttributeValue> >()\n                      {\n                          new Dictionary<string, AttributeValue>()\n                          {\n                              { \"Name\", new AttributeValue {\n                            S = \"Amazon DynamoDB\"\n                        } }\n                          },\n                          new Dictionary<string, AttributeValue>()\n                          {\n                              { \"Name\", new AttributeValue {\n                            S = \"Amazon S3\"\n                        } }\n                          }\n                      }\n                  }},\n                {\n                    table2Name,\n                    new KeysAndAttributes\n                    {\n                        Keys = new List<Dictionary<string, AttributeValue> >()\n                        {\n                            new Dictionary<string, AttributeValue>()\n                            {\n                                { \"ForumName\", new AttributeValue {\n                                      S = \"Amazon DynamoDB\"\n                                  } },\n                                { \"Subject\", new AttributeValue {\n                                      S = \"DynamoDB Thread 1\"\n                                  } }\n                            },\n                            new Dictionary<string, AttributeValue>()\n                            {\n                                { \"ForumName\", new AttributeValue {\n                                      S = \"Amazon DynamoDB\"\n                                  } },\n                                { \"Subject\", new AttributeValue {\n                                      S = \"DynamoDB Thread 2\"\n                                  } }\n                            },\n                            new Dictionary<string, AttributeValue>()\n                            {\n                                { \"ForumName\", new AttributeValue {\n                                      S = \"Amazon S3\"\n                                  } },\n                                { \"Subject\", new AttributeValue {\n                                      S = \"S3 Thread 1\"\n                                  } }\n                            }\n                        }\n                    }\n                }\n            }\n            };\n\n            BatchGetItemResponse response;\n            do\n            {\n                Console.WriteLine(\"Making request\");\n                response = client.BatchGetItem(request);\n\n                // Check the response.\n                var responses = response.Responses; // Attribute list in the response.\n\n                foreach (var tableResponse in responses)\n                {\n                    var tableResults = tableResponse.Value;\n                    Console.WriteLine(\"Items retrieved from table {0}\", tableResponse.Key);\n                    foreach (var item1 in tableResults)\n                    {\n                        PrintItem(item1);\n                    }\n                }\n\n                // Any unprocessed keys? could happen if you exceed ProvisionedThroughput or some other error.\n                Dictionary<string, KeysAndAttributes> unprocessedKeys = response.UnprocessedKeys;\n                foreach (var unprocessedTableKeys in unprocessedKeys)\n                {\n                    // Print table name.\n                    Console.WriteLine(unprocessedTableKeys.Key);\n                    // Print unprocessed primary keys.\n                    foreach (var key in unprocessedTableKeys.Value.Keys)\n                    {\n                        PrintItem(key);\n                    }\n                }\n\n                request.RequestItems = unprocessedKeys;\n            } while (response.UnprocessedKeys.Count > 0);\n        }\n\n        private static void PrintItem(Dictionary<string, AttributeValue> attributeList)\n        {\n            foreach (KeyValuePair<string, AttributeValue> kvp in attributeList)\n            {\n                string attributeName = kvp.Key;\n                AttributeValue value = kvp.Value;\n\n                Console.WriteLine(\n                    attributeName + \" \" +\n                    (value.S == null ? \"\" : \"S=[\" + value.S + \"]\") +\n                    (value.N == null ? \"\" : \"N=[\" + value.N + \"]\") +\n                    (value.SS == null ? \"\" : \"SS=[\" + string.Join(\",\", value.SS.ToArray()) + \"]\") +\n                    (value.NS == null ? \"\" : \"NS=[\" + string.Join(\",\", value.NS.ToArray()) + \"]\")\n                    );\n            }\n            Console.WriteLine(\"************************************************\");\n        }\n    }\n}\n"
  },
  {
    "title": "Working with items: .NET - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LowLevelDotNetItemCRUD.html",
    "html": "Working with items: .NET\nPDF\nRSS\n\nYou can use the AWS SDK for .NET low-level API to perform typical create, read, update, and delete (CRUD) operations on an item in a table. The following are the common steps that you follow to perform data CRUD operations using the .NET low-level API:\n\nCreate an instance of the AmazonDynamoDBClient class (the client).\n\nProvide the operation-specific required parameters in a corresponding request object.\n\nFor example, use the PutItemRequest request object when uploading an item and use the GetItemRequest request object when retrieving an existing item.\n\nYou can use the request object to provide both the required and optional parameters.\n\nRun the appropriate method provided by the client by passing in the request object that you created in the preceding step.\n\nThe AmazonDynamoDBClient client provides PutItem, GetItem, UpdateItem, and DeleteItem methods for the CRUD operations.\n\nTopics\nPutting an item\nGetting an item\nUpdating an item\nAtomic counter\nDeleting an item\nBatch write: Putting and deleting multiple items\nBatch get: Getting multiple items\nExample: CRUD operations using the AWS SDK for .NET low-level API\nExample: Batch operations using the AWS SDK for .NET low-level API\nExample: Handling binary type attributes using the AWS SDK for .NET low-level API\nPutting an item\n\nThe PutItem method uploads an item to a table. If the item exists, it replaces the entire item.\n\nNote\n\nInstead of replacing the entire item, if you want to update only specific attributes, you can use the UpdateItem method. For more information, see Updating an item.\n\nThe following are the steps to upload an item using the low-level .NET SDK API:\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nProvide the required parameters by creating an instance of the PutItemRequest class.\n\nTo put an item, you must provide the table name and the item.\n\nRun the PutItem method by providing the PutItemRequest object that you created in the preceding step.\n\nThe following C# example demonstrates the preceding steps. The example uploads an item to the ProductCatalog table.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"ProductCatalog\";\n\nvar request = new PutItemRequest\n{\n   TableName = tableName,\n   Item = new Dictionary<string, AttributeValue>()\n      {\n          { \"Id\", new AttributeValue { N = \"201\" }},\n          { \"Title\", new AttributeValue { S = \"Book 201 Title\" }},\n          { \"ISBN\", new AttributeValue { S = \"11-11-11-11\" }},\n          { \"Price\", new AttributeValue { S = \"20.00\" }},\n          {\n            \"Authors\",\n            new AttributeValue\n            { SS = new List<string>{\"Author1\", \"Author2\"}   }\n          }\n      }\n};\nclient.PutItem(request);\n\nIn the preceding example, you upload a book item that has the Id, Title, ISBN, and Authors attributes. Note that Id is a numeric type attribute, and all other attributes are of the string type. Authors is a String set.\n\nSpecifying optional parameters\n\nYou can also provide optional parameters using the PutItemRequest object as shown in the following C# example. The example specifies the following optional parameters:\n\nExpressionAttributeNames, ExpressionAttributeValues, and ConditionExpression specify that the item can be replaced only if the existing item has the ISBN attribute with a specific value.\n\nReturnValues parameter to request the old item in the response.\n\nExample\nvar request = new PutItemRequest\n {\n   TableName = tableName,\n   Item = new Dictionary<string, AttributeValue>()\n               {\n                   { \"Id\", new AttributeValue { N = \"104\" }},\n                   { \"Title\", new AttributeValue { S = \"Book 104  Title\" }},\n                   { \"ISBN\", new AttributeValue { S = \"444-4444444444\" }},\n                   { \"Authors\",\n                     new AttributeValue { SS = new List<string>{\"Author3\"}}}\n               },\n    // Optional parameters.\n    ExpressionAttributeNames = new Dictionary<string,string>()\n    {\n        {\"#I\", \"ISBN\"}\n    },\n    ExpressionAttributeValues = new Dictionary<string, AttributeValue>()\n    {\n        {\":isbn\",new AttributeValue {S = \"444-4444444444\"}}\n    },\n    ConditionExpression = \"#I = :isbn\"\n\n};\nvar response = client.PutItem(request);\n\nFor more information, see PutItem.\n\nGetting an item\n\nThe GetItem method retrieves an item.\n\nNote\n\nTo retrieve multiple items, you can use the BatchGetItem method. For more information, see Batch get: Getting multiple items.\n\nThe following are the steps to retrieve an existing item using the low-level AWS SDK for .NET API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nProvide the required parameters by creating an instance of the GetItemRequest class.\n\nTo get an item, you must provide the table name and primary key of the item.\n\nRun the GetItem method by providing the GetItemRequest object that you created in the preceding step.\n\nThe following C# example demonstrates the preceding steps. The example retrieves an item from the ProductCatalog table.\n\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"ProductCatalog\";\n\nvar request = new GetItemRequest\n {\n   TableName = tableName,\n   Key = new Dictionary<string,AttributeValue>() { { \"Id\", new AttributeValue { N = \"202\" } } },\n };\n var response = client.GetItem(request);\n\n// Check the response.\nvar result = response.GetItemResult;\nvar attributeMap = result.Item; // Attribute list in the response.\nSpecifying optional parameters\n\nYou can also provide optional parameters using the GetItemRequest object, as shown in the following C# example. The sample specifies the following optional parameters:\n\nProjectionExpression parameter to specify the attributes to retrieve.\n\nConsistentRead parameter to perform a strongly consistent read. To learn more read consistency, see Read consistency.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"ProductCatalog\";\n\nvar request = new GetItemRequest\n {\n   TableName = tableName,\n   Key = new Dictionary<string,AttributeValue>() { { \"Id\", new AttributeValue { N = \"202\" } } },\n   // Optional parameters.\n   ProjectionExpression = \"Id, ISBN, Title, Authors\",\n   ConsistentRead = true\n };\n\n var response = client.GetItem(request);\n\n// Check the response.\nvar result = response.GetItemResult;\nvar attributeMap = result.Item; \n\nFor more information, see GetItem.\n\nUpdating an item\n\nThe UpdateItem method updates an existing item if it is present. You can use the UpdateItem operation to update existing attribute values, add new attributes, or delete attributes from the existing collection. If the item that has the specified primary key is not found, it adds a new item.\n\nThe UpdateItem operation uses the following guidelines:\n\nIf the item does not exist, UpdateItem adds a new item using the primary key that is specified in the input.\n\nIf the item exists, UpdateItem applies the updates as follows:\n\nReplaces the existing attribute values by the values in the update.\n\nIf the attribute that you provide in the input does not exist, it adds a new attribute to the item.\n\nIf the input attribute is null, it deletes the attribute, if it is present.\n\nIf you use ADD for the Action, you can add values to an existing set (string or number set), or mathematically add (use a positive number) or subtract (use a negative number) from the existing numeric attribute value.\n\nNote\n\nThe PutItem operation also can perform an update. For more information, see Putting an item. For example, if you call PutItem to upload an item and the primary key exists, the PutItem operation replaces the entire item. If there are attributes in the existing item and those attributes are not specified in the input, the PutItem operation deletes those attributes. However, UpdateItem updates only the specified input attributes. Any other existing attributes of that item remain unchanged.\n\nThe following are the steps to update an existing item using the low-level .NET SDK API:\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nProvide the required parameters by creating an instance of the UpdateItemRequest class.\n\nThis is the request object in which you describe all the updates, such as add attributes, update existing attributes, or delete attributes. To delete an existing attribute, specify the attribute name with null value.\n\nRun the UpdateItem method by providing the UpdateItemRequest object that you created in the preceding step.\n\nThe following C# code example demonstrates the preceding steps. The example updates a book item in the ProductCatalog table. It adds a new author to the Authors collection, and deletes the existing ISBN attribute. It also reduces the price by one.\n\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"ProductCatalog\";\n\nvar request = new UpdateItemRequest\n{\n    TableName = tableName,\n    Key = new Dictionary<string,AttributeValue>() { { \"Id\", new AttributeValue { N = \"202\" } } },\n    ExpressionAttributeNames = new Dictionary<string,string>()\n    {\n        {\"#A\", \"Authors\"},\n        {\"#P\", \"Price\"},\n        {\"#NA\", \"NewAttribute\"},\n        {\"#I\", \"ISBN\"}\n    },\n    ExpressionAttributeValues = new Dictionary<string, AttributeValue>()\n    {\n        {\":auth\",new AttributeValue { SS = {\"Author YY\",\"Author ZZ\"}}},\n        {\":p\",new AttributeValue {N = \"1\"}},\n        {\":newattr\",new AttributeValue {S = \"someValue\"}},\n    },\n\n    // This expression does the following:\n    // 1) Adds two new authors to the list\n    // 2) Reduces the price\n    // 3) Adds a new attribute to the item\n    // 4) Removes the ISBN attribute from the item\n    UpdateExpression = \"ADD #A :auth SET #P = #P - :p, #NA = :newattr REMOVE #I\"\n};\nvar response = client.UpdateItem(request);\nSpecifying optional parameters\n\nYou can also provide optional parameters using the UpdateItemRequest object, as shown in the following C# example. It specifies the following optional parameters:\n\nExpressionAttributeValues and ConditionExpression to specify that the price can be updated only if the existing price is 20.00.\n\nReturnValues parameter to request the updated item in the response.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"ProductCatalog\";\n\nvar request = new UpdateItemRequest\n{\n    Key = new Dictionary<string,AttributeValue>() { { \"Id\", new AttributeValue { N = \"202\" } } },\n\n    // Update price only if the current price is 20.00.\n    ExpressionAttributeNames = new Dictionary<string,string>()\n    {\n        {\"#P\", \"Price\"}\n    },\n    ExpressionAttributeValues = new Dictionary<string, AttributeValue>()\n    {\n        {\":newprice\",new AttributeValue {N = \"22\"}},\n        {\":currprice\",new AttributeValue {N = \"20\"}}\n    },\n    UpdateExpression = \"SET #P = :newprice\",\n    ConditionExpression = \"#P = :currprice\",\n    TableName = tableName,\n    ReturnValues = \"ALL_NEW\" // Return all the attributes of the updated item.\n};\n\nvar response = client.UpdateItem(request);\n\nFor more information, see UpdateItem.\n\nAtomic counter\n\nYou can use updateItem to implement an atomic counter, where you increment or decrement the value of an existing attribute without interfering with other write requests. To update an atomic counter, use updateItem with an attribute of type Number in the UpdateExpression parameter, and ADD as the Action.\n\nThe following example demonstrates this, incrementing the Quantity attribute by one.\n\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"ProductCatalog\";\n\nvar request = new UpdateItemRequest\n{\n    Key = new Dictionary<string, AttributeValue>() { { \"Id\", new AttributeValue { N = \"121\" } } },\n    ExpressionAttributeNames = new Dictionary<string, string>()\n    {\n        {\"#Q\", \"Quantity\"}\n    },\n    ExpressionAttributeValues = new Dictionary<string, AttributeValue>()\n    {\n        {\":incr\",new AttributeValue {N = \"1\"}}\n    },\n    UpdateExpression = \"SET #Q = #Q + :incr\",\n    TableName = tableName\n};\n\nvar response = client.UpdateItem(request);\nDeleting an item\n\nThe DeleteItem method deletes an item from a table.\n\nThe following are the steps to delete an item using the low-level .NET SDK API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nProvide the required parameters by creating an instance of the DeleteItemRequest class.\n\nTo delete an item, the table name and item's primary key are required.\n\nRun the DeleteItem method by providing the DeleteItemRequest object that you created in the preceding step.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"ProductCatalog\";\n\nvar request = new DeleteItemRequest\n{\n    TableName = tableName,\n    Key = new Dictionary<string,AttributeValue>() { { \"Id\", new AttributeValue { N = \"201\" } } },\n};\n\nvar response = client.DeleteItem(request);\nSpecifying optional parameters\n\nYou can also provide optional parameters using the DeleteItemRequest object as shown in the following C# code example. It specifies the following optional parameters:\n\nExpressionAttributeValues and ConditionExpression to specify that the book item can be deleted only if it is no longer in publication (the InPublication attribute value is false).\n\nReturnValues parameter to request the deleted item in the response.\n\nExample\nvar request = new DeleteItemRequest\n{\n    TableName = tableName,\n    Key = new Dictionary<string,AttributeValue>() { { \"Id\", new AttributeValue { N = \"201\" } } },\n\n    // Optional parameters.\n    ReturnValues = \"ALL_OLD\",\n    ExpressionAttributeNames = new Dictionary<string, string>()\n    {\n        {\"#IP\", \"InPublication\"}\n    },\n    ExpressionAttributeValues = new Dictionary<string, AttributeValue>()\n    {\n        {\":inpub\",new AttributeValue {BOOL = false}}\n    },\n    ConditionExpression = \"#IP = :inpub\"\n};\n\nvar response = client.DeleteItem(request);\n\nFor more information, see DeleteItem.\n\nBatch write: Putting and deleting multiple items\n\nBatch write refers to putting and deleting multiple items in a batch. The BatchWriteItem method enables you to put and delete multiple items from one or more tables in a single call. The following are the steps to retrieve multiple items using the low-level .NET SDK API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nDescribe all the put and delete operations by creating an instance of the BatchWriteItemRequest class.\n\nRun the BatchWriteItem method by providing the BatchWriteItemRequest object that you created in the preceding step.\n\nProcess the response. You should check if there were any unprocessed request items returned in the response. This could happen if you reach the provisioned throughput quota or some other transient error. Also, DynamoDB limits the request size and the number of operations you can specify in a request. If you exceed these limits, DynamoDB rejects the request. For more information, see BatchWriteItem.\n\nThe following C# code example demonstrates the preceding steps. The example creates a BatchWriteItemRequest to perform the following write operations:\n\nPut an item in Forum table.\n\nPut and delete an item from Thread table.\n\nThe code runs BatchWriteItem to perform a batch operation.\n\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\nstring table1Name = \"Forum\";\nstring table2Name = \"Thread\";\n\nvar request = new BatchWriteItemRequest\n {\n   RequestItems = new Dictionary<string, List<WriteRequest>>\n    {\n      {\n        table1Name, new List<WriteRequest>\n        {\n          new WriteRequest\n          {\n             PutRequest = new PutRequest\n             {\n                Item = new Dictionary<string,AttributeValue>\n                {\n                  { \"Name\", new AttributeValue { S = \"Amazon S3 forum\" } },\n                  { \"Threads\", new AttributeValue { N = \"0\" }}\n                }\n             }\n          }\n        }\n      } ,\n      {\n        table2Name, new List<WriteRequest>\n        {\n          new WriteRequest\n          {\n            PutRequest = new PutRequest\n            {\n               Item = new Dictionary<string,AttributeValue>\n               {\n                 { \"ForumName\", new AttributeValue { S = \"Amazon S3 forum\" } },\n                 { \"Subject\", new AttributeValue { S = \"My sample question\" } },\n                 { \"Message\", new AttributeValue { S = \"Message Text.\" } },\n                 { \"KeywordTags\", new AttributeValue { SS = new List<string> { \"Amazon S3\", \"Bucket\" }  } }\n               }\n            }\n          },\n          new WriteRequest\n          {\n             DeleteRequest = new DeleteRequest\n             {\n                Key = new Dictionary<string,AttributeValue>()\n                {\n                   { \"ForumName\", new AttributeValue { S = \"Some forum name\" } },\n                   { \"Subject\", new AttributeValue { S = \"Some subject\" } }\n                }\n             }\n          }\n        }\n      }\n    }\n };\nresponse = client.BatchWriteItem(request);\n\nFor a working example, see Example: Batch operations using the AWS SDK for .NET low-level API.\n\nBatch get: Getting multiple items\n\nThe BatchGetItem method enables you to retrieve multiple items from one or more tables.\n\nNote\n\nTo retrieve a single item, you can use the GetItem method.\n\nThe following are the steps to retrieve multiple items using the low-level AWS SDK for .NET API.\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nProvide the required parameters by creating an instance of the BatchGetItemRequest class.\n\nTo retrieve multiple items, the table name and a list of primary key values are required.\n\nRun the BatchGetItem method by providing the BatchGetItemRequest object that you created in the preceding step.\n\nProcess the response. You should check if there were any unprocessed keys, which could happen if you reach the provisioned throughput quota or some other transient error.\n\nThe following C# code example demonstrates the preceding steps. The example retrieves items from two tables, Forum and Thread. The request specifies two items in the Forum and three items in the Thread table. The response includes items from both of the tables. The code shows how you can process the response.\n\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\nstring table1Name = \"Forum\";\nstring table2Name = \"Thread\";\n\nvar request = new BatchGetItemRequest\n{\n  RequestItems = new Dictionary<string, KeysAndAttributes>()\n  {\n    { table1Name,\n      new KeysAndAttributes\n      {\n        Keys = new List<Dictionary<string, AttributeValue>>()\n        {\n          new Dictionary<string, AttributeValue>()\n          {\n            { \"Name\", new AttributeValue { S = \"DynamoDB\" } }\n          },\n          new Dictionary<string, AttributeValue>()\n          {\n            { \"Name\", new AttributeValue { S = \"Amazon S3\" } }\n          }\n        }\n      }\n    },\n    {\n      table2Name,\n      new KeysAndAttributes\n      {\n        Keys = new List<Dictionary<string, AttributeValue>>()\n        {\n          new Dictionary<string, AttributeValue>()\n          {\n            { \"ForumName\", new AttributeValue { S = \"DynamoDB\" } },\n            { \"Subject\", new AttributeValue { S = \"DynamoDB Thread 1\" } }\n          },\n          new Dictionary<string, AttributeValue>()\n          {\n            { \"ForumName\", new AttributeValue { S = \"DynamoDB\" } },\n            { \"Subject\", new AttributeValue { S = \"DynamoDB Thread 2\" } }\n          },\n          new Dictionary<string, AttributeValue>()\n          {\n            { \"ForumName\", new AttributeValue { S = \"Amazon S3\" } },\n            { \"Subject\", new AttributeValue { S = \"Amazon S3 Thread 1\" } }\n          }\n        }\n      }\n    }\n  }\n};\n\nvar response = client.BatchGetItem(request);\n\n// Check the response.\nvar result = response.BatchGetItemResult;\nvar responses = result.Responses; // The attribute list in the response.\n\nvar table1Results = responses[table1Name];\nConsole.WriteLine(\"Items in table {0}\" + table1Name);\nforeach (var item1 in table1Results.Items)\n{\n  PrintItem(item1);\n}\n\nvar table2Results = responses[table2Name];\nConsole.WriteLine(\"Items in table {1}\" + table2Name);\nforeach (var item2 in table2Results.Items)\n{\n  PrintItem(item2);\n}\n// Any unprocessed keys? could happen if you exceed ProvisionedThroughput or some other error.\nDictionary<string, KeysAndAttributes> unprocessedKeys = result.UnprocessedKeys;\nforeach (KeyValuePair<string, KeysAndAttributes> pair in unprocessedKeys)\n{\n    Console.WriteLine(pair.Key, pair.Value);\n}\n\nSpecifying optional parameters\n\nYou can also provide optional parameters using the BatchGetItemRequest object as shown in the following C# code example. The example retrieves two items from the Forum table. It specifies the following optional parameter:\n\nProjectionExpression parameter to specify the attributes to retrieve.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\nstring table1Name = \"Forum\";\n\nvar request = new BatchGetItemRequest\n{\n  RequestItems = new Dictionary<string, KeysAndAttributes>()\n  {\n    { table1Name,\n      new KeysAndAttributes\n      {\n        Keys = new List<Dictionary<string, AttributeValue>>()\n        {\n          new Dictionary<string, AttributeValue>()\n          {\n            { \"Name\", new AttributeValue { S = \"DynamoDB\" } }\n          },\n          new Dictionary<string, AttributeValue>()\n          {\n            { \"Name\", new AttributeValue { S = \"Amazon S3\" } }\n          }\n        }\n      },\n      // Optional - name of an attribute to retrieve.\n      ProjectionExpression = \"Title\"\n    }\n  }\n};\n\nvar response = client.BatchGetItem(request);\n\nFor more information, see BatchGetItem."
  },
  {
    "title": "Example: CRUD operations using the AWS SDK for .NET low-level API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LowLevelDotNetItemsExample.html",
    "html": "Example: CRUD operations using the AWS SDK for .NET low-level API\nPDF\nRSS\n\nThe following C# code example illustrates CRUD operations on an Amazon DynamoDB item. The example adds an item to the ProductCatalog table, retrieves it, performs various updates, and finally deletes the item. If you followed the steps in Creating tables and loading data for code examples in DynamoDB, you already have the ProductCatalog table created. You can also create these sample tables programmatically. For more information, see Creating example tables and uploading data using the AWS SDK for .NET.\n\nFor step-by-step instructions for testing the following sample, see .NET code examples.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.Model;\nusing Amazon.Runtime;\nusing Amazon.SecurityToken;\n\nnamespace com.amazonaws.codesamples\n{\n    class LowLevelItemCRUDExample\n    {\n        private static string tableName = \"ProductCatalog\";\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                CreateItem();\n                RetrieveItem();\n\n                // Perform various updates.\n                UpdateMultipleAttributes();\n                UpdateExistingAttributeConditionally();\n\n                // Delete item.\n                DeleteItem();\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (Exception e)\n            {\n                Console.WriteLine(e.Message);\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n        }\n\n        private static void CreateItem()\n        {\n            var request = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = new Dictionary<string, AttributeValue>()\n            {\n                { \"Id\", new AttributeValue {\n                      N = \"1000\"\n                  }},\n                { \"Title\", new AttributeValue {\n                      S = \"Book 201 Title\"\n                  }},\n                { \"ISBN\", new AttributeValue {\n                      S = \"11-11-11-11\"\n                  }},\n                { \"Authors\", new AttributeValue {\n                      SS = new List<string>{\"Author1\", \"Author2\" }\n                  }},\n                { \"Price\", new AttributeValue {\n                      N = \"20.00\"\n                  }},\n                { \"Dimensions\", new AttributeValue {\n                      S = \"8.5x11.0x.75\"\n                  }},\n                { \"InPublication\", new AttributeValue {\n                      BOOL = false\n                  } }\n            }\n            };\n            client.PutItem(request);\n        }\n\n        private static void RetrieveItem()\n        {\n            var request = new GetItemRequest\n            {\n                TableName = tableName,\n                Key = new Dictionary<string, AttributeValue>()\n            {\n                { \"Id\", new AttributeValue {\n                      N = \"1000\"\n                  } }\n            },\n                ProjectionExpression = \"Id, ISBN, Title, Authors\",\n                ConsistentRead = true\n            };\n            var response = client.GetItem(request);\n\n            // Check the response.\n            var attributeList = response.Item; // attribute list in the response.\n            Console.WriteLine(\"\\nPrinting item after retrieving it ............\");\n            PrintItem(attributeList);\n        }\n\n        private static void UpdateMultipleAttributes()\n        {\n            var request = new UpdateItemRequest\n            {\n                Key = new Dictionary<string, AttributeValue>()\n            {\n                { \"Id\", new AttributeValue {\n                      N = \"1000\"\n                  } }\n            },\n                // Perform the following updates:\n                // 1) Add two new authors to the list\n                // 1) Set a new attribute\n                // 2) Remove the ISBN attribute\n                ExpressionAttributeNames = new Dictionary<string, string>()\n            {\n                {\"#A\",\"Authors\"},\n                {\"#NA\",\"NewAttribute\"},\n                {\"#I\",\"ISBN\"}\n            },\n                ExpressionAttributeValues = new Dictionary<string, AttributeValue>()\n            {\n                {\":auth\",new AttributeValue {\n                     SS = {\"Author YY\", \"Author ZZ\"}\n                 }},\n                {\":new\",new AttributeValue {\n                     S = \"New Value\"\n                 }}\n            },\n\n                UpdateExpression = \"ADD #A :auth SET #NA = :new REMOVE #I\",\n\n                TableName = tableName,\n                ReturnValues = \"ALL_NEW\" // Give me all attributes of the updated item.\n            };\n            var response = client.UpdateItem(request);\n\n            // Check the response.\n            var attributeList = response.Attributes; // attribute list in the response.\n                                                     // print attributeList.\n            Console.WriteLine(\"\\nPrinting item after multiple attribute update ............\");\n            PrintItem(attributeList);\n        }\n\n        private static void UpdateExistingAttributeConditionally()\n        {\n            var request = new UpdateItemRequest\n            {\n                Key = new Dictionary<string, AttributeValue>()\n            {\n                { \"Id\", new AttributeValue {\n                      N = \"1000\"\n                  } }\n            },\n                ExpressionAttributeNames = new Dictionary<string, string>()\n            {\n                {\"#P\", \"Price\"}\n            },\n                ExpressionAttributeValues = new Dictionary<string, AttributeValue>()\n            {\n                {\":newprice\",new AttributeValue {\n                     N = \"22.00\"\n                 }},\n                {\":currprice\",new AttributeValue {\n                     N = \"20.00\"\n                 }}\n            },\n                // This updates price only if current price is 20.00.\n                UpdateExpression = \"SET #P = :newprice\",\n                ConditionExpression = \"#P = :currprice\",\n\n                TableName = tableName,\n                ReturnValues = \"ALL_NEW\" // Give me all attributes of the updated item.\n            };\n            var response = client.UpdateItem(request);\n\n            // Check the response.\n            var attributeList = response.Attributes; // attribute list in the response.\n            Console.WriteLine(\"\\nPrinting item after updating price value conditionally ............\");\n            PrintItem(attributeList);\n        }\n\n        private static void DeleteItem()\n        {\n            var request = new DeleteItemRequest\n            {\n                TableName = tableName,\n                Key = new Dictionary<string, AttributeValue>()\n            {\n                { \"Id\", new AttributeValue {\n                      N = \"1000\"\n                  } }\n            },\n\n                // Return the entire item as it appeared before the update.\n                ReturnValues = \"ALL_OLD\",\n                ExpressionAttributeNames = new Dictionary<string, string>()\n            {\n                {\"#IP\", \"InPublication\"}\n            },\n                ExpressionAttributeValues = new Dictionary<string, AttributeValue>()\n            {\n                {\":inpub\",new AttributeValue {\n                     BOOL = false\n                 }}\n            },\n                ConditionExpression = \"#IP = :inpub\"\n            };\n\n            var response = client.DeleteItem(request);\n\n            // Check the response.\n            var attributeList = response.Attributes; // Attribute list in the response.\n                                                     // Print item.\n            Console.WriteLine(\"\\nPrinting item that was just deleted ............\");\n            PrintItem(attributeList);\n        }\n\n        private static void PrintItem(Dictionary<string, AttributeValue> attributeList)\n        {\n            foreach (KeyValuePair<string, AttributeValue> kvp in attributeList)\n            {\n                string attributeName = kvp.Key;\n                AttributeValue value = kvp.Value;\n\n                Console.WriteLine(\n                    attributeName + \" \" +\n                    (value.S == null ? \"\" : \"S=[\" + value.S + \"]\") +\n                    (value.N == null ? \"\" : \"N=[\" + value.N + \"]\") +\n                    (value.SS == null ? \"\" : \"SS=[\" + string.Join(\",\", value.SS.ToArray()) + \"]\") +\n                    (value.NS == null ? \"\" : \"NS=[\" + string.Join(\",\", value.NS.ToArray()) + \"]\")\n                    );\n            }\n            Console.WriteLine(\"************************************************\");\n        }\n    }\n}\n"
  },
  {
    "title": "Example: Handling binary type attributes using the AWS SDK for Java document API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/JavaDocumentAPIBinaryTypeExample.html",
    "html": "Example: Handling binary type attributes using the AWS SDK for Java document API\nPDF\nRSS\n\nThe following Java code example illustrates handling binary type attributes. The example adds an item to the Reply table. The item includes a binary type attribute (ExtendedMessage) that stores compressed data. The example then retrieves the item and prints all the attribute values. For illustration, the example uses the GZIPOutputStream class to compress a sample stream and assign it to the ExtendedMessage attribute. When the binary attribute is retrieved, it is decompressed using the GZIPInputStream class.\n\nNote\n\nThe SDK for Java also provides an object persistence model, enabling you to map your client-side classes to DynamoDB tables. This approach can reduce the amount of code that you have to write. For more information, see Java 1.x: DynamoDBMapper.\n\nIf you followed the Creating tables and loading data for code examples in DynamoDB section, you should already have created the Reply table. You can also create this table programmatically. For more information, see Creating example tables and uploading data using the AWS SDK for Java.\n\nFor step-by-step instructions for testing the following sample, see Java code examples.\n\nExample\n\npackage com.amazonaws.codesamples.document;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.nio.ByteBuffer;\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\nimport java.util.TimeZone;\nimport java.util.zip.GZIPInputStream;\nimport java.util.zip.GZIPOutputStream;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.document.DynamoDB;\nimport com.amazonaws.services.dynamodbv2.document.Item;\nimport com.amazonaws.services.dynamodbv2.document.Table;\nimport com.amazonaws.services.dynamodbv2.document.spec.GetItemSpec;\n\npublic class DocumentAPIItemBinaryExample {\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n    static DynamoDB dynamoDB = new DynamoDB(client);\n\n    static String tableName = \"Reply\";\n    static SimpleDateFormat dateFormatter = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\n\n    public static void main(String[] args) throws IOException {\n        try {\n\n            // Format the primary key values\n            String threadId = \"Amazon DynamoDB#DynamoDB Thread 2\";\n\n            dateFormatter.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n            String replyDateTime = dateFormatter.format(new Date());\n\n            // Add a new reply with a binary attribute type\n            createItem(threadId, replyDateTime);\n\n            // Retrieve the reply with a binary attribute type\n            retrieveItem(threadId, replyDateTime);\n\n            // clean up by deleting the item\n            deleteItem(threadId, replyDateTime);\n        } catch (Exception e) {\n            System.err.println(\"Error running the binary attribute type example: \" + e);\n            e.printStackTrace(System.err);\n        }\n    }\n\n    public static void createItem(String threadId, String replyDateTime) throws IOException {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        // Craft a long message\n        String messageInput = \"Long message to be compressed in a lengthy forum reply\";\n\n        // Compress the long message\n        ByteBuffer compressedMessage = compressString(messageInput.toString());\n\n        table.putItem(new Item().withPrimaryKey(\"Id\", threadId).withString(\"ReplyDateTime\", replyDateTime)\n                .withString(\"Message\", \"Long message follows\").withBinary(\"ExtendedMessage\", compressedMessage)\n                .withString(\"PostedBy\", \"User A\"));\n    }\n\n    public static void retrieveItem(String threadId, String replyDateTime) throws IOException {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        GetItemSpec spec = new GetItemSpec().withPrimaryKey(\"Id\", threadId, \"ReplyDateTime\", replyDateTime)\n                .withConsistentRead(true);\n\n        Item item = table.getItem(spec);\n\n        // Uncompress the reply message and print\n        String uncompressed = uncompressString(ByteBuffer.wrap(item.getBinary(\"ExtendedMessage\")));\n\n        System.out.println(\"Reply message:\\n\" + \" Id: \" + item.getString(\"Id\") + \"\\n\" + \" ReplyDateTime: \"\n                + item.getString(\"ReplyDateTime\") + \"\\n\" + \" PostedBy: \" + item.getString(\"PostedBy\") + \"\\n\"\n                + \" Message: \"\n                + item.getString(\"Message\") + \"\\n\" + \" ExtendedMessage (uncompressed): \" + uncompressed + \"\\n\");\n    }\n\n    public static void deleteItem(String threadId, String replyDateTime) {\n\n        Table table = dynamoDB.getTable(tableName);\n        table.deleteItem(\"Id\", threadId, \"ReplyDateTime\", replyDateTime);\n    }\n\n    private static ByteBuffer compressString(String input) throws IOException {\n        // Compress the UTF-8 encoded String into a byte[]\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        GZIPOutputStream os = new GZIPOutputStream(baos);\n        os.write(input.getBytes(\"UTF-8\"));\n        os.close();\n        baos.close();\n        byte[] compressedBytes = baos.toByteArray();\n\n        // The following code writes the compressed bytes to a ByteBuffer.\n        // A simpler way to do this is by simply calling\n        // ByteBuffer.wrap(compressedBytes);\n        // However, the longer form below shows the importance of resetting the\n        // position of the buffer\n        // back to the beginning of the buffer if you are writing bytes directly\n        // to it, since the SDK\n        // will consider only the bytes after the current position when sending\n        // data to DynamoDB.\n        // Using the \"wrap\" method automatically resets the position to zero.\n        ByteBuffer buffer = ByteBuffer.allocate(compressedBytes.length);\n        buffer.put(compressedBytes, 0, compressedBytes.length);\n        buffer.position(0); // Important: reset the position of the ByteBuffer\n                            // to the beginning\n        return buffer;\n    }\n\n    private static String uncompressString(ByteBuffer input) throws IOException {\n        byte[] bytes = input.array();\n        ByteArrayInputStream bais = new ByteArrayInputStream(bytes);\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        GZIPInputStream is = new GZIPInputStream(bais);\n\n        int chunkSize = 1024;\n        byte[] buffer = new byte[chunkSize];\n        int length = 0;\n        while ((length = is.read(buffer, 0, chunkSize)) != -1) {\n            baos.write(buffer, 0, length);\n        }\n\n        String result = new String(baos.toByteArray(), \"UTF-8\");\n\n        is.close();\n        baos.close();\n        bais.close();\n\n        return result;\n    }\n}\n\n"
  },
  {
    "title": "Example: Batch operations using AWS SDK for Java document API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/batch-operation-document-api-java.html",
    "html": "Example: Batch operations using AWS SDK for Java document API\nPDF\nRSS\n\nThis section provides examples of batch write and batch get operations in Amazon DynamoDB using the AWS SDK for Java Document API.\n\nNote\n\nThe SDK for Java also provides an object persistence model, enabling you to map your client-side classes to DynamoDB tables. This approach can reduce the amount of code that you have to write. For more information, see Java 1.x: DynamoDBMapper.\n\nTopics\nExample: Batch write operation using the AWS SDK for Java document API\nExample: Batch get operation using the AWS SDK for Java document API\nExample: Batch write operation using the AWS SDK for Java document API\n\nThe following Java code example uses the batchWriteItem method to perform the following put and delete operations:\n\nPut one item in the Forum table.\n\nPut one item and delete one item from the Thread table.\n\nYou can specify any number of put and delete requests against one or more tables when creating your batch write request. However, batchWriteItem limits the size of a batch write request and the number of put and delete operations in a single batch write operation. If your request exceeds these limits, your request is rejected. If your table does not have sufficient provisioned throughput to serve this request, the unprocessed request items are returned in the response.\n\nThe following example checks the response to see if it has any unprocessed request items. If it does, it loops back and resends the batchWriteItem request with unprocessed items in the request. If you followed the Creating tables and loading data for code examples in DynamoDB section, you should already have created the Forum and Thread tables. You can also create these tables and upload sample data programmatically. For more information, see Creating example tables and uploading data using the AWS SDK for Java.\n\nFor step-by-step instructions for testing the following sample, see Java code examples.\n\nExample\n\npackage com.amazonaws.codesamples.document;\n\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.document.BatchWriteItemOutcome;\nimport com.amazonaws.services.dynamodbv2.document.DynamoDB;\nimport com.amazonaws.services.dynamodbv2.document.Item;\nimport com.amazonaws.services.dynamodbv2.document.TableWriteItems;\nimport com.amazonaws.services.dynamodbv2.model.WriteRequest;\n\npublic class DocumentAPIBatchWrite {\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n    static DynamoDB dynamoDB = new DynamoDB(client);\n\n    static String forumTableName = \"Forum\";\n    static String threadTableName = \"Thread\";\n\n    public static void main(String[] args) throws IOException {\n\n        writeMultipleItemsBatchWrite();\n\n    }\n\n    private static void writeMultipleItemsBatchWrite() {\n        try {\n\n            // Add a new item to Forum\n            TableWriteItems forumTableWriteItems = new TableWriteItems(forumTableName) // Forum\n                    .withItemsToPut(new Item().withPrimaryKey(\"Name\", \"Amazon RDS\").withNumber(\"Threads\", 0));\n\n            // Add a new item, and delete an existing item, from Thread\n            // This table has a partition key and range key, so need to specify\n            // both of them\n            TableWriteItems threadTableWriteItems = new TableWriteItems(threadTableName)\n                    .withItemsToPut(\n                            new Item().withPrimaryKey(\"ForumName\", \"Amazon RDS\", \"Subject\", \"Amazon RDS Thread 1\")\n                                    .withString(\"Message\", \"ElastiCache Thread 1 message\")\n                                    .withStringSet(\"Tags\", new HashSet<String>(Arrays.asList(\"cache\", \"in-memory\"))))\n                    .withHashAndRangeKeysToDelete(\"ForumName\", \"Subject\", \"Amazon S3\", \"S3 Thread 100\");\n\n            System.out.println(\"Making the request.\");\n            BatchWriteItemOutcome outcome = dynamoDB.batchWriteItem(forumTableWriteItems, threadTableWriteItems);\n\n            do {\n\n                // Check for unprocessed keys which could happen if you exceed\n                // provisioned throughput\n\n                Map<String, List<WriteRequest>> unprocessedItems = outcome.getUnprocessedItems();\n\n                if (outcome.getUnprocessedItems().size() == 0) {\n                    System.out.println(\"No unprocessed items found\");\n                } else {\n                    System.out.println(\"Retrieving the unprocessed items\");\n                    outcome = dynamoDB.batchWriteItemUnprocessed(unprocessedItems);\n                }\n\n            } while (outcome.getUnprocessedItems().size() > 0);\n\n        } catch (Exception e) {\n            System.err.println(\"Failed to retrieve items: \");\n            e.printStackTrace(System.err);\n        }\n\n    }\n\n}\n\n\nExample: Batch get operation using the AWS SDK for Java document API\n\nThe following Java code example uses the batchGetItem method to retrieve multiple items from the Forum and the Thread tables. The BatchGetItemRequest specifies the table names and a list of keys for each item to get. The example processes the response by printing the items retrieved.\n\nNote\n\nThis code example assumes that you have already loaded data into DynamoDB for your account by following the instructions in the Creating tables and loading data for code examples in DynamoDB section.\n\nFor step-by-step instructions to run the following example, see Java code examples.\n\nExample\n\npackage com.amazonaws.codesamples.document;\n\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.Map;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.document.BatchGetItemOutcome;\nimport com.amazonaws.services.dynamodbv2.document.DynamoDB;\nimport com.amazonaws.services.dynamodbv2.document.Item;\nimport com.amazonaws.services.dynamodbv2.document.TableKeysAndAttributes;\nimport com.amazonaws.services.dynamodbv2.model.KeysAndAttributes;\n\npublic class DocumentAPIBatchGet {\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n    static DynamoDB dynamoDB = new DynamoDB(client);\n\n    static String forumTableName = \"Forum\";\n    static String threadTableName = \"Thread\";\n\n    public static void main(String[] args) throws IOException {\n        retrieveMultipleItemsBatchGet();\n    }\n\n    private static void retrieveMultipleItemsBatchGet() {\n\n        try {\n\n            TableKeysAndAttributes forumTableKeysAndAttributes = new TableKeysAndAttributes(forumTableName);\n            // Add a partition key\n            forumTableKeysAndAttributes.addHashOnlyPrimaryKeys(\"Name\", \"Amazon S3\", \"Amazon DynamoDB\");\n\n            TableKeysAndAttributes threadTableKeysAndAttributes = new TableKeysAndAttributes(threadTableName);\n            // Add a partition key and a sort key\n            threadTableKeysAndAttributes.addHashAndRangePrimaryKeys(\"ForumName\", \"Subject\", \"Amazon DynamoDB\",\n                    \"DynamoDB Thread 1\", \"Amazon DynamoDB\", \"DynamoDB Thread 2\", \"Amazon S3\", \"S3 Thread 1\");\n\n            System.out.println(\"Making the request.\");\n\n            BatchGetItemOutcome outcome = dynamoDB.batchGetItem(forumTableKeysAndAttributes,\n                    threadTableKeysAndAttributes);\n\n            Map<String, KeysAndAttributes> unprocessed = null;\n\n            do {\n                for (String tableName : outcome.getTableItems().keySet()) {\n                    System.out.println(\"Items in table \" + tableName);\n                    List<Item> items = outcome.getTableItems().get(tableName);\n                    for (Item item : items) {\n                        System.out.println(item.toJSONPretty());\n                    }\n                }\n\n                // Check for unprocessed keys which could happen if you exceed\n                // provisioned\n                // throughput or reach the limit on response size.\n                unprocessed = outcome.getUnprocessedKeys();\n\n                if (unprocessed.isEmpty()) {\n                    System.out.println(\"No unprocessed keys found\");\n                } else {\n                    System.out.println(\"Retrieving the unprocessed keys\");\n                    outcome = dynamoDB.batchGetItemUnprocessed(unprocessed);\n                }\n\n            } while (!unprocessed.isEmpty());\n\n        } catch (Exception e) {\n            System.err.println(\"Failed to retrieve items.\");\n            System.err.println(e.getMessage());\n        }\n\n    }\n\n}\n\n"
  },
  {
    "title": "Example: CRUD operations using the AWS SDK for Java document API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/JavaDocumentAPICRUDExample.html",
    "html": "Example: CRUD operations using the AWS SDK for Java document API\nPDF\nRSS\n\nThe following code example illustrates CRUD operations on an Amazon DynamoDB item. The example creates an item, retrieves it, performs various updates, and finally deletes the item.\n\nNote\n\nThe SDK for Java also provides an object persistence model, enabling you to map your client-side classes to DynamoDB tables. This approach can reduce the amount of code that you have to write. For more information, see Java 1.x: DynamoDBMapper.\n\nNote\n\nThis code example assumes that you have already loaded data into DynamoDB for your account by following the instructions in the Creating tables and loading data for code examples in DynamoDB section.\n\nFor step-by-step instructions to run the following example, see Java code examples.\n\n\npackage com.amazonaws.codesamples.document;\n\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.Map;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.document.DeleteItemOutcome;\nimport com.amazonaws.services.dynamodbv2.document.DynamoDB;\nimport com.amazonaws.services.dynamodbv2.document.Item;\nimport com.amazonaws.services.dynamodbv2.document.Table;\nimport com.amazonaws.services.dynamodbv2.document.UpdateItemOutcome;\nimport com.amazonaws.services.dynamodbv2.document.spec.DeleteItemSpec;\nimport com.amazonaws.services.dynamodbv2.document.spec.UpdateItemSpec;\nimport com.amazonaws.services.dynamodbv2.document.utils.NameMap;\nimport com.amazonaws.services.dynamodbv2.document.utils.ValueMap;\nimport com.amazonaws.services.dynamodbv2.model.ReturnValue;\n\npublic class DocumentAPIItemCRUDExample {\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n    static DynamoDB dynamoDB = new DynamoDB(client);\n\n    static String tableName = \"ProductCatalog\";\n\n    public static void main(String[] args) throws IOException {\n\n        createItems();\n\n        retrieveItem();\n\n        // Perform various updates.\n        updateMultipleAttributes();\n        updateAddNewAttribute();\n        updateExistingAttributeConditionally();\n\n        // Delete the item.\n        deleteItem();\n\n    }\n\n    private static void createItems() {\n\n        Table table = dynamoDB.getTable(tableName);\n        try {\n\n            Item item = new Item().withPrimaryKey(\"Id\", 120).withString(\"Title\", \"Book 120 Title\")\n                    .withString(\"ISBN\", \"120-1111111111\")\n                    .withStringSet(\"Authors\", new HashSet<String>(Arrays.asList(\"Author12\", \"Author22\")))\n                    .withNumber(\"Price\", 20).withString(\"Dimensions\", \"8.5x11.0x.75\").withNumber(\"PageCount\", 500)\n                    .withBoolean(\"InPublication\", false).withString(\"ProductCategory\", \"Book\");\n            table.putItem(item);\n\n            item = new Item().withPrimaryKey(\"Id\", 121).withString(\"Title\", \"Book 121 Title\")\n                    .withString(\"ISBN\", \"121-1111111111\")\n                    .withStringSet(\"Authors\", new HashSet<String>(Arrays.asList(\"Author21\", \"Author 22\")))\n                    .withNumber(\"Price\", 20).withString(\"Dimensions\", \"8.5x11.0x.75\").withNumber(\"PageCount\", 500)\n                    .withBoolean(\"InPublication\", true).withString(\"ProductCategory\", \"Book\");\n            table.putItem(item);\n\n        } catch (Exception e) {\n            System.err.println(\"Create items failed.\");\n            System.err.println(e.getMessage());\n\n        }\n    }\n\n    private static void retrieveItem() {\n        Table table = dynamoDB.getTable(tableName);\n\n        try {\n\n            Item item = table.getItem(\"Id\", 120, \"Id, ISBN, Title, Authors\", null);\n\n            System.out.println(\"Printing item after retrieving it....\");\n            System.out.println(item.toJSONPretty());\n\n        } catch (Exception e) {\n            System.err.println(\"GetItem failed.\");\n            System.err.println(e.getMessage());\n        }\n\n    }\n\n    private static void updateAddNewAttribute() {\n        Table table = dynamoDB.getTable(tableName);\n\n        try {\n\n            UpdateItemSpec updateItemSpec = new UpdateItemSpec().withPrimaryKey(\"Id\", 121)\n                    .withUpdateExpression(\"set #na = :val1\").withNameMap(new NameMap().with(\"#na\", \"NewAttribute\"))\n                    .withValueMap(new ValueMap().withString(\":val1\", \"Some value\"))\n                    .withReturnValues(ReturnValue.ALL_NEW);\n\n            UpdateItemOutcome outcome = table.updateItem(updateItemSpec);\n\n            // Check the response.\n            System.out.println(\"Printing item after adding new attribute...\");\n            System.out.println(outcome.getItem().toJSONPretty());\n\n        } catch (Exception e) {\n            System.err.println(\"Failed to add new attribute in \" + tableName);\n            System.err.println(e.getMessage());\n        }\n    }\n\n    private static void updateMultipleAttributes() {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        try {\n\n            UpdateItemSpec updateItemSpec = new UpdateItemSpec().withPrimaryKey(\"Id\", 120)\n                    .withUpdateExpression(\"add #a :val1 set #na=:val2\")\n                    .withNameMap(new NameMap().with(\"#a\", \"Authors\").with(\"#na\", \"NewAttribute\"))\n                    .withValueMap(\n                            new ValueMap().withStringSet(\":val1\", \"Author YY\", \"Author ZZ\").withString(\":val2\",\n                                    \"someValue\"))\n                    .withReturnValues(ReturnValue.ALL_NEW);\n\n            UpdateItemOutcome outcome = table.updateItem(updateItemSpec);\n\n            // Check the response.\n            System.out.println(\"Printing item after multiple attribute update...\");\n            System.out.println(outcome.getItem().toJSONPretty());\n\n        } catch (Exception e) {\n            System.err.println(\"Failed to update multiple attributes in \" + tableName);\n            System.err.println(e.getMessage());\n\n        }\n    }\n\n    private static void updateExistingAttributeConditionally() {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        try {\n\n            // Specify the desired price (25.00) and also the condition (price =\n            // 20.00)\n\n            UpdateItemSpec updateItemSpec = new UpdateItemSpec().withPrimaryKey(\"Id\", 120)\n                    .withReturnValues(ReturnValue.ALL_NEW).withUpdateExpression(\"set #p = :val1\")\n                    .withConditionExpression(\"#p = :val2\").withNameMap(new NameMap().with(\"#p\", \"Price\"))\n                    .withValueMap(new ValueMap().withNumber(\":val1\", 25).withNumber(\":val2\", 20));\n\n            UpdateItemOutcome outcome = table.updateItem(updateItemSpec);\n\n            // Check the response.\n            System.out.println(\"Printing item after conditional update to new attribute...\");\n            System.out.println(outcome.getItem().toJSONPretty());\n\n        } catch (Exception e) {\n            System.err.println(\"Error updating item in \" + tableName);\n            System.err.println(e.getMessage());\n        }\n    }\n\n    private static void deleteItem() {\n\n        Table table = dynamoDB.getTable(tableName);\n\n        try {\n\n            DeleteItemSpec deleteItemSpec = new DeleteItemSpec().withPrimaryKey(\"Id\", 120)\n                    .withConditionExpression(\"#ip = :val\").withNameMap(new NameMap().with(\"#ip\", \"InPublication\"))\n                    .withValueMap(new ValueMap().withBoolean(\":val\", false)).withReturnValues(ReturnValue.ALL_OLD);\n\n            DeleteItemOutcome outcome = table.deleteItem(deleteItemSpec);\n\n            // Check the response.\n            System.out.println(\"Printing item that was deleted...\");\n            System.out.println(outcome.getItem().toJSONPretty());\n\n        } catch (Exception e) {\n            System.err.println(\"Error deleting item in \" + tableName);\n            System.err.println(e.getMessage());\n        }\n    }\n}\n\n"
  },
  {
    "title": "Working with items: Java - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/JavaDocumentAPIItemCRUD.html",
    "html": "Working with items: Java\nPDF\nRSS\n\nYou can use the AWS SDK for Java Document API to perform typical create, read, update, and delete (CRUD) operations on Amazon DynamoDB items in a table.\n\nNote\n\nThe SDK for Java also provides an object persistence model, allowing you to map your client-side classes to DynamoDB tables. This approach can reduce the amount of code that you have to write. For more information, see Java 1.x: DynamoDBMapper.\n\nThis section contains Java examples to perform several Java Document API item actions and several complete working examples.\n\nTopics\nPutting an item\nGetting an item\nBatch write: Putting and deleting multiple items\nBatch get: Getting multiple items\nUpdating an item\nDeleting an item\nExample: CRUD operations using the AWS SDK for Java document API\nExample: Batch operations using AWS SDK for Java document API\nExample: Handling binary type attributes using the AWS SDK for Java document API\nPutting an item\n\nThe putItem method stores an item in a table. If the item exists, it replaces the entire item. Instead of replacing the entire item, if you want to update only specific attributes, you can use the updateItem method. For more information, see Updating an item.\n\nFollow these steps:\n\nCreate an instance of the DynamoDB class.\n\nCreate an instance of the Table class to represent the table you want to work with.\n\nCreate an instance of the Item class to represent the new item. You must specify the new item's primary key and its attributes.\n\nCall the putItem method of the Table object, using the Item that you created in the preceding step.\n\nThe following Java code example demonstrates the preceding tasks. The code writes a new item to the ProductCatalog table.\n\nExample\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\nTable table = dynamoDB.getTable(\"ProductCatalog\");\n\n// Build a list of related items\nList<Number> relatedItems = new ArrayList<Number>();\nrelatedItems.add(341);\nrelatedItems.add(472);\nrelatedItems.add(649);\n\n//Build a map of product pictures\nMap<String, String> pictures = new HashMap<String, String>();\npictures.put(\"FrontView\", \"http://example.com/products/123_front.jpg\");\npictures.put(\"RearView\", \"http://example.com/products/123_rear.jpg\");\npictures.put(\"SideView\", \"http://example.com/products/123_left_side.jpg\");\n\n//Build a map of product reviews\nMap<String, List<String>> reviews = new HashMap<String, List<String>>();\n\nList<String> fiveStarReviews = new ArrayList<String>();\nfiveStarReviews.add(\"Excellent! Can't recommend it highly enough!  Buy it!\");\nfiveStarReviews.add(\"Do yourself a favor and buy this\");\nreviews.put(\"FiveStar\", fiveStarReviews);\n\nList<String> oneStarReviews = new ArrayList<String>();\noneStarReviews.add(\"Terrible product!  Do not buy this.\");\nreviews.put(\"OneStar\", oneStarReviews);\n\n// Build the item\nItem item = new Item()\n    .withPrimaryKey(\"Id\", 123)\n    .withString(\"Title\", \"Bicycle 123\")\n    .withString(\"Description\", \"123 description\")\n    .withString(\"BicycleType\", \"Hybrid\")\n    .withString(\"Brand\", \"Brand-Company C\")\n    .withNumber(\"Price\", 500)\n    .withStringSet(\"Color\",  new HashSet<String>(Arrays.asList(\"Red\", \"Black\")))\n    .withString(\"ProductCategory\", \"Bicycle\")\n    .withBoolean(\"InStock\", true)\n    .withNull(\"QuantityOnHand\")\n    .withList(\"RelatedItems\", relatedItems)\n    .withMap(\"Pictures\", pictures)\n    .withMap(\"Reviews\", reviews);\n\n// Write the item to the table\nPutItemOutcome outcome = table.putItem(item);\n\nIn the preceding example, the item has attributes that are scalars (String, Number, Boolean, Null), sets (String Set), and document types (List, Map).\n\nSpecifying optional parameters\n\nAlong with the required parameters, you can also specify optional parameters to the putItem method. For example, the following Java code example uses an optional parameter to specify a condition for uploading the item. If the condition you specify is not met, the AWS SDK for Java throws a ConditionalCheckFailedException. The code example specifies the following optional parameters in the putItem method:\n\nA ConditionExpression that defines the conditions for the request. The code defines the condition that the existing item with the same primary key is replaced only if it has an ISBN attribute that equals a specific value.\n\nA map for ExpressionAttributeValues that is used in the condition. In this case, there is only one substitution required: The placeholder :val in the condition expression is replaced at runtime with the actual ISBN value to be checked.\n\nThe following example adds a new book item using these optional parameters.\n\nExample\nItem item = new Item()\n    .withPrimaryKey(\"Id\", 104)\n    .withString(\"Title\", \"Book 104 Title\")\n    .withString(\"ISBN\", \"444-4444444444\")\n    .withNumber(\"Price\", 20)\n    .withStringSet(\"Authors\",\n        new HashSet<String>(Arrays.asList(\"Author1\", \"Author2\")));\n\nMap<String, Object> expressionAttributeValues = new HashMap<String, Object>();\nexpressionAttributeValues.put(\":val\", \"444-4444444444\");\n\nPutItemOutcome outcome = table.putItem(\n    item,\n    \"ISBN = :val\", // ConditionExpression parameter\n    null,          // ExpressionAttributeNames parameter - we're not using it for this example\n    expressionAttributeValues);\nPutItem and JSON documents\n\nYou can store a JSON document as an attribute in a DynamoDB table. To do this, use the withJSON method of Item. This method parses the JSON document and maps each element to a native DynamoDB data type.\n\nSuppose that you wanted to store the following JSON document, containing vendors that can fulfill orders for a particular product.\n\nExample\n{\n    \"V01\": {\n        \"Name\": \"Acme Books\",\n        \"Offices\": [ \"Seattle\" ]\n    },\n    \"V02\": {\n        \"Name\": \"New Publishers, Inc.\",\n        \"Offices\": [\"London\", \"New York\"\n        ]\n    },\n    \"V03\": {\n        \"Name\": \"Better Buy Books\",\n        \"Offices\": [ \"Tokyo\", \"Los Angeles\", \"Sydney\"\n        ]\n    }\n}\n\nYou can use the withJSON method to store this in the ProductCatalog table, in a Map attribute named VendorInfo. The following Java code example demonstrates how to do this.\n\n// Convert the document into a String.  Must escape all double-quotes.\nString vendorDocument = \"{\"\n    + \"    \\\"V01\\\": {\"\n    + \"        \\\"Name\\\": \\\"Acme Books\\\",\"\n    + \"        \\\"Offices\\\": [ \\\"Seattle\\\" ]\"\n    + \"    },\"\n    + \"    \\\"V02\\\": {\"\n    + \"        \\\"Name\\\": \\\"New Publishers, Inc.\\\",\"\n    + \"        \\\"Offices\\\": [ \\\"London\\\", \\\"New York\\\"\" + \"]\" + \"},\"\n    + \"    \\\"V03\\\": {\"\n    + \"        \\\"Name\\\": \\\"Better Buy Books\\\",\"\n    +          \"\\\"Offices\\\": [ \\\"Tokyo\\\", \\\"Los Angeles\\\", \\\"Sydney\\\"\"\n    + \"            ]\"\n    + \"        }\"\n    + \"    }\";\n\nItem item = new Item()\n    .withPrimaryKey(\"Id\", 210)\n    .withString(\"Title\", \"Book 210 Title\")\n    .withString(\"ISBN\", \"210-2102102102\")\n    .withNumber(\"Price\", 30)\n    .withJSON(\"VendorInfo\", vendorDocument);\n\nPutItemOutcome outcome = table.putItem(item); \nGetting an item\n\nTo retrieve a single item, use the getItem method of a Table object. Follow these steps:\n\nCreate an instance of the DynamoDB class.\n\nCreate an instance of the Table class to represent the table you want to work with.\n\nCall the getItem method of the Table instance. You must specify the primary key of the item that you want to retrieve.\n\nThe following Java code example demonstrates the preceding steps. The code gets the item that has the specified partition key.\n\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\nTable table = dynamoDB.getTable(\"ProductCatalog\");\n\nItem item = table.getItem(\"Id\", 210);\nSpecifying optional parameters\n\nAlong with the required parameters, you can also specify optional parameters for the getItem method. For example, the following Java code example uses an optional method to retrieve only a specific list of attributes and to specify strongly consistent reads. (To learn more about read consistency, see Read consistency.)\n\nYou can use a ProjectionExpression to retrieve only specific attributes or elements, rather than an entire item. A ProjectionExpression can specify top-level or nested attributes using document paths. For more information, see Projection expressions.\n\nThe parameters of the getItem method don't let you specify read consistency. However, you can create a GetItemSpec, which provides full access to all of the inputs to the low-level GetItem operation. The following code example creates a GetItemSpec and uses that spec as input to the getItem method.\n\nExample\nGetItemSpec spec = new GetItemSpec()\n    .withPrimaryKey(\"Id\", 206)\n    .withProjectionExpression(\"Id, Title, RelatedItems[0], Reviews.FiveStar\")\n    .withConsistentRead(true);\n\nItem item = table.getItem(spec);\n\nSystem.out.println(item.toJSONPretty());\n\nTo print an Item in a human-readable format, use the toJSONPretty method. The output from the previous example looks like the following.\n\n{\n  \"RelatedItems\" : [ 341 ],\n  \"Reviews\" : {\n    \"FiveStar\" : [ \"Excellent! Can't recommend it highly enough! Buy it!\", \"Do yourself a favor and buy this\" ]\n  },\n  \"Id\" : 123,\n  \"Title\" : \"20-Bicycle 123\"\n}\nGetItem and JSON documents\n\nIn the PutItem and JSON documents section, you store a JSON document in a Map attribute named VendorInfo. You can use the getItem method to retrieve the entire document in JSON format. Or you can use document path notation to retrieve only some of the elements in the document. The following Java code example demonstrates these techniques.\n\nGetItemSpec spec = new GetItemSpec()\n    .withPrimaryKey(\"Id\", 210);\n\nSystem.out.println(\"All vendor info:\");\nspec.withProjectionExpression(\"VendorInfo\");\nSystem.out.println(table.getItem(spec).toJSON());\n\nSystem.out.println(\"A single vendor:\");\nspec.withProjectionExpression(\"VendorInfo.V03\");\nSystem.out.println(table.getItem(spec).toJSON());\n\nSystem.out.println(\"First office location for this vendor:\");\nspec.withProjectionExpression(\"VendorInfo.V03.Offices[0]\");\nSystem.out.println(table.getItem(spec).toJSON());\n \n\nThe output from the previous example looks like the following.\n\nAll vendor info:\n{\"VendorInfo\":{\"V03\":{\"Name\":\"Better Buy Books\",\"Offices\":[\"Tokyo\",\"Los Angeles\",\"Sydney\"]},\"V02\":{\"Name\":\"New Publishers, Inc.\",\"Offices\":[\"London\",\"New York\"]},\"V01\":{\"Name\":\"Acme Books\",\"Offices\":[\"Seattle\"]}}}\nA single vendor:\n{\"VendorInfo\":{\"V03\":{\"Name\":\"Better Buy Books\",\"Offices\":[\"Tokyo\",\"Los Angeles\",\"Sydney\"]}}}\nFirst office location for a single vendor:\n{\"VendorInfo\":{\"V03\":{\"Offices\":[\"Tokyo\"]}}}\n\nNote\n\nYou can use the toJSON method to convert any item (or its attributes) to a JSON-formatted string. The following code retrieves several top-level and nested attributes and prints the results as JSON.\n\nGetItemSpec spec = new GetItemSpec()\n    .withPrimaryKey(\"Id\", 210)\n    .withProjectionExpression(\"VendorInfo.V01, Title, Price\");\n\nItem item = table.getItem(spec);\nSystem.out.println(item.toJSON());\n\nThe output looks like the following.\n\n{\"VendorInfo\":{\"V01\":{\"Name\":\"Acme Books\",\"Offices\":[\"Seattle\"]}},\"Price\":30,\"Title\":\"Book 210 Title\"}\n\nBatch write: Putting and deleting multiple items\n\nBatch write refers to putting and deleting multiple items in a batch. The batchWriteItem method enables you to put and delete multiple items from one or more tables in a single call. The following are the steps to put or delete multiple items using the AWS SDK for Java Document API.\n\nCreate an instance of the DynamoDB class.\n\nCreate an instance of the TableWriteItems class that describes all the put and delete operations for a table. If you want to write to multiple tables in a single batch write operation, you must create one TableWriteItems instance per table.\n\nCall the batchWriteItem method by providing the TableWriteItems objects that you created in the preceding step.\n\nProcess the response. You should check if there were any unprocessed request items returned in the response. This could happen if you reach the provisioned throughput quota or some other transient error. Also, DynamoDB limits the request size and the number of operations you can specify in a request. If you exceed these limits, DynamoDB rejects the request. For more information, see Service, account, and table quotas in Amazon DynamoDB.\n\nThe following Java code example demonstrates the preceding steps. The example performs a batchWriteItem operation on two tables: Forum and Thread. The corresponding TableWriteItems objects define the following actions:\n\nPut an item in the Forum table.\n\nPut and delete an item in the Thread table.\n\nThe code then calls batchWriteItem to perform the operation.\n\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\nTableWriteItems forumTableWriteItems = new TableWriteItems(\"Forum\")\n    .withItemsToPut(\n        new Item()\n            .withPrimaryKey(\"Name\", \"Amazon RDS\")\n            .withNumber(\"Threads\", 0));\n\nTableWriteItems threadTableWriteItems = new TableWriteItems(\"Thread\")\n    .withItemsToPut(\n        new Item()\n            .withPrimaryKey(\"ForumName\",\"Amazon RDS\",\"Subject\",\"Amazon RDS Thread 1\")\n    .withHashAndRangeKeysToDelete(\"ForumName\",\"Some partition key value\", \"Amazon S3\", \"Some sort key value\");\n\nBatchWriteItemOutcome outcome = dynamoDB.batchWriteItem(forumTableWriteItems, threadTableWriteItems);\n\n// Code for checking unprocessed items is omitted in this example\n\nFor a working example, see Example: Batch write operation using the AWS SDK for Java document API.\n\nBatch get: Getting multiple items\n\nThe batchGetItem method enables you to retrieve multiple items from one or more tables. To retrieve a single item, you can use the getItem method.\n\nFollow these steps:\n\nCreate an instance of the DynamoDB class.\n\nCreate an instance of the TableKeysAndAttributes class that describes a list of primary key values to retrieve from a table. If you want to read from multiple tables in a single batch get operation, you must create one TableKeysAndAttributes instance per table.\n\nCall the batchGetItem method by providing the TableKeysAndAttributes objects that you created in the preceding step.\n\nThe following Java code example demonstrates the preceding steps. The example retrieves two items from the Forum table and three items from the Thread table.\n\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\n    TableKeysAndAttributes forumTableKeysAndAttributes = new TableKeysAndAttributes(forumTableName);\n    forumTableKeysAndAttributes.addHashOnlyPrimaryKeys(\"Name\",\n    \"Amazon S3\",\n    \"Amazon DynamoDB\");\n\nTableKeysAndAttributes threadTableKeysAndAttributes = new TableKeysAndAttributes(threadTableName);\nthreadTableKeysAndAttributes.addHashAndRangePrimaryKeys(\"ForumName\", \"Subject\",\n    \"Amazon DynamoDB\",\"DynamoDB Thread 1\",\n    \"Amazon DynamoDB\",\"DynamoDB Thread 2\",\n    \"Amazon S3\",\"S3 Thread 1\");\n\nBatchGetItemOutcome outcome = dynamoDB.batchGetItem(\n    forumTableKeysAndAttributes, threadTableKeysAndAttributes);\n\nfor (String tableName : outcome.getTableItems().keySet()) {\n    System.out.println(\"Items in table \" + tableName);\n    List<Item> items = outcome.getTableItems().get(tableName);\n    for (Item item : items) {\n        System.out.println(item);\n    }\n} \nSpecifying optional parameters\n\nAlong with the required parameters, you can also specify optional parameters when using batchGetItem. For example, you can provide a ProjectionExpression with each TableKeysAndAttributes you define. This allows you to specify the attributes that you want to retrieve from the table.\n\nThe following code example retrieves two items from the Forum table. The withProjectionExpression parameter specifies that only the Threads attribute is to be retrieved.\n\nExample\nTableKeysAndAttributes forumTableKeysAndAttributes = new TableKeysAndAttributes(\"Forum\")\n    .withProjectionExpression(\"Threads\");\n\nforumTableKeysAndAttributes.addHashOnlyPrimaryKeys(\"Name\",\n    \"Amazon S3\",\n    \"Amazon DynamoDB\");\n\nBatchGetItemOutcome outcome = dynamoDB.batchGetItem(forumTableKeysAndAttributes);\nUpdating an item\n\nThe updateItem method of a Table object can update existing attribute values, add new attributes, or delete attributes from an existing item.\n\nThe updateItem method behaves as follows:\n\nIf an item does not exist (no item in the table with the specified primary key), updateItem adds a new item to the table.\n\nIf an item exists, updateItem performs the update as specified by the UpdateExpression parameter.\n\nNote\n\nIt is also possible to \"update\" an item using putItem. For example, if you call putItem to add an item to the table, but there is already an item with the specified primary key, putItem replaces the entire item. If there are attributes in the existing item that are not specified in the input, putItem removes those attributes from the item.\n\nIn general, we recommend that you use updateItem whenever you want to modify any item attributes. The updateItem method only modifies the item attributes that you specify in the input, and the other attributes in the item remain unchanged.\n\nFollow these steps:\n\nCreate an instance of the Table class to represent the table that you want to work with.\n\nCall the updateTable method of the Table instance. You must specify the primary key of the item that you want to retrieve, along with an UpdateExpression that describes the attributes to modify and how to modify them.\n\nThe following Java code example demonstrates the preceding tasks. The code updates a book item in the ProductCatalog table. It adds a new author to the set of Authors and deletes the existing ISBN attribute. It also reduces the price by one.\n\nAn ExpressionAttributeValues map is used in the UpdateExpression. The placeholders :val1 and :val2 are replaced at runtime with the actual values for Authors and Price.\n\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\nTable table = dynamoDB.getTable(\"ProductCatalog\");\n\nMap<String, String> expressionAttributeNames = new HashMap<String, String>();\nexpressionAttributeNames.put(\"#A\", \"Authors\");\nexpressionAttributeNames.put(\"#P\", \"Price\");\nexpressionAttributeNames.put(\"#I\", \"ISBN\");\n\nMap<String, Object> expressionAttributeValues = new HashMap<String, Object>();\nexpressionAttributeValues.put(\":val1\",\n    new HashSet<String>(Arrays.asList(\"Author YY\",\"Author ZZ\")));\nexpressionAttributeValues.put(\":val2\", 1);   //Price\n\nUpdateItemOutcome outcome =  table.updateItem(\n    \"Id\",          // key attribute name\n    101,           // key attribute value\n    \"add #A :val1 set #P = #P - :val2 remove #I\", // UpdateExpression\n    expressionAttributeNames,\n    expressionAttributeValues);\nSpecifying optional parameters\n\nAlong with the required parameters, you can also specify optional parameters for the updateItem method, including a condition that must be met in order for the update is to occur. If the condition you specify is not met, the AWS SDK for Java throws a ConditionalCheckFailedException. For example, the following Java code example conditionally updates a book item price to 25. It specifies a ConditionExpression stating that the price should be updated only if the existing price is 20.\n\nExample\nTable table = dynamoDB.getTable(\"ProductCatalog\");\n\nMap<String, String> expressionAttributeNames = new HashMap<String, String>();\nexpressionAttributeNames.put(\"#P\", \"Price\");\n\nMap<String, Object> expressionAttributeValues = new HashMap<String, Object>();\nexpressionAttributeValues.put(\":val1\", 25);  // update Price to 25...\nexpressionAttributeValues.put(\":val2\", 20);  //...but only if existing Price is 20\n\nUpdateItemOutcome outcome = table.updateItem(\n    new PrimaryKey(\"Id\",101),\n    \"set #P = :val1\", // UpdateExpression\n    \"#P = :val2\",     // ConditionExpression\n    expressionAttributeNames,\n    expressionAttributeValues);\nAtomic counter\n\nYou can use updateItem to implement an atomic counter, where you increment or decrement the value of an existing attribute without interfering with other write requests. To increment an atomic counter, use an UpdateExpression with a set action to add a numeric value to an existing attribute of type Number.\n\nThe following example demonstrates this, incrementing the Quantity attribute by one. It also demonstrates the use of the ExpressionAttributeNames parameter in an UpdateExpression.\n\nTable table = dynamoDB.getTable(\"ProductCatalog\");\n\nMap<String,String> expressionAttributeNames = new HashMap<String,String>();\nexpressionAttributeNames.put(\"#p\", \"PageCount\");\n\nMap<String,Object> expressionAttributeValues = new HashMap<String,Object>();\nexpressionAttributeValues.put(\":val\", 1);\n\nUpdateItemOutcome outcome = table.updateItem(\n    \"Id\", 121,\n    \"set #p = #p + :val\",\n    expressionAttributeNames,\n    expressionAttributeValues);\nDeleting an item\n\nThe deleteItem method deletes an item from a table. You must provide the primary key of the item that you want to delete.\n\nFollow these steps:\n\nCreate an instance of the DynamoDB client.\n\nCall the deleteItem method by providing the key of the item you want to delete.\n\nThe following Java example demonstrates these tasks.\n\nExample\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\nTable table = dynamoDB.getTable(\"ProductCatalog\");\n\nDeleteItemOutcome outcome = table.deleteItem(\"Id\", 101);\nSpecifying optional parameters\n\nYou can specify optional parameters for deleteItem. For example, the following Java code example specifies a ConditionExpression, stating that a book item in ProductCatalog can only be deleted if the book is no longer in publication (the InPublication attribute is false).\n\nExample\nMap<String,Object> expressionAttributeValues = new HashMap<String,Object>();\nexpressionAttributeValues.put(\":val\", false);\n\nDeleteItemOutcome outcome = table.deleteItem(\"Id\",103,\n    \"InPublication = :val\",\n    null, // ExpressionAttributeNames - not used in this example\n    expressionAttributeValues);"
  },
  {
    "title": "Enable time to live (TTL) - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/time-to-live-ttl-how-to.html",
    "html": "Enable time to live (TTL)\nPDF\nRSS\n\nYou can enable TTL in the Amazon DynamoDB Console, the AWS Command Line Interface (AWS CLI), or using the Amazon DynamoDB API Reference with any of the supposed AWS SDKs. It takes approximately one hour to enable TTL across all partitions.\n\nEnable DynamoDB TTL using the AWS console\n\nSign in to the AWS Management Console and open the DynamoDB console at https://console.aws.amazon.com/dynamodb/.\n\nChoose Tables, and then choose the table that you want to modify.\n\nIn the Additional settings tab, in the Time to Live (TTL) section, choose Turn on to enable TTL.\n\nWhen enabling TTL on a table, DynamoDB requires you to identify a specific attribute name that the service will look for when determining if an item is eligible for expiration. The TTL attribute name, shown below, is case sensitive and must match the attribute defined in your read and write operations. A mismatch will cause expired items to go undeleted. Renaming the TTL attribute requires you to disable TTL and then re-enable it with the new attribute going forward. TTL will continue to process deletions for approximately 30 minutes once it is disabled. TTL must be reconfigured on restored tables.\n\n(Optional) You can perform a test by simulating the date and time of the expiration and matching a few items. This provides you with a sample list of items and confirms that there are items containing the TTL attribute name provided along with the expiration time.\n\nAfter TTL is enabled, the TTL attribute is marked TTL when you view items on the DynamoDB console. You can view the date and time that an item expires by hovering your pointer over the attribute.\n\nEnable DynamoDB TTL using the API\nPython\nJavaScript\n\nYou can enable TTL with code, using the UpdateTimeToLive operation.\n\nimport boto3\n\n\ndef enable_ttl(table_name, ttl_attribute_name):\n    \"\"\"\n    Enables TTL on DynamoDB table for a given attribute name\n        on success, returns a status code of 200\n        on error, throws an exception\n\n    :param table_name: Name of the DynamoDB table\n    :param ttl_attribute_name: The name of the TTL attribute being provided to the table.\n    \"\"\"\n    try:\n        dynamodb = boto3.client('dynamodb')\n\n        # Enable TTL on an existing DynamoDB table\n        response = dynamodb.update_time_to_live(\n            TableName=table_name,\n            TimeToLiveSpecification={\n                'Enabled': True,\n                'AttributeName': ttl_attribute_name\n            }\n        )\n\n        # In the returned response, check for a successful status code.\n        if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n            print(\"TTL has been enabled successfully.\")\n        else:\n            print(f\"Failed to enable TTL, status code {response['ResponseMetadata']['HTTPStatusCode']}\")\n    except Exception as ex:\n        print(\"Couldn't enable TTL in table %s. Here's why: %s\" % (table_name, ex))\n        raise\n\n\n# your values\nenable_ttl('your-table-name', 'expirationDate')\n\nYou can confirm TTL is enabled by using the DescribeTimeToLive operation, which describes the TTL status on a table. The TimeToLive status is either ENABLED or DISABLED.\n\n# create a DynamoDB client\ndynamodb = boto3.client('dynamodb')\n\n# set the table name\ntable_name = 'YourTable'\n\n# describe TTL\nresponse = dynamodb.describe_time_to_live(TableName=table_name)\nEnable Time to Live using the AWS CLI\n\nEnable TTL on the TTLExample table.\n\naws dynamodb update-time-to-live --table-name TTLExample --time-to-live-specification \"Enabled=true, AttributeName=ttl\"\n\nDescribe TTL on the TTLExample table.\n\naws dynamodb describe-time-to-live --table-name TTLExample\n{\n    \"TimeToLiveDescription\": {\n        \"AttributeName\": \"ttl\",\n        \"TimeToLiveStatus\": \"ENABLED\"\n    }\n} \n\nAdd an item to the TTLExample table with the Time to Live attribute set using the BASH shell and the AWS CLI.\n\nEXP=`date -d '+5 days' +%s`\naws dynamodb put-item --table-name \"TTLExample\" --item '{\"id\": {\"N\": \"1\"}, \"ttl\": {\"N\": \"'$EXP'\"}}'\n\nThis example starts with the current date and adds 5 days to it to create an expiration time. Then, it converts the expiration time to epoch time format to finally add an item to the \"TTLExample\" table.\n\nNote\n\nOne way to set expiration values for Time to Live is to calculate the number of seconds to add to the expiration time. For example, 5 days is 432,000 seconds. However, it is often preferable to start with a date and work from there.\n\nIt is fairly simple to get the current time in epoch time format, as in the following examples.\n\nLinux Terminal: date +%s\n\nPython: import time; int(time.time())\n\nJava: System.currentTimeMillis() / 1000L\n\nJavaScript: Math.floor(Date.now() / 1000)\n\nEnable DynamoDB TTL using AWS CloudFormation\n\nEnable TTL on the TTLExample table.\n\naws dynamodb update-time-to-live --table-name TTLExample --time-to-live-specification \"Enabled=true, AttributeName=ttl\"\n\nDescribe TTL on the TTLExample table.\n\naws dynamodb describe-time-to-live --table-name TTLExample\n{\n    \"TimeToLiveDescription\": {\n        \"AttributeName\": \"ttl\",\n        \"TimeToLiveStatus\": \"ENABLED\"\n    }\n} \n\nAdd an item to the TTLExample table with the Time to Live attribute set using the BASH shell and the AWS CLI.\n\nEXP=`date -d '+5 days' +%s`\naws dynamodb put-item --table-name \"TTLExample\" --item '{\"id\": {\"N\": \"1\"}, \"ttl\": {\"N\": \"'$EXP'\"}}'\n\nThis example starts with the current date and adds 5 days to it to create an expiration time. Then, it converts the expiration time to epoch time format to finally add an item to the \"TTLExample\" table.\n\nNote\n\nOne way to set expiration values for Time to Live is to calculate the number of seconds to add to the expiration time. For example, 5 days is 432,000 seconds. However, it is often preferable to start with a date and work from there.\n\nIt is fairly simple to get the current time in epoch time format, as in the following examples.\n\nLinux Terminal: date +%s\n\nPython: import time; int(time.time())\n\nJava: System.currentTimeMillis() / 1000L\n\nJavaScript: Math.floor(Date.now() / 1000)"
  },
  {
    "title": "Working with expired items - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ttl-expired-items.html",
    "html": "Working with expired items\nPDF\nRSS\n\nExpired items that are pending deletion can be filtered from read and write operations. This is useful in scenarios when expired data is no longer valid and should not be used. If they are not filtered, they’ll continue to show in read and write operations until they are deleted by the background process.\n\nNote\n\nThese items still count towards storage and read costs until they are deleted.\n\nTTL deletions can be identified in DynamoDB Streams, but only in the Region where the deletion occurred. TTL deletions that are replicated to global table regions are not identifiable in DynamoDB streams in the regions the deletion is replicated to.\n\nFilter expired items from read operations\n\nFor read operations such as Scan and Query, a filter expression can filter out expired items that are pending deletion. As shown in the code snippet below, the filter expression can filter out items where the TTL time is equal to or less than the current time. This is done with an assignment statement that obtains the current time as a variable (now), which is converted to int for epoch time format.\n\nPython\nJavascript\nimport boto3\nfrom datetime import datetime\n\n\ndef query_dynamodb_items(table_name, partition_key):\n    \"\"\"\n\n    :param table_name: Name of the DynamoDB table\n    :param partition_key:\n    :return:\n    \"\"\"\n    try:\n        # Initialize a DynamoDB resource\n        dynamodb = boto3.resource('dynamodb',\n                                  region_name='us-east-1')\n\n        # Specify your table\n        table = dynamodb.Table(table_name)\n\n        # Get the current time in epoch format\n        current_time = int(datetime.now().timestamp())\n\n        # Perform the query operation with a filter expression to exclude expired items\n        # response = table.query(\n        #    KeyConditionExpression=boto3.dynamodb.conditions.Key('partitionKey').eq(partition_key),\n        #    FilterExpression=boto3.dynamodb.conditions.Attr('expireAt').gt(current_time)\n        # )\n        response = table.query(\n            KeyConditionExpression=dynamodb.conditions.Key('partitionKey').eq(partition_key),\n            FilterExpression=dynamodb.conditions.Attr('expireAt').gt(current_time)\n        )\n\n        # Print the items that are not expired\n        for item in response['Items']:\n            print(item)\n\n    except Exception as e:\n        print(f\"Error querying items: {e}\")\n\n\n# Call the function with your values\nquery_dynamodb_items('Music', 'your-partition-key-value')\n\nThe output from the update operation shows that, while the createdAt time is unchanged, the updatedAt and expireAt times have been updated. The expireAt time is now set to 90 days from the time of the last update, which is Thursday, October 19, 2023 at 1:27:15 PM.\n\npartition_key\tcreatedAt\tupdatedAt\texpireAt\tattribute_1\tattribute_2\n\n\nsome_value\n\n\t2023-07-17 14:11:05.322323\t2023-07-19 13:27:15.213423\t1697722035\tnew_value\tsome_value\nConditionally write to expired items\n\nA condition expression can be used to avoid writes against expired items. The code snippet below is a conditional update that checks whether the expiration time is greater than the current time. If true, the write operation will continue.\n\nPython\nJavascript\nimport boto3\nfrom datetime import datetime, timedelta\nfrom botocore.exceptions import ClientError\n\n\ndef update_dynamodb_item(table_name, region, primary_key, sort_key, ttl_attribute):\n    \"\"\"\n    Updates an existing record in a DynamoDB table with a new or updated TTL attribute.\n\n    :param table_name: Name of the DynamoDB table\n    :param region: AWS Region of the table - example `us-east-1`\n    :param primary_key: one attribute known as the partition key.\n    :param sort_key: Also known as a range attribute.\n    :param ttl_attribute: name of the TTL attribute in the target DynamoDB table\n    :return:\n    \"\"\"\n    try:\n        dynamodb = boto3.resource('dynamodb', region_name=region)\n        table = dynamodb.Table(table_name)\n\n        # Generate updated TTL in epoch second format\n        updated_expiration_time = int((datetime.now() + timedelta(days=90)).timestamp())\n\n        # Define the update expression for adding/updating a new attribute\n        update_expression = \"SET newAttribute = :val1\"\n\n        # Define the condition expression for checking if 'ttlExpirationDate' is not expired\n        condition_expression = \"ttlExpirationDate > :val2\"\n\n        # Define the expression attribute values\n        expression_attribute_values = {\n            ':val1': ttl_attribute,\n            ':val2': updated_expiration_time\n        }\n\n        response = table.update_item(\n            Key={\n                'primaryKey': primary_key,\n                'sortKey': sort_key\n            },\n            UpdateExpression=update_expression,\n            ConditionExpression=condition_expression,\n            ExpressionAttributeValues=expression_attribute_values\n        )\n\n        print(\"Item updated successfully.\")\n        return response['ResponseMetadata']['HTTPStatusCode']  # Ideally a 200 OK\n    except ClientError as e:\n        if e.response['Error']['Code'] == \"ConditionalCheckFailedException\":\n            print(\"Condition check failed: Item's 'ttlExpirationDate' is expired.\")\n        else:\n            print(f\"Error updating item: {e}\")\n    except Exception as e:\n        print(f\"Error updating item: {e}\")\n\n\n# replace with your values\nupdate_dynamodb_item('your-table-name', 'us-east-1', 'your-partition-key-value', 'your-sort-key-value',\n                     'your-ttl-attribute-value')\n\nThe output from the update operation shows that, while the createdAt time is unchanged, the updatedAt and expireAt times have been updated. The expireAt time is now set to 90 days from the time of the last update, which is Thursday, October 19, 2023 at 1:27:15 PM.\n\npartition_key\tcreatedAt\tupdatedAt\texpireAt\tattribute_1\tattribute_2\n\n\nsome_value\n\n\t2023-07-17 14:11:05.322323\t2023-07-19 13:27:15.213423\t1697722035\tnew_value\tsome_value\nIdentifying deleted items in DynamoDB Streams\n\nThe streams record contains a user identity field Records[<index>].userIdentity. Items that are deleted by the TTL process have the following fields:\n\nRecords[<index>].userIdentity.type\n\"Service\"\n\nRecords[<index>].userIdentity.principalId\n\"dynamodb.amazonaws.com\"\n\n\nThe following JSON shows the relevant portion of a single streams record:\n\n\"Records\": [ \n  { \n\t... \n\t\t\"userIdentity\": {\n\t\t\"type\": \"Service\", \n      \t\"principalId\": \"dynamodb.amazonaws.com\" \n   \t} \n   ... \n\t} \n]\n"
  },
  {
    "title": "Computing time to live (TTL) - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/time-to-live-ttl-before-you-start.html",
    "html": "Computing time to live (TTL)\nPDF\nRSS\n\nA common way to implement TTL is to set an expiration time for items based on when they were created or last updated. This can be done by adding time to the createdAt and updatedAt timestamps. For example, the TTL for newly created items can be set to createdAt + 90 days. When the item is updated the TTL can be recalculated to updatedAt + 90 days.\n\nThe computed expiration time must be in epoch format, in seconds. To be considered for expiry and deletion, the TTL can't be more than five years in the past. If you use any other format, the TTL processes ignore the item. If you set the expiration date to sometime in the future when you want the item to expire, the item will be expired after that time. For example, say that you set the expiration date to 1724241326 (which is Monday, August 21st, 2024 11:55:26 (GMT)). The item will be expired after the specified time.\n\nTopics\nCreate an item and set the Time to Live\nUpdate an item and refresh the Time to Live\nCreate an item and set the Time to Live\n\nThe following example demonstrates how to calculate the expiration time when creating a new item, using 'expireAt' as the TTL attribute name for JavaScript and 'expirationDate' for Python. An assignment statement obtains the current time as a variable. In the example, the expiration time is calculated as 90 days from the current time. The time is then converted to epoch format and saved as an integer data type in the TTL attribute.\n\nPython\nJavaScript\nimport boto3\nfrom datetime import datetime, timedelta\n\n\ndef create_dynamodb_item(table_name, region, primary_key, sort_key):\n    \"\"\"\n    Creates a DynamoDB item with an attached expiry attribute.\n\n    :param table_name: Table name for the boto3 resource to target when creating an item\n    :param region: string representing the AWS region. Example: `us-east-1`\n    :param primary_key: one attribute known as the partition key.\n    :param sort_key: Also known as a range attribute.\n    :return: Void (nothing)\n    \"\"\"\n    try:\n        dynamodb = boto3.resource('dynamodb', region_name=region)\n        table = dynamodb.Table(table_name)\n\n        # Get the current time in epoch second format\n        current_time = int(datetime.now().timestamp())\n\n        # Calculate the expiration time (90 days from now) in epoch second format\n        expiration_time = int((datetime.now() + timedelta(days=90)).timestamp())\n\n        item = {\n            'primaryKey': primary_key,\n            'sortKey': sort_key,\n            'creationDate': current_time,\n            'expirationDate': expiration_time\n        }\n\n        table.put_item(Item=item)\n\n        print(\"Item created successfully.\")\n    except Exception as e:\n        print(f\"Error creating item: {e}\")\n        raise\n\n\n# Use your own values\ncreate_dynamodb_item('your-table-name', 'us-west-2', 'your-partition-key-value', 'your-sort-key-value')\nUpdate an item and refresh the Time to Live\n\nThis example is a continuation of the one from the previous section. The expiration time can be recomputed if the item is updated. The following example recomputes the expireAt timestamp to be 90 days from the current time.\n\nPython\nJavaScript\nimport boto3\nfrom datetime import datetime, timedelta\n\n\ndef update_dynamodb_item(table_name, region, primary_key, sort_key):\n    \"\"\"\n    Update an existing DynamoDB item with a TTL.\n    :param table_name: Name of the DynamoDB table\n    :param region: AWS Region of the table - example `us-east-1`\n    :param primary_key: one attribute known as the partition key.\n    :param sort_key: Also known as a range attribute.\n    :return: Void (nothing)\n    \"\"\"\n    try:\n        # Create the DynamoDB resource.\n        dynamodb = boto3.resource('dynamodb', region_name=region)\n        table = dynamodb.Table(table_name)\n\n        # Get the current time in epoch second format\n        current_time = int(datetime.now().timestamp())\n\n        # Calculate the expireAt time (90 days from now) in epoch second format\n        expire_at = int((datetime.now() + timedelta(days=90)).timestamp())\n\n        table.update_item(\n            Key={\n                'partitionKey': primary_key,\n                'sortKey': sort_key\n            },\n            UpdateExpression=\"set updatedAt=:c, expireAt=:e\",\n            ExpressionAttributeValues={\n                ':c': current_time,\n                ':e': expire_at\n            },\n        )\n\n        print(\"Item updated successfully.\")\n    except Exception as e:\n        print(f\"Error updating item: {e}\")\n\n\n# Replace with your own values\nupdate_dynamodb_item('your-table-name', 'us-west-2', 'your-partition-key-value', 'your-sort-key-value')\n\nThe output from the update operation shows that, while the createdAt time is unchanged, the updatedAt and expireAt times have been updated. The expireAt time is now set to 90 days from the time of the last update, which is Thursday, October 19, 2023 at 1:27:15 PM.\n\npartition_key\tcreatedAt\tupdatedAt\texpireAt\tattribute_1\tattribute_2\n\n\nsome_value\n\n\t2023-07-17 14:11:05.322323\t2023-07-19 13:27:15.213423\t1697722035\tnew_value\tsome_value\n\nThe TTL examples discussed in this introduction demonstrate a method to ensure only recently updated items are kept in a table. Updated items have their lifespan extended, whereas items not updated post-creation expire and are deleted at no cost, reducing storage and maintaining clean tables."
  },
  {
    "title": "Comparison operator and function reference - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.OperatorsAndFunctions.html",
    "html": "Comparison operator and function reference\nPDF\nRSS\n\nThis section covers the built-in functions and keywords for writing filter expressions and condition expressions in Amazon DynamoDB. For more detailed information on functions and programming with DynamoDB, see Programming with DynamoDB and the AWS SDKs and the DynamoDB API Reference.\n\nTopics\nSyntax for filter and condition expressions\nMaking comparisons\nFunctions\nLogical evaluations\nParentheses\nPrecedence in conditions\nSyntax for filter and condition expressions\n\nIn the following syntax summary, an operand can be the following:\n\nA top-level attribute name, such as Id, Title, Description, or ProductCategory\n\nA document path that references a nested attribute\n\ncondition-expression ::=\n      operand comparator operand\n    | operand BETWEEN operand AND operand\n    | operand IN ( operand (',' operand (, ...) ))\n    | function\n    | condition AND condition\n    | condition OR condition\n    | NOT condition\n    | ( condition )\n\ncomparator ::=\n    =\n    | <>\n    | <\n    | <=\n    | >\n    | >=\n\nfunction ::=\n    attribute_exists (path)\n    | attribute_not_exists (path)\n    | attribute_type (path, type)\n    | begins_with (path, substr)\n    | contains (path, operand)\n    | size (path)\nMaking comparisons\n\nUse these comparators to compare an operand against a range of values or an enumerated list of values:\n\na = b – True if a is equal to b.\n\na <> b – True if a is not equal to b.\n\na < b – True if a is less than b.\n\na <= b – True if a is less than or equal to b.\n\na > b – True if a is greater than b.\n\na >= b – True if a is greater than or equal to b.\n\nUse the BETWEEN and IN keywords to compare an operand against a range of values or an enumerated list of values:\n\na BETWEEN b AND c – True if a is greater than or equal to b, and less than or equal to c.\n\na IN (b, c, d) – True if a is equal to any value in the list—for example, any of b, c, or d. The list can contain up to 100 values, separated by commas.\n\nFunctions\n\nUse the following functions to determine whether an attribute exists in an item, or to evaluate the value of an attribute. These function names are case sensitive. For a nested attribute, you must provide its full document path.\n\nFunction\tDescription\n\n\nattribute_exists (path)\n\n\t\n\nTrue if the item contains the attribute specified by path.\n\nExample: Check whether an item in the Product table has a side view picture.\n\nattribute_exists (#Pictures.#SideView)\n\n\n\n\nattribute_not_exists (path)\n\n\t\n\nTrue if the attribute specified by path does not exist in the item.\n\nExample: Check whether an item has a Manufacturer attribute.\n\nattribute_not_exists (Manufacturer)\n\n\n\n\nattribute_type (path, type)\n\n\t\n\nTrue if the attribute at the specified path is of a particular data type. The type parameter must be one of the following:\n\nS – String\n\nSS – String set\n\nN – Number\n\nNS – Number set\n\nB – Binary\n\nBS – Binary set\n\nBOOL – Boolean\n\nNULL – Null\n\nL – List\n\nM – Map\n\nYou must use an expression attribute value for the type parameter.\n\nExample: Check whether the QuantityOnHand attribute is of type List. In this example, :v_sub is a placeholder for the string L.\n\nattribute_type (ProductReviews.FiveStar, :v_sub)\n\nYou must use an expression attribute value for the type parameter.\n\n\n\n\nbegins_with (path, substr)\n\n\t\n\nTrue if the attribute specified by path begins with a particular substring.\n\nExample: Check whether the first few characters of the front view picture URL are http://.\n\nbegins_with (Pictures.FrontView, :v_sub)\n\nThe expression attribute value :v_sub is a placeholder for http://.\n\n\n\n\ncontains (path, operand)\n\n\t\n\nTrue if the attribute specified by path is one of the following:\n\nA String that contains a particular substring.\n\nA Set that contains a particular element within the set.\n\nA List that contains a particular element within the list.\n\nIf the attribute specified by path is a String, the operand must be a String. If the attribute specified by path is a Set, the operand must be the set's element type.\n\nThe path and the operand must be distinct. That is, contains (a, a) returns an error.\n\nExample: Check whether the Brand attribute contains the substring Company.\n\ncontains (Brand, :v_sub)\n\nThe expression attribute value :v_sub is a placeholder for Company.\n\nExample: Check whether the product is available in red.\n\ncontains (Color, :v_sub)\n\nThe expression attribute value :v_sub is a placeholder for Red.\n\n\n\n\nsize (path)\n\n\t\n\nReturns a number that represents an attribute's size. The following are valid data types for use with size.\n\nIf the attribute is of type String, size returns the length of the string.\n\nExample: Check whether the string Brand is less than or equal to 20 characters. The expression attribute value :v_sub is a placeholder for 20.\n\nsize (Brand) <= :v_sub\n\nIf the attribute is of type Binary, size returns the number of bytes in the attribute value.\n\nExample: Suppose that the ProductCatalog item has a binary attribute named VideoClip that contains a short video of the product in use. The following expression checks whether VideoClip exceeds 64,000 bytes. The expression attribute value :v_sub is a placeholder for 64000.\n\nsize(VideoClip) > :v_sub\n\nIf the attribute is a Set data type, size returns the number of elements in the set.\n\nExample: Check whether the product is available in more than one color. The expression attribute value :v_sub is a placeholder for 1.\n\nsize (Color) < :v_sub\n\nIf the attribute is of type List or Map, size returns the number of child elements.\n\nExample: Check whether the number of OneStar reviews has exceeded a certain threshold. The expression attribute value :v_sub is a placeholder for 3.\n\nsize(ProductReviews.OneStar) > :v_sub\n\nLogical evaluations\n\nUse the AND, OR, and NOT keywords to perform logical evaluations. In the following list, a and b represent conditions to be evaluated.\n\na AND b – True if a and b are both true.\n\na OR b – True if either a or b (or both) are true.\n\nNOT a – True if a is false. False if a is true.\n\nThe following is a code example of AND in an operation.\n\ndynamodb-local (*)> select * from exprtest where a > 3 and a < 5;\n\nParentheses\n\nUse parentheses to change the precedence of a logical evaluation. For example, suppose that conditions a and b are true, and that condition c is false. The following expression evaluates to true:\n\na OR b AND c\n\nHowever, if you enclose a condition in parentheses, it is evaluated first. For example, the following evaluates to false:\n\n(a OR b) AND c\n\nNote\n\nYou can nest parentheses in an expression. The innermost ones are evaluated first.\n\nThe following is a code example with parentheses in a logical evaluation.\n\ndynamodb-local (*)> select * from exprtest where attribute_type(b, string) or ( a = 5 and c = “coffee”);\n\nPrecedence in conditions\n\nDynamoDB evaluates conditions from left to right using the following precedence rules:\n\n= <> < <= > >=\n\nIN\n\nBETWEEN\n\nattribute_exists attribute_not_exists begins_with contains\n\nParentheses\n\nNOT\n\nAND\n\nOR"
  },
  {
    "title": "Time to Live (TTL) - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html",
    "html": "Time to Live (TTL)\nPDF\nRSS\n\nTime To Live (TTL) for DynamoDB is a cost-effective method for deleting items that are no longer relevant. TTL allows you to define a per-item expiration timestamp that indicates when an item is no longer needed. DynamoDB automatically deletes expired items within a few days of their expiration time, without consuming write throughput.\n\nTo use TTL, first enable it on a table and then define a specific attribute to store the TTL expiration timestamp. The timestamp must be stored in Unix epoch time format at the seconds granularity. Each time an item is created or updated, you can compute the expiration time and save it in the TTL attribute.\n\nItems with valid, expired TTL attributes may be deleted by the system at any time, typically within a few days of their expiration. You can still update the expired items that are pending deletion, including changing or removing their TTL attributes. While updating an expired item, we recommended that you use a condition expression to make sure the item has not been subsequently deleted. Use filter expressions to remove expired items from Scan and Query results.\n\nDeleted items work similarly to those deleted through typical delete operations. Once deleted, items go into DynamoDB Streams as service deletions instead of user deletes, and are removed from local secondary indexes and global secondary indexes just like other delete operations.\n\nIf you are using Global Tables version 2019.11.21 (Current) of global tables and you also use the TTL feature, DynamoDB replicates TTL deletes to all replica tables. The initial TTL delete does not consume Write Capacity Units (WCU) in the region in which the TTL expiry occurs. However, the replicated TTL delete to the replica table(s) consumes a replicated Write Capacity Unit when using provisioned capacity, or Replicated Write Unit when using on-demand capacity mode, in each of the replica regions and applicable charges will apply.\n\nFor more information about TTL, see these topics:\n\nTopics\nEnable time to live (TTL)\nComputing time to live (TTL)\nWorking with expired items"
  },
  {
    "title": "Update expressions - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.UpdateExpressions.html",
    "html": "Update expressions\nPDF\nRSS\n\nThe UpdateItem operation updates an existing item, or adds a new item to the table if it does not already exist. You must provide the key of the item that you want to update. You must also provide an update expression, indicating the attributes that you want to modify and the values that you want to assign to them.\n\nAn update expression specifies how UpdateItem will modify the attributes of an item—for example, setting a scalar value or removing elements from a list or a map.\n\nThe following is a syntax summary for update expressions.\n\nupdate-expression ::=\n    [ SET action [, action] ... ]\n    [ REMOVE action [, action] ...]\n    [ ADD action [, action] ... ]\n    [ DELETE action [, action] ...]\n\nAn update expression consists of one or more clauses. Each clause begins with a SET, REMOVE, ADD, or DELETE keyword. You can include any of these clauses in an update expression, in any order. However, each action keyword can appear only once.\n\nWithin each clause, there are one or more actions separated by commas. Each action represents a data modification.\n\nThe examples in this section are based on the ProductCatalog item shown in Projection expressions.\n\nThe topics below cover some different use cases for the SET action.\n\nTopics\nSET — modifying or adding item attributes\nREMOVE — deleting attributes from an item\nADD — updating numbers and sets\nDELETE — removing elements from a set\nUsing multiple update expressions\nSET — modifying or adding item attributes\n\nUse the SET action in an update expression to add one or more attributes to an item. If any of these attributes already exists, they are overwritten by the new values.\n\nYou can also use SET to add or subtract from an attribute that is of type Number. To perform multiple SET actions, separate them with commas.\n\nIn the following syntax summary:\n\nThe path element is the document path to the item.\n\nAn operand element can be either a document path to an item or a function.\n\nset-action ::=\n    path = value\n\nvalue ::=\n    operand\n    | operand '+' operand\n    | operand '-' operand\n\noperand ::=\n    path | function\n\nThe following PutItem operation creates a sample item that the examples refer to.\n\naws dynamodb put-item \\\n    --table-name ProductCatalog \\\n    --item file://item.json\n\nThe arguments for --item are stored in the item.json file. (For simplicity, only a few item attributes are used.)\n\n{\n    \"Id\": {\"N\": \"789\"},\n    \"ProductCategory\": {\"S\": \"Home Improvement\"},\n    \"Price\": {\"N\": \"52\"},\n    \"InStock\": {\"BOOL\": true},\n    \"Brand\": {\"S\": \"Acme\"}\n}\nTopics\nModifying attributes\nAdding lists and maps\nAdding elements to a list\nAdding nested map attributes\nIncrementing and decrementing numeric attributes\nAppending elements to a list\nPreventing overwrites of an existing attribute\nModifying attributes\nExample\n\nUpdate the ProductCategory and Price attributes.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"SET ProductCategory = :c, Price = :p\" \\\n    --expression-attribute-values file://values.json \\\n    --return-values ALL_NEW\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":c\": { \"S\": \"Hardware\" },\n    \":p\": { \"N\": \"60\" }\n}\nNote\n\nIn the UpdateItem operation, --return-values ALL_NEW causes DynamoDB to return the item as it appears after the update.\n\nAdding lists and maps\nExample\n\nAdd a new list and a new map.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"SET RelatedItems = :ri, ProductReviews = :pr\" \\\n    --expression-attribute-values file://values.json \\\n    --return-values ALL_NEW\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":ri\": {\n        \"L\": [\n            { \"S\": \"Hammer\" }\n        ]\n    },\n    \":pr\": {\n        \"M\": {\n            \"FiveStar\": {\n                \"L\": [\n                    { \"S\": \"Best product ever!\" }\n                ]\n            }\n        }\n    }\n}\nAdding elements to a list\nExample\n\nAdd a new attribute to the RelatedItems list. (Remember that list elements are zero-based, so [0] represents the first element in the list, [1] represents the second, and so on.)\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"SET RelatedItems[1] = :ri\" \\\n    --expression-attribute-values file://values.json \\\n    --return-values ALL_NEW\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":ri\": { \"S\": \"Nails\" }\n}\nNote\n\nWhen you use SET to update a list element, the contents of that element are replaced with the new data that you specify. If the element doesn't already exist, SET appends the new element at the end of the list.\n\nIf you add multiple elements in a single SET operation, the elements are sorted in order by element number.\n\nAdding nested map attributes\nExample\n\nAdd some nested map attributes.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"SET #pr.#5star[1] = :r5, #pr.#3star = :r3\" \\\n    --expression-attribute-names file://names.json \\\n    --expression-attribute-values file://values.json \\\n    --return-values ALL_NEW\n\nThe arguments for --expression-attribute-names are stored in the names.json file.\n\n{\n    \"#pr\": \"ProductReviews\",\n    \"#5star\": \"FiveStar\",\n    \"#3star\": \"ThreeStar\"\n}\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":r5\": { \"S\": \"Very happy with my purchase\" },\n    \":r3\": {\n        \"L\": [\n            { \"S\": \"Just OK - not that great\" }\n        ]\n    }\n}\nIncrementing and decrementing numeric attributes\n\nYou can add to or subtract from an existing numeric attribute. To do this, use the + (plus) and - (minus) operators.\n\nExample\n\nDecrease the Price of an item.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"SET Price = Price - :p\" \\\n    --expression-attribute-values '{\":p\": {\"N\":\"15\"}}' \\\n    --return-values ALL_NEW\n\nTo increase the Price, you would use the + operator in the update expression.\n\nAppending elements to a list\n\nYou can add elements to the end of a list. To do this, use SET with the list_append function. (The function name is case sensitive.) The list_append function is specific to the SET action and can only be used in an update expression. The syntax is as follows.\n\nlist_append (list1, list2)\n\nThe function takes two lists as input and appends all elements from list2 to list1.\n\nExample\n\nIn Adding elements to a list, you create the RelatedItems list and populate it with two elements: Hammer and Nails. Now you append two more elements to the end of RelatedItems.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"SET #ri = list_append(#ri, :vals)\" \\\n    --expression-attribute-names '{\"#ri\": \"RelatedItems\"}' \\\n    --expression-attribute-values file://values.json  \\\n    --return-values ALL_NEW\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":vals\": {\n        \"L\": [\n            { \"S\": \"Screwdriver\" },\n            {\"S\": \"Hacksaw\" }\n        ]\n    }\n}\n\nFinally, you append one more element to the beginning of RelatedItems. To do this, swap the order of the list_append elements. (Remember that list_append takes two lists as input and appends the second list to the first.)\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"SET #ri = list_append(:vals, #ri)\" \\\n    --expression-attribute-names '{\"#ri\": \"RelatedItems\"}' \\\n    --expression-attribute-values '{\":vals\": {\"L\": [ { \"S\": \"Chisel\" }]}}' \\\n    --return-values ALL_NEW\n\nThe resulting RelatedItems attribute now contains five elements, in the following order: Chisel, Hammer, Nails, Screwdriver, Hacksaw.\n\nPreventing overwrites of an existing attribute\n\nIf you want to avoid overwriting an existing attribute, you can use SET with the if_not_exists function. (The function name is case sensitive.) The if_not_exists function is specific to the SET action and can only be used in an update expression. The syntax is as follows.\n\nif_not_exists (path, value)\n\nIf the item does not contain an attribute at the specified path, if_not_exists evaluates to value; otherwise, it evaluates to path.\n\nExample\n\nSet the Price of an item, but only if the item does not already have a Price attribute. (If Price already exists, nothing happens.)\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"SET Price = if_not_exists(Price, :p)\" \\\n    --expression-attribute-values '{\":p\": {\"N\": \"100\"}}' \\\n    --return-values ALL_NEW\nREMOVE — deleting attributes from an item\n\nUse the REMOVE action in an update expression to remove one or more attributes from an item in Amazon DynamoDB. To perform multiple REMOVE actions, separate them with commas.\n\nThe following is a syntax summary for REMOVE in an update expression. The only operand is the document path for the attribute that you want to remove.\n\nremove-action ::=\n    path\nExample\n\nRemove some attributes from an item. (If the attributes don't exist, nothing happens.)\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"REMOVE Brand, InStock, QuantityOnHand\" \\\n    --return-values ALL_NEW\nRemoving elements from a list\n\nYou can use REMOVE to delete individual elements from a list.\n\nExample\n\nIn Appending elements to a list, you modify a list attribute (RelatedItems) so that it contained five elements:\n\n[0]—Chisel\n\n[1]—Hammer\n\n[2]—Nails\n\n[3]—Screwdriver\n\n[4]—Hacksaw\n\nThe following AWS Command Line Interface (AWS CLI) example deletes Hammer and Nails from the list.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"REMOVE RelatedItems[1], RelatedItems[2]\" \\\n    --return-values ALL_NEW\n\nAfter Hammer and Nails are removed, the remaining elements are shifted. The list now contains the following:\n\n[0]—Chisel\n\n[1]—Screwdriver\n\n[2]—Hacksaw\n\nADD — updating numbers and sets\nNote\n\nIn general, we recommend using SET rather than ADD.\n\nUse the ADD action in an update expression to add a new attribute and its values to an item.\n\nIf the attribute already exists, the behavior of ADD depends on the attribute's data type:\n\nIf the attribute is a number, and the value you are adding is also a number, the value is mathematically added to the existing attribute. (If the value is a negative number, it is subtracted from the existing attribute.)\n\nIf the attribute is a set, and the value you are adding is also a set, the value is appended to the existing set.\n\nNote\n\nThe ADD action supports only number and set data types.\n\nTo perform multiple ADD actions, separate them with commas.\n\nIn the following syntax summary:\n\nThe path element is the document path to an attribute. The attribute must be either a Number or a set data type.\n\nThe value element is a number that you want to add to the attribute (for Number data types), or a set to append to the attribute (for set types).\n\nadd-action ::=\n    path value\n\nThe topics below cover some different use cases for the ADD action.\n\nTopics\nAdding a number\nAdding elements to a set\nAdding a number\n\nAssume that the QuantityOnHand attribute does not exist. The following AWS CLI example sets QuantityOnHand to 5.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"ADD QuantityOnHand :q\" \\\n    --expression-attribute-values '{\":q\": {\"N\": \"5\"}}' \\\n    --return-values ALL_NEW\n\nNow that QuantityOnHand exists, you can rerun the example to increment QuantityOnHand by 5 each time.\n\nAdding elements to a set\n\nAssume that the Color attribute does not exist. The following AWS CLI example sets Color to a string set with two elements.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"ADD Color :c\" \\\n    --expression-attribute-values '{\":c\": {\"SS\":[\"Orange\", \"Purple\"]}}' \\\n    --return-values ALL_NEW\n\nNow that Color exists, you can add more elements to it.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"ADD Color :c\" \\\n    --expression-attribute-values '{\":c\": {\"SS\":[\"Yellow\", \"Green\", \"Blue\"]}}' \\\n    --return-values ALL_NEW\nDELETE — removing elements from a set\nImportant\n\nThe DELETE action supports only Set data types.\n\nUse the DELETE action in an update expression to remove one or more elements from a set. To perform multiple DELETE actions, separate them with commas.\n\nIn the following syntax summary:\n\nThe path element is the document path to an attribute. The attribute must be a set data type.\n\nThe subset is one or more elements that you want to delete from path. You must specify subset as a set type.\n\ndelete-action ::=\n    path subset\nExample\n\nIn Adding elements to a set, you create the Color string set. This example removes some of the elements from that set.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"DELETE Color :p\" \\\n    --expression-attribute-values '{\":p\": {\"SS\": [\"Yellow\", \"Purple\"]}}' \\\n    --return-values ALL_NEW\nUsing multiple update expressions\n\nYou can use multiple update expressions in a single statement.\n\nIf you want to modify an attribute's value and completely remove another attribute, you could use a SET and a REMOVE action in a single statement. This operation would reduce the Price value to 15 while also removing the InStock attribute from the item.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"SET Price = Price - :p REMOVE InStock\" \\\n    --expression-attribute-values '{\":p\": {\"N\":\"15\"}}' \\\n    --return-values ALL_NEW\n\nIf you want to add to a list while also changing another attribute's value, you could use two SET actions in a single statement. This operation would add \"Nails\" to the RelatedItems list attribute and also set the Price value to 21.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"789\"}}' \\\n    --update-expression \"SET RelatedItems[1] = :newValue, Price = :newPrice\" \\\n    --expression-attribute-values '{\":newValue\": {\"S\":\"Nails\"}, \":newPrice\": {\"N\":\"21\"}}'  \\\n    --return-values ALL_NEW"
  },
  {
    "title": "Condition expressions - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ConditionExpressions.html",
    "html": "Condition expressions\nPDF\nRSS\n\nTo manipulate data in an Amazon DynamoDB table, you use the PutItem, UpdateItem, and DeleteItem operations.\n\nFor these data manipulation operations, you can specify a condition expression to determine which items should be modified. If the condition expression evaluates to true, the operation succeeds; otherwise, the operation fails.\n\nThe PutItem, UpdateItem, and DeleteItem operations have a ReturnValues parameter you can use to return attribute values as they appeared before or after you modified them. For more information, see ReturnValues.\n\nThe following are some AWS Command Line Interface (AWS CLI) examples of using condition expressions. These examples are based on the ProductCatalog table, which was introduced in Specifying item attributes when using expressions. The partition key for this table is Id; there is no sort key. The following PutItem operation creates a sample ProductCatalog item that the examples refer to.\n\naws dynamodb put-item \\\n    --table-name ProductCatalog \\\n    --item file://item.json\n\nThe arguments for --item are stored in the item.json file. (For simplicity, only a few item attributes are used.)\n\n{\n    \"Id\": {\"N\": \"456\" },\n    \"ProductCategory\": {\"S\": \"Sporting Goods\" },\n    \"Price\": {\"N\": \"650\" }\n}\nTopics\nConditional put\nConditional deletes\nConditional updates\nConditional expression examples\nComparison operator and function reference\nConditional put\n\nThe PutItem operation overwrites an item with the same primary key (if it exists). If you want to avoid this, use a condition expression. This allows the write to proceed only if the item in question does not already have the same primary key.\n\nThe following example uses attribute_not_exists() to check whether the primary key exists in the table before attempting the write operation.\n\nNote\n\nIf your primary key consists of both a partition key(pk) and a sort key(sk), the parameter will check whether attribute_not_exists(pk) AND attribute_not_exists(sk) evaluate to true or false before attempting the write operation.\n\naws dynamodb put-item \\\n    --table-name ProductCatalog \\\n    --item file://item.json \\\n    --condition-expression \"attribute_not_exists(Id)\"\n\nIf the condition expression evaluates to false, DynamoDB returns the following error message: The conditional request failed.\n\nNote\n\nFor more information about attribute_not_exists and other functions, see Comparison operator and function reference.\n\nConditional deletes\n\nTo perform a conditional delete, you use a DeleteItem operation with a condition expression. The condition expression must evaluate to true in order for the operation to succeed; otherwise, the operation fails.\n\nConsider the item from Condition expressions.\n\n{\n    \"Id\": {\n        \"N\": \"456\"\n    },\n    \"Price\": {\n        \"N\": \"650\"\n    },\n    \"ProductCategory\": {\n        \"S\": \"Sporting Goods\"\n    }\n}\n\nSuppose that you wanted to delete the item, but only under the following conditions:\n\nThe ProductCategory is either \"Sporting Goods\" or \"Gardening Supplies.\"\n\nThe Price is between 500 and 600.\n\nThe following example tries to delete the item.\n\naws dynamodb delete-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"456\"}}' \\\n    --condition-expression \"(ProductCategory IN (:cat1, :cat2)) and (Price between :lo and :hi)\" \\\n    --expression-attribute-values file://values.json\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":cat1\": {\"S\": \"Sporting Goods\"},\n    \":cat2\": {\"S\": \"Gardening Supplies\"},\n    \":lo\": {\"N\": \"500\"},\n    \":hi\": {\"N\": \"600\"}\n}\nNote\n\nIn the condition expression, the : (colon character) indicates an expression attribute value—a placeholder for an actual value. For more information, see Expression attribute values.\n\nFor more information about IN, AND, and other keywords, see Comparison operator and function reference.\n\nIn this example, the ProductCategory comparison evaluates to true, but the Price comparison evaluates to false. This causes the condition expression to evaluate to false and the DeleteItem operation to fail.\n\nConditional updates\n\nTo perform a conditional update, you use an UpdateItem operation with a condition expression. The condition expression must evaluate to true in order for the operation to succeed; otherwise, the operation fails.\n\nNote\n\nUpdateItem also supports update expressions, where you specify the modifications you want to make to an item. For more information, see Update expressions.\n\nSuppose that you started with the item shown in Condition expressions.\n\n{\n    \"Id\": { \"N\": \"456\"},\n    \"Price\": {\"N\": \"650\"},\n    \"ProductCategory\": {\"S\": \"Sporting Goods\"}\n}\n\nThe following example performs an UpdateItem operation. It tries to reduce the Price of a product by 75—but the condition expression prevents the update if the current Price is less than or equal to 500.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\": {\"N\": \"456\"}}' \\\n    --update-expression \"SET Price = Price - :discount\" \\\n    --condition-expression \"Price > :limit\" \\\n    --expression-attribute-values file://values.json\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":discount\": { \"N\": \"75\"},\n    \":limit\": {\"N\": \"500\"}\n}\n\nIf the starting Price is 650, the UpdateItem operation reduces the Price to 575. If you run the UpdateItem operation again, the Price is reduced to 500. If you run it a third time, the condition expression evaluates to false, and the update fails.\n\nNote\n\nIn the condition expression, the : (colon character) indicates an expression attribute value—a placeholder for an actual value. For more information, see Expression attribute values.\n\nFor more information about \">\" and other operators, see Comparison operator and function reference.\n\nConditional expression examples\n\nFor more information about the functions used in the following examples, see Comparison operator and function reference. If you want to know more about how to specify different attribute types in an expression, see Specifying item attributes when using expressions.\n\nChecking for attributes in an item\n\nYou can check for the existence (or nonexistence) of any attribute. If the condition expression evaluates to true, the operation succeeds; otherwise, it fails.\n\nThe following example uses attribute_not_exists to delete a product only if it does not have a Price attribute.\n\naws dynamodb delete-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\": {\"N\": \"456\"}}' \\\n    --condition-expression \"attribute_not_exists(Price)\"\n\nDynamoDB also provides an attribute_exists function. The following example deletes a product only if it has received poor reviews.\n\naws dynamodb delete-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\": {\"N\": \"456\"}}' \\\n    --condition-expression \"attribute_exists(ProductReviews.OneStar)\"\nChecking for attribute type\n\nYou can check the data type of an attribute value by using the attribute_type function. If the condition expression evaluates to true, the operation succeeds; otherwise, it fails.\n\nThe following example uses attribute_type to delete a product only if it has a Color attribute of type String Set.\n\naws dynamodb delete-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\": {\"N\": \"456\"}}' \\\n    --condition-expression \"attribute_type(Color, :v_sub)\" \\\n    --expression-attribute-values file://expression-attribute-values.json\n\nThe arguments for --expression-attribute-values are stored in the expression-attribute-values.json file.\n\n{\n    \":v_sub\":{\"S\":\"SS\"}\n}\nChecking string starting value\n\nYou can check if a String attribute value begins with a particular substring by using the begins_with function. If the condition expression evaluates to true, the operation succeeds; otherwise, it fails.\n\nThe following example uses begins_with to delete a product only if the FrontView element of the Pictures map starts with a specific value.\n\naws dynamodb delete-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\": {\"N\": \"456\"}}' \\\n    --condition-expression \"begins_with(Pictures.FrontView, :v_sub)\" \\\n    --expression-attribute-values file://expression-attribute-values.json\n\nThe arguments for --expression-attribute-values are stored in the expression-attribute-values.json file.\n\n{\n    \":v_sub\":{\"S\":\"http://\"}\n}\nChecking for an element in a set\n\nYou can check for an element in a set or look for a substring within a string by using the contains function. If the condition expression evaluates to true, the operation succeeds; otherwise, it fails.\n\nThe following example uses contains to delete a product only if the Color String Set has an element with a specific value.\n\naws dynamodb delete-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\": {\"N\": \"456\"}}' \\\n    --condition-expression \"contains(Color, :v_sub)\" \\\n    --expression-attribute-values file://expression-attribute-values.json\n\nThe arguments for --expression-attribute-values are stored in the expression-attribute-values.json file.\n\n{\n    \":v_sub\":{\"S\":\"Red\"}\n}\nChecking the size of an attribute value\n\nYou can check for the size of an attribute value by using the size function. If the condition expression evaluates to true, the operation succeeds; otherwise, it fails.\n\nThe following example uses size to delete a product only if the size of the VideoClip Binary attribute is greater than 64000 bytes.\n\naws dynamodb delete-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\": {\"N\": \"456\"}}' \\\n    --condition-expression \"size(VideoClip) > :v_sub\" \\\n    --expression-attribute-values file://expression-attribute-values.json\n\nThe arguments for --expression-attribute-values are stored in the expression-attribute-values.json file.\n\n{\n    \":v_sub\":{\"N\":\"64000\"}\n}"
  },
  {
    "title": "Expression attribute values - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ExpressionAttributeValues.html",
    "html": "Expression attribute values\nPDF\nRSS\n\nIf you need to compare an attribute with a value, define an expression attribute value as a placeholder. Expression attribute values in Amazon DynamoDB are substitutes for the actual values that you want to compare—values that you might not know until runtime. An expression attribute value must begin with a colon (:) and be followed by one or more alphanumeric characters.\n\nFor example, suppose that you wanted to return all of the ProductCatalog items that are available in Black and cost 500 or less. You could use a Scan operation with a filter expression, as in this AWS Command Line Interface (AWS CLI) example.\n\naws dynamodb scan \\\n    --table-name ProductCatalog \\\n    --filter-expression \"contains(Color, :c) and Price <= :p\" \\\n    --expression-attribute-values file://values.json\n\nThe arguments for --expression-attribute-values are stored in the values.json file.\n\n{\n    \":c\": { \"S\": \"Black\" },\n    \":p\": { \"N\": \"500\" }\n}\nNote\n\nA Scan operation reads every item in a table. So you should avoid using Scan with large tables.\n\nThe filter expression is applied to the Scan results, and items that don't match the filter expression are discarded.\n\nIf you define an expression attribute value, you must use it consistently throughout the entire expression. Also, you can't omit the : symbol.\n\nExpression attribute values are used with key condition expressions, condition expressions, update expressions, and filter expressions.\n\nNote\n\nFor programming language-specific code examples, see Getting started with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Expression attribute names in DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ExpressionAttributeNames.html",
    "html": "Expression attribute names in DynamoDB\nPDF\nRSS\n\nAn expression attribute name is a placeholder that you use in an Amazon DynamoDB expression as an alternative to an actual attribute name. An expression attribute name must begin with a pound sign (#), and be followed by one or more alphanumeric characters and the underscore (_) character.\n\nThis section describes several situations in which you must use expression attribute names.\n\nNote\n\nThe examples in this section use the AWS Command Line Interface (AWS CLI). For programming language-specific code examples, see Getting started with DynamoDB and the AWS SDKs.\n\nTopics\nReserved words\nAttribute names containing special characters\nNested attributes\nRepeating attribute names\nReserved words\n\nSometimes you might need to write an expression containing an attribute name that conflicts with a DynamoDB reserved word. (For a complete list of reserved words, see Reserved words in DynamoDB.)\n\nFor example, the following AWS CLI example would fail because COMMENT is a reserved word.\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"123\"}}' \\\n    --projection-expression \"Comment\"\n\nTo work around this, you can replace Comment with an expression attribute name such as #c. The # (pound sign) is required and indicates that this is a placeholder for an attribute name. The AWS CLI example would now look like the following.\n\naws dynamodb get-item \\\n     --table-name ProductCatalog \\\n     --key '{\"Id\":{\"N\":\"123\"}}' \\\n     --projection-expression \"#c\" \\\n     --expression-attribute-names '{\"#c\":\"Comment\"}'\nNote\n\nIf an attribute name begins with a number, contains a space or contains a reserved word, you must use an expression attribute name to replace that attribute's name in the expression.\n\nAttribute names containing special characters\n\nIn an expression, a dot (\".\") is interpreted as a separator character in a document path. However, DynamoDB also allows you to use a dot character and other special characters, such as a hyphen (\"-\") as part of an attribute name. This can be ambiguous in some cases. To illustrate, suppose that you wanted to retrieve the Safety.Warning attribute from a ProductCatalog item (see Specifying item attributes when using expressions).\n\nSuppose that you wanted to access Safety.Warning using a projection expression.\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"123\"}}' \\\n    --projection-expression \"Safety.Warning\"\n\nDynamoDB would return an empty result, rather than the expected string (\"Always wear a helmet\"). This is because DynamoDB interprets a dot in an expression as a document path separator. In this case, you must define an expression attribute name (such as #sw) as a substitute for Safety.Warning. You could then use the following projection expression.\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"123\"}}' \\\n    --projection-expression \"#sw\" \\\n    --expression-attribute-names '{\"#sw\":\"Safety.Warning\"}'\n\nDynamoDB would then return the correct result.\n\nNote\n\nIf an attribute name contains a dot (\".\") or a hyphen (\"-\"), you must use an expression attribute name to replace that attribute's name in the expression.\n\nNested attributes\n\nSuppose that you wanted to access the nested attribute ProductReviews.OneStar, using the following projection expression.\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"123\"}}' \\\n    --projection-expression \"ProductReviews.OneStar\"\n\nThe result would contain all of the one-star product reviews, which is expected.\n\nBut what if you decided to use an expression attribute name instead? For example, what would happen if you were to define #pr1star as a substitute for ProductReviews.OneStar?\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"123\"}}' \\\n    --projection-expression \"#pr1star\"  \\\n    --expression-attribute-names '{\"#pr1star\":\"ProductReviews.OneStar\"}'\n\nDynamoDB would return an empty result instead of the expected map of one-star reviews. This is because DynamoDB interprets a dot in an expression attribute name as a character within an attribute's name. When DynamoDB evaluates the expression attribute name #pr1star, it determines that ProductReviews.OneStar refers to a scalar attribute—which is not what was intended.\n\nThe correct approach would be to define an expression attribute name for each element in the document path:\n\n#pr — ProductReviews\n\n#1star — OneStar\n\nYou could then use #pr.#1star for the projection expression.\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"123\"}}' \\\n    --projection-expression \"#pr.#1star\"  \\\n    --expression-attribute-names '{\"#pr\":\"ProductReviews\", \"#1star\":\"OneStar\"}'\n\nDynamoDB would then return the correct result.\n\nRepeating attribute names\n\nExpression attribute names are helpful when you need to refer to the same attribute name repeatedly. For example, consider the following expression for retrieving some of the reviews from a ProductCatalog item.\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"123\"}}' \\\n    --projection-expression \"ProductReviews.FiveStar, ProductReviews.ThreeStar, ProductReviews.OneStar\"\n\nTo make this more concise, you can replace ProductReviews with an expression attribute name such as #pr. The revised expression would now look like the following.\n\n#pr.FiveStar, #pr.ThreeStar, #pr.OneStar\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"123\"}}' \\\n    --projection-expression \"#pr.FiveStar, #pr.ThreeStar, #pr.OneStar\" \\\n    --expression-attribute-names '{\"#pr\":\"ProductReviews\"}'\n\nIf you define an expression attribute name, you must use it consistently throughout the entire expression. Also, you cannot omit the # symbol."
  },
  {
    "title": "Projection expressions - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ProjectionExpressions.html",
    "html": "Projection expressions\nPDF\nRSS\n\nTo read data from a table, you use operations such as GetItem, Query, or Scan. Amazon DynamoDB returns all the item attributes by default. To get only some, rather than all of the attributes, use a projection expression.\n\nA projection expression is a string that identifies the attributes that you want. To retrieve a single attribute, specify its name. For multiple attributes, the names must be comma-separated.\n\nThe following are some examples of projection expressions, based on the ProductCatalog item from Specifying item attributes when using expressions:\n\nA single top-level attribute.\n\nTitle\n\nThree top-level attributes. DynamoDB retrieves the entire Color set.\n\nTitle, Price, Color\n\nFour top-level attributes. DynamoDB returns the entire contents of RelatedItems and ProductReviews.\n\nTitle, Description, RelatedItems, ProductReviews\n\nDynamoDB has a list of reserved words and special characters. You can use any attribute name in a projection expression, provided that the first character is a-z or A-Z and the second character (if present) is a-z, A-Z, or 0-9. If an attribute name doesn't meet this requirement, you must define an expression attribute name as a placeholder. For a complete list, see Reserved words in DynamoDB. Also, the following characters have special meaning in DynamoDB: # (hash) and : (colon).\n\nAlthough DynamoDB allows you to use these reserved words and special characters for names, we recommend that you avoid doing so because you have to define placeholder variables whenever you use these names in an expression. For more information, see Expression attribute names in DynamoDB.\n\nThe following AWS CLI example shows how to use a projection expression with a GetItem operation. This projection expression retrieves a top-level scalar attribute (Description), the first element in a list (RelatedItems[0]), and a list nested within a map (ProductReviews.FiveStar).\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key file://key.json \\\n    --projection-expression \"Description, RelatedItems[0], ProductReviews.FiveStar\"\n\nThe following JSON would be returned for this example.\n\n{\n    \"Item\": {\n        \"Description\": {\n            \"S\": \"123 description\"\n        },\n        \"ProductReviews\": {\n            \"M\": {\n                \"FiveStar\": {\n                    \"L\": [\n                        {\n                            \"S\": \"Excellent! Can't recommend it highly enough! Buy it!\"\n                        },\n                        {\n                            \"S\": \"Do yourself a favor and buy this.\"\n                        }\n                    ]\n                }\n            }\n        },\n        \"RelatedItems\": {\n            \"L\": [\n                {\n                    \"N\": \"341\"\n                }\n            ]\n        }\n    }\n}\n\nThe arguments for --key are stored in the key.json file.\n\n{\n    \"Id\": { \"N\": \"123\" }\n}\n\nFor programming language-specific code examples, see Getting started with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Specifying item attributes when using expressions - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.Attributes.html",
    "html": "Specifying item attributes when using expressions\nPDF\nRSS\n\nThis section describes how to refer to item attributes in an expression in Amazon DynamoDB. You can work with any attribute, even if it is deeply nested within multiple lists and maps.\n\nTopics\nTop-level attributes\nNested attributes\nDocument paths\nA Sample Item: ProductCatalog\n\nThe following is a representation of an item in the ProductCatalog table. (This table is described in Example tables and data.)\n\n{\n    \"Id\": 123,\n    \"Title\": \"Bicycle 123\",\n    \"Description\": \"123 description\",\n    \"BicycleType\": \"Hybrid\",\n    \"Brand\": \"Brand-Company C\",\n    \"Price\": 500,\n    \"Color\": [\"Red\", \"Black\"],\n    \"ProductCategory\": \"Bicycle\",\n    \"InStock\": true,\n    \"QuantityOnHand\": null,\n    \"RelatedItems\": [\n        341,\n        472,\n        649\n    ],\n    \"Pictures\": {\n        \"FrontView\": \"http://example.com/products/123_front.jpg\",\n        \"RearView\": \"http://example.com/products/123_rear.jpg\",\n        \"SideView\": \"http://example.com/products/123_left_side.jpg\"\n    },\n    \"ProductReviews\": {\n\t    \"FiveStar\": [\n\t    \t\t\"Excellent! Can't recommend it highly enough! Buy it!\",\n\t    \t\t\"Do yourself a favor and buy this.\"\n\t    ],\n\t    \"OneStar\": [\n\t    \t\t\"Terrible product! Do not buy this.\"\n\t    ]\n    },\n    \"Comment\": \"This product sells out quickly during the summer\",\n    \"Safety.Warning\": \"Always wear a helmet\"\n }\n\nNote the following:\n\nThe partition key value (Id) is 123. There is no sort key.\n\nMost of the attributes have scalar data types, such as String, Number, Boolean, and Null.\n\nOne attribute (Color) is a String Set.\n\nThe following attributes are document data types:\n\nA list of RelatedItems. Each element is an Id for a related product.\n\nA map of Pictures. Each element is a short description of a picture, along with a URL for the corresponding image file.\n\nA map of ProductReviews. Each element represents a rating and a list of reviews corresponding to that rating. Initially, this map is populated with five-star and one-star reviews.\n\nTop-level attributes\n\nAn attribute is said to be top level if it is not embedded within another attribute. For the ProductCatalog item, the top-level attributes are as follows:\n\nId\n\nTitle\n\nDescription\n\nBicycleType\n\nBrand\n\nPrice\n\nColor\n\nProductCategory\n\nInStock\n\nQuantityOnHand\n\nRelatedItems\n\nPictures\n\nProductReviews\n\nComment\n\nSafety.Warning\n\nAll of these top-level attributes are scalars, except for Color (list), RelatedItems (list), Pictures (map), and ProductReviews (map).\n\nNested attributes\n\nAn attribute is said to be nested if it is embedded within another attribute. To access a nested attribute, you use dereference operators:\n\n[n] — for list elements\n\n. (dot) — for map elements\n\nAccessing list elements\n\nThe dereference operator for a list element is [N], where n is the element number. List elements are zero-based, so [0] represents the first element in the list, [1] represents the second, and so on. Here are some examples:\n\nMyList[0]\n\nAnotherList[12]\n\nThisList[5][11]\n\nThe element ThisList[5] is itself a nested list. Therefore, ThisList[5][11] refers to the 12th element in that list.\n\nThe number within the square brackets must be a non-negative integer. Therefore, the following expressions are not valid:\n\nMyList[-1]\n\nMyList[0.4]\n\nAccessing map elements\n\nThe dereference operator for a map element is . (a dot). Use a dot as a separator between elements in a map:\n\nMyMap.nestedField\n\nMyMap.nestedField.deeplyNestedField\n\nDocument paths\n\nIn an expression, you use a document path to tell DynamoDB where to find an attribute. For a top-level attribute, the document path is simply the attribute name. For a nested attribute, you construct the document path using dereference operators.\n\nThe following are some examples of document paths. (Refer to the item shown in Specifying item attributes when using expressions.)\n\nA top-level scalar attribute.\n\nDescription\n\nA top-level list attribute. (This returns the entire list, not just some of the elements.)\n\nRelatedItems\n\nThe third element from the RelatedItems list. (Remember that list elements are zero-based.)\n\nRelatedItems[2]\n\nThe front-view picture of the product.\n\nPictures.FrontView\n\nAll of the five-star reviews.\n\nProductReviews.FiveStar\n\nThe first of the five-star reviews.\n\nProductReviews.FiveStar[0]\n\nNote\n\nThe maximum depth for a document path is 32. Therefore, the number of dereferences operators in a path cannot exceed this limit.\n\nYou can use any attribute name in a document path as long as they meet these requirements:\n\nThe attribute name must begin with a pound sign (#)\n\nThe first character is a-z or A-Z and or 0-9\n\nThe second character (if present) is a-z, A-Z\n\nNote\n\nIf an attribute name does not meet this requirement, you must define an expression attribute name as a placeholder.\n\nFor more information, see Expression attribute names in DynamoDB."
  },
  {
    "title": "Using expressions in DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.html",
    "html": "Using expressions in DynamoDB\nPDF\nRSS\n\nIn Amazon DynamoDB, you use expressions to denote the attributes that you want to read from an item. You also use expressions when writing an item to indicate any conditions that must be met (also known as a conditional update), and to indicate how the attributes are to be updated. This section describes the basic expression grammar and the available kinds of expressions.\n\nNote\n\nFor backward compatibility, DynamoDB also supports conditional parameters that do not use expressions. For more information, see Legacy conditional parameters.\n\nNew applications should use expressions rather than the legacy parameters.\n\nTopics\nSpecifying item attributes when using expressions\nProjection expressions\nExpression attribute names in DynamoDB\nExpression attribute values\nCondition expressions\nUpdate expressions"
  },
  {
    "title": "Working with items and attributes - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html",
    "html": "Working with items and attributes\nPDF\nRSS\n\nIn Amazon DynamoDB, an item is a collection of attributes. Each attribute has a name and a value. An attribute value can be a scalar, a set, or a document type. For more information, see Amazon DynamoDB: How it works.\n\nDynamoDB provides four operations for basic create, read, update, and delete (CRUD) functionality. All these operations are atomic.\n\nPutItem — Create an item.\n\nGetItem — Read an item.\n\nUpdateItem — Update an item.\n\nDeleteItem — Delete an item.\n\nEach of these operations requires that you specify the primary key of the item that you want to work with. For example, to read an item using GetItem, you must specify the partition key and sort key (if applicable) for that item.\n\nIn addition to the four basic CRUD operations, DynamoDB also provides the following:\n\nBatchGetItem — Read up to 100 items from one or more tables.\n\nBatchWriteItem — Create or delete up to 25 items in one or more tables.\n\nThese batch operations combine multiple CRUD operations into a single request. In addition, the batch operations read and write items in parallel to minimize response latencies.\n\nThis section describes how to use these operations and includes related topics, such as conditional updates and atomic counters. This section also includes example code that uses the AWS SDKs.\n\nTopics\nReading an item\nWriting an item\nReturn values\nBatch operations\nAtomic counters\nConditional writes\nUsing expressions in DynamoDB\nTime to Live (TTL)\nWorking with items: Java\nWorking with items: .NET\nReading an item\n\nTo read an item from a DynamoDB table, use the GetItem operation. You must provide the name of the table, along with the primary key of the item you want.\n\nExample\n\nThe following AWS CLI example shows how to read an item from the ProductCatalog table.\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"1\"}}'\nNote\n\nWith GetItem, you must specify the entire primary key, not just part of it. For example, if a table has a composite primary key (partition key and sort key), you must supply a value for the partition key and a value for the sort key.\n\nA GetItem request performs an eventually consistent read by default. You can use the ConsistentRead parameter to request a strongly consistent read instead. (This consumes additional read capacity units, but it returns the most up-to-date version of the item.)\n\nGetItem returns all of the item's attributes. You can use a projection expression to return only some of the attributes. For more information, see Projection expressions.\n\nTo return the number of read capacity units consumed by GetItem, set the ReturnConsumedCapacity parameter to TOTAL.\n\nExample\n\nThe following AWS Command Line Interface (AWS CLI) example shows some of the optional GetItem parameters.\n\naws dynamodb get-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"1\"}}' \\\n    --consistent-read \\\n    --projection-expression \"Description, Price, RelatedItems\" \\\n    --return-consumed-capacity TOTAL\nWriting an item\n\nTo create, update, or delete an item in a DynamoDB table, use one of the following operations:\n\nPutItem\n\nUpdateItem\n\nDeleteItem\n\nFor each of these operations, you must specify the entire primary key, not just part of it. For example, if a table has a composite primary key (partition key and sort key), you must provide a value for the partition key and a value for the sort key.\n\nTo return the number of write capacity units consumed by any of these operations, set the ReturnConsumedCapacity parameter to one of the following:\n\nTOTAL — Returns the total number of write capacity units consumed.\n\nINDEXES — Returns the total number of write capacity units consumed, with subtotals for the table and any secondary indexes that were affected by the operation.\n\nNONE — No write capacity details are returned. (This is the default.)\n\nPutItem\n\nPutItem creates a new item. If an item with the same key already exists in the table, it is replaced with the new item.\n\nExample\n\nWrite a new item to the Thread table. The primary key for Thread consists of ForumName (partition key) and Subject (sort key).\n\naws dynamodb put-item \\\n    --table-name Thread \\\n    --item file://item.json\n\nThe arguments for --item are stored in the item.json file.\n\n{\n    \"ForumName\": {\"S\": \"Amazon DynamoDB\"},\n    \"Subject\": {\"S\": \"New discussion thread\"},\n    \"Message\": {\"S\": \"First post in this thread\"},\n    \"LastPostedBy\": {\"S\": \"fred@example.com\"},\n    \"LastPostDateTime\": {\"S\": \"201603190422\"}\n}\nUpdateItem\n\nIf an item with the specified key does not exist, UpdateItem creates a new item. Otherwise, it modifies an existing item's attributes.\n\nYou use an update expression to specify the attributes that you want to modify and their new values. For more information, see Update expressions.\n\nWithin the update expression, you use expression attribute values as placeholders for the actual values. For more information, see Expression attribute values.\n\nExample\n\nModify various attributes in the Thread item. The optional ReturnValues parameter shows the item as it appears after the update. For more information, see Return values.\n\naws dynamodb update-item \\\n    --table-name Thread \\\n    --key file://key.json \\\n    --update-expression \"SET Answered = :zero, Replies = :zero, LastPostedBy = :lastpostedby\" \\\n    --expression-attribute-values file://expression-attribute-values.json \\\n    --return-values ALL_NEW\n\nThe arguments for --key are stored in the key.json file.\n\n{\n    \"ForumName\": {\"S\": \"Amazon DynamoDB\"},\n    \"Subject\": {\"S\": \"New discussion thread\"}\n}\n\nThe arguments for --expression-attribute-values are stored in the expression-attribute-values.json file.\n\n{\n    \":zero\": {\"N\":\"0\"},\n    \":lastpostedby\": {\"S\":\"barney@example.com\"}\n}\nDeleteItem\n\nDeleteItem deletes the item with the specified key.\n\nExample\n\nThe following AWS CLI example shows how to delete the Thread item.\n\naws dynamodb delete-item \\\n    --table-name Thread \\\n    --key file://key.json\nReturn values\n\nIn some cases, you might want DynamoDB to return certain attribute values as they appeared before or after you modified them. The PutItem, UpdateItem, and DeleteItem operations have a ReturnValues parameter that you can use to return the attribute values before or after they are modified.\n\nThe default value for ReturnValues is NONE, meaning that DynamoDB does not return any information about attributes that were modified.\n\nThe following are the other valid settings for ReturnValues, organized by DynamoDB API operation.\n\nPutItem\n\nReturnValues: ALL_OLD\n\nIf you overwrite an existing item, ALL_OLD returns the entire item as it appeared before the overwrite.\n\nIf you write a nonexistent item, ALL_OLD has no effect.\n\nUpdateItem\n\nThe most common usage for UpdateItem is to update an existing item. However, UpdateItem actually performs an upsert, meaning that it automatically creates the item if it doesn't already exist.\n\nReturnValues: ALL_OLD\n\nIf you update an existing item, ALL_OLD returns the entire item as it appeared before the update.\n\nIf you update a nonexistent item (upsert), ALL_OLD has no effect.\n\nReturnValues: ALL_NEW\n\nIf you update an existing item, ALL_NEW returns the entire item as it appeared after the update.\n\nIf you update a nonexistent item (upsert), ALL_NEW returns the entire item.\n\nReturnValues: UPDATED_OLD\n\nIf you update an existing item, UPDATED_OLD returns only the updated attributes, as they appeared before the update.\n\nIf you update a nonexistent item (upsert), UPDATED_OLD has no effect.\n\nReturnValues: UPDATED_NEW\n\nIf you update an existing item, UPDATED_NEW returns only the affected attributes, as they appeared after the update.\n\nIf you update a nonexistent item (upsert), UPDATED_NEW returns only the updated attributes, as they appear after the update.\n\nDeleteItem\n\nReturnValues: ALL_OLD\n\nIf you delete an existing item, ALL_OLD returns the entire item as it appeared before you deleted it.\n\nIf you delete a nonexistent item, ALL_OLD doesn't return any data.\n\nBatch operations\n\nFor applications that need to read or write multiple items, DynamoDB provides the BatchGetItem and BatchWriteItem operations. Using these operations can reduce the number of network round trips from your application to DynamoDB. In addition, DynamoDB performs the individual read or write operations in parallel. Your applications benefit from this parallelism without having to manage concurrency or threading.\n\nThe batch operations are essentially wrappers around multiple read or write requests. For example, if a BatchGetItem request contains five items, DynamoDB performs five GetItem operations on your behalf. Similarly, if a BatchWriteItem request contains two put requests and four delete requests, DynamoDB performs two PutItem and four DeleteItem requests.\n\nIn general, a batch operation does not fail unless all the requests in the batch fail. For example, suppose that you perform a BatchGetItem operation, but one of the individual GetItem requests in the batch fails. In this case, BatchGetItem returns the keys and data from the GetItem request that failed. The other GetItem requests in the batch are not affected.\n\nBatchGetItem\n\nA single BatchGetItem operation can contain up to 100 individual GetItem requests and can retrieve up to 16 MB of data. In addition, a BatchGetItem operation can retrieve items from multiple tables.\n\nExample\n\nRetrieve two items from the Thread table, using a projection expression to return only some of the attributes.\n\naws dynamodb batch-get-item \\\n    --request-items file://request-items.json\n\nThe arguments for --request-items are stored in the request-items.json file.\n\n{\n    \"Thread\": {\n        \"Keys\": [\n            {\n                \"ForumName\":{\"S\": \"Amazon DynamoDB\"},\n                \"Subject\":{\"S\": \"DynamoDB Thread 1\"}\n            },\n            {\n                \"ForumName\":{\"S\": \"Amazon S3\"},\n                \"Subject\":{\"S\": \"S3 Thread 1\"}\n            }\n        ],\n        \"ProjectionExpression\":\"ForumName, Subject, LastPostedDateTime, Replies\"\n    }\n}\nBatchWriteItem\n\nThe BatchWriteItem operation can contain up to 25 individual PutItem and DeleteItem requests and can write up to 16 MB of data. (The maximum size of an individual item is 400 KB.) In addition, a BatchWriteItem operation can put or delete items in multiple tables.\n\nNote\n\nBatchWriteItem does not support UpdateItem requests.\n\nExample\n\nWrite two items to the ProductCatalog table.\n\naws dynamodb batch-write-item \\\n    --request-items file://request-items.json\n\nThe arguments for --request-items are stored in the request-items.json file.\n\n{\n    \"ProductCatalog\": [\n        {\n            \"PutRequest\": {\n                \"Item\": {\n                    \"Id\": { \"N\": \"601\" },\n                    \"Description\": { \"S\": \"Snowboard\" },\n                    \"QuantityOnHand\": { \"N\": \"5\" },\n                    \"Price\": { \"N\": \"100\" }\n                }\n            }\n        },\n        {\n            \"PutRequest\": {\n                \"Item\": {\n                    \"Id\": { \"N\": \"602\" },\n                    \"Description\": { \"S\": \"Snow shovel\" }\n                }\n            }\n        }\n    ]\n}\nAtomic counters\n\nYou can use the UpdateItem operation to implement an atomic counter—a numeric attribute that is incremented, unconditionally, without interfering with other write requests. (All write requests are applied in the order in which they were received.) With an atomic counter, the updates are not idempotent. In other words, the numeric value increments or decrements each time you call UpdateItem. If the increment value used to update the atomic counter is positive, then it can cause overcounting. If the increment value is negative, then it can cause undercounting.\n\nYou might use an atomic counter to track the number of visitors to a website. In this case, your application would increment a numeric value, regardless of its current value. If an UpdateItem operation fails, the application could simply retry the operation. This would risk updating the counter twice, but you could probably tolerate a slight overcounting or undercounting of website visitors.\n\nAn atomic counter would not be appropriate where overcounting or undercounting can't be tolerated (for example, in a banking application). In this case, it is safer to use a conditional update instead of an atomic counter.\n\nFor more information, see Incrementing and decrementing numeric attributes.\n\nExample\n\nThe following AWS CLI example increments the Price of a product by 5. For this example, the item was known to exist before the counter is updated. Because UpdateItem is not idempotent, the Price increases every time you run this code.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\": { \"N\": \"601\" }}' \\\n    --update-expression \"SET Price = Price + :incr\" \\\n    --expression-attribute-values '{\":incr\":{\"N\":\"5\"}}' \\\n    --return-values UPDATED_NEW\nConditional writes\n\nBy default, the DynamoDB write operations (PutItem, UpdateItem, DeleteItem) are unconditional: Each operation overwrites an existing item that has the specified primary key.\n\nDynamoDB optionally supports conditional writes for these operations. A conditional write succeeds only if the item attributes meet one or more expected conditions. Otherwise, it returns an error.\n\nConditional writes check their conditions against the most recently updated version of the item. Note that if the item did not previously exist or if the most recent successful operation against that item was a delete, then the conditional write will find no previous item.\n\nConditional writes are helpful in many situations. For example, you might want a PutItem operation to succeed only if there is not already an item with the same primary key. Or you could prevent an UpdateItem operation from modifying an item if one of its attributes has a certain value.\n\nConditional writes are helpful in cases where multiple users attempt to modify the same item. Consider the following diagram, in which two users (Alice and Bob) are working with the same item from a DynamoDB table.\n\nSuppose that Alice uses the AWS CLI to update the Price attribute to 8.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"1\"}}' \\\n    --update-expression \"SET Price = :newval\" \\\n    --expression-attribute-values file://expression-attribute-values.json\n\nThe arguments for --expression-attribute-values are stored in the file expression-attribute-values.json:\n\n{\n    \":newval\":{\"N\":\"8\"}\n}\n\nNow suppose that Bob issues a similar UpdateItem request later, but changes the Price to 12. For Bob, the --expression-attribute-values parameter looks like the following.\n\n{\n    \":newval\":{\"N\":\"12\"}\n}\n\nBob's request succeeds, but Alice's earlier update is lost.\n\nTo request a conditional PutItem, DeleteItem, or UpdateItem, you specify a condition expression. A condition expression is a string containing attribute names, conditional operators, and built-in functions. The entire expression must evaluate to true. Otherwise, the operation fails.\n\nNow consider the following diagram, showing how conditional writes would prevent Alice's update from being overwritten.\n\nAlice first tries to update Price to 8, but only if the current Price is 10.\n\naws dynamodb update-item \\\n    --table-name ProductCatalog \\\n    --key '{\"Id\":{\"N\":\"1\"}}' \\\n    --update-expression \"SET Price = :newval\" \\\n    --condition-expression \"Price = :currval\" \\\n    --expression-attribute-values file://expression-attribute-values.json\n\nThe arguments for --expression-attribute-values are stored in the expression-attribute-values.json file.\n\n{\n    \":newval\":{\"N\":\"8\"},\n    \":currval\":{\"N\":\"10\"}\n}\n\nAlice's update succeeds because the condition evaluates to true.\n\nNext, Bob attempts to update the Price to 12, but only if the current Price is 10. For Bob, the --expression-attribute-values parameter looks like the following.\n\n{\n    \":newval\":{\"N\":\"12\"},\n    \":currval\":{\"N\":\"10\"}\n}\n\nBecause Alice has previously changed the Price to 8, the condition expression evaluates to false, and Bob's update fails.\n\nFor more information, see Condition expressions.\n\nConditional write idempotence\n\nConditional writes can be idempotent if the conditional check is on the same attribute that is being updated. This means that DynamoDB performs a given write request only if certain attribute values in the item match what you expect them to be at the time of the request.\n\nFor example, suppose that you issue an UpdateItem request to increase the Price of an item by 3, but only if the Price is currently 20. After you send the request, but before you get the results back, a network error occurs, and you don't know whether the request was successful. Because this conditional write is idempotent, you can retry the same UpdateItem request, and DynamoDB updates the item only if the Price is currently 20.\n\nCapacity units consumed by conditional writes\n\nIf a ConditionExpression evaluates to false during a conditional write, DynamoDB still consumes write capacity from the table. The amount consumed is dependent on the size of the existing item (or a minimum of 1). For example, if an existing item is 300kb and the new item you are trying to create or update is 310kb, the write capacity units consumed will be the 300 if the condition fails, and 310 if the condition succeeds. If this is a new item (no existing item), then the write capacity units consumed will be 1 if the condition fails and 310 if the condition succeeds.\n\nNote\n\nWrite operations consume write capacity units only. They never consume read capacity units.\n\nA failed conditional write returns a ConditionalCheckFailedException. When this occurs, you don't receive any information in the response about the write capacity that was consumed. .\n\nTo return the number of write capacity units consumed during a conditional write, you use the ReturnConsumedCapacity parameter:\n\nTOTAL — Returns the total number of write capacity units consumed.\n\nINDEXES — Returns the total number of write capacity units consumed, with subtotals for the table and any secondary indexes that were affected by the operation.\n\nNONE — No write capacity details are returned. (This is the default.)\n\nNote\n\nUnlike a global secondary index, a local secondary index shares its provisioned throughput capacity with its table. Read and write activity on a local secondary index consumes provisioned throughput capacity from the table."
  },
  {
    "title": "DynamoDB API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDB_API.html",
    "html": "DynamoDB API\nPDF\nRSS\nTopics\nWorking with items and attributes\nItem collections - how to model one-to-many relationships in DynamoDB\nWorking with scans in DynamoDB"
  },
  {
    "title": "Upgrading global tables to Current (2019.11.21) version from Legacy(2017.11.29) version - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_upgrade.html",
    "html": "Upgrading global tables to Current (2019.11.21) version from Legacy(2017.11.29) version\nPDF\nRSS\nThere are two versions of DynamoDB global tables available: Global Tables version 2019.11.21 (Current) and Global tables version 2017.11.29 (Legacy). Customers should use version 2019.11.21 (Current) when possible, as it provides greater flexibility, higher efficiency and consumes less write capacity than 2017.11.29 (Legacy). To determine which version you're using, see Determining the global table version you are using.\n\nThis section describes how to upgrade your global tables to Version 2019.11.21 (Current) using the DynamoDB console. Upgrading from Version 2017.11.29 (Legacy) to Version 2019.11.21 (Current) is a one-time action and you cannot reverse it. Currently, you can upgrade global tables using the console only.\n\nTopics\nLegacy and Current version behavior differences\nUpgrade prerequisites\nRequired permissions\nWhat to expect during the upgrade\nDynamoDB Streams behavior\nUpgrading to Version 2019.11.21 (Current)\nDifferences in behavior between Legacy and Current versions\n\nThe following list describes the differences in behavior between the Legacy and Current versions of global tables.\n\nVersion 2019.11.21 (Current) consumes less write capacity for several DynamoDB operations compared to Version 2017.11.29 (Legacy), and therefore, is more cost-effective for most customers. The differences for these DynamoDB operations are as follows:\n\nInvoking PutItem for a 1KB item in a Region and replicating to other Regions requires 2 rWRUs per region for 2017.11.29 (Legacy), but only 1 rWRU for 2019.11.21 (Current).\n\nInvoking UpdateItem for a 1KB item requires 2 rWRUs in the source Region and 1 rWRU per destination Region for 2017.11.29 (Legacy), but only 1 rWRU for both source and destination Regions for 2019.11.21 (Current).\n\nInvoking DeleteItem for a 1KB item requires 1 rWRU in the source Region and 2 rWRUs per destination Region for 2017.11.29 (Legacy), but only 1 rWRU for both source or destination Region for 2019.11.21 (Current).\n\nThe following table shows the rWRU consumption for 2017.11.29 (Legacy) and 2019.11.21 (Current) tables.\n\nrWRU consumption of 2017.11.29 (Legacy) and 2019.11.21 (Current) tables for a 1KB item in two Regions\n\nOperation\t2017.11.29 (Legacy)\t2019.11.21 (Current)\tSavings\nPutItem\t4 rWRUs\t2 rWRUs\t50%\nUpdateItem\t3 rWRUs\t2 rWRUs\t33%\nDeleteItem\t3 rWRUs\t2 rWRUs\t33%\n\nVersion 2017.11.29 (Legacy) is available in only 11 AWS Regions. However, Version 2019.11.21 (Current) is available in all the AWS Regions.\n\nYou create Version 2017.11.29 (Legacy) global tables by first creating a set of empty Regional tables, then invoking the CreateGlobalTable API to form the global table. You create Version 2019.11.21 (Current) global tables by invoking the UpdateTable API to add a replica to an existing Regional table.\n\nVersion 2017.11.29 (Legacy) requires you to empty all replicas in the table before adding a replica in a new Region (including during creation). Version 2019.11.21 (Current) supports you to add and remove replicas to Regions on a table that already contains data.\n\nVersion 2017.11.29 (Legacy) uses the following dedicated set of control plane APIs for managing replicas:\n\nCreateGlobalTable\n\nDescribeGlobalTable\n\nDescribeGlobalTableSettings\n\nListGlobalTables\n\nUpdateGlobalTable\n\nUpdateGlobalTableSettings\n\nVersion 2019.11.21 (Current) uses the DescribeTable and UpdateTable APIs to manage replicas.\n\nVersion 2017.11.29 (Legacy) publishes two DynamoDB Streams records for each write. Version 2019.11.21 (Current) only publishes one DynamoDB Streams record for each write.\n\nVersion 2017.11.29 (Legacy) populates and updates the aws:rep:deleting, aws:rep:updateregion, and aws:rep:updatetime attributes. Version 2019.11.21 (Current) does not populate or update these attributes.\n\nVersion 2017.11.29 (Legacy) does not synchronize Time to Live (TTL) settings across replicas. Version 2019.11.21 (Current) synchronizes TTL settings across replicas.\n\nVersion 2017.11.29 (Legacy) does not replicate TTL deletes to other replicas. Version 2019.11.21 (Current) replicates TTL deletes to all replicas.\n\nVersion 2017.11.29 (Legacy) does not synchronize auto scaling settings across replicas. Version 2019.11.21 (Current) synchronizes auto scaling settings across replicas.\n\nVersion 2017.11.29 (Legacy) does not synchronize global secondary index (GSI) settings across replicas. Version 2019.11.21 (Current) synchronizes GSI settings across replicas.\n\nVersion 2017.11.29 (Legacy) does not synchronize encryption at rest settings across replicas. Version 2019.11.21 (Current) synchronizes encryption at rest settings across replicas.\n\nVersion 2017.11.29 (Legacy) publishes the PendingReplicationCount metric. Version 2019.11.21 (Current) does not publish this metric.\n\nUpgrade prerequisites\n\nBefore you start upgrading to Version 2019.11.21 (Current) global tables, you must fulfill the following prerequisites:\n\nTime to Live (TTL) settings on replicas are consistent across Regions.\n\nGlobal secondary index (GSI) definitions on replicas are consistent across Regions.\n\nEncryption at rest settings on replicas are consistent across Regions.\n\nDynamoDB auto scaling is enabled for WCUs for all replicas, or on-demand capacity mode is enabled for all replicas.\n\nApplications don't require the presence of the of aws:rep:deleting, aws:rep:updateregion, and aws:rep:updatetime attributes in table items.\n\nRequired permissions for global tables upgrade\n\nTo upgrade to Version 2019.11.21 (Current), you must have dynamodb:UpdateGlobalTableVersion permissions in all Regions with replicas. These permissions are required in addition to the permissions needed for accessing the DynamoDB console and viewing tables.\n\nThe following IAM policy grants permissions to upgrade any global table to Version 2019.11.21 (Current).\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"dynamodb:UpdateGlobalTableVersion\",\n            \"Resource\": \"*\"\n        }\n    ]\n}\n\nThe following IAM policy grants permissions to upgrade only the Music global table with replicas in two Regions to Version 2019.11.21 (Current).\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"dynamodb:UpdateGlobalTableVersion\",\n            \"Resource\": [\n                \"arn:aws:dynamodb::123456789012:global-table/Music\",\n                \"arn:aws:dynamodb:ap-southeast-1:123456789012:table/Music\",\n                \"arn:aws:dynamodb:us-east-2:123456789012:table/Music\"\n            ]\n        }\n    ]\n}\nWhat to expect during the upgrade\n\nAll global table replicas will continue to process read and write traffic while upgrading.\n\nThe upgrade process requires between a few minutes to several hours depending on the table size and number of replicas.\n\nDuring the upgrade process, the value of TableStatus will change from ACTIVE to UPDATING. You can view the status of the table by invoking the DescribeTable API, or with the Tables view in the DynamoDB console.\n\nAuto scaling will not adjust the provisioned capacity settings for a global table while the table is being upgraded. We strongly recommend that you set the table to on-demand capacity mode during the upgrade.\n\nIf you choose to use provisioned capacity mode with auto scaling during the upgrade, you must increase the minimum read and write throughput on your policies to accommodate any expected increases in traffic to avoid throttling during the upgrade.\n\nWhen the upgrade process is complete, your table status will change to ACTIVE.\n\nDynamoDB Streams behavior before, during, and after upgrade\nOperation\tReplica Region\tBehavior before upgrade\tBehavior during upgrade\tBehavior after upgrade\n\n\nPut or Update\n\n\t\n\nSource\n\n\tTimestamp population happens using UpdateItem.\tTimestamp population happens using PutItem.\tNo customer visible timestamp is generated.\nTwo Streams records are generated. The first record contains the customer written attributes. The second record contains the aws:rep:* attributes.\tTwo Streams records are generated. The first record contains the customer written attributes. The second record contains the aws:rep:* attributes.\tA single Streams record is generated containing the customer-writen attributes.\nTwo rWCUs are consumed for each customer write.\tTwo rWCUs are consumed for each customer write.\tOne rWCU is consumed for each customer write.\nReplicationLatency and PendingReplicationCount metrics are published in CloudWatch.\tReplicationLatency and PendingReplicationCount metrics are published in CloudWatch.\tReplicationLatency metric is published in CloudWatch.\n\n\nDestination\n\n\tReplication happens using PutItem.\tReplication happens using PutItem.\tReplication happens using PutItem.\nA single Streams record is generated, which contains both the customer-written attributes and the aws:rep:* attributes.\tA single Streams record is generated, which contains both the customer-written attributes and the aws:rep:* attributes.\tA single Streams record is generated, which contains the customer-written attributes only and no replication attributes.\nOne rWCU is consumed if the item exists in the destination Region. Two rWCUs are consumed if the item doesn't exist in the destination Region.\tOne rWCU is consumed if the item exists in the destination Region. Two rWCUs are consumed if the item doesn't exist in the destination Region.\tOne rWCU is consumed for each customer write.\nReplicationLatency and PendingReplicationCount metrics are published in CloudWatch.\tReplicationLatency and PendingReplicationCount metrics are published in CloudWatch.\tReplicationLatency metric is published in CloudWatch.\n\n\nDelete\n\n\t\n\nSource\n\n\tDelete any item with smaller timestamp using DeleteItem.\tDelete any item with smaller timestamp using DeleteItem.\tDelete any item with smaller timestamp using DeleteItem.\nA single Streams record is generated, which contains both the customer-written attributes and the aws:rep:* attributes.\tA single Streams record is generated, which contains both the customer-written attributes and the aws:rep:* attributes.\tA single Streams record is generated, which contains the customer-written attributes.\nOne rWCU is consumed for each customer delete.\tOne rWCU is consumed for each customer delete.\tOne rWCU is consumed for each customer delete.\nReplicationLatency and PendingReplicationCount metrics are published in CloudWatch.\tReplicationLatency and PendingReplicationCount metrics are published in CloudWatch.\tReplicationLatency metric is published in CloudWatch.\n\n\nDestination\n\n\t\n\nTwo-phase deletes take place:\n\nIn Phase 1, UpdateItem sets the deleting flag.\n\nIn Phase 2, DeleteItem deletes the item.\n\n\tDeletes the item using DeleteItem.\tDeletes the item using DeleteItem.\nTwo Streams records are generated. The first record contains the change to the aws:rep:deleting field. The second record contains the customer-written attributes and the aws:rep:* attributes.\tA single Stream record is generated, which contains the customer-written attributes.\tA single Stream record is generated, which contains the customer-written attributes.\nTwo rWCUs are consumed for each customer delete.\tOne rWCU is consumed for each customer delete.\tOne rWCU is consumed for each customer delete.\nReplicationLatency and PendingReplicationCount metrics are published in CloudWatch.\tReplicationLatency metric is published in CloudWatch.\tReplicationLatency metric is published in CloudWatch.\nUpgrading to Version 2019.11.21 (Current)\n\nPerform the following steps to upgrade your version of DynamoDB global tables using the AWS Management Console.\n\nTo upgrade global tables to Version 2019.11.21 (Current)\n\nOpen the DynamoDB console at https://console.aws.amazon.com/dynamodb/home.\n\nIn the navigation pane on the left side of the console, choose Tables, and then select the global table that you want to upgrade to Version 2019.11.21 (Current).\n\nChoose the Global Tables tab.\n\nChoose Update version.\n\nRead and agree to the new requirements, and then choose Update version.\n\nAfter the upgrade process is complete, the global tables version that appears on the console changes to 2019.11.21."
  },
  {
    "title": "Working with read and write operations - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithReadWriteOperations.html",
    "html": "Working with read and write operations\nPDF\nRSS\n\nYou can perform read and write operations with either the DynamoDB API or PartiQL for DynamoDB. These operations will allow you to interact with the items in your table to perform basic create, read, update, and delete (CRUD) functionality.\n\nThe following sections go more in depth on this topic.\n\nTopics\nDynamoDB API\nPartiQL query language"
  },
  {
    "title": "Determining the global table version you are using - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/globaltables.DetermineVersion.html",
    "html": "Determining the global table version you are using\nPDF\nRSS\n\nThere are two versions of DynamoDB global tables available: Global Tables version 2019.11.21 (Current) and Global tables version 2017.11.29 (Legacy). We recommend using Global Tables version 2019.11.21 (Current). It is more efficient and consumes less write capacity than Global tables version 2017.11.29 (Legacy). The advantages of the current version include:\n\nThe source and target tables are maintained together and kept aligned automatically for throughput, TTL settings, auto scaling settings, and other useful attributes.\n\nGlobal secondary indexes are also kept aligned.\n\nYou can dynamically add new replica tables from a table populated with data\n\nThe metadata attributes required to control replication are hidden which helps prevent writing of them which would cause issues with replication.\n\nThe current version supports more Regions than the legacy version, and lets you add or remove Regions to an existing table while the legacy version does not.\n\nGlobal Tables version 2019.11.21 (Current) is more efficient and consumes less write capacity than Global tables version 2017.11.29 (Legacy), and therefore is more cost effective. In specifics:\n\nInserting a new item in one Region and then replicating to other Regions requires 2 rWCUs per region for Version 2017.11.29 (Legacy), but only 1 for Version 2019.11.21 (Current).\n\nUpdating an item requires 2 rWCUs in the source Region and 1 then rWCU per destination Region in Version 2017.11.29 (Legacy), but only 1 rWCU per source or destination in Version 2019.11.21 (Current).\n\nDeleting an item requires 1 rWCU in the source Region and then 2 rWCUs per destination Region in Version 2017.11.29 (Legacy), but only 1 rWCU per source or destination in Version 2019.11.21 (Current).\n\nFor more information see Amazon DynamoDB Pricing.\n\nDeterming the version through the CLI\n\nTo find out which version of global tables you are usingthrough the AWS CLI, check DescribeTable and DescribeGlobalTable. DescribeTable will show the table version if it is Version 2019.11.21 (Current), and the DescribeGlobalTable property will show the table version if it is Version 2017.11.29 (Legacy).\n\nDeterming the version through the console\n\nFinding the version through the console\n\nTo find out which version of global tables you are using through the console, do the following:\n\nOpen the DynamoDB console at https://console.aws.amazon.com/dynamodb/home.\n\nIn the navigation pane on the left side of the console, choose Tables.\n\nChoose the table you want to use.\n\nChoose the Global Tables tab.\n\nThe Global table version displays the version of global tables in use:\n\nTo upgrade from global tables Version 2017.11.29 (Legacy) to Version 2019.11.21 (Current), follow these steps here. The overall upgrade process will work without disrupting live tables, and should finish in less than an hour. For more information, see Updating to Version 2019.11.21 (Current)\n\nNote\n\nIf the Global table version message does not appear in the console, that means there is another table in a different Region with the same name. In this case, the current table can't be made into a global table. Either the current table must be copied to a new table with a unique name, or all other tables with the same name must be removed.\n\nIf you are using Global Tables version 2019.11.21 (Current) of global tables and you also use the Time to Live feature, DynamoDB replicates TTL deletes to all replica tables. The initial TTL delete does not consume write capacity in the region in which the TTL expiry occurs. However, the replicated TTL delete to the replica table(s) consumes a replicated write capacity unit when using provisioned capacity, or replicated write when using on-demand capacity mode, in each of the replica regions and applicable charges will apply.\n\nIn Global Tables version 2019.11.21 (Current), when a TTL delete occurs it is replicated to all replica regions. These replicated writes do not contain type or principalID properties. This can make it difficult to distinguish a TTL delete from a user delete in the replicated tables."
  },
  {
    "title": "Using IAM with global tables - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2gt_IAM.html",
    "html": "Using IAM with global tables\nPDF\nRSS\n\nWhen you create a global table for the first time, Amazon DynamoDB automatically creates an AWS Identity and Access Management (IAM) service-linked role for you. This role is named AWSServiceRoleForDynamoDBReplication, and it allows DynamoDB to manage cross-Region replication for global tables on your behalf. Don't delete this service-linked role. If you do, all of your global tables will no longer function.\n\nFor more information about service-linked roles, see Using service-linked roles in the IAM User Guide.\n\nTo create replica tables in DynamoDB, you must have the following permissions in the source region.\n\ndynamodb:UpdateTable\n\nTo create replica tables in DynamoDB, you must have the following permissions in destination regions.\n\ndynamodb:CreateTable\n\ndynamodb:CreateTableReplica\n\ndynamodb:Scan\n\ndynamodb:Query\n\ndynamodb:UpdateItem\n\ndynamodb:PutItem\n\ndynamodb:GetItem\n\ndynamodb:DeleteItem\n\ndynamodb:BatchWriteItem\n\nTo delete replica tables in DynamoDB, you must have the following permissions in the destination regions.\n\ndynamodb:DeleteTable\n\ndynamodb:DeleteTableReplica\n\nTo update replica auto scaling policy through UpdateTableReplicaAutoScaling, you must have the following permissions in all Regions where table replicas exist\n\napplication-autoscaling:DeleteScalingPolicy\n\napplication-autoscaling:DeleteScheduledAction\n\napplication-autoscaling:DeregisterScalableTarget\n\napplication-autoscaling:DescribeScalableTargets\n\napplication-autoscaling:DescribeScalingActivities\n\napplication-autoscaling:DescribeScalingPolicies\n\napplication-autoscaling:DescribeScheduledActions\n\napplication-autoscaling:PutScalingPolicy\n\napplication-autoscaling:PutScheduledAction\n\napplication-autoscaling:RegisterScalableTarget\n\nTo use UpdateTimeToLive you must have permission for dynamodb:UpdateTimeToLive in all Regions where table replicas exist.\n\nExample: Add replica\n\nThe following IAM policy grants permissions to allow you to add replicas to a global table.\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"dynamodb:CreateTable\",\n                \"dynamodb:DescribeTable\",\n                \"dynamodb:UpdateTable\",\n                \"dynamodb:CreateTableReplica\",\n                \"iam:CreateServiceLinkedRole\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\nExample: Update AutoScaling policy\n\nThe following IAM policy grants permissions to allow you to update replica auto scaling policy.\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"application-autoscaling:RegisterScalableTarget\",\n                \"application-autoscaling:DeleteScheduledAction\",\n                \"application-autoscaling:DescribeScalableTargets\",\n                \"application-autoscaling:DescribeScalingActivities\",\n                \"application-autoscaling:DescribeScalingPolicies\",\n                \"application-autoscaling:PutScalingPolicy\",\n                \"application-autoscaling:DescribeScheduledActions\",\n                \"application-autoscaling:DeleteScalingPolicy\",\n                \"application-autoscaling:PutScheduledAction\",\n                \"application-autoscaling:DeregisterScalableTarget\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\nExample: Allow replica creations for a specific table name and regions\n\nThe following IAM policy grants permissions to allow table and replica creation for Customers table with replicas in three Regions.\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"dynamodb:CreateTable\",\n                \"dynamodb:DescribeTable\",                \n                \"dynamodb:UpdateTable\"\n            ],\n            \n            \"Resource\": [\n                \"arn:aws:dynamodb:us-east-1:123456789012:table/Customers\",\n                \"arn:aws:dynamodb:us-west-1:123456789012:table/Customers\",\n                \"arn:aws:dynamodb:eu-east-2:123456789012:table/Customers\"\n            ]\n        }\n    ]\n}"
  },
  {
    "title": "Monitoring global tables - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_monitoring.html",
    "html": "Monitoring global tables\nPDF\nRSS\n\nYou can use Amazon CloudWatch to monitor the behavior and performance of a global table. Amazon DynamoDB publishes ReplicationLatency metric for each replica in the global table.\n\nReplicationLatency—The elapsed time between when an item is written to a replica table, and when that item appears in another replica in the global table. ReplicationLatency is expressed in milliseconds and is emitted for every source- and destination-Region pair.\n\nDuring normal operation, ReplicationLatency should be fairly constant. An elevated value for ReplicationLatency could indicate that updates from one replica are not propagating to other replica tables in a timely manner. Over time, this could result in other replica tables falling behind because they no longer receive updates consistently. In this case, you should verify that the read capacity units (RCUs) and write capacity units (WCUs) are identical for each of the replica tables. In addition, when choosing WCU settings, follow the recommendations in Global tables version.\n\nReplicationLatency can increase if an AWS Region becomes degraded and you have a replica table in that Region. In this case, you can temporarily redirect your application's read and write activity to a different AWS Region.\n\nFor more information, see DynamoDB Metrics and dimensions."
  },
  {
    "title": "Tutorial: Creating a global table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables.tutorial.html",
    "html": "Tutorial: Creating a global table\nPDF\nRSS\n\nThis section describes how to create a global table using the Amazon DynamoDB console or the AWS Command Line Interface (AWS CLI).\n\nTopics\nCreating a global table (console)\nCreating a global table (AWS CLI)\nCreating a global table (Java)\nCreating a global table (console)\n\nFollow these steps to create a global table using the console. The following example creates a global table with replica tables in United States and Europe.\n\nOpen the DynamoDB console at https://console.aws.amazon.com/dynamodb/home. For this example, choose the US East (Ohio) Region.\n\nIn the navigation pane on the left side of the console, choose Tables.\n\nChoose Create Table.\n\nFor Table name, enter Music.\n\nFor Partition key enter Artist. For Sort key enter SongTitle. (Artist and SongTitle should both be strings.)\n\nTo create the table, choose Create table. This table serves as the first replica table in a new global table. It is the prototype for other replica tables that you add later.\n\nChoose the Global Tables tab, and then choose Create replica.\n\nFrom the Available replication Regions dropdown, choose US West (Oregon).\n\nThe console checks to ensure that a table with the same name doesn't exist in the selected Region. If a table with the same name does exist, you must delete the existing table before you can create a new replica table in that Region.\n\nChoose Create Replica. This starts the table creation process in US West (Oregon);.\n\nThe Global Table tab for the selected table (and for any other replica tables) shows that the table has been replicated in multiple Regions.\n\nNow add another Region so that your global table is replicated and synchronized across the United States and Europe. To do this, repeat step 5, but this time, specify Europe (Frankfurt) instead of US West (Oregon).\n\nYou should still be using the AWS Management Console in the US East (Ohio) Region. Select Items in the left navigation menu, select the Music table, then choose Create Item.\n\nFor Artist, enter item_1.\n\nFor SongTitle, enter Song Value 1.\n\nTo write the item, choose Create item.\n\nAfter a short time, the item is replicated across all three Regions of your global table. To verify this, in the console, on the Region selector in the upper-right corner, choose Europe (Frankfurt). The Music table in Europe (Frankfurt) should contain the new item.\n\nRepeat step 9 and choose US West (Oregon) to verify replication in that region.\n\nCreating a global table (AWS CLI)\n\nFollow these steps to create a global table Music using the AWS CLI. The following example creates a global table, with replica tables in the United States and in Europe.\n\nCreate a new table (Music) in US East (Ohio), with DynamoDB Streams enabled (NEW_AND_OLD_IMAGES).\n\naws dynamodb create-table \\\n    --table-name Music \\\n    --attribute-definitions \\\n        AttributeName=Artist,AttributeType=S \\\n        AttributeName=SongTitle,AttributeType=S \\\n    --key-schema \\\n        AttributeName=Artist,KeyType=HASH \\\n        AttributeName=SongTitle,KeyType=RANGE \\\n    --billing-mode PAY_PER_REQUEST \\\n    --stream-specification StreamEnabled=true,StreamViewType=NEW_AND_OLD_IMAGES \\\n    --region us-east-2\n\nCreate an identical Music table in US East (N. Virginia).\n\naws dynamodb update-table --table-name Music --cli-input-json  \\\n'{\n  \"ReplicaUpdates\":\n  [\n    {\n      \"Create\": {\n        \"RegionName\": \"us-east-1\"\n      }\n    }\n  ]\n}' \\\n--region=us-east-2 \n\nRepeat step 2 to create a table in Europe (Ireland) (eu-west-1).\n\nYou can view the list of replicas created using describe-table.\n\naws dynamodb describe-table --table-name Music --region us-east-2 \n\nTo verify that replication is working, add a new item to the Music table in US East (Ohio).\n\naws dynamodb put-item \\\n    --table-name Music \\\n    --item '{\"Artist\": {\"S\":\"item_1\"},\"SongTitle\": {\"S\":\"Song Value 1\"}}' \\\n    --region us-east-2\n\nWait for a few seconds, and then check to see whether the item has been successfully replicated to US East (N. Virginia) and Europe (Ireland).\n\naws dynamodb get-item \\\n    --table-name Music \\\n    --key '{\"Artist\": {\"S\":\"item_1\"},\"SongTitle\": {\"S\":\"Song Value 1\"}}' \\\n    --region us-east-1\naws dynamodb get-item \\\n    --table-name Music \\\n    --key '{\"Artist\": {\"S\":\"item_1\"},\"SongTitle\": {\"S\":\"Song Value 1\"}}' \\\n    --region eu-west-1\n\nDelete the replica table in Europe (Ireland) Region.\n\naws dynamodb update-table --table-name Music --cli-input-json \\\n'{\n  \"ReplicaUpdates\":\n  [\n    {\n      \"Delete\": {\n        \"RegionName\": \"eu-west-1\"\n      }\n    }\n  ]\n}'\nCreating a global table (Java)\n\nThe following java code sample, create a Music table in Europe (Ireland) region then creates a replica in Asia Pacific (Seoul) region.\n\npackage com.amazonaws.codesamples.gtv2\nimport java.util.logging.Logger;\nimport com.amazonaws.auth.profile.ProfileCredentialsProvider;\nimport com.amazonaws.regions.Regions;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.model.AmazonDynamoDBException;\nimport com.amazonaws.services.dynamodbv2.model.AttributeDefinition;\nimport com.amazonaws.services.dynamodbv2.model.BillingMode;\nimport com.amazonaws.services.dynamodbv2.model.CreateReplicationGroupMemberAction;\nimport com.amazonaws.services.dynamodbv2.model.CreateTableRequest;\nimport com.amazonaws.services.dynamodbv2.model.DescribeTableRequest;\nimport com.amazonaws.services.dynamodbv2.model.GlobalSecondaryIndex;\nimport com.amazonaws.services.dynamodbv2.model.KeySchemaElement;\nimport com.amazonaws.services.dynamodbv2.model.KeyType;\nimport com.amazonaws.services.dynamodbv2.model.Projection;\nimport com.amazonaws.services.dynamodbv2.model.ProjectionType;\nimport com.amazonaws.services.dynamodbv2.model.ProvisionedThroughput;\nimport com.amazonaws.services.dynamodbv2.model.ProvisionedThroughputOverride;\nimport com.amazonaws.services.dynamodbv2.model.ReplicaGlobalSecondaryIndex;\nimport com.amazonaws.services.dynamodbv2.model.ReplicationGroupUpdate;\nimport com.amazonaws.services.dynamodbv2.model.ScalarAttributeType;\nimport com.amazonaws.services.dynamodbv2.model.StreamSpecification;\nimport com.amazonaws.services.dynamodbv2.model.StreamViewType;\nimport com.amazonaws.services.dynamodbv2.model.UpdateTableRequest;\nimport com.amazonaws.waiters.WaiterParameters;\n\n\npublic class App\n{\n    private final static Logger LOGGER = Logger.getLogger(Logger.GLOBAL_LOGGER_NAME);\n\n    public static void main( String[] args )\n    {\n\n        String tableName = \"Music\";\n        String indexName = \"index1\";\n\n        Regions calledRegion = Regions.EU_WEST_1;\n        Regions destRegion = Regions.AP_NORTHEAST_2;\n\n        AmazonDynamoDB ddbClient = AmazonDynamoDBClientBuilder.standard()\n                .withCredentials(new ProfileCredentialsProvider(\"default\"))\n                .withRegion(calledRegion)\n                .build();\n\n\n        LOGGER.info(\"Creating a regional table - TableName: \" + tableName +\", IndexName: \" + indexName + \" .....\");\n        ddbClient.createTable(new CreateTableRequest()\n                .withTableName(tableName)\n                .withAttributeDefinitions(\n                        new AttributeDefinition()\n                                .withAttributeName(\"Artist\").withAttributeType(ScalarAttributeType.S),\n                        new AttributeDefinition()\n                                .withAttributeName(\"SongTitle\").withAttributeType(ScalarAttributeType.S))\n                .withKeySchema(\n                        new KeySchemaElement().withAttributeName(\"Artist\").withKeyType(KeyType.HASH),\n                        new KeySchemaElement().withAttributeName(\"SongTitle\").withKeyType(KeyType.RANGE))\n                .withBillingMode(BillingMode.PAY_PER_REQUEST)\n                .withGlobalSecondaryIndexes(new GlobalSecondaryIndex()\n                        .withIndexName(indexName)\n                        .withKeySchema(new KeySchemaElement()\n                                .withAttributeName(\"SongTitle\")\n                                .withKeyType(KeyType.HASH))\n                        .withProjection(new Projection().withProjectionType(ProjectionType.ALL)))\n                .withStreamSpecification(new StreamSpecification()\n                        .withStreamEnabled(true)\n                        .withStreamViewType(StreamViewType.NEW_AND_OLD_IMAGES)));\n\n        LOGGER.info(\"Waiting for ACTIVE table status .....\");\n        ddbClient.waiters().tableExists().run(new WaiterParameters<>(new DescribeTableRequest(tableName)));\n\n\n        LOGGER.info(\"Testing parameters for adding a new Replica in \" + destRegion + \" .....\");\n\n        CreateReplicationGroupMemberAction createReplicaAction = new CreateReplicationGroupMemberAction()\n                .withRegionName(destRegion.getName())\n                .withGlobalSecondaryIndexes(new ReplicaGlobalSecondaryIndex()\n                        .withIndexName(indexName)\n                        .withProvisionedThroughputOverride(new ProvisionedThroughputOverride()\n                                .withReadCapacityUnits(15L)));\n\n\n        ddbClient.updateTable(new UpdateTableRequest()\n                .withTableName(tableName)\n                .withReplicaUpdates(new ReplicationGroupUpdate()\n                        .withCreate(createReplicaAction.withKMSMasterKeyId(null))));\n\n\n\n\n    }\n}"
  },
  {
    "title": "Best practices and requirements for managing global tables - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_reqs_bestpractices.html",
    "html": "Best practices and requirements for managing global tables\nPDF\nRSS\n\nUsing Amazon DynamoDB global tables, you can replicate your table data across AWS Regions. It is important that the replica tables and secondary indexes in your global table have identical write capacity settings to ensure proper replication of data.\n\nFor future clarity, it can be useful not to put the Region in the name for any table that might someday be turned into a global table.\n\nWarning\n\nThe table name for each global table must be unique within your AWS account.\n\nGlobal tables version\n\nTo determine the version of the global table that you're using, see Determining the global table version you are using.\n\nRequirements for Managing Capacity\n\nA global table must have throughput capacity configured one of two ways:\n\nOn-demand capacity mode, measured in replicated write request units (rWRUs)\n\nProvisioned capacity mode with auto scaling, measured in replicated write capacity units (rWCUs)\n\nUsing provisioned capacity mode with auto scaling or on-demand capacity mode helps ensure a global table has sufficient capacity to perform replicated writes to all regions of the global table.\n\nNote\n\nSwitching from one table capacity mode to the other capacity mode in any Region switches the mode for all replicas.\n\nDeploying global tables\n\nIn AWS CloudFormation, each global table is controlled by a single stack in a single Region. This is regardless of the number of replicas. When you deploy your template, CloudFormation will create/update all replicas as part of a single stack operation. For this reason, you should not deploy the same AWS::DynamoDB::GlobalTable resource in multiple Regions. Doing so is unsupported and will result in errors.\n\nIf you deploy your application template in multiple Regions, you can use conditions to create the resource in only one Region. Alternatively, you can choose to define your AWS::DynamoDB::GlobalTable resources in a stack separate from your application stack and make sure it is only deployed to a single Region. For more information see Global tables in CloudFormation\n\nA DynamoDB table is referred to by AWS::DynamoDB::Table , and a global table is AWS::DynamoDB::GlobalTable. As far as CloudFormation is concerned, this essentially makes them two different resources. As a result, one approach is to create all tables that might ever be global by using the GlobalTable construct. You can then keep them as standalone tables to start, and add them later to Regions if needed.\n\nIf you have a regular table and you want to convert it while using CloudFormation, a recommended method is to:\n\nSet the deletion policy to retain.\n\nRemove the table from the stack.\n\nConvert the table to a Global Table in the console.\n\nImport the global table as a new resource to the stack.\n\nNote\n\nCross-account replication is not supported at this time.\n\nUsing global tables to help handle a potential Region outage\n\nHave or be able to quickly create independent copies of your execution stack in alternative Regions, each accessing its local DynamoDB endpoint.\n\nUse Route53 or AWS Global Accelerator to route to the nearest healthy Region. Alternately, have the client aware of the multiple endpoints it might use.\n\nUse health checks in each Region that will be able to determine reliably if there’s any issue with the stack, including if DynamoDB is degraded. For example, don’t just ping that the DynamoDB endpoint is up. Actually do a call that ensures a full successful database flow.\n\nIf the health check fail, traffic can route to other Regions (by updating the DNS entry with Route53, by having Global Accelerator route differently, or by having the client choose a different endpoint). Global tables have a good RPO (recovery point objective) because the data is continuously syncing and a good RTO (recovery time objective) because both Regions always keep a table ready for both read and write traffic.\n\nFor further information on health checks see Health check types.\n\nNote\n\nDynamoDB is a core service on which other services frequently build their control plane operations, so it’s unlikely you’ll encounter a scenario where DynamoDB has degraded service in a Region while other services are unimpacted.\n\nBacking up global tables\n\nWhen backing up global tables, a backup of tables in one Region should be sufficient and backing up all tables in all Regions shouldn't be required. If the purpose is to be able to recover erroneously deleted or modified data, then PITR in one Region should suffice. Similarly, when preserving a snapshot for historic purposes such as regulatory requirements then backing up in one Region should suffice. The backed up data can be replicated to multiple Regions via AWS Backup.\n\nReplicas and calculating write units\n\nFor planning, you should take the number of writes that one Region will perform and add that to the number of writes happening for each other Region. This is critical as every write that is performed in one Region must also be performed in every replica Region. If you do not have enough capacity to handle all of the writes, capacity exceptions will occur. In addition, inter-regional replication wait times will rise.\n\nFor example, suppose that you expect 5 writes per second to your replica table in Ohio, 10 writes per second to your replica table in N. Virginia, and 5 writes per second to your replica table in Ireland. In this case, you should expect to consume 20 rWCUs or rWRUs in each Region: Ohio, N. Virginia, and Ireland. In other words, you should expect to consume 60 rWCUs total across all three Regions.\n\nFor details about provisioned capacity with auto scaling and DynamoDB, see Managing throughput capacity automatically with DynamoDB auto scaling.\n\nNote\n\nIf a table is running in provisioned capacity mode with auto scaling, the provisioned write capacity is allowed to float within those autoscaling settings for each Region."
  },
  {
    "title": "Global tables: How it works - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_HowItWorks.html",
    "html": "Global tables: How it works\nPDF\nRSS\n\nThe following sections describe the concepts and behaviors of global tables in Amazon DynamoDB.\n\nGlobal table concepts\n\nA global table is a collection of one or more replica tables, all owned by a single AWS account.\n\nA replica table (or replica, for short) is a single DynamoDB table that functions as a part of a global table. Each replica stores the same set of data items. Any given global table can only have one replica table per AWS Region. For more information about how to get started with global tables, see Tutorial: Creating a global table.\n\nWhen you create a DynamoDB global table, it consists of multiple replica tables (one per Region) that DynamoDB treats as a single unit. Every replica has the same table name and the same primary key schema. When an application writes data to a replica table in one Region, DynamoDB propagates the write to the other replica tables in the other AWS Regions automatically.\n\nYou can add replica tables to the global table so that it can be available in additional Regions.\n\nWith Version 2019.11.21 (Current), when you create a Global Secondary Index in one Region it is automatically replicated to the other Region(s) as well as automatically backfilled.\n\nCommon tasks\n\nCommon tasks for global tables work as follows.\n\nYou can delete a global table’s replica table the same as a regular table. This will stop replication to that Region and delete the table copy kept in that Region. You can't sever the replication and have copies of the table exist as independent entities. You can copy the global table to a local table in that Region, and then delete the global replica for that Region.\n\nNote\n\nYou won’t be able to delete a source table until at least 24 hours after it’s used to initiate a new Region. If you try to delete it too soon you will receive an error.\n\nConflicts can arise if applications update the same item in different Regions at about the same time. To help ensure eventual consistency, DynamoDB global tables use a “last writer wins” method to reconcile between concurrent updates. All the replicas will agree on the latest update and converge toward a state in which they all have identical data.\n\nNote\n\nThere are several ways to avoid conflicts, including:\n\nOnly allowing writes to the table in one Region.\n\nRouting user traffic to different Regions according to your write policies, to ensure there are no conflicts.\n\nAvoiding the use of non-idempotent updates such as Bookmark = Bookmark + 1, in favor of static updates such as Bookmark=25.\n\nKeeping in mind that when you route writes or reads to one Region, it’s up to your application to ensure that flow is enforced.\n\nMonitoring global tables\n\nYou can use CloudWatch to observe the metric ReplicationLatency. This tracks the elapsed time between when an item is written to a replica table, and when that item appears in another replica in the global table. It’s expressed in milliseconds and is emitted for every source-Region and destination-Region pair. This metric is kept at the source Region. This is the only CloudWatch metric provided by Global Tables v2.\n\nThe replication latency you will experience depends on the distance between your chosen AWS Regions, as well as other variables. If your original table was in the US West (N. California) (us-west-1) Region, a replica in a closer Region, such as the US West (Oregon) (us-west-2) Region, would have lower replication latency compared to a replica in a Region which is much further away, such as the Africa (Cape Town) (af-south-1) Region.\n\nNote\n\nReplication latency doesn't effect API latency. If you have a client and table in Region A and you add a global tables replica in Region B, the client and table in Region A will have the same latency as before adding Region B. If you call the PutItem API operation in Region B, it'll eventually be available to read in Region A after a delay of approximately the ReplicationLatency statistic available in Amazon CloudWatch. Before it is replicated, you'd receive an empty response and after it's replicated, you'd receive the item; both calls would have approximately the same API latency.\n\nTime To Live (TTL)\n\nYou can use Time To Live (TTL) to specify an attribute name whose value indicates the time of expiration for the item. This value is given as a number in seconds since the start of the Unix epoch. After that time, DynamoDB can delete the item without incurring write costs.\n\nWith global tables you configure TTL in one Region, and that setting is auto replicated to the other Region(s). When an item is deleted via a TTL rule, that work is performed without consuming Write Units on the source table - but the target table(s) will incur Replicated Write Unit costs.\n\nBe aware that if the source and target tables have very low Provisioned write capacities, this may cause throttling, as the TTL deletions require write capacity.\n\nStreams and transactions with global tables\n\nEach global table produces an independent stream based on all its writes, regardless of the origination point for those writes. You can choose to consume this DynamoDB stream in one Region or in all Regions independently.\n\nIf you want processed local writes but not replicated writes, you can add your own Region attribute to each item. Then you can use a Lambda event filter to invoke only the Lambda for writes in the local Region.\n\nTransactional operations provide ACID (Atomicity, Consistency, Isolation, and Durability) guarantees only within the Region where the write is originally made. Transactions aren't supported across Regions in global tables.\n\nFor example, if you have a global table with replicas in the US East (Ohio) and US West (Oregon) Regions and perform a TransactWriteItems operation in the US East (Ohio) Region, you may observe partially completed transactions in US West (Oregon) Region as changes are replicated. Changes will only be replicated to other Regions once they've been committed in the source Region.\n\nNote\n\nGlobal tables “write around” DynamoDB Accelerator by updating DynamoDB directly. As a result DAX will not be aware it's holding stale data. The DAX cache will only be refreshed when the cache’s TTL expires.\n\nTags on global tables don't automatically propagate.\n\nRead and write throughput\n\nGlobal tables manage read and write throughput in the following ways.\n\nThe write capacity must be the same on all table instances across Regions.\n\nWith Version 2019.11.21 (Current), if the table is set to support auto scaling or is in on-demand mode then the write capacity is automatically kept in sync. This means that a write capacity change to one table replicates to the others.\n\nRead capacity can differ between Regions because reads may not be equal. When adding a global replica to a table, the capacity of the source Region is propagated. After creation, you can adjust the read capacity for one replica, and this new setting isn't transferred to the other side.\n\nConsistency and conflict resolution\n\nAny changes made to any item in any replica table are replicated to all the other replicas within the same global table. In a global table, a newly written item is usually propagated to all replica tables within a second.\n\nWith a global table, each replica table stores the same set of data items. DynamoDB does not support partial replication of only some of the items.\n\nAn application can read and write data to any replica table. If your application only uses eventually consistent reads and only issues reads against one AWS Region, it will work without any modification. However, if your application requires strongly consistent reads, it must perform all of its strongly consistent reads and writes in the same Region. DynamoDB doesn't support strongly consistent reads across Regions. Therefore, if you write to one Region and read from another Region, the read response might include stale data that doesn't reflect the results of recently completed writes in the other Region.\n\nIf applications update the same item in different Regions at about the same time, conflicts can arise. To help ensure eventual consistency, DynamoDB global tables use a last writer wins reconciliation between concurrent updates, in which DynamoDB makes a best effort to determine the last writer. This is performed at the item level. With this conflict resolution mechanism, all the replicas will agree on the latest update and converge toward a state in which they all have identical data.\n\nAvailability and durability\n\nIf a single AWS Region becomes isolated or degraded, your application can redirect to a different Region and perform reads and writes against a different replica table. You can apply custom business logic to determine when to redirect requests to other Regions.\n\nIf a Region becomes isolated or degraded, DynamoDB keeps track of any writes that have been performed but haven't been propagated to all of the replica tables. When the Region comes back online, DynamoDB resumes propagating any pending writes from that Region to the replica tables in other Regions. It also resumes propagating writes from other replica tables to the Region that's now back online."
  },
  {
    "title": "Global tables - multi-Region replication for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GlobalTables.html",
    "html": "Global tables - multi-Region replication for DynamoDB\nPDF\nRSS\n\nAmazon DynamoDB global tables are a fully managed, multi-Region, and multi-active database option that delivers fast and localized read and write performance for massively scaled global applications.\n\nGlobal tables provide a fully managed solution for deploying a multi-Region, multi-active database, without having to build and maintain your own replication solution. You can specify the AWS Regions where you want the tables to be available and DynamoDB will propagate ongoing data changes to all of them.\n\nSpecific benefits for using global tables include:\n\nReplicating your DynamoDB tables automatically across your choice of AWS Regions\n\nEliminating the difficult work of replicating data between Regions and resolving update conflicts, so you can focus on your application's business logic.\n\nHelping your applications stay highly available even in the unlikely event of isolation or degradation of an entire Region.\n\nDynamoDB global tables are ideal for massively scaled applications with globally dispersed users. In such an environment, users expect very fast application performance. Global tables provide automatic multi-active replication to AWS Regions worldwide. They enable you to deliver low-latency data access to your users no matter where they are located.\n\nThe following video will give you an introductory look at global tables.\n\nYou can set up global tables in the AWS Management Console or AWS CLI. Global tables use existing DynamoDB APIs, so no application changes are required. You pay only for the resources provisioned with no upfront costs or commitments.\n\nTopics\nReplicate data seamlessly across Regions with global tables\nProvide security and access for your global tables with AWS KMS\nGlobal tables: How it works\nBest practices and requirements for managing global tables\nTutorial: Creating a global table\nMonitoring global tables\nUsing IAM with global tables\nDetermining the global table version you are using\nUpgrading global tables to Current (2019.11.21) version from Legacy(2017.11.29) version\nReplicate data seamlessly across Regions with global tables\n\nSuppose you have a large customer base spread across three geographic areas—the US East Coast, the US West Coast, and Western Europe. These customers can update their profile information using your application. To satisfy this use case, you need to create three identical DynamoDB tables named CustomerProfiles, in three different AWS Regions where the customers are located. These three tables would be entirely separate from each other—changes to the data in one table would not be reflected in the others. Without a managed replication solution, you would have to write code to replicate the data changes. However, doing this would be a time-consuming and labor-intensive effort.\n\nInstead of writing your own code, you could create a global table consisting of your three Region-specific CustomerProfiles tables. DynamoDB would then automatically replicate data changes among those tables so that changes to CustomerProfiles data in one Region would seamlessly propagate to the other Regions. In addition, if one of the AWS Regions were to become temporarily unavailable, your customers could still access the same CustomerProfiles data in the other Regions.\n\nNote\n\nRegion support for global tables Global tables version 2017.11.29 (Legacy) is limited to US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Europe (Ireland), Europe (London), Europe (Frankfurt), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), and Asia Pacific (Seoul).\n\nTransactional operations provide atomicity, consistency, isolation, and durability (ACID) guarantees only within the region where the write is made originally. Transactions are not supported across regions in global tables. For example, if you have a global table with replicas in the US East (Ohio) and US West (Oregon) regions and perform a TransactWriteItems operation in the US East (N. Virginia) Region, you may observe partially completed transactions in US West (Oregon) Region as changes are replicated. Changes will only be replicated to other regions once they have been committed in the source region.\n\nIf you disable an AWS Region, DynamoDB will remove this replica from the replication group, 20 hours after detecting the AWS Region as inaccessible. The replica will not be deleted and replication will stop from and to this region.\n\nYou must wait 24 hours from the time you add a read replica to successfully delete a source table. If you attempt to delete a table during the first 24 hours after adding a read replica, you will receive an error message stating: \"Replica cannot be deleted because it has acted as a source region for new replicas being added in the table in the last 24 hours\".\n\nThere is no performance impact on source regions when adding new replicas.\n\nWhen you change the read and write capacity of a replica, the new write capacity is reflected to other synchronized replicas but the new read capacity is not.\n\nFor information about the AWS Region availability and pricing, see Amazon DynamoDB Pricing.\n\nProvide security and access for your global tables with AWS KMS\n\nYou can perform AWS KMS operations on your global tables by using the AWSServiceRoleForDynamoDBReplication service-linked role against the customer managed key or the AWS managed key used to encrypt the replica.\n\nIf the customer managed key used to encrypt a replica is inaccessible, DynamoDB will remove this replica from the replication group. The replica will not be deleted and replication will stop from and to this region, 20 hours after detecting the KMS key as inaccessible.\n\nIf you want to disable your customer managed key that is used to encrypt a replica table, you must do so only if the key is no longer used to encrypt a replica table. After issuing a command to delete a replica table, you must wait for the delete operation to complete and for the global table to become Active before disabling the key. Not doing so could result in partial data replication from and to the replica table.\n\nIf you want to modify or delete your IAM role policy for the replica table, you must do so when the replica table is in the Active state. If you don’t do this, creating, updating, or deleting the replica table could fail.\n\nGlobal tables are created with deletion protection disabled by default. Even when deletion protection is enabled for a global table, any replicas of that table will start with deletion protection disabled by default.\n\nWhile deletion protection is disabled for a table, it can be accidentally deleted. While deletion protection is enabled for a table, no one can delete it.\n\nChanging the deletion protection setting for one replica table will not update other replicas in the group.\n\nNote\n\nCustomer managed keys are not supported in Global tables version 2017.11.29 (Legacy). If you want to use a customer managed key in a DynamoDB Global Table, you need to upgrade the table to Global Tables version 2019.11.21 (Current) and then enable it."
  },
  {
    "title": "Example: Create, update, delete, and list tables using the AWS SDK for .NET low-level API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LowLevelDotNetTableOperationsExample.html",
    "html": "Example: Create, update, delete, and list tables using the AWS SDK for .NET low-level API\nPDF\nRSS\n\nThe following C# example creates, updates, and deletes a table (ExampleTable). It also lists all the tables in your account and gets the description of a specific table. The table update increases the provisioned throughput values. For step-by-step instructions to test the following example, see .NET code examples.\n\nusing System;\nusing System.Collections.Generic;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.Model;\nusing Amazon.Runtime;\n\nnamespace com.amazonaws.codesamples\n{\n    class LowLevelTableExample\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n        private static string tableName = \"ExampleTable\";\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                CreateExampleTable();\n                ListMyTables();\n                GetTableInformation();\n                UpdateExampleTable();\n\n                DeleteExampleTable();\n\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (AmazonDynamoDBException e) { Console.WriteLine(e.Message); }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n        }\n\n        private static void CreateExampleTable()\n        {\n            Console.WriteLine(\"\\n*** Creating table ***\");\n            var request = new CreateTableRequest\n            {\n                AttributeDefinitions = new List<AttributeDefinition>()\n            {\n                new AttributeDefinition\n                {\n                    AttributeName = \"Id\",\n                    AttributeType = \"N\"\n                },\n                new AttributeDefinition\n                {\n                    AttributeName = \"ReplyDateTime\",\n                    AttributeType = \"N\"\n                }\n            },\n                KeySchema = new List<KeySchemaElement>\n            {\n                new KeySchemaElement\n                {\n                    AttributeName = \"Id\",\n                    KeyType = \"HASH\" //Partition key\n                },\n                new KeySchemaElement\n                {\n                    AttributeName = \"ReplyDateTime\",\n                    KeyType = \"RANGE\" //Sort key\n                }\n            },\n                ProvisionedThroughput = new ProvisionedThroughput\n                {\n                    ReadCapacityUnits = 5,\n                    WriteCapacityUnits = 6\n                },\n                TableName = tableName\n            };\n\n            var response = client.CreateTable(request);\n\n            var tableDescription = response.TableDescription;\n            Console.WriteLine(\"{1}: {0} \\t ReadsPerSec: {2} \\t WritesPerSec: {3}\",\n                      tableDescription.TableStatus,\n                      tableDescription.TableName,\n                      tableDescription.ProvisionedThroughput.ReadCapacityUnits,\n                      tableDescription.ProvisionedThroughput.WriteCapacityUnits);\n\n            string status = tableDescription.TableStatus;\n            Console.WriteLine(tableName + \" - \" + status);\n\n            WaitUntilTableReady(tableName);\n        }\n\n        private static void ListMyTables()\n        {\n            Console.WriteLine(\"\\n*** listing tables ***\");\n            string lastTableNameEvaluated = null;\n            do\n            {\n                var request = new ListTablesRequest\n                {\n                    Limit = 2,\n                    ExclusiveStartTableName = lastTableNameEvaluated\n                };\n\n                var response = client.ListTables(request);\n                foreach (string name in response.TableNames)\n                    Console.WriteLine(name);\n\n                lastTableNameEvaluated = response.LastEvaluatedTableName;\n            } while (lastTableNameEvaluated != null);\n        }\n\n        private static void GetTableInformation()\n        {\n            Console.WriteLine(\"\\n*** Retrieving table information ***\");\n            var request = new DescribeTableRequest\n            {\n                TableName = tableName\n            };\n\n            var response = client.DescribeTable(request);\n\n            TableDescription description = response.Table;\n            Console.WriteLine(\"Name: {0}\", description.TableName);\n            Console.WriteLine(\"# of items: {0}\", description.ItemCount);\n            Console.WriteLine(\"Provision Throughput (reads/sec): {0}\",\n                      description.ProvisionedThroughput.ReadCapacityUnits);\n            Console.WriteLine(\"Provision Throughput (writes/sec): {0}\",\n                      description.ProvisionedThroughput.WriteCapacityUnits);\n        }\n\n        private static void UpdateExampleTable()\n        {\n            Console.WriteLine(\"\\n*** Updating table ***\");\n            var request = new UpdateTableRequest()\n            {\n                TableName = tableName,\n                ProvisionedThroughput = new ProvisionedThroughput()\n                {\n                    ReadCapacityUnits = 6,\n                    WriteCapacityUnits = 7\n                }\n            };\n\n            var response = client.UpdateTable(request);\n\n            WaitUntilTableReady(tableName);\n        }\n\n        private static void DeleteExampleTable()\n        {\n            Console.WriteLine(\"\\n*** Deleting table ***\");\n            var request = new DeleteTableRequest\n            {\n                TableName = tableName\n            };\n\n            var response = client.DeleteTable(request);\n\n            Console.WriteLine(\"Table is being deleted...\");\n        }\n\n        private static void WaitUntilTableReady(string tableName)\n        {\n            string status = null;\n            // Let us wait until table is created. Call DescribeTable.\n            do\n            {\n                System.Threading.Thread.Sleep(5000); // Wait 5 seconds.\n                try\n                {\n                    var res = client.DescribeTable(new DescribeTableRequest\n                    {\n                        TableName = tableName\n                    });\n\n                    Console.WriteLine(\"Table name: {0}, status: {1}\",\n                              res.Table.TableName,\n                              res.Table.TableStatus);\n                    status = res.Table.TableStatus;\n                }\n                catch (ResourceNotFoundException)\n                {\n                    // DescribeTable is eventually consistent. So you might\n                    // get resource not found. So we handle the potential exception.\n                }\n            } while (status != \"ACTIVE\");\n        }\n    }\n}\n"
  },
  {
    "title": "Working with DynamoDB tables in .NET - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LowLevelDotNetWorkingWithTables.html",
    "html": "Working with DynamoDB tables in .NET\nPDF\nRSS\n\nYou can use the AWS SDK for .NET to create, update, and delete tables, list all the tables in your account, or get information about a specific table.\n\nThe following are the common steps for Amazon DynamoDB table operations using the AWS SDK for .NET.\n\nCreate an instance of the AmazonDynamoDBClient class (the client).\n\nProvide the required and optional parameters for the operation by creating the corresponding request objects.\n\nFor example, create a CreateTableRequest object to create a table and UpdateTableRequest object to update an existing table.\n\nRun the appropriate method provided by the client that you created in the preceding step.\n\nNote\n\nThe examples in this section don't work with .NET core because it doesn't support synchronous methods. For more information, see AWS asynchronous APIs for .NET.\n\nTopics\nCreating a table\nUpdating a table\nDeleting a table\nListing tables\nExample: Create, update, delete, and list tables using the AWS SDK for .NET low-level API\nCreating a table\n\nTo create a table, you must provide the table name, its primary key, and the provisioned throughput values.\n\nTo create a table using the AWS SDK for .NET low-level API\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nCreate an instance of the CreateTableRequest class to provide the request information.\n\nYou must provide the table name, primary key, and the provisioned throughput values.\n\nRun the AmazonDynamoDBClient.CreateTable method by providing the request object as a parameter.\n\nThe following C# example demonstrates the preceding steps. The sample creates a table (ProductCatalog) that uses Id as the primary key and set of provisioned throughput values. Depending on your application requirements, you can update the provisioned throughput values by using the UpdateTable API.\n\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"ProductCatalog\";\n\nvar request = new CreateTableRequest\n{\n  TableName = tableName,\n  AttributeDefinitions = new List<AttributeDefinition>()\n  {\n    new AttributeDefinition\n    {\n      AttributeName = \"Id\",\n      AttributeType = \"N\"\n    }\n  },\n  KeySchema = new List<KeySchemaElement>()\n  {\n    new KeySchemaElement\n    {\n      AttributeName = \"Id\",\n      KeyType = \"HASH\"  //Partition key\n    }\n  },\n  ProvisionedThroughput = new ProvisionedThroughput\n  {\n    ReadCapacityUnits = 10,\n    WriteCapacityUnits = 5\n  }\n};\n\nvar response = client.CreateTable(request);\n\nYou must wait until DynamoDB creates the table and sets its status to ACTIVE. The CreateTable response includes the TableDescription property that provides the necessary table information.\n\nExample\nvar result = response.CreateTableResult;\n var tableDescription = result.TableDescription;\n Console.WriteLine(\"{1}: {0} \\t ReadCapacityUnits: {2} \\t WriteCapacityUnits: {3}\",\n                 tableDescription.TableStatus,\n                 tableDescription.TableName,\n                 tableDescription.ProvisionedThroughput.ReadCapacityUnits,\n                 tableDescription.ProvisionedThroughput.WriteCapacityUnits);\n\n string status = tableDescription.TableStatus;\n Console.WriteLine(tableName + \" - \" + status);\n\nYou can also call the DescribeTable method of the client to get table information at any time.\n\nExample\nvar res = client.DescribeTable(new DescribeTableRequest{TableName = \"ProductCatalog\"});\nUpdating a table\n\nYou can update only the provisioned throughput values of an existing table. Depending on your application requirements, you might need to update these values.\n\nNote\n\nYou can increase throughput capacity as often as needed, and decrease it within certain constraints. For more information about throughput increases and decreases per day, see Service, account, and table quotas in Amazon DynamoDB.\n\nTo update a table using the AWS SDK for .NET low-level API\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nCreate an instance of the UpdateTableRequest class to provide the request information.\n\nYou must provide the table name and the new provisioned throughput values.\n\nRun the AmazonDynamoDBClient.UpdateTable method by providing the request object as a parameter.\n\nThe following C# example demonstrates the preceding steps.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"ExampleTable\";\n\nvar request = new UpdateTableRequest()\n {\n   TableName = tableName,\n   ProvisionedThroughput = new ProvisionedThroughput()\n   {\n     // Provide new values.\n     ReadCapacityUnits = 20,\n     WriteCapacityUnits = 10\n   }\n };\nvar response = client.UpdateTable(request);\nDeleting a table\n\nFollow these steps to delete a table using the .NET low-level API.\n\nTo delete a table using the AWS SDK for .NET low-level API\n\nCreate an instance of the AmazonDynamoDBClient class.\n\nCreate an instance of the DeleteTableRequest class, and provide the table name that you want to delete.\n\nRun the AmazonDynamoDBClient.DeleteTable method by providing the request object as a parameter.\n\nThe following C# code example demonstrates the preceding steps.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\nstring tableName = \"ExampleTable\";\n\nvar request = new DeleteTableRequest{ TableName = tableName };\nvar response = client.DeleteTable(request);\nListing tables\n\nTo list tables in your account using the AWS SDK for .NET low-level API, create an instance of the AmazonDynamoDBClient and run the ListTables method.\n\nThe ListTables operation requires no parameters. However, you can specify optional parameters. For example, you can set the Limit parameter if you want to use paging to limit the number of table names per page. This requires you to create a ListTablesRequest object and provide optional parameters as shown in the following C# example. Along with the page size, the request sets the ExclusiveStartTableName parameter. Initially, ExclusiveStartTableName is null. However, after fetching the first page of results, to retrieve the next page of results, you must set this parameter value to the LastEvaluatedTableName property of the current result.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n// Initial value for the first page of table names.\nstring lastEvaluatedTableName = null;\ndo\n{\n   // Create a request object to specify optional parameters.\n   var request = new ListTablesRequest\n   {\n     Limit = 10, // Page size.\n     ExclusiveStartTableName = lastEvaluatedTableName\n   };\n\n   var response = client.ListTables(request);\n   ListTablesResult result = response.ListTablesResult;\n   foreach (string name in result.TableNames)\n     Console.WriteLine(name);\n\n   lastEvaluatedTableName = result.LastEvaluatedTableName;\n\n} while (lastEvaluatedTableName != null);"
  },
  {
    "title": "Example: Create, update, delete, and list tables using the AWS SDK for Java document API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/JavaDocumentAPITablesExample.html",
    "html": "Example: Create, update, delete, and list tables using the AWS SDK for Java document API\nPDF\nRSS\n\nThe following code example uses the AWS SDK for Java Document API to create, update, and delete an Amazon DynamoDB table (ExampleTable). As part of the table update, it increases the provisioned throughput values. The example also lists all the tables in your account and gets the description of a specific table. For step-by-step instructions to run the following example, see Java code examples.\n\n\npackage com.amazonaws.codesamples.document;\n\nimport java.util.ArrayList;\nimport java.util.Iterator;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.document.DynamoDB;\nimport com.amazonaws.services.dynamodbv2.document.Table;\nimport com.amazonaws.services.dynamodbv2.document.TableCollection;\nimport com.amazonaws.services.dynamodbv2.model.AttributeDefinition;\nimport com.amazonaws.services.dynamodbv2.model.CreateTableRequest;\nimport com.amazonaws.services.dynamodbv2.model.KeySchemaElement;\nimport com.amazonaws.services.dynamodbv2.model.KeyType;\nimport com.amazonaws.services.dynamodbv2.model.ListTablesResult;\nimport com.amazonaws.services.dynamodbv2.model.ProvisionedThroughput;\nimport com.amazonaws.services.dynamodbv2.model.TableDescription;\n\npublic class DocumentAPITableExample {\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n    static DynamoDB dynamoDB = new DynamoDB(client);\n\n    static String tableName = \"ExampleTable\";\n\n    public static void main(String[] args) throws Exception {\n\n        createExampleTable();\n        listMyTables();\n        getTableInformation();\n        updateExampleTable();\n\n        deleteExampleTable();\n    }\n\n    static void createExampleTable() {\n\n        try {\n\n            List<AttributeDefinition> attributeDefinitions = new ArrayList<AttributeDefinition>();\n            attributeDefinitions.add(new AttributeDefinition().withAttributeName(\"Id\").withAttributeType(\"N\"));\n\n            List<KeySchemaElement> keySchema = new ArrayList<KeySchemaElement>();\n            keySchema.add(new KeySchemaElement().withAttributeName(\"Id\").withKeyType(KeyType.HASH)); // Partition\n                                                                                                     // key\n\n            CreateTableRequest request = new CreateTableRequest().withTableName(tableName).withKeySchema(keySchema)\n                    .withAttributeDefinitions(attributeDefinitions).withProvisionedThroughput(\n                            new ProvisionedThroughput().withReadCapacityUnits(5L).withWriteCapacityUnits(6L));\n\n            System.out.println(\"Issuing CreateTable request for \" + tableName);\n            Table table = dynamoDB.createTable(request);\n\n            System.out.println(\"Waiting for \" + tableName + \" to be created...this may take a while...\");\n            table.waitForActive();\n\n            getTableInformation();\n\n        } catch (Exception e) {\n            System.err.println(\"CreateTable request failed for \" + tableName);\n            System.err.println(e.getMessage());\n        }\n\n    }\n\n    static void listMyTables() {\n\n        TableCollection<ListTablesResult> tables = dynamoDB.listTables();\n        Iterator<Table> iterator = tables.iterator();\n\n        System.out.println(\"Listing table names\");\n\n        while (iterator.hasNext()) {\n            Table table = iterator.next();\n            System.out.println(table.getTableName());\n        }\n    }\n\n    static void getTableInformation() {\n\n        System.out.println(\"Describing \" + tableName);\n\n        TableDescription tableDescription = dynamoDB.getTable(tableName).describe();\n        System.out.format(\n                \"Name: %s:\\n\" + \"Status: %s \\n\" + \"Provisioned Throughput (read capacity units/sec): %d \\n\"\n                        + \"Provisioned Throughput (write capacity units/sec): %d \\n\",\n                tableDescription.getTableName(), tableDescription.getTableStatus(),\n                tableDescription.getProvisionedThroughput().getReadCapacityUnits(),\n                tableDescription.getProvisionedThroughput().getWriteCapacityUnits());\n    }\n\n    static void updateExampleTable() {\n\n        Table table = dynamoDB.getTable(tableName);\n        System.out.println(\"Modifying provisioned throughput for \" + tableName);\n\n        try {\n            table.updateTable(new ProvisionedThroughput().withReadCapacityUnits(6L).withWriteCapacityUnits(7L));\n\n            table.waitForActive();\n        } catch (Exception e) {\n            System.err.println(\"UpdateTable request failed for \" + tableName);\n            System.err.println(e.getMessage());\n        }\n    }\n\n    static void deleteExampleTable() {\n\n        Table table = dynamoDB.getTable(tableName);\n        try {\n            System.out.println(\"Issuing DeleteTable request for \" + tableName);\n            table.delete();\n\n            System.out.println(\"Waiting for \" + tableName + \" to be deleted...this may take a while...\");\n\n            table.waitForDelete();\n        } catch (Exception e) {\n            System.err.println(\"DeleteTable request failed for \" + tableName);\n            System.err.println(e.getMessage());\n        }\n    }\n\n}\n\n"
  },
  {
    "title": "Working with DynamoDB tables in Java - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/JavaDocumentAPIWorkingWithTables.html",
    "html": "Working with DynamoDB tables in Java\nPDF\nRSS\n\nYou can use the AWS SDK for Java to create, update, and delete Amazon DynamoDB tables, list all the tables in your account, or get information about a specific table.\n\nTopics\nCreating a table\nUpdating a table\nDeleting a table\nListing tables\nExample: Create, update, delete, and list tables using the AWS SDK for Java document API\nCreating a table\n\nTo create a table, you must provide the table name, its primary key, and the provisioned throughput values. The following code snippet creates an example table that uses a numeric type attribute ID as its primary key.\n\nTo create a table using the AWS SDK for Java API\n\nCreate an instance of the DynamoDB class.\n\nInstantiate a CreateTableRequest to provide the request information.\n\nYou must provide the table name, attribute definitions, key schema, and provisioned throughput values.\n\nRun the createTable method by providing the request object as a parameter.\n\nThe following code example demonstrates the preceding steps.\n\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\nList<AttributeDefinition> attributeDefinitions= new ArrayList<AttributeDefinition>();\nattributeDefinitions.add(new AttributeDefinition().withAttributeName(\"Id\").withAttributeType(\"N\"));\n\nList<KeySchemaElement> keySchema = new ArrayList<KeySchemaElement>();\nkeySchema.add(new KeySchemaElement().withAttributeName(\"Id\").withKeyType(KeyType.HASH));\n\nCreateTableRequest request = new CreateTableRequest()\n        .withTableName(tableName)\n        .withKeySchema(keySchema)\n        .withAttributeDefinitions(attributeDefinitions)\n        .withProvisionedThroughput(new ProvisionedThroughput()\n            .withReadCapacityUnits(5L)\n            .withWriteCapacityUnits(6L));\n\nTable table = dynamoDB.createTable(request);\n\ntable.waitForActive();\n\nThe table is not ready for use until DynamoDB creates it and sets its status to ACTIVE. The createTable request returns a Table object that you can use to obtain more information about the table.\n\nExample\nTableDescription tableDescription =\n    dynamoDB.getTable(tableName).describe();\n\nSystem.out.printf(\"%s: %s \\t ReadCapacityUnits: %d \\t WriteCapacityUnits: %d\",\n    tableDescription.getTableStatus(),\n    tableDescription.getTableName(),\n    tableDescription.getProvisionedThroughput().getReadCapacityUnits(),\n    tableDescription.getProvisionedThroughput().getWriteCapacityUnits());\n\nYou can call the describe method of the client to get table information at any time.\n\nExample\nTableDescription tableDescription = dynamoDB.getTable(tableName).describe();\nUpdating a table\n\nYou can update only the provisioned throughput values of an existing table. Depending on your application requirements, you might need to update these values.\n\nNote\n\nFor more information about throughput increases and decreases per day, see Service, account, and table quotas in Amazon DynamoDB.\n\nTo update a table using the AWS SDK for Java API\n\nCreate an instance of the Table class.\n\nCreate an instance of the ProvisionedThroughput class to provide the new throughput values.\n\nRun the updateTable method by providing the ProvisionedThroughput instance as a parameter.\n\nThe following code example demonstrates the preceding steps.\n\nExample\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\nTable table = dynamoDB.getTable(\"ProductCatalog\");\n\nProvisionedThroughput provisionedThroughput = new ProvisionedThroughput()\n    .withReadCapacityUnits(15L)\n    .withWriteCapacityUnits(12L);\n\ntable.updateTable(provisionedThroughput);\n\ntable.waitForActive();\nDeleting a table\nTo delete a table using the AWS SDK for Java API\n\nCreate an instance of the Table class.\n\nCreate an instance of the DeleteTableRequest class and provide the table name that you want to delete.\n\nRun the deleteTable method by providing the Table instance as a parameter.\n\nThe following code example demonstrates the preceding steps.\n\nExample\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\nTable table = dynamoDB.getTable(\"ProductCatalog\");\n\ntable.delete();\n\ntable.waitForDelete();\nListing tables\n\nTo list tables in your account, create an instance of DynamoDB and run the listTables method. The ListTables operation requires no parameters.\n\nExample\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\nDynamoDB dynamoDB = new DynamoDB(client);\n\nTableCollection<ListTablesResult> tables = dynamoDB.listTables();\nIterator<Table> iterator = tables.iterator();\n\nwhile (iterator.hasNext()) {\n    Table table = iterator.next();\n    System.out.println(table.getTableName());\n}"
  },
  {
    "title": "Cost allocation reports - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CostAllocationReports.html",
    "html": "Cost allocation reports\nPDF\nRSS\n\nAWS uses tags to organize resource costs on your cost allocation report. AWS provides two types of cost allocation tags:\n\nAn AWS-generated tag. AWS defines, creates, and applies this tag for you.\n\nUser-defined tags. You define, create, and apply these tags.\n\nYou must activate both types of tags separately before they can appear in Cost Explorer or on a cost allocation report.\n\nTo activate AWS-generated tags:\n\nSign in to the AWS Management Console and open the Billing and Cost Management console at https://console.aws.amazon.com/billing/home#/.\n\nIn the navigation pane, choose Cost Allocation Tags.\n\nUnder AWS-Generated Cost Allocation Tags, choose Activate.\n\nTo activate user-defined tags:\n\nSign in to the AWS Management Console and open the Billing and Cost Management console at https://console.aws.amazon.com/billing/home#/.\n\nIn the navigation pane, choose Cost Allocation Tags.\n\nUnder User-Defined Cost Allocation Tags, choose Activate.\n\nAfter you create and activate tags, AWS generates a cost allocation report with your usage and costs grouped by your active tags. The cost allocation report includes all of your AWS costs for each billing period. The report includes both tagged and untagged resources, so that you can clearly organize the charges for resources.\n\nNote\n\nCurrently, any data transferred out from DynamoDB won't be broken down by tags on cost allocation reports.\n\nFor more information, see Using cost allocation tags."
  },
  {
    "title": "Tagging resources in DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Tagging.Operations.html",
    "html": "Tagging resources in DynamoDB\nPDF\nRSS\n\nYou can use the Amazon DynamoDB console or the AWS Command Line Interface (AWS CLI) to add, list, edit, or delete tags. You can then activate these user-defined tags so that they appear on the AWS Billing and Cost Management console for cost allocation tracking. For more information, see Cost allocation reports.\n\nFor bulk editing, you can also use Tag Editor on the AWS Management Console. For more information, see Working with Tag Editor.\n\nTo use the DynamoDB API instead, see the following operations in the Amazon DynamoDB API Reference:\n\nTagResource\n\nUntagResource\n\nListTagsOfResource\n\nTopics\nSetting permissions to filter by tags\nAdding tags to new or existing tables (AWS Management Console)\nAdding tags to new or existing tables (AWS CLI)\nSetting permissions to filter by tags\n\nTo use tags to filter your table list in the DynamoDB console, make sure your user's policies include access to the following operations:\n\ntag:GetTagKeys\n\ntag:GetTagValues\n\nYou can access these operations by attaching a new IAM policy to your user by following the steps below.\n\nGo to the IAM console with an Admin user.\n\nSelect \"Policies\" in the left navigation menu.\n\nSelect \"Create policy.\"\n\nPaste the following policy into the JSON editor.\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"tag:GetTagKeys\",\n                \"tag:GetTagValues\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n\nComplete the wizard and assign a name to the policy (for example, TagKeysAndValuesReadAccess).\n\nSelect \"Users\" in the left navigation menu.\n\nFrom the list, select the user you normally use to access the DynamoDB console.\n\nSelect \"Add permissions.\"\n\nSelect \"Attach existing policies directly.\"\n\nFrom the list, select the policy you created previously.\n\nComplete the wizard.\n\nAdding tags to new or existing tables (AWS Management Console)\n\nYou can use the DynamoDB console to add tags to new tables when you create them, or to add, edit, or delete tags for existing tables.\n\nTo tag resources on creation (console)\n\nSign in to the AWS Management Console and open the DynamoDB console at https://console.aws.amazon.com/dynamodb/.\n\nIn the navigation pane, choose Tables, and then choose Create table.\n\nOn the Create DynamoDB table page, provide a name and primary key. In the Tags section, choose Add new tag and enter the tags that you want to use.\n\nFor information about tag structure, see Tagging restrictions in DynamoDB.\n\nFor more information about creating tables, see Basic operations on DynamoDB tables.\n\nTo tag existing resources (console)\n\nOpen the DynamoDB console at https://console.aws.amazon.com/dynamodb/.\n\nIn the navigation pane, choose Tables.\n\nChoose a table in the list, and then choose the Additional settings tab. You can add, edit, or delete your tags in the Tags section at the bottom of the page.\n\nAdding tags to new or existing tables (AWS CLI)\n\nThe following examples show how to use the AWS CLI to specify tags when you create tables and indexes, and to tag existing resources.\n\nTo tag resources on creation (AWS CLI)\n\nThe following example creates a new Movies table and adds the Owner tag with a value of blueTeam:\n\naws dynamodb create-table \\\n    --table-name Movies \\\n    --attribute-definitions AttributeName=Title,AttributeType=S \\\n    --key-schema AttributeName=Title,KeyType=HASH \\\n    --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \\\n    --tags Key=Owner,Value=blueTeam \nTo tag existing resources (AWS CLI)\n\nThe following example adds the Owner tag with a value of blueTeam for the Movies table:\n\naws dynamodb tag-resource \\\n    --resource-arn arn:aws:dynamodb:us-east-1:123456789012:table/Movies \\\n    --tags Key=Owner,Value=blueTeam \nTo list all tags for a table (AWS CLI)\n\nThe following example lists all the tags that are associated with the Movies table:\n\naws dynamodb list-tags-of-resource \\\n    --resource-arn arn:aws:dynamodb:us-east-1:123456789012:table/Movies "
  },
  {
    "title": "Tagging restrictions in DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TaggingRestrictions.html",
    "html": "Tagging restrictions in DynamoDB\nPDF\nRSS\n\nEach tag consists of a key and a value, both of which you define. The following restrictions apply:\n\nEach DynamoDB table can have only one tag with the same key. If you try to add an existing tag (same key), the existing tag value is updated to the new value.\n\nTag keys and values are case sensitive.\n\nThe maximum key length is 128 Unicode characters.\n\nThe maximum value length is 256 Unicode characters.\n\nThe allowed characters are letters, white space, and numbers, plus the following special characters: + - = . _ : /\n\nThe maximum number of tags per resource is 50.\n\nAWS-assigned tag names and values are automatically assigned the aws: prefix, which you can't assign. AWS-assigned tag names don't count toward the tag limit of 50. User-assigned tag names have the prefix user: in the cost allocation report.\n\nYou can't backdate the application of a tag."
  },
  {
    "title": "Adding tags and labels to resources - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Tagging.html",
    "html": "Adding tags and labels to resources\nPDF\nRSS\n\nYou can label Amazon DynamoDB resources using tags. Tags let you categorize your resources in different ways, for example, by purpose, owner, environment, or other criteria. Tags can help you do the following:\n\nQuickly identify a resource based on the tags that you assigned to it.\n\nSee AWS bills broken down by tags.\n\nNote\n\nAny local secondary indexes (LSI) and global secondary indexes (GSI) related to tagged tables are labeled with the same tags automatically. Currently, DynamoDB Streams usage cannot be tagged.\n\nTagging is supported by AWS services like Amazon EC2, Amazon S3, DynamoDB, and more. Efficient tagging can provide cost insights by enabling you to create reports across services that carry a specific tag.\n\nTo get started with tagging, do the following:\n\nUnderstand Tagging restrictions in DynamoDB.\n\nCreate tags by using Tagging resources in DynamoDB.\n\nUse Cost allocation reports to track your AWS costs per active tag.\n\nFinally, it is good practice to follow optimal tagging strategies. For information, see AWS tagging strategies."
  },
  {
    "title": "DynamoDB Item sizes and formats - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CapacityUnitCalculations.html",
    "html": "DynamoDB Item sizes and formats\nPDF\nRSS\n\nDynamoDB tables are schemaless, except for the primary key, so the items in a table can all have different attributes, sizes, and data types.\n\nThe total size of an item is the sum of the lengths of its attribute names and values, plus any applicable overhead as described below. You can use the following guidelines to estimate attribute sizes:\n\nStrings are Unicode with UTF-8 binary encoding. The size of a string is (number of UTF-8-encoded bytes of attribute name) + (number of UTF-8-encoded bytes).\n\nNumbers are variable length, with up to 38 significant digits. Leading and trailing zeroes are trimmed. The size of a number is approximately (number of UTF-8-encoded bytes of attribute name) + (1 byte per two significant digits) + (1 byte).\n\nA binary value must be encoded in base64 format before it can be sent to DynamoDB, but the value's raw byte length is used for calculating size. The size of a binary attribute is (number of UTF-8-encoded bytes of attribute name) + (number of raw bytes).\n\nThe size of a null attribute or a Boolean attribute is (number of UTF-8-encoded bytes of attribute name) + (1 byte).\n\nAn attribute of type List or Map requires 3 bytes of overhead, regardless of its contents. The size of a List or Map is (number of UTF-8-encoded bytes of attribute name) + sum (size of nested elements) + (3 bytes) . The size of an empty List or Map is (number of UTF-8-encoded bytes of attribute name) + (3 bytes).\n\nEach List or Map element also requires 1 byte of overhead.\n\nNote\n\nWe recommend that you choose shorter attribute names rather than long ones. This helps you reduce the amount of storage required, but also can lower the amount of RCU/WCUs you use.\n\nFor storage billing purposes, each item includes a per-item storage overhead that depends on the features you have enabled.\n\nAll items in DynamoDB require 100 bytes of storage overhead for indexing.\n\nSome DynamoDB features (global tables, transactions, change data capture for Kinesis Data Streams with DynamoDB) require additional storage overhead to account for system-created attributes resulting from enabling those features. For example, global tables requires an additional 48 bytes of storage overhead."
  },
  {
    "title": "Considerations when choosing a table class - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.tableclasses.html",
    "html": "Considerations when choosing a table class\nPDF\nRSS\n\nDynamoDB offers two table classes designed to help you optimize for cost. The DynamoDB Standard table class is the default, and is recommended for the vast majority of workloads. The DynamoDB Standard-Infrequent Access (DynamoDB Standard-IA) table class is optimized for tables where storage is the dominant cost. For example, tables that store infrequently accessed data, such as application logs, old social media posts, e-commerce order history, and past gaming achievements, are good candidates for the Standard-IA table class.\n\nEvery DynamoDB table is associated with a table class. All secondary indexes associated with the table use the same table class. You can set your table class when creating your table (DynamoDB Standard by default) and update the table class of an existing table using the AWS Management Console, AWS CLI, or AWS SDK. DynamoDB also supports managing your table class using AWS CloudFormation for single-region tables (tables that are not global tables). Each table class offers different pricing for data storage as well as read and write requests. When choosing a table class for your table, keep the following in mind:\n\nThe DynamoDB Standard table class offers lower throughput costs than DynamoDB Standard-IA and is the most cost-effective option for tables where throughput is the dominant cost.\n\nThe DynamoDB Standard-IA table class offers lower storage costs than DynamoDB Standard, and is the most cost-effective option for tables where storage is the dominant cost. When storage exceeds 50% of the throughput (reads and writes) cost of a table using the DynamoDB Standard table class, the DynamoDB Standard-IA table class can help you reduce your total table cost.\n\nDynamoDB Standard-IA tables offer the same performance, durability, and availability as DynamoDB Standard tables.\n\nSwitching between the DynamoDB Standard and DynamoDB Standard-IA table classes does not require changing your application code. You use the same DynamoDB APIs and service endpoints regardless of the table class your tables use.\n\nDynamoDB Standard-IA tables are compatible with all existing DynamoDB features such as auto scaling, on-demand mode, time-to-live (TTL), on-demand backups, point-in-time recovery (PITR), and global secondary indexes.\n\nThe most cost-effective table class for your table depends on your table's expected storage and throughput usage patterns. You can look at your table's historical storage and throughput cost and usage with AWS Cost and Usage Reports and the AWS Cost Explorer. Use this historical data to determine the most cost-effective table class for your table. To learn more about using AWS Cost and Usage Reports and the AWS Cost Explorer, see the AWS Billing and Cost Management Documentation. See Amazon DynamoDB Pricing for details about table class pricing.\n\nNote\n\nA table class update is a background process. You can still access your table normally during a table class update. The time to update your table class depends on your table traffic, storage size, and other related variables. No more than two table class updates on your table are allowed in a 30-day trailing period."
  },
  {
    "title": "Basic operations on DynamoDB tables - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.Basics.html",
    "html": "Basic operations on DynamoDB tables\nPDF\nRSS\n\nSimilar to other database systems, Amazon DynamoDB stores data in tables. You can manage your tables using a few basic operations.\n\nTopics\nCreating a table\nDescribing a table\nUpdating a table\nDeleting a table\nUsing deletion protection\nListing table names\nDescribing provisioned throughput quotas\nCreating a table\n\nUse the CreateTable operation to create a table in Amazon DynamoDB. To create the table, you must provide the following information:\n\nTable name. The name must conform to the DynamoDB naming rules, and must be unique for the current AWS account and Region. For example, you could create a People table in US East (N. Virginia) and another People table in Europe (Ireland). However, these two tables would be entirely different from each other. For more information, see Supported data types and naming rules in Amazon DynamoDB.\n\nPrimary key. The primary key can consist of one attribute (partition key) or two attributes (partition key and sort key). You need to provide the attribute names, data types, and the role of each attribute: HASH (for a partition key) and RANGE (for a sort key). For more information, see Primary key.\n\nThroughput settings (for provisioned tables). If using provisioned mode, you must specify the initial read and write throughput settings for the table. You can modify these settings later, or enable DynamoDB auto scaling to manage the settings for you. For more information, see Provisioned capacity mode and Managing throughput capacity automatically with DynamoDB auto scaling.\n\nExample 1: Create a provisioned table\n\nThe following AWS CLI example shows how to create a table (Music). The primary key consists of Artist (partition key) and SongTitle (sort key), each of which has a data type of String. The maximum throughput for this table is 10 read capacity units and 5 write capacity units.\n\naws dynamodb create-table \\\n    --table-name Music \\\n    --attribute-definitions \\\n        AttributeName=Artist,AttributeType=S \\\n        AttributeName=SongTitle,AttributeType=S \\\n    --key-schema \\\n        AttributeName=Artist,KeyType=HASH \\\n        AttributeName=SongTitle,KeyType=RANGE \\\n    --provisioned-throughput \\\n        ReadCapacityUnits=10,WriteCapacityUnits=5\n\nThe CreateTable operation returns metadata for the table, as shown following.\n\n{\n    \"TableDescription\": {\n        \"TableArn\": \"arn:aws:dynamodb:us-east-1:123456789012:table/Music\",\n        \"AttributeDefinitions\": [\n            {\n                \"AttributeName\": \"Artist\",\n                \"AttributeType\": \"S\"\n            },\n            {\n                \"AttributeName\": \"SongTitle\",\n                \"AttributeType\": \"S\"\n            }\n        ],\n        \"ProvisionedThroughput\": {\n            \"NumberOfDecreasesToday\": 0,\n            \"WriteCapacityUnits\": 5,\n            \"ReadCapacityUnits\": 10\n        },\n        \"TableSizeBytes\": 0,\n        \"TableName\": \"Music\",\n        \"TableStatus\": \"CREATING\",\n        \"TableId\": \"12345678-0123-4567-a123-abcdefghijkl\",\n        \"KeySchema\": [\n            {\n                \"KeyType\": \"HASH\",\n                \"AttributeName\": \"Artist\"\n            },\n            {\n                \"KeyType\": \"RANGE\",\n                \"AttributeName\": \"SongTitle\"\n            }\n        ],\n        \"ItemCount\": 0,\n        \"CreationDateTime\": 1542397215.37\n    }\n}\n\nThe TableStatus element indicates the current state of the table (CREATING). It might take a while to create the table, depending on the values you specify for ReadCapacityUnits and WriteCapacityUnits. Larger values for these require DynamoDB to allocate more resources for the table.\n\nExample 2: Create an on-demand table\n\nTo create the same table Music using on-demand mode.\n\naws dynamodb create-table \\\n    --table-name Music \\\n    --attribute-definitions \\\n        AttributeName=Artist,AttributeType=S \\\n        AttributeName=SongTitle,AttributeType=S \\\n    --key-schema \\\n        AttributeName=Artist,KeyType=HASH \\\n        AttributeName=SongTitle,KeyType=RANGE \\\n    --billing-mode=PAY_PER_REQUEST\n\nThe CreateTable operation returns metadata for the table, as shown following.\n\n{\n    \"TableDescription\": {\n        \"TableArn\": \"arn:aws:dynamodb:us-east-1:123456789012:table/Music\",\n        \"AttributeDefinitions\": [\n            {\n                \"AttributeName\": \"Artist\",\n                \"AttributeType\": \"S\"\n            },\n            {\n                \"AttributeName\": \"SongTitle\",\n                \"AttributeType\": \"S\"\n            }\n        ],\n        \"ProvisionedThroughput\": {\n            \"NumberOfDecreasesToday\": 0,\n            \"WriteCapacityUnits\": 0,\n            \"ReadCapacityUnits\": 0\n        },\n        \"TableSizeBytes\": 0,\n        \"TableName\": \"Music\",\n        \"BillingModeSummary\": {\n            \"BillingMode\": \"PAY_PER_REQUEST\"\n        },\n        \"TableStatus\": \"CREATING\",\n        \"TableId\": \"12345678-0123-4567-a123-abcdefghijkl\",\n        \"KeySchema\": [\n            {\n                \"KeyType\": \"HASH\",\n                \"AttributeName\": \"Artist\"\n            },\n            {\n                \"KeyType\": \"RANGE\",\n                \"AttributeName\": \"SongTitle\"\n            }\n        ],\n        \"ItemCount\": 0,\n        \"CreationDateTime\": 1542397468.348\n    }\n}\nImportant\n\nWhen calling DescribeTable on an on-demand table, read capacity units and write capacity units are set to 0.\n\nExample 3: Create a table using the DynamoDB standard-infrequent access table class\n\nTo create the same Music table using the DynamoDB Standard-Infrequent Access table class.\n\naws dynamodb create-table \\\n    --table-name Music \\\n    --attribute-definitions \\\n        AttributeName=Artist,AttributeType=S \\\n        AttributeName=SongTitle,AttributeType=S \\\n    --key-schema \\\n        AttributeName=Artist,KeyType=HASH \\\n        AttributeName=SongTitle,KeyType=RANGE \\\n    --provisioned-throughput \\\n        ReadCapacityUnits=10,WriteCapacityUnits=5 \\\n    --table-class STANDARD_INFREQUENT_ACCESS\n\nThe CreateTable operation returns metadata for the table, as shown following.\n\n{\n    \"TableDescription\": {\n        \"TableArn\": \"arn:aws:dynamodb:us-east-1:123456789012:table/Music\",\n        \"AttributeDefinitions\": [\n            {\n                \"AttributeName\": \"Artist\",\n                \"AttributeType\": \"S\"\n            },\n            {\n                \"AttributeName\": \"SongTitle\",\n                \"AttributeType\": \"S\"\n            }\n        ],\n        \"ProvisionedThroughput\": {\n            \"NumberOfDecreasesToday\": 0,\n            \"WriteCapacityUnits\": 5,\n            \"ReadCapacityUnits\": 10\n        },\n        \"TableClassSummary\": {\n            \"LastUpdateDateTime\": 1542397215.37,\n            \"TableClass\": \"STANDARD_INFREQUENT_ACCESS\"\n        },\n        \"TableSizeBytes\": 0,\n        \"TableName\": \"Music\",\n        \"TableStatus\": \"CREATING\",\n        \"TableId\": \"12345678-0123-4567-a123-abcdefghijkl\",\n        \"KeySchema\": [\n            {\n                \"KeyType\": \"HASH\",\n                \"AttributeName\": \"Artist\"\n            },\n            {\n                \"KeyType\": \"RANGE\",\n                \"AttributeName\": \"SongTitle\"\n            }\n        ],\n        \"ItemCount\": 0,\n        \"CreationDateTime\": 1542397215.37\n    }\n}\nDescribing a table\n\nTo view details about a table, use the DescribeTable operation. You must provide the table name. The output from DescribeTable is in the same format as that from CreateTable. It includes the timestamp when the table was created, its key schema, its provisioned throughput settings, its estimated size, and any secondary indexes that are present.\n\nImportant\n\nWhen calling DescribeTable on an on-demand table, read capacity units and write capacity units are set to 0.\n\nExample\naws dynamodb describe-table --table-name Music\n\nThe table is ready for use when the TableStatus has changed from CREATING to ACTIVE.\n\nNote\n\nIf you issue a DescribeTable request immediately after a CreateTable request, DynamoDB might return an error (ResourceNotFoundException). This is because DescribeTable uses an eventually consistent query, and the metadata for your table might not be available at that moment. Wait for a few seconds, and then try the DescribeTable request again.\n\nFor billing purposes, your DynamoDB storage costs include a per-item overhead of 100 bytes. (For more information, go to DynamoDB Pricing.) This extra 100 bytes per item is not used in capacity unit calculations or by the DescribeTable operation.\n\nUpdating a table\n\nThe UpdateTable operation allows you to do one of the following:\n\nModify a table's provisioned throughput settings (for provisioned mode tables).\n\nChange the table's read/write capacity mode.\n\nManipulate global secondary indexes on the table (see Using Global Secondary Indexes in DynamoDB).\n\nEnable or disable DynamoDB Streams on the table (see Change data capture for DynamoDB Streams).\n\nExample\n\nThe following AWS CLI example shows how to modify a table's provisioned throughput settings.\n\naws dynamodb update-table --table-name Music \\\n    --provisioned-throughput ReadCapacityUnits=20,WriteCapacityUnits=10\nNote\n\nWhen you issue an UpdateTable request, the status of the table changes from AVAILABLE to UPDATING. The table remains fully available for use while it is UPDATING. When this process is completed, the table status changes from UPDATING to AVAILABLE.\n\nExample\n\nThe following AWS CLI example shows how to modify a table's read/write capacity mode to on-demand mode.\n\naws dynamodb update-table --table-name Music \\\n    --billing-mode PAY_PER_REQUEST\nDeleting a table\n\nYou can remove an unused table with the DeleteTable operation. Deleting a table is an unrecoverable operation.\n\nExample\n\nThe following AWS CLI example shows how to delete a table.\n\naws dynamodb delete-table --table-name Music\n\nWhen you issue a DeleteTable request, the table's status changes from ACTIVE to DELETING. It might take a while to delete the table, depending on the resources it uses (such as the data stored in the table, and any streams or indexes on the table).\n\nWhen the DeleteTable operation concludes, the table no longer exists in DynamoDB.\n\nUsing deletion protection\n\nYou can protect a table from accidental deletion with the deletion protection property. Enabling this property for tables helps ensure that tables do not get accidentally deleted during regular table management operations by your administrators. This will help prevent disruption to your normal business operations.\n\nThe table owner or an authorized administrator controls the deletion protection property for each table. The deletion protection property for every table is off by default. This includes global replicas, and tables restored from backups. When deletion protection is disabled for a table, the table can be deleted by any users authorized by an Identity and Access Management (IAM) policy. When deletion protection is enabled for a table, it cannot be deleted by anyone.\n\nTo change this setting, go to the table’s Additional settings, navigate to the Deletion Protection panel and select Enable delete protection.\n\nThe deletion protection property is supported by the DynamoDB console, API, CLI/SDK and AWS CloudFormation. The CreateTable API supports the deletion protection property at table creation time, and the UpdateTable API supports changing the deletion protection property for existing tables.\n\nNote\n\nIf an AWS account is deleted, all of that account's data including tables are still deleted within 90 days.\n\nIf DynamoDB loses access to a customer managed key that was used to encrypt a table, it will still archive the table. Archiving involves making a backup of the table and deleting the original.\n\nListing table names\n\nThe ListTables operation returns the names of the DynamoDB tables for the current AWS account and Region.\n\nExample\n\nThe following AWS CLI example shows how to list the DynamoDB table names.\n\naws dynamodb list-tables\nDescribing provisioned throughput quotas\n\nThe DescribeLimits operation returns the current read and write capacity quotas for the current AWS account and Region.\n\nExample\n\nThe following AWS CLI example shows how to describe the current provisioned throughput quotas.\n\naws dynamodb describe-limits\n\nThe output shows the upper quotas of read and write capacity units for the current AWS account and Region.\n\nFor more information about these quotas, and how to request quota increases, see Throughput default quotas."
  },
  {
    "title": "Programming DynamoDB with the AWS SDK for Java 2.x - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ProgrammingWithJava.html",
    "html": "Programming DynamoDB with the AWS SDK for Java 2.x\nPDF\nRSS\n\nThis programming guide provides an orientation for programmers who want to use Amazon DynamoDB with Java. The guide covers different concepts including abstraction layers, configuration management, error handling, controlling retry policies, and managing keep-alive.\n\nTopics\nAbout the AWS SDK for Java 2.x\nGetting started\nSDK for Java 2.x documentation\nSupported interfaces\nAdditional code examples\nSync and async programming\nHTTP clients\nConfig\nError handling\nAWS request ID\nLogging\nPagination\nData class annotations\nAbout the AWS SDK for Java 2.x\n\nYou can access DynamoDB from Java using the official AWS SDK for Java. The SDK for Java has two versions: 1.x and 2.x. The end-of-support for 1.x was announced on January 12, 2024. It will enter maintenance mode on July 31, 2024 and its end-of-support is due on December 31, 2025. For new development, we highly recommend that you use 2.x, which was first released in 2018. This guide exclusively targets 2.x and focuses only on the parts of the SDK relevant to DynamoDB.\n\nFor information about maintenance and support for the AWS SDKs, see AWS SDK and Tools maintenance policy and AWS SDKs and Tools version support matrix in the AWS SDKs and Tools Reference Guide.\n\nThe AWS SDK for Java 2.x is a major rewrite of the 1.x code base. The SDK for Java 2.x supports modern Java features, such as the non-blocking I/O introduced in Java 8. The SDK for Java 2.x also adds support for pluggable HTTP client implementations to provide more network connection flexibility and configuration options.\n\nA noticeable change between the SDK for Java 1.x and the SDK for Java 2.x is the use of a new package name. The Java 1.x SDK uses the com.amazonaws package name, while the Java 2.x SDK uses software.amazon.awssdk. Similarly, Maven artifacts for the Java 1.x SDK use the com.amazonaws groupId, while Java 2.x SDK artifacts use the software.amazon.awssdk groupId.\n\nImportant\n\nThe AWS SDK for Java 1.x has a DynamoDB package named com.amazonaws.dynamodbv2. The \"v2\" in the package name doesn't indicate that it's for Java 2 (J2SE). Rather, \"v2\" indicates that the package supports the second version of the DynamoDB low-level API instead of the original version of the low-level API.\n\nSupport for Java versions\n\nThe AWS SDK for Java 2.x provides full support for long-term support (LTS) Java releases.\n\nGetting started with the AWS SDK for Java 2.x\n\nThe following tutorial shows you how to use Apache Maven for defining dependencies for the SDK for Java 2.x. This tutorial also shows you how to write the code that connects to DynamoDB for listing the available DynamoDB tables. The tutorial in this guide is based on the tutorial Get started with the AWS SDK for Java 2.x in the AWS SDK for Java 2.x Developer Guide. We've edited this tutorial to make calls to DynamoDB instead of Amazon S3.\n\nTo complete this tutorial, do the following:\nStep 1: Set up for this tutorial\nStep 2: Create the project\nStep 3: Write the code\nStep 4: Build and run the application\nStep 1: Set up for this tutorial\n\nBefore you begin this tutorial, you need the following:\n\nPermission to access DynamoDB.\n\nA Java development environment that's configured with single sign-on access to AWS services using the AWS access portal.\n\nTo set up for this tutorial, follow the instructions in Setup overview in the AWS SDK for Java 2.x Developer Guide. After you configure your development environment with single sign-on access for the Java SDK and you have an active AWS access portal session, then continue to Step 2 of this tutorial.\n\nStep 2: Create the project\n\nTo create the project for this tutorial, you run a Maven command that prompts you for input on how to configure the project. After all input is entered and confirmed, Maven finishes building out the project by creating a pom.xml file and creating stub Java files.\n\nOpen a terminal or command prompt window and navigate to a directory of your choice, for example, your Desktop or Home folder.\n\nEnter the following command at the terminal, and then press Enter.\n\nmvn archetype:generate \\\n   -DarchetypeGroupId=software.amazon.awssdk \\\n   -DarchetypeArtifactId=archetype-app-quickstart \\\n   -DarchetypeVersion=2.22.0\n\nFor each prompt, enter the value listed in the second column.\n\nPrompt\tValue to enter\nDefine value for property 'service':\tdynamodb\nDefine value for property 'httpClient':\tapache-client\nDefine value for property 'nativeImage':\tfalse\nDefine value for property 'credentialProvider'\tidentity-center\nDefine value for property 'groupId':\torg.example\nDefine value for property 'artifactId':\tgetstarted\nDefine value for property 'version' 1.0-SNAPSHOT:\t<Enter>\nDefine value for property 'package' org.example:\t<Enter>\n\nAfter you enter the last value, Maven lists the choices that you made. To confirm, enter Y. Or, enter N, and then re-enter your choices.\n\nMaven creates a project folder named getstarted based on the artifactId value that you entered. Inside the getstarted folder, find a file named README.md that you can review, a pom.xml file, and a src directory.\n\nMaven builds the following directory tree.\n\ngetstarted\n ├── README.md\n ├── pom.xml\n └── src\n     ├── main\n     │   ├── java\n     │   │   └── org\n     │   │       └── example\n     │   │           ├── App.java\n     │   │           ├── DependencyFactory.java\n     │   │           └── Handler.java\n     │   └── resources\n     │       └── simplelogger.properties\n     └── test\n         └── java\n             └── org\n                 └── example\n                     └── HandlerTest.java\n \n 10 directories, 7 files\n\nThe following shows the contents of the pom.xml project file.\n\npom.xml\nStep 3: Write the code\n\nThe following code shows the App class that Maven creates. The main method is the entry point into the application, which creates an instance of the Handler class and then calls its sendRequest method.\n\nApp class\n\nThe DependencyFactory class that Maven creates contains the dynamoDbClient factory method that builds and returns an DynamoDbClient instance. The DynamoDbClient instance uses an instance of the Apache-based HTTP client. This is because you specified apache-client when Maven prompted you for which HTTP client to use.\n\nThe following code shows the DependencyFactory class.\n\nDependencyFactory class\n\nThe Handler class contains the main logic of your program. When an instance of Handler is created in the App class, the DependencyFactory furnishes the DynamoDbClient service client. Your code uses the DynamoDbClient instance to call DynamoDB.\n\nMaven generates the following Handler class with a TODO comment. The next step in the tutorial replaces the TODO comment with code.\n\nHandler class, Maven-generated\n\nTo fill in the logic, replace the entire contents of the Handler class with the following code. The sendRequest method is filled in and the necessary imports are added.\n\nHandler class, implemented\nStep 4: Build and run the application\n\nAfter you create the project and it contains the complete Handler class, build and run the application.\n\nMake sure that you have an active AWS IAM Identity Center session. To confirm, run the AWS Command Line Interface (AWS CLI) command aws sts get-caller-identity and check the response. If you don't have an active session, then see Sign in using the AWS CLI for instructions.\n\nOpen a terminal or command prompt window and navigate to your project directory getstarted.\n\nTo build your project, run the following command:\n\nmvn clean package\n\nTo run the application, run the following command:\n\nmvn exec:java -Dexec.mainClass=\"org.example.App\"\n\nAfter you view the file, delete the object, and then delete the bucket.\n\nSuccess\n\nIf your Maven project built and ran without error, then congratulations! You've successfully built your first Java application using the SDK for Java 2.x.\n\nCleanup\n\nTo clean up the resources that you created during this tutorial, delete the project folder getstarted.\n\nReviewing the AWS SDK for Java 2.x documentation\n\nThe AWS SDK for Java 2.x Developer Guide covers all aspects of the SDK across all AWS services. We recommend that you review the following topics:\n\nMigrate from version 1.x to 2.x – Includes a detailed explanation of the differences between 1.x and 2.x. This topic also contains instructions about how to use both major versions side-by-side.\n\nDynamoDB guide for Java 2.x SDK – Shows you how to perform basic DynamoDB operations: creating a table, manipulating items, and retrieving items. These examples use the low-level interface. Java has several interfaces, as explained in the following section: Supported interfaces.\n\nTip\n\nAfter you review these topics, bookmark the AWS SDK for Java 2.x API Reference. It covers all AWS services, and we recommend that you use it as your main API reference.\n\nSupported interfaces\n\nThe AWS SDK for Java 2.x supports the following interfaces, depending on the level of abstraction that you want.\n\nTopics in this section\nLow-level interface\nHigh-level interface\nDocument interface\nComparing interfaces with a Query example\nLow-level interface\n\nThe low-level interface provides a one-to-one mapping to the underlying service API. Every DynamoDB API is available through this interface. This means that the low-level interface can provide complete functionality, but it's often more verbose and complex to use. For example, you have to use the .s() functions to hold strings and the .n() functions to hold numbers. The following example of PutItem inserts an item using the low-level interface.\n\nimport org.slf4j.*;\nimport software.amazon.awssdk.http.crt.AwsCrtHttpClient;\nimport software.amazon.awssdk.services.dynamodb.DynamoDbClient;\nimport software.amazon.awssdk.services.dynamodb.model.*;\n\nimport java.util.Map;\n\npublic class PutItem {\n\n    // Create a DynamoDB client with the default settings connected to the DynamoDB\n    // endpoint in the default region based on the default credentials provider chain.\n    private static final DynamoDbClient DYNAMODB_CLIENT = DynamoDbClient.create();\n    private static final Logger LOGGER = LoggerFactory.getLogger(PutItem.class);\n\n    private void putItem() {\n        PutItemResponse response = DYNAMODB_CLIENT.putItem(PutItemRequest.builder()\n                .item(Map.of(\n                        \"pk\", AttributeValue.builder().s(\"123\").build(),\n                        \"sk\", AttributeValue.builder().s(\"cart#123\").build(),\n                        \"item_data\", AttributeValue.builder().s(\"YourItemData\").build(),\n                        \"inventory\", AttributeValue.builder().n(\"500\").build()\n                        // ... more attributes ...\n                ))\n                .returnConsumedCapacity(ReturnConsumedCapacity.TOTAL)\n                .tableName(\"YourTableName\")\n                .build());\n        LOGGER.info(\"PutItem call consumed [\" + response.consumedCapacity().capacityUnits() + \"] Write Capacity Unites (WCU)\");\n    }\n}\nHigh-level interface\n\nThe high-level interface in the AWS SDK for Java 2.x is called the DynamoDB enhanced client. This interface provides a more idiomatic code authoring experience.\n\nThe enhanced client offers a way to map between client-side data classes and DynamoDB tables designed to store that data. You define the relationships between tables and their corresponding model classes in your code. Then, you can rely on the SDK to manage the data type manipulation. For more information about the enhanced client, see DynamoDB enhanced client API in the AWS SDK for Java 2.x Developer Guide.\n\nThe following example of PutItem uses the high-level interface. In this example, the DynamoDbBean named YourItem creates a TableSchema that enables its direct use as input for the putItem() call.\n\nimport org.slf4j.*;\nimport software.amazon.awssdk.enhanced.dynamodb.*;\nimport software.amazon.awssdk.enhanced.dynamodb.mapper.annotations.*;\nimport software.amazon.awssdk.enhanced.dynamodb.model.*;\nimport software.amazon.awssdk.services.dynamodb.model.ReturnConsumedCapacity;\n\npublic class DynamoDbEnhancedClientPutItem {\n    private static final DynamoDbEnhancedClient ENHANCED_DYNAMODB_CLIENT = DynamoDbEnhancedClient.builder().build();\n    private static final DynamoDbTable<YourItem> DYNAMODB_TABLE = ENHANCED_DYNAMODB_CLIENT.table(\"YourTableName\", TableSchema.fromBean(YourItem.class));\n    private static final Logger LOGGER = LoggerFactory.getLogger(PutItem.class);\n\n    private void putItem() {\n        PutItemEnhancedResponse<YourItem> response = DYNAMODB_TABLE.putItemWithResponse(PutItemEnhancedRequest.builder(YourItem.class)\n                .item(new YourItem(\"123\", \"cart#123\", \"YourItemData\", 500))\n                .returnConsumedCapacity(ReturnConsumedCapacity.TOTAL)\n                .build());\n        LOGGER.info(\"PutItem call consumed [\" + response.consumedCapacity().capacityUnits() + \"] Write Capacity Unites (WCU)\");\n    }\n\n    @DynamoDbBean\n    public static class YourItem {\n\n        public YourItem() {}\n\n        public YourItem(String pk, String sk, String itemData, int inventory) {\n            this.pk = pk;\n            this.sk = sk;\n            this.itemData = itemData;\n            this.inventory = inventory;\n        }\n\n        private String pk;\n        private String sk;\n        private String itemData;\n\n        private int inventory;\n\n        @DynamoDbPartitionKey\n        public void setPk(String pk) {\n            this.pk = pk;\n        }\n\n        public String getPk() {\n            return pk;\n        }\n\n        @DynamoDbSortKey\n        public void setSk(String sk) {\n            this.sk = sk;\n        }\n\n        public String getSk() {\n            return sk;\n        }\n\n        public void setItemData(String itemData) {\n            this.itemData = itemData;\n        }\n\n        public String getItemData() {\n            return itemData;\n        }\n\n        public void setInventory(int inventory) {\n            this.inventory = inventory;\n        }\n\n        public int getInventory() {\n            return inventory;\n        }\n    }\n}\n\nThe AWS SDK for Java 1.x has its own high-level interface, which is often referred to by its main class DynamoDBMapper. The AWS SDK for Java 2.x is published in a separate package (and Maven artifact) named software.amazon.awssdk.enhanced.dynamodb. The Java 2.x SDK is often referred to by its main class DynamoDbEnhancedClient.\n\nHigh-level interface using immutable data classes\n\nThe mapping feature of the DynamoDB enhanced client API also works with immutable data classes. An immutable class has only getters and requires a builder class that the SDK uses to create instances of the class. Immutability in Java is a commonly used style that developers can use to create classes that have no side-effects. These classes are more predictable in their behavior in complex multi-threaded applications. Instead of using the @DynamoDbBean annotation as shown in the High-level interface example, immutable classes use the @DynamoDbImmutable annotation, which takes the builder class as its input.\n\nThe following example takes the builder class DynamoDbEnhancedClientImmutablePutItem as input to create a table schema. The example then provides the schema as input for the PutItem API call.\n\nimport org.slf4j.*;\nimport software.amazon.awssdk.enhanced.dynamodb.*;\nimport software.amazon.awssdk.enhanced.dynamodb.model.*;\nimport software.amazon.awssdk.services.dynamodb.model.ReturnConsumedCapacity;\n\npublic class DynamoDbEnhancedClientImmutablePutItem {\n    private static final DynamoDbEnhancedClient ENHANCED_DYNAMODB_CLIENT = DynamoDbEnhancedClient.builder().build();\n    private static final DynamoDbTable<YourImmutableItem> DYNAMODB_TABLE = ENHANCED_DYNAMODB_CLIENT.table(\"YourTableName\", TableSchema.fromImmutableClass(YourImmutableItem.class));\n    private static final Logger LOGGER = LoggerFactory.getLogger(DynamoDbEnhancedClientImmutablePutItem.class);\n\n    private void putItem() {\n        PutItemEnhancedResponse<YourImmutableItem> response = DYNAMODB_TABLE.putItemWithResponse(PutItemEnhancedRequest.builder(YourImmutableItem.class)\n                .item(YourImmutableItem.builder()\n                                        .pk(\"123\")\n                                        .sk(\"cart#123\")\n                                        .itemData(\"YourItemData\")\n                                        .inventory(500)\n                                        .build())\n                .returnConsumedCapacity(ReturnConsumedCapacity.TOTAL)\n                .build());\n        LOGGER.info(\"PutItem call consumed [\" + response.consumedCapacity().capacityUnits() + \"] Write Capacity Unites (WCU)\");\n    }\n}\n\nThe following example shows the immutable data class.\n\n@DynamoDbImmutable(builder = YourImmutableItem.YourImmutableItemBuilder.class)\nclass YourImmutableItem {\n    private final String pk;\n    private final String sk;\n    private final String itemData;\n    private final int inventory;\n    public YourImmutableItem(YourImmutableItemBuilder builder) {\n        this.pk = builder.pk;\n        this.sk = builder.sk;\n        this.itemData = builder.itemData;\n        this.inventory = builder.inventory;\n    }\n\n    public static YourImmutableItemBuilder builder() { return new YourImmutableItemBuilder(); }\n\n    @DynamoDbPartitionKey\n    public String getPk() {\n        return pk;\n    }\n\n    @DynamoDbSortKey\n    public String getSk() {\n        return sk;\n    }\n\n    public String getItemData() {\n        return itemData;\n    }\n\n    public int getInventory() {\n        return inventory;\n    }\n\n    static final class YourImmutableItemBuilder {\n        private String pk;\n        private String sk;\n        private String itemData;\n        private int inventory;\n\n        private YourImmutableItemBuilder() {}\n\n        public YourImmutableItemBuilder pk(String pk) { this.pk = pk; return this; }\n        public YourImmutableItemBuilder sk(String sk) { this.sk = sk; return this; }\n        public YourImmutableItemBuilder itemData(String itemData) { this.itemData = itemData; return this; }\n        public YourImmutableItemBuilder inventory(int inventory) { this.inventory = inventory; return this; }\n\n        public YourImmutableItem build() { return new YourImmutableItem(this); }\n    }\n}\nHigh-level interface using immutable data classes and third-party boilerplate generation libraries\n\nImmutable data classes (shown in the previous example) require some boilerplate code. For example, the getter and setter logic on the data classes, in addition to the Builder classes. Third-party libraries, such as Project Lombok, can help you generate that type of boilerplate code. Reducing most of the boilerplate code helps you limit the amount of code needed for working with immutable data classes and the AWS SDK. This further results in improved productivity and readability of your code. For more information, see Use third-party libraries, such as Lombok in the AWS SDK for Java 2.x Developer Guide.\n\nThe following example demonstrates how Project Lombok simplifies the code needed to use the DynamoDB enhanced client API.\n\nimport org.slf4j.*;\nimport software.amazon.awssdk.enhanced.dynamodb.*;\nimport software.amazon.awssdk.enhanced.dynamodb.model.*;\nimport software.amazon.awssdk.services.dynamodb.model.ReturnConsumedCapacity;\n\npublic class DynamoDbEnhancedClientImmutableLombokPutItem {\n\n    private static final DynamoDbEnhancedClient ENHANCED_DYNAMODB_CLIENT = DynamoDbEnhancedClient.builder().build();\n    private static final DynamoDbTable<YourImmutableLombokItem> DYNAMODB_TABLE = ENHANCED_DYNAMODB_CLIENT.table(\"YourTableName\", TableSchema.fromImmutableClass(YourImmutableLombokItem.class));\n    private static final Logger LOGGER = LoggerFactory.getLogger(DynamoDbEnhancedClientImmutableLombokPutItem.class);\n\n    private void putItem() {\n        PutItemEnhancedResponse<YourImmutableLombokItem> response = DYNAMODB_TABLE.putItemWithResponse(PutItemEnhancedRequest.builder(YourImmutableLombokItem.class)\n                .item(YourImmutableLombokItem.builder()\n                        .pk(\"123\")\n                        .sk(\"cart#123\")\n                        .itemData(\"YourItemData\")\n                        .inventory(500)\n                        .build())\n                .returnConsumedCapacity(ReturnConsumedCapacity.TOTAL)\n                .build());\n        LOGGER.info(\"PutItem call consumed [\" + response.consumedCapacity().capacityUnits() + \"] Write Capacity Unites (WCU)\");\n    }\n}\n\nThe following example shows the immutable data object of the immutable data class.\n\nimport lombok.*;\nimport software.amazon.awssdk.enhanced.dynamodb.mapper.annotations.*;\n\n@Builder\n@DynamoDbImmutable(builder = YourImmutableLombokItem.YourImmutableLombokItemBuilder.class)\n@Value\npublic class YourImmutableLombokItem {\n\n    @Getter(onMethod_=@DynamoDbPartitionKey)\n    String pk;\n    @Getter(onMethod_=@DynamoDbSortKey)\n    String sk;\n    String itemData;\n    int inventory;\n}\n\nThe YourImmutableLombokItem class uses the following annotations that Project Lombok and the AWS SDK provide:\n\n@Builder – Produces complex builder APIs for data classes that Project Lombok provides.\n\n@DynamoDbImmutable – Identifies the DynamoDbImmutable class as a DynamoDB mappable entity annotation that the AWS SDK provides.\n\n@Value – The immutable variant of @Data. By default, all fields are made private and final, and setters are not generated. Project Lombok provides this annotation.\n\nDocument interface\n\nThe AWS SDK for Java 2.x Document interface avoids the need to specify data type descriptors. The data types are implied by the semantics of the data itself. This Document interface is similar to the AWS SDK for Java 1.x, Document interface, but with a redesigned interface.\n\nThe following Document interface example shows the PutItem call expressed using the Document interface. The example also uses EnhancedDocument. To run commands against a DynamoDB table using the enhanced document API, you must first associate the table with your document table schema to create a DynamoDBTable resource object. The Document table schema builder requires the primary index key and attribute converter providers.\n\nYou can use AttributeConverterProvider.defaultProvider() to convert document attributes of default types. You can change the overall default behavior with a custom AttributeConverterProvider implementation. You can also change the converter for a single attribute. The AWS SDKs and Tools Reference Guide provides more details and examples about how to use custom converters. Their primary use is for attributes of your domain classes that don't have a default converter available. Using a custom converter, you can provide the SDK with the needed information to write or read to DynamoDB.\n\nimport org.slf4j.*;\nimport software.amazon.awssdk.enhanced.dynamodb.*;\nimport software.amazon.awssdk.enhanced.dynamodb.document.EnhancedDocument;\nimport software.amazon.awssdk.enhanced.dynamodb.model.*;\nimport software.amazon.awssdk.services.dynamodb.model.ReturnConsumedCapacity;\n\npublic class DynamoDbEnhancedDocumentClientPutItem {\n    private static final DynamoDbEnhancedClient ENHANCED_DYNAMODB_CLIENT = DynamoDbEnhancedClient.builder().build();\n    private static final DynamoDbTable<EnhancedDocument> DYNAMODB_TABLE =\n            ENHANCED_DYNAMODB_CLIENT.table(\"YourTableName\", TableSchema.documentSchemaBuilder()\n                            .addIndexPartitionKey(TableMetadata.primaryIndexName(),\"pk\", AttributeValueType.S)\n                            .addIndexSortKey(TableMetadata.primaryIndexName(), \"sk\", AttributeValueType.S)\n                            .attributeConverterProviders(AttributeConverterProvider.defaultProvider())\n                            .build());\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(DynamoDbEnhancedDocumentClientPutItem.class);\n\n    private void putItem() {\n        PutItemEnhancedResponse<EnhancedDocument> response = DYNAMODB_TABLE.putItemWithResponse(\n                        PutItemEnhancedRequest.builder(EnhancedDocument.class)\n                                .item(\n                                    EnhancedDocument.builder()\n                                            .attributeConverterProviders(AttributeConverterProvider.defaultProvider())\n                                            .putString(\"pk\", \"123\")\n                                            .putString(\"sk\", \"cart#123\")\n                                            .putString(\"item_data\", \"YourItemData\")\n                                            .putNumber(\"inventory\", 500)\n                                            .build())\n                                .returnConsumedCapacity(ReturnConsumedCapacity.TOTAL)\n                                .build());\n        LOGGER.info(\"PutItem call consumed [\" + response.consumedCapacity().capacityUnits() + \"] Write Capacity Unites (WCU)\");\n    }\n\n}\n\nTo convert JSON documents to and from the native Amazon DynamoDB data types, you can use the following utility methods:\n\nEnhancedDocument.fromJson(String json) – Creates a new EnhancedDocument instance from a JSON string.\n\nEnhancedDocument.toJson() – Creates a JSON string representation of the document that you can use in your application like any other JSON object.\n\nComparing interfaces with a Query example\n\nThis section shows the same Query call expressed using the various interfaces. To fine tune the results of these queries, note the following:\n\nDynamoDB targets one specific partition key value, so you must specify the partition key completely.\n\nTo have the query target only cart items, the sort key has a key condition expression that uses begins_with.\n\nWe use limit() to limit the query to a maximum of 100 returned items.\n\nWe set the scanIndexForward to false. The results are returned in order of UTF-8 bytes, which usually means the cart item with the lowest number is returned first. By setting the scanIndexForward to false, we reverse the order and the cart item with the highest number is returned first.\n\nWe apply a filter to remove any result that does not match the criteria. The data being filtered consumes read capacity whether the item matches the filter.\n\nExample Query using the low-level interface\n\nThe following example queries a table named YourTableName using a keyConditionExpression. This limits the query to a specific partition key value and sort key value that begin with a specific prefix value. These key conditions limit the amount of data read from DynamoDB. Finally, the query applies a filter on the data retrieved from DynamoDB using a filterExpression.\n\nimport org.slf4j.*;\nimport software.amazon.awssdk.services.dynamodb.DynamoDbClient;\nimport software.amazon.awssdk.services.dynamodb.model.*;\n\nimport java.util.Map;\n\npublic class Query {\n\n    // Create a DynamoDB client with the default settings connected to the DynamoDB \n    // endpoint in the default region based on the default credentials provider chain.\n    private static final DynamoDbClient DYNAMODB_CLIENT = DynamoDbClient.builder().build();\n    private static final Logger LOGGER = LoggerFactory.getLogger(Query.class);\n\n    private static void query() {\n        QueryResponse response = DYNAMODB_CLIENT.query(QueryRequest.builder()\n                .expressionAttributeNames(Map.of(\"#name\", \"name\"))\n                .expressionAttributeValues(Map.of(\n                    \":pk_val\", AttributeValue.fromS(\"id#1\"),\n                    \":sk_val\", AttributeValue.fromS(\"cart#\"),\n                    \":name_val\", AttributeValue.fromS(\"SomeName\")))\n                .filterExpression(\"#name = :name_val\")\n                .keyConditionExpression(\"pk = :pk_val AND begins_with(sk, :sk_val)\")\n                .limit(100)\n                .scanIndexForward(false)\n                .tableName(\"YourTableName\")\n                .build());\n\n        LOGGER.info(\"nr of items: \" + response.count());\n        LOGGER.info(\"First item pk: \" + response.items().get(0).get(\"pk\"));\n        LOGGER.info(\"First item sk: \" + response.items().get(0).get(\"sk\"));\n    }\n}\nExample Query using the Document interface\n\nThe following example queries a table named YourTableName using the Document interface.\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.enhanced.dynamodb.*;\nimport software.amazon.awssdk.enhanced.dynamodb.document.EnhancedDocument;\nimport software.amazon.awssdk.enhanced.dynamodb.model.*;\n\nimport java.util.Map;\n\npublic class DynamoDbEnhancedDocumentClientQuery {\n\n    // Create a DynamoDB client with the default settings connected to the DynamoDB \n    // endpoint in the default region based on the default credentials provider chain.\n    private static final DynamoDbEnhancedClient ENHANCED_DYNAMODB_CLIENT = DynamoDbEnhancedClient.builder().build();\n    private static final DynamoDbTable<EnhancedDocument> DYNAMODB_TABLE =\n            ENHANCED_DYNAMODB_CLIENT.table(\"YourTableName\", TableSchema.documentSchemaBuilder()\n                    .addIndexPartitionKey(TableMetadata.primaryIndexName(),\"pk\", AttributeValueType.S)\n                    .addIndexSortKey(TableMetadata.primaryIndexName(), \"sk\", AttributeValueType.S)\n                    .attributeConverterProviders(AttributeConverterProvider.defaultProvider())\n                    .build());\n    private static final Logger LOGGER = LoggerFactory.getLogger(DynamoDbEnhancedDocumentClientQuery.class);\n\n    private void query() {\n        PageIterable<EnhancedDocument> response = DYNAMODB_TABLE.query(QueryEnhancedRequest.builder()\n                .filterExpression(Expression.builder()\n                        .expression(\"#name = :name_val\")\n                        .expressionNames(Map.of(\"#name\", \"name\"))\n                        .expressionValues(Map.of(\":name_val\", AttributeValue.fromS(\"SomeName\")))\n                        .build())\n                .limit(100)\n                .queryConditional(QueryConditional.sortBeginsWith(Key.builder()\n                        .partitionValue(\"id#1\")\n                        .sortValue(\"cart#\")\n                        .build()))\n                .scanIndexForward(false)\n                .build());\n\n        LOGGER.info(\"nr of items: \" + response.items().stream().count());\n        LOGGER.info(\"First item pk: \" + response.items().iterator().next().getString(\"pk\"));\n        LOGGER.info(\"First item sk: \" + response.items().iterator().next().getString(\"sk\"));\n\n    }\n}\nExample Query using the high-level interface\n\nThe following example queries a table named YourTableName using the DynamoDB enhanced client API.\n\nimport org.slf4j.*;\nimport software.amazon.awssdk.enhanced.dynamodb.*;\nimport software.amazon.awssdk.enhanced.dynamodb.mapper.annotations.*;\nimport software.amazon.awssdk.enhanced.dynamodb.model.*;\nimport software.amazon.awssdk.services.dynamodb.model.AttributeValue;\n\nimport java.util.Map;\n\npublic class DynamoDbEnhancedClientQuery {\n\n    private static final DynamoDbEnhancedClient ENHANCED_DYNAMODB_CLIENT = DynamoDbEnhancedClient.builder().build();\n    private static final DynamoDbTable<YourItem> DYNAMODB_TABLE = ENHANCED_DYNAMODB_CLIENT.table(\"YourTableName\", TableSchema.fromBean(DynamoDbEnhancedClientQuery.YourItem.class));\n    private static final Logger LOGGER = LoggerFactory.getLogger(DynamoDbEnhancedClientQuery.class);\n\n    private void query() {\n        PageIterable<YourItem> response = DYNAMODB_TABLE.query(QueryEnhancedRequest.builder()\n                .filterExpression(Expression.builder()\n                        .expression(\"#name = :name_val\")\n                        .expressionNames(Map.of(\"#name\", \"name\"))\n                        .expressionValues(Map.of(\":name_val\", AttributeValue.fromS(\"SomeName\")))\n                        .build())\n                .limit(100)\n                .queryConditional(QueryConditional.sortBeginsWith(Key.builder()\n                        .partitionValue(\"id#1\")\n                        .sortValue(\"cart#\")\n                        .build()))\n                .scanIndexForward(false)\n                .build());\n\n        LOGGER.info(\"nr of items: \" + response.items().stream().count());\n        LOGGER.info(\"First item pk: \" + response.items().iterator().next().getPk());\n        LOGGER.info(\"First item sk: \" + response.items().iterator().next().getSk());\n    }\n\n    @DynamoDbBean\n    public static class YourItem {\n\n        public YourItem() {}\n\n        public YourItem(String pk, String sk, String name) {\n            this.pk = pk;\n            this.sk = sk;\n            this.name = name;\n        }\n\n        private String pk;\n        private String sk;\n        private String name;\n\n        @DynamoDbPartitionKey\n        public void setPk(String pk) {\n            this.pk = pk;\n        }\n\n        public String getPk() {\n            return pk;\n        }\n\n        @DynamoDbSortKey\n        public void setSk(String sk) {\n            this.sk = sk;\n        }\n\n        public String getSk() {\n            return sk;\n        }\n\n        public void setName(String name) {\n            this.name = name;\n        }\n\n        public String getName() {\n            return name;\n        }\n    }\n}\nHigh-level interface using immutable data classes\n\nWhen you perform a Query with the high-level immutable data classes, the code is the same as the high-level interface example except for the construction of the entity class YourItem or YourImmutableItem. For more information, see the PutItem example.\n\nHigh-level interface using immutable data classes and third-party boilerplate generation libraries\n\nWhen you perform a Query with the high-level immutable data classes, the code is the same as the high-level interface example except for the construction of the entity class YourItem or YourImmutableLombokItem. For more information, see the PutItem example.\n\nAdditional code examples\n\nFor additional examples of how to use DynamoDB with the SDK for Java 2.x, refer to the following code example repositories:\n\nOfficial AWS single-action code examples\n\nCommunity-maintained single-action code examples\n\nOfficial AWS scenario-oriented code examples\n\nSynchronous and asynchronous programming\n\nThe AWS SDK for Java 2.x provides both synchronous and asynchronous clients for AWS services, such as DynamoDB.\n\nThe DynamoDbClient and DynamoDbEnhancedClient classes provide synchronous methods that block your thread's execution until the client receives a response from the service. This client is the most straightforward way of interacting with DynamoDB if you have no need for asynchronous operations.\n\nThe DynamoDbAsyncClient and DynamoDbEnhancedAsyncClient classes provide asynchronous methods that return immediately, and give control back to the calling thread without waiting for a response. The non-blocking client has an advantage that it uses for high concurrency across a few threads, which provides efficient handling of I/O requests with minimal compute resources. This improves throughput and responsiveness.\n\nThe AWS SDK for Java 2.x uses the native support for non-blocking I/O. The AWS SDK for Java 1.x had to simulate non-blocking I/O.\n\nThe synchronous methods return before a response is available, so you need a way to get the response when it's ready. The asynchronous methods in the AWS SDK for Java return a CompletableFuture object that contains the results of the asynchronous operation in the future. When you call get() or join() on these CompletableFuture objects, your code blocks until the result is available. If you call these at the same time that you make the request, then the behavior is similar to a plain synchronous call.\n\nFor more information about asynchronous programming, see Use asynchronous programming in the AWS SDK for Java 2.x Developer Guide.\n\nHTTP clients\n\nFor supporting every client, there exists an HTTP client that handles communication with the AWS services. You can plug in alternative HTTP clients, choosing one that has the characteristics that best fit your application. Some are more lightweight; some have more configuration options.\n\nSome HTTP clients support only synchronous use, while others support only asynchronous use. For a flowchart that can help you select the optimal HTTP client for your workload, see HTTP client recommendations in the AWS SDK for Java 2.x Developer Guide.\n\nThe following list presents some of the possible HTTP clients:\n\nTopics\nApache-based HTTP client\nURLConnection-based HTTP client\nNetty-based HTTP client\nAWS CRT-based HTTP client\nApache-based HTTP client\n\nThe ApacheHttpClient class supports synchronous service clients. It's the default HTTP client for synchronous use. For information about configuring the ApacheHttpClient class, see Configure the Apache-based HTTP client in the AWS SDK for Java 2.x Developer Guide.\n\nURLConnection-based HTTP client\n\nThe UrlConnectionHttpClient class is another option for synchronous clients. It loads more quickly than the Apache-based HTTP client, but has fewer features. For information about configuring the UrlConnectionHttpClient class, see Configure the URLConnection-based HTTP client in the AWS SDK for Java 2.x Developer Guide.\n\nNetty-based HTTP client\n\nThe NettyNioAsyncHttpClient class supports async clients. It's the default choice for async use. For information about configuring the NettyNioAsyncHttpClient class, see Configure the Netty-based HTTP client in the AWS SDK for Java 2.x Developer Guide.\n\nAWS CRT-based HTTP client\n\nThe newer AwsCrtHttpClient and AwsCrtAsyncHttpClient classes from the AWS Common Runtime (CRT) libraries are more options that support synchronous and asynchronous clients. Compared to other HTTP clients, AWS CRT offers:\n\nFaster SDK startup time\n\nSmaller memory footprint\n\nReduced latency time\n\nConnection health management\n\nDNS load balancing\n\nFor information about configuring the AwsCrtHttpClient and AwsCrtAsyncHttpClient classes, see Configure the AWS CRT-based HTTP clients in the AWS SDK for Java 2.x Developer Guide.\n\nThe AWS CRT-based HTTP client isn't the default because that would break backward compatibility for existing applications. However, for DynamoDB we recommend that you use the AWS CRT-based HTTP client for both sync and async uses.\n\nFor an introduction to the AWS CRT-based HTTP client, see Announcing availability of the AWS CRT HTTP Client in the AWS SDK for Java 2.x on the AWS Developer Tools Blog.\n\nConfiguring an HTTP client\n\nWhen configuring a client, you can provide various configuration options, including:\n\nSetting timeouts for different aspects of API calls.\n\nEnabling TCP Keep-Alive.\n\nControlling the retry policy when encountering errors.\n\nSpecifying execution attributes that Execution interceptor instances can modify. Execution interceptors can write code that intercept the execution of your API requests and responses. This enables you to perform tasks such as publishing metrics and modifying requests in-flight.\n\nAdding or manipulating HTTP headers.\n\nEnabling the tracking of client-side performance metrics. Using this feature helps you to collect metrics about the service clients in your application and analyze the output in Amazon CloudWatch.\n\nSpecifying an alternate executor service to be used for scheduling tasks, such as async retry attempts and timeout tasks.\n\nYou control the configuration by providing a ClientOverrideConfiguration object to the service client Builder class. You'll see this in some code examples in the following sections.\n\nThe ClientOverrideConfiguration provides standard configuration choices. The different pluggable HTTP clients have implementation-specific configuration possibilities as well.\n\nTopics in this section\nTimeout configuration\nRetryMode\nDefaultsMode\nKeep-Alive configuration\nTimeout configuration\n\nYou can adjust the client configuration to control various timeouts related to the service calls. DynamoDB provides lower latencies compared to other AWS services. Therefore, you might want to adjust these properties to lower timeout values so that you can fail fast if there's a networking issue.\n\nYou can customize the latency related behavior using ClientOverrideConfiguration on the DynamoDB client or by changing detailed configuration options on the underlying HTTP client implementation.\n\nYou can configure the following impactful properties using ClientOverrideConfiguration:\n\napiCallAttemptTimeout – The amount of time to wait for a single attempt for an HTTP request to complete before giving up and timing out.\n\napiCallTimeout – The amount of time that the client has to completely execute an API call. This includes the request handler execution that consists of all the HTTP requests, including retries.\n\nThe AWS SDK for Java 2.x provides default values for some timeout options, such as connection timeout and socket timeouts. The SDK doesn't provide default values for API call timeouts or individual API call attempt timeouts. If these timeouts aren't set in the ClientOverrideConfiguration, then the SDK uses the socket timeout value instead for the overall API call timeout. The socket timeout has a default value of 30 seconds.\n\nRetryMode\n\nAnother configuration related to the timeout configuration that you should consider is the RetryMode configuration object. This configuration object contains a collection of retry behaviors.\n\nThe SDK for Java 2.x supports the following retry modes:\n\nlegacy – The default retry mode if you don't explicitly change it. This retry mode is specific to the Java SDK. It's characterized by up to three retries, or more for services such as DynamoDB, which has up to eight retries.\n\nstandard – Named \"standard\" because it's more consistent with other AWS SDKs. This mode waits for a random amount of time ranging from 0ms to 1,000ms for the first retry. If another retry is necessary, then this mode picks another random time from 0ms to 1,000ms and multiplies it by two. If an additional retry is necessary, then it does the same random pick multiplied by four, and so on. Each wait is capped at 20 seconds. This mode performs retries on more detected failure conditions than the legacy mode. For DynamoDB, it performs up to three total max attempts unless you override with numRetries.\n\nadaptive – Builds on standard mode and dynamically limits the rate of AWS requests to maximize success rate. This can occur at the expense of request latency. We don't recommend adaptive retry mode when predictable latency is important.\n\nYou can find an expanded definition of these retry modes in the Retry behavior topic in the AWS SDKs and Tools Reference Guide.\n\nRetry policies\n\nAll RetryMode configurations have a RetryPolicy, which is built based on one or more RetryCondition configurations. The TokenBucketRetryCondition is especially important to the retry behavior of the DynamoDB SDK client implementation. This condition limits the number of retries that the SDK makes using a token bucket algorithm. Depending on the selected retry mode, throttling exceptions may or may not subtract tokens from the TokenBucket.\n\nWhen a client encounters a retryable error, such as a throttling exception or a temporary server error, then the SDK automatically retries the request. You can control how many times and how quickly these retries happen.\n\nWhen configuring a client, you can provide a RetryPolicy that supports the following parameters:\n\nnumRetries – The maximum number of retries that should be applied before a request is considered to be failed. The default value is 8 regardless of the retry mode that you use.\n\nWarning\n\nMake sure that you change this default value after due consideration.\n\nbackoffStrategy – The BackoffStrategy to apply to the retries, with FullJitterBackoffStrategy being the default strategy. This strategy performs an exponential delay between additional retries based on the current number or retries, a base delay, and a maximum backoff time. It then adds jitter to provide a bit of randomness. The base delay used in the exponential delay is 25 ms regardless of the retry mode.\n\nretryCondition – The RetryCondition determines whether to retry a request at all. By default, it retries a specific set of HTTP status codes and exceptions that it believes are retryable. For most situations, the default configuration should be sufficient.\n\nThe following code provides an alternative retry policy. It specifies a total of five retries (six total requests). The first retry should occur after a delay of approximately 100ms, with each additional retry doubling that time exponentially, up to a maximum delay of one second.\n\nDynamoDbClient client = DynamoDbClient.builder()\n    .overrideConfiguration(ClientOverrideConfiguration.builder()\n        .retryPolicy(RetryPolicy.builder()\n            .backoffStrategy(FullJitterBackoffStrategy.builder()\n                .baseDelay(Duration.ofMillis(100))\n                .maxBackoffTime(Duration.ofSeconds(1))\n                .build())\n            .numRetries(5)\n            .build())\n        .build())\n    .build();\n\nDefaultsMode\n\nThe timeout properties that ClientOverrideConfiguration and the RetryMode don't manage are typically configured implicitly by specifying a DefaultsMode.\n\nThe AWS SDK for Java 2.x (version 2.17.102 or later) introduced support for DefaultsMode. This feature provides a set of default values for common configurable settings, such as HTTP communication settings, retry behavior, service Regional endpoint settings, and potentially any SDK-related configuration. When you use this feature, you can get new configuration defaults tailored to common usage scenarios.\n\nThe default modes are standardized across all of the AWS SDKs. The SDK for Java 2.x supports the following default modes:\n\nlegacy – Provides default settings that vary by AWS SDK and that existed before DefaultsMode was established.\n\nstandard – Provides default non-optimized settings for most scenarios.\n\nin-region – Builds on the standard mode and includes settings tailored for applications that call AWS services from within the same AWS Region.\n\ncross-region – Builds on the standard mode and includes settings with high timeouts for applications that call AWS services in a different Region.\n\nmobile – Builds on the standard mode and includes settings with high timeouts tailored for mobile applications with higher latencies.\n\nauto – Builds on the standard mode and includes experimental features. The SDK attempts to discover the runtime environment to determine the appropriate settings automatically. The auto-detection is heuristics-based and does not provide 100% accuracy. If the runtime environment can't be determined, then standard mode is used. The auto-detection might query Instance metadata and user data, which might introduce latency. If startup latency is critical to your application, we recommend choosing an explicit DefaultsMode instead.\n\nYou can configure the defaults mode in the following ways:\n\nDirectly on a client, through AwsClientBuilder.Builder#defaultsMode(DefaultsMode).\n\nOn a configuration profile, through the defaults_mode profile file property.\n\nGlobally, through the aws.defaultsMode system property.\n\nGlobally, through the AWS_DEFAULTS_MODE environment variable.\n\nNote\n\nFor any mode other than legacy, the vended default values might change as best practices evolve. Therefore, if you're using a mode other than legacy, then we encourage you to perform testing when upgrading the SDK.\n\nThe Smart configuration defaults in the AWS SDKs and Tools Reference Guide provides a list of configuration properties and their default values in the different default modes.\n\nYou choose the defaults mode value based on your application's characteristics and the AWS service that the application interacts with.\n\nThese values are configured with a broad selection of AWS services in mind. For a typical DynamoDB deployment in which both your DynamoDB tables and application are deployed in one Region, the in-region defaults mode is most relevant among the standard default modes.\n\nExample DynamoDB SDK client configuration tuned for low-latency calls\n\nThe following example adjusts the timeouts to lower values for an expected low-latency DynamoDB call.\n\nDynamoDbAsyncClient asyncClient = DynamoDbAsyncClient.builder()\n    .defaultsMode(DefaultsMode.IN_REGION)\n    .httpClientBuilder(AwsCrtAsyncHttpClient.builder())\n    .overrideConfiguration(ClientOverrideConfiguration.builder()\n        .apiCallTimeout(Duration.ofSeconds(3))\n        .apiCallAttemptTimeout(Duration.ofMillis(500))\n        .build())\n    .build();\n\n\nThe individual HTTP client implementation may provide you with even more granular control over the timeout and connection usage behavior. For example, for the AWS CRT-based client, you can enable ConnectionHealthConfiguration, which enables the client to actively monitor the health of the used connections. For more information, see Advanced configuration of AWS CRT-based HTTP clients in the AWS SDK for Java 2.x Developer Guide.\n\nKeep-Alive configuration\n\nEnabling keep-alive can reduce latencies by reusing connections. There are two different kinds of keep-alive: HTTP Keep-Alive and TCP Keep-Alive.\n\nHTTP Keep-Alive attempts to maintain the HTTPS connection between the client and server so later requests can reuse that connection. This skips the heavyweight HTTPS authentication on later requests. HTTP Keep-Alive is enabled by default on all clients.\n\nTCP Keep-Alive requests that the underlying operating system sends small packets over the socket connection to provide extra assurance that the socket is kept alive and to immediately detect any drops. This ensures that a later request won't spend time trying to use a dropped socket. By default, TCP Keep-Alive is disabled on all clients. The following code examples show how to enable it on each HTTP client. When enabled for all non-CRT based HTTP clients, the actual Keep-Alive mechanism is dependent on the operating system. Therefore, you must configure additional TCP Keep-Alive values, such as timeout and number of packets, through the operating system. You can do this using sysctl on Linux or macOS, or using registry values on Windows.\n\nExample to enable TCP Keep-Alive on an Apache-based HTTP client\nDynamoDbClient client = DynamoDbClient.builder()\n    .httpClientBuilder(ApacheHttpClient.builder().tcpKeepAlive(true))\n    .build();\n\nURLConnection-based HTTP client\n\nAny synchronous client that uses the URLConnection-based HTTP client HttpURLConnection doesn't have a mechanism to enable keep-alive.\n\nExample to enable TCP Keep-Alive on a Netty-based HTTP client\nDynamoDbAsyncClient client = DynamoDbAsyncClient.builder()\n    .httpClientBuilder(NettyNioAsyncHttpClient.builder().tcpKeepAlive(true))\n    .build();\n\nExample to enable TCP Keep-Alive on an AWS CRT-based HTTP client\n\nWith the AWS CRT-based HTTP client, you can enable TCP keep-alive and control the duration.\n\nDynamoDbClient client = DynamoDbClient.builder()\n    .httpClientBuilder(AwsCrtHttpClient.builder()\n    .tcpKeepAliveConfiguration(TcpKeepAliveConfiguration.builder()\n        .keepAliveInterval(Duration.ofSeconds(50))\n        .keepAliveTimeout(Duration.ofSeconds(5))\n        .build()))\n    .build();\n\n\nWhen using the asynchronous DynamoDB client, you can enable TCP Keep-Alive as shown in the following code.\n\nDynamoDbAsyncClient client = DynamoDbAsyncClient.builder()\n    .httpClientBuilder(AwsCrtAsyncHttpClient.builder()\n    .tcpKeepAliveConfiguration(TcpKeepAliveConfiguration.builder()\n        .keepAliveInterval(Duration.ofSeconds(50))\n        .keepAliveTimeout(Duration.ofSeconds(5))\n        .build()))\n    .build();\n\nError handling\n\nWhen it comes to exception handling, the AWS SDK for Java 2.x uses runtime (unchecked) exceptions.\n\nThe base exception, covering all SDK exceptions, is SdkServiceException, which extends from the Java unchecked RuntimeException. If you catch this, you'll catch all exceptions that the SDK throws.\n\nSdkServiceException has a subclass called AwsServiceException. This subclass indicates any issue in communication with the AWS service. It has a subclass called DynamoDbException, which indicates an issue in communication with DynamoDB. If you catch this, you'll catch all exceptions related to DynamoDB, but no other SDK exceptions.\n\nThere are more specific exception types under DynamoDbException. Some of these exception types apply to control-plane operations such as TableAlreadyExistsException. Others apply to data-plane operations. The following is an example of a common data-plane exception:\n\nConditionalCheckFailedException – You specified a condition in the request that evaluated to false. For example, you might have tried to perform a conditional update on an item, but the actual value of the attribute did not match the expected value in the condition. A request that fails in this manner isn't retried.\n\nOther situations don't have a specific exception defined. For example, when your requests get throttled the specific ProvisionedThroughputExceededException might get thrown, while in other cases the more generic DynamoDbException is thrown. In either case, you can determine if throttling caused the exception by checking if isThrottlingException() returns true.\n\nDepending on your application needs, you can catch all AwsServiceException or DynamoDbException instances. However, you often need different behavior in different situations. The logic to deal with a condition check failure is different than that to handle throttling. Define which exceptional paths you want to deal with and make sure to test the alternative paths. This helps you make sure that you can deal with all relevant scenarios.\n\nFor lists of common errors that you might encounter, see Error handling with DynamoDB. Also see Common Errors in the Amazon DynamoDB API Reference. The API Reference also provides the exact errors possible for each API operation, such as for the Query operation. For information about handling exceptions, see Exception handling for the AWS SDK for Java 2.x in the AWS SDK for Java 2.x Developer Guide.\n\nAWS request ID\n\nEach request includes a request ID, which can be useful to pull if you're working with AWS Support to diagnose an issue. Each exception derived from SdkServiceException has a requestId() method available to retrieve the request ID.\n\nLogging\n\nUsing the logging provided that the SDK provides can be useful both for catching any important messages from the client libraries and for more in-depth debugging purposes. Loggers are hierarchical and the SDK uses software.amazon.awssdk as its root logger. You can configure the level with one of TRACE, DEBUG, INFO, WARN, ERROR, ALL, or OFF. The configured level applies to that logger and down into the logger hierarchy.\n\nFor its logging, the AWS SDK for Java 2.x uses the Simple Logging Façade for Java (SLF4J). This acts as an abstraction layer around other loggers, and you can use it to plug in the logger that you prefer. For instructions about plugging in loggers, see the SLF4J user manual.\n\nEach logger has a particular behavior. By default, the Log4j 2.x logger creates a ConsoleAppender, which appends log events to System.out and defaults to the ERROR log level.\n\nThe SimpleLogger logger included in SLF4J outputs by default to System.err and defaults to the INFO log level.\n\nWe recommend that you set the level to WARN for software.amazon.awssdk for any production deployments to catch any important messages from the SDK's client libraries while limiting the output quantity.\n\nIf SLF4J can't find a supported logger on the class path (no SLF4J binding), then it defaults to a no operation implementation. This implementation results in logging messages to System.err explaining that SLF4J could not find a logger implementation on the classpath. To prevent this situation, you must add a logger implementation. To do this, you can add a dependency in your Apache Maven pom.xml on artifacts, such as org.slf4j.slf4j-simple or org.apache.logging.log4j.log4j-slf4j2-imp.\n\nFor information about how to configure the logging in the SDK, including adding logging dependencies to your application configuration, see Logging with the SDK for Java 2.x in the AWS SDK for Java Developer Guide.\n\nThe following configuration in the Log4j2.xml file shows how to adjust the logging behavior if you use the Apache Log4j 2 logger. This configuration sets the root logger level to WARN. All loggers in the hierarchy inherit this log level, including the software.amazon.awssdk logger.\n\nBy default, the output goes to System.out. In the following example, we still override the default output Log4j appender to apply a tailored Log4j PatternLayout.\n\nExample of a Log4j2.xml configuration file\n\nThe following configuration logs messages to the console at the ERROR and WARN levels for all logger hierarchies.\n\n<Configuration status=\"WARN\">\n  <Appenders>\n    <Console name=\"ConsoleAppender\" target=\"SYSTEM_OUT\">\n      <PatternLayout pattern=\"%d{YYYY-MM-dd HH:mm:ss} [%t] %-5p %c:%L - %m%n\" />\n    </Console>\n  </Appenders>\n\n  <Loggers>\n    <Root level=\"WARN\">\n      <AppenderRef ref=\"ConsoleAppender\"/>\n    </Root>\n  </Loggers>\n</Configuration>\n\nAWS request ID logging\n\nWhen something goes wrong, you can find request IDs within exceptions. However, if you want the request IDs for requests that aren't generating exceptions, then you can use logging.\n\nThe software.amazon.awssdk.request logger outputs request IDs at the DEBUG level. The following example extends the previous configuration example to keep the root logger level at ERROR, the software.amazon.awssdk at level WARN, and the software.amazon.awssdk.request at level DEBUG. Setting these levels helps to catch the request IDs and other request-related details, such as the endpoint and status code.\n\n<Configuration status=\"WARN\">\n  <Appenders>\n    <Console name=\"ConsoleAppender\" target=\"SYSTEM_OUT\">\n      <PatternLayout pattern=\"%d{YYYY-MM-dd HH:mm:ss} [%t] %-5p %c:%L - %m%n\" />\n    </Console>\n  </Appenders>\n\n  <Loggers>\n    <Root level=\"ERROR\">\n      <AppenderRef ref=\"ConsoleAppender\"/>\n    </Root>\n    <Logger name=\"software.amazon.awssdk\" level=\"WARN\" />\n    <Logger name=\"software.amazon.awssdk.request\" level=\"DEBUG\" />\n  </Loggers>\n</Configuration>\n\n\nHere is an example of the log output:\n\n2022-09-23 16:02:08 [main] DEBUG software.amazon.awssdk.request:85 - Sending Request: DefaultSdkHttpFullRequest(httpMethod=POST, protocol=https, host=dynamodb.us-east-1.amazonaws.com, encodedPath=/, headers=[amz-sdk-invocation-id, Content-Length, Content-Type, User-Agent, X-Amz-Target], queryParameters=[])\n 2022-09-23 16:02:08 [main] DEBUG software.amazon.awssdk.request:85 - Received successful response: 200, Request ID: QS9DUMME2NHEDH8TGT9N5V53OJVV4KQNSO5AEMVJF66Q9ASUAAJG, Extended Request ID: not available\nPagination\n\nSome requests, such as Query and Scan, limit the size of data returned on a single request and require you make repeated requests to pull subsequent pages.\n\nYou can control the maximum number of items to read for each page with the Limit parameter. For example, you can use the Limit parameter to retrieve only the last 10 items. This limit specifies how many items to read from the table before any filtering is applied. If you want exactly 10 items after filtering, there's no way to specify that. You can control only the pre-filtered count and check client-side when you've actually retrieved 10 items. Regardless of the limit, responses always have a maximum size of 1 MB.\n\nA LastEvaluatedKey might be included in the API response. This indicates that the response ended because it reached a count limit or a size limit. This key is the last key evaluated for that response. By interacting directly with the API, you can retrieve this LastEvaluatedKey and pass it to a follow-up call as ExclusiveStartKey to read the next chunk from that starting point. If no LastEvaluatedKey is returned, it means that there are no more items that match the Query or Scan API call.\n\nThe following example uses the low-level interface to limit the items to 100 based on the keyConditionExpression parameter.\n\nQueryRequest.Builder queryRequestBuilder = QueryRequest.builder()\n        .expressionAttributeValues(Map.of(\n                \":pk_val\", AttributeValue.fromS(\"123\"),\n                \":sk_val\", AttributeValue.fromN(\"1000\")))\n        .keyConditionExpression(\"pk = :pk_val AND sk > :sk_val\")\n        .limit(100)\n        .tableName(TABLE_NAME);\n\nwhile (true) {\n    QueryResponse queryResponse = DYNAMODB_CLIENT.query(queryRequestBuilder.build());\n\n    queryResponse.items().forEach(item -> {\n        LOGGER.info(\"item PK: [\" + item.get(\"pk\") + \"] and SK: [\" + item.get(\"sk\") + \"]\");\n    });\n\n    if (!queryResponse.hasLastEvaluatedKey()) {\n        break;\n    }\n    queryRequestBuilder.exclusiveStartKey(queryResponse.lastEvaluatedKey());\n}\n\n\nThe AWS SDK for Java 2.x can simplify this interaction with DynamoDB by providing auto-pagination methods that make multiple service calls to automatically get the next pages of results for you. This simplifies your code, but it takes away some control of resource usage that you would keep by manually reading pages.\n\nBy using the Iterable methods available in the DynamoDB client, such as QueryPaginator and ScanPaginator, the SDK takes care of the pagination. The return type of these methods is a custom iterable that you can use to iterate through all the pages. The SDK internally handles service calls for you. Using the Java Stream API, you can handle the result of QueryPaginator as shown in the following example.\n\nQueryPublisher queryPublisher =\n    DYNAMODB_CLIENT.queryPaginator(QueryRequest.builder()\n        .expressionAttributeValues(Map.of(\n            \":pk_val\", AttributeValue.fromS(\"123\"),\n            \":sk_val\", AttributeValue.fromN(\"1000\")))\n        .keyConditionExpression(\"pk = :pk_val AND sk > :sk_val\")\n        .limit(100)\n        .tableName(\"YourTableName\")\n        .build());\n\nqueryPublisher.items().subscribe(item ->\n    System.out.println(item.get(\"itemData\"))).join();\n\nData class annotations\n\nThe Java SDK provides several annotations that you can put on the attributes of your data class. These annotations influence how the SDK interacts with the attributes. By adding an annotation, you can have an attribute behave as an implicit atomic counter, maintain an auto-generated timestamp value, or track an item version number. For more information, see Data class annotations."
  },
  {
    "title": "Working with tables, items, queries, scans, and indexes - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithDynamo.html",
    "html": "Working with tables, items, queries, scans, and indexes\nPDF\nRSS\n\nThis section provides details about working with tables, items, queries, and more in Amazon DynamoDB.\n\nTopics\nWorking with tables and data in DynamoDB\nGlobal tables - multi-Region replication for DynamoDB\nWorking with read and write operations\nImproving data access with secondary indexes\nManaging complex workflows with DynamoDB transactions\nChange data capture with Amazon DynamoDB\nUsing On-Demand backup and restore for DynamoDB\nPoint-in-time recovery for DynamoDB"
  },
  {
    "title": "Programming Amazon DynamoDB with JavaScript - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/programming-with-javascript.html",
    "html": "Programming Amazon DynamoDB with JavaScript\nPDF\nRSS\n\nThis guide provides an orientation to programmers wanting to use Amazon DynamoDB with JavaScript. Learn about the AWS SDK for JavaScript, abstraction layers available, configuring connections, handling errors, defining retry policies, managing keep-alive, and more.\n\nTopics\nAbout AWS SDK for JavaScript\nUsing the AWS SDK for JavaScript V3\nAccessing JavaScript documentation\nAbstraction layers\nUsing the marshall utility function\nReading items\nConditional writes\nPagination\nSpecifying configuration\nWaiters\nError handling\nLogging\nConsiderations\nAbout AWS SDK for JavaScript\n\nThe AWS SDK for JavaScript provides access to AWS services using either browser scripts or Node.js. This documentation focuses on the latest version of the SDK (V3). The AWS SDK for JavaScript V3 is maintained by AWS as an open-source project hosted on GitHub. Issues and feature requests are public and you can access them on the issues page for the GitHub repository.\n\nJavaScript V2 is similar to V3, but contains syntax differences. V3 is more modular, making it easier to ship smaller dependencies, and has first-class TypeScript support. We recommend using the latest version of the SDK.\n\nUsing the AWS SDK for JavaScript V3\n\nYou can add the SDK to your Node.js application using the Node Package Manager. The examples below show how to add the most common SDK packages for working with DynamoDB.\n\nnpm install @aws-sdk/client-dynamodb\n\nnpm install @aws-sdk/lib-dynamodb\n\nnpm install @aws-sdk/util-dynamodb\n\nInstalling packages adds references to the dependency section of your package.json project file. You have the option to use the newer ECMAScript module syntax. For further details on these two approaches, see the Considerations section.\n\nAccessing JavaScript documentation\n\nGet started with JavaScript documentation with the following resources:\n\nAccess the Developer guide for core JavaScript documentation. Installation instructions are located in the Setting up section.\n\nAccess the API reference documentation to explore all available classes and methods.\n\nThe SDK for JavaScript supports many AWS services other than DynamoDB. Use the following procedure to locate specific API coverage for DynamoDB:\n\nFrom Services, choose DynamoDB and Libraries. This documents the low-level client.\n\nChoose lib-dynamodb. This documents the high-level client. The two clients represent two different abstraction layers that you have the choice to use. See the section below for more information about abstraction layers.\n\nAbstraction layers\n\nThe SDK for JavaScript V3 has a low-level client (DynamoDBClient) and a high-level client (DynamoDBDocumentClient).\n\nTopics\nLow-level client (DynamoDBClient)\nHigh-level client (DynamoDBDocumentClient)\nLow-level client (DynamoDBClient)\n\nThe low-level client provides no extra abstractions over the underlying wire protocol. It gives you full control over all aspects of communication, but because there are no abstractions, you must do things like provide item definitions using the DynamoDB JSON format.\n\nAs the example below shows, with this format data types must be stated explicitly. An S indicates a string value and an N indicates a number value. Numbers on the wire are always sent as strings tagged as number types to ensure no loss in precision. The low-level API calls have a naming pattern such as PutItemCommand and GetItemCommand.\n\nThe following example is using low-level client with Item defined using DynamoDB JSON:\n\nconst { DynamoDBClient, PutItemCommand } = require(\"@aws-sdk/client-dynamodb\");\n\nconst client = new DynamoDBClient({});\n\nasync function addProduct() {\n  const params = {\n    TableName: \"products\",\n    Item: {\n      \"id\": { S: \"Product01\" },\n      \"description\": { S: \"Hiking Boots\" },\n      \"category\": { S: \"footwear\" },\n      \"sku\": { S: \"hiking-sku-01\" },\n      \"size\": { N: \"9\" }\n    }\n  };\n\n  try {\n    const data = await client.send(new PutItemCommand(params));\n    console.log('result : ' + JSON.stringify(data));\n  } catch (error) {\n    console.error(\"Error:\", error);\n  }\n}\naddProduct();\n\nHigh-level client (DynamoDBDocumentClient)\n\nThe high-level DynamoDB document client offers built-in convenience features, such as eliminating the need to manually marshal data and allowing for direct reads and writes using standard JavaScript objects. The documentation for lib-dynamodb provides the list of advantages.\n\nTo instantiate the DynamoDBDocumentClient, construct a low-level DynamoDBClient and then wrap it with a DynamoDBDocumentClient. The function naming convention differs slightly between the two packages. For instance, the low-level uses PutItemCommand while the high-level uses PutCommand. The distinct names allow both sets of functions to coexist in the same context, allowing you to mix both in the same script.\n\nconst { DynamoDBClient } = require(\"@aws-sdk/client-dynamodb\");\nconst { DynamoDBDocumentClient, PutCommand } = require(\"@aws-sdk/lib-dynamodb\");\n\nconst client = new DynamoDBClient({});\n\nconst docClient = DynamoDBDocumentClient.from(client);\n\nasync function addProduct() {\n  const params = {\n    TableName: \"products\",\n    Item: {\n      id: \"Product01\",\n      description: \"Hiking Boots\",\n      category: \"footwear\",\n      sku: \"hiking-sku-01\",\n      size: 9,\n    },\n  };\n\n  try {\n    const data = await docClient.send(new PutCommand(params));\n    console.log('result : ' + JSON.stringify(data));\n  } catch (error) {\n    console.error(\"Error:\", error);\n  }\n}\n\naddProduct();\n\n\nThe pattern of usage is consistent when you're reading items using API operations such as GetItem, Query, or Scan.\n\nUsing the marshall utility function\n\nYou can use the low-level client and marshall or unmarshall the data types on your own. The utility package, util-dynamodb, has a marshall() utility function that accepts JSON and produces DynamoDB JSON, as well as an unmarshall() function, that does the reverse. The following example uses the low-level client with data marshalling handled by the marshall() call.\n\nconst { DynamoDBClient, PutItemCommand } = require(\"@aws-sdk/client-dynamodb\");\nconst { marshall } = require(\"@aws-sdk/util-dynamodb\");\n\nconst client = new DynamoDBClient({});\n\nasync function addProduct() {\n  const params = {\n    TableName: \"products\",\n    Item: marshall({\n      id: \"Product01\",\n      description: \"Hiking Boots\",\n      category: \"footwear\",\n      sku: \"hiking-sku-01\",\n      size: 9,\n    }),\n  };\n\n  try {\n    const data = await client.send(new PutItemCommand(params));\n  } catch (error) {\n    console.error(\"Error:\", error);\n  }\n}\naddProduct();\n\nReading items\n\nTo read a single item from DynamoDB, you use the GetItem API operation. Similar to the PutItem command, you have the choice to use either the low-level client or the high-level Document client. The example below demonstrates using the high-level Document client to retrieve an item.\n\nconst { DynamoDBClient } = require(\"@aws-sdk/client-dynamodb\");\nconst { DynamoDBDocumentClient, GetCommand } = require(\"@aws-sdk/lib-dynamodb\");\n\nconst client = new DynamoDBClient({});\n\nconst docClient = DynamoDBDocumentClient.from(client);\n\nasync function getProduct() {\n  const params = {\n    TableName: \"products\",\n    Key: {\n      id: \"Product01\",\n    },\n  };\n\n  try {\n    const data = await docClient.send(new GetCommand(params));\n    console.log('result : ' + JSON.stringify(data));\n  } catch (error) {\n    console.error(\"Error:\", error);\n  }\n}\n\ngetProduct();\n\n\nUse the Query API operation to read multiple items. You can use the low-level client or the Document client. The example below uses the high-level Document client.\n\nconst { DynamoDBClient } = require(\"@aws-sdk/client-dynamodb\");\nconst {\n  DynamoDBDocumentClient,\n  QueryCommand,\n} = require(\"@aws-sdk/lib-dynamodb\");\n\nconst client = new DynamoDBClient({});\n\nconst docClient = DynamoDBDocumentClient.from(client);\n\nasync function productSearch() {\n  const params = {\n    TableName: \"products\",\n    IndexName: \"GSI1\",\n    KeyConditionExpression: \"#category = :category and begins_with(#sku, :sku)\",\n    ExpressionAttributeNames: {\n      \"#category\": \"category\",\n      \"#sku\": \"sku\",\n    },\n    ExpressionAttributeValues: {\n      \":category\": \"footwear\",\n      \":sku\": \"hiking\",\n    },\n  };\n\n  try {\n    const data = await docClient.send(new QueryCommand(params));\n    console.log('result : ' + JSON.stringify(data));\n  } catch (error) {\n    console.error(\"Error:\", error);\n  }\n}\n\nproductSearch();\n\nConditional writes\n\nDynamoDB write operations can specify a logical condition expression that must evaluate to true for the write to proceed. If the condition does not evaluate to true, the write operation generates an exception. The condition expression can check if the item already exists or if its attributes match certain constraints.\n\nConditionExpression = \"version = :ver AND size(VideoClip) < :maxsize\"\n\nWhen the conditional expression fails, you can use ReturnValuesOnConditionCheckFailure to request that the error response include the item that didn't satisfy the conditions to deduce what the problem was. For more details, see Handle conditional write errors in high concurrency scenarios with Amazon DynamoDB.\n\ntry {\n      const response = await client.send(new PutCommand({\n          TableName: \"YourTableName\",\n          Item: item,\n          ConditionExpression: \"attribute_not_exists(pk)\",\n          ReturnValuesOnConditionCheckFailure: \"ALL_OLD\"\n      }));\n  } catch (e) {\n      if (e.name === 'ConditionalCheckFailedException') {\n          console.log('Item already exists:', e.Item);\n      } else {\n          throw e;\n      }\n  }\n\n\nAdditional code examples showing other aspects of JavsScript SDK V3 usage are available in the JavaScript SDK V3 Documentation and under the DynamoDB-SDK-Examples GitHub repository.\n\nPagination\nTopics\nUsing the paginateScan convenience method\n\nRead requests such as Scan or Query will likely return multiple items in a dataset. If you perform a Scan or Query with a Limit parameter, then once the system has read that many items, a partial response will be sent, and you'll need to paginate to retrieve additional items.\n\nThe system will only read a maximum of 1 megabyte of data per request. If you're including a Filter expression, the system will still read a megabyte, at maximum, of data from disk, but will return the items of that megabyte that match the filter. The filter operation could return 0 items for a page, but still require further pagination before the search is exhausted.\n\nYou should look for LastEvaluatedKey in the response and using it as the ExclusiveStartKey parameter in a subsequent request to continue data retrieval. This serves as a bookmark as noted in the following example.\n\nNote\n\nThe sample passes a null lastEvaluatedKey as the ExclusiveStartKey on the first iteration and this is allowed.\n\nExample using the LastEvaluatedKey:\n\nconst { DynamoDBClient, ScanCommand } = require(\"@aws-sdk/client-dynamodb\");\n\nconst client = new DynamoDBClient({});\n\nasync function paginatedScan() {\n  let lastEvaluatedKey;\n  let pageCount = 0;\n\n  do {\n    const params = {\n      TableName: \"products\",\n      ExclusiveStartKey: lastEvaluatedKey,\n    };\n\n    const response = await client.send(new ScanCommand(params));\n    pageCount++;\n    console.log(`Page ${pageCount}, Items:`, response.Items);\n    lastEvaluatedKey = response.LastEvaluatedKey;\n  } while (lastEvaluatedKey);\n}\n\npaginatedScan().catch((err) => {\n  console.error(err);\n});\n\nUsing the paginateScan convenience method\n\nThe SDK provides convenience methods called paginateScan and paginateQuery that do this work for you and makes the repeated requests behind the scenes. Specify the max number of items to read per request using the standard Limit parameter.\n\nconst { DynamoDBClient, paginateScan } = require(\"@aws-sdk/client-dynamodb\");\n\nconst client = new DynamoDBClient({});\n\nasync function paginatedScanUsingPaginator() {\n  const params = {\n    TableName: \"products\",\n    Limit: 100\n  };\n\n  const paginator = paginateScan({client}, params);\n\n  let pageCount = 0;\n\n  for await (const page of paginator) {\n    pageCount++;\n    console.log(`Page ${pageCount}, Items:`, page.Items);\n  }\n}\n\npaginatedScanUsingPaginator().catch((err) => {\n  console.error(err);\n});\n\nNote\n\nPerforming full table scans regularly is not a recommended access pattern unless the table is small.\n\nSpecifying configuration\nTopics\nConfig for timeouts\nConfig for keep-alive\nConfig for retries\n\nWhen setting up the DynamoDBClient, you can specify various configuration overrides by passing a configuration object to the constructor. For example, you can specify the Region to connect to if it's not already known to the calling context or the endpoint URL to use. This is useful if you want to target a DynamoDB Local instance for development purposes.\n\nconst client = new DynamoDBClient({\n  region: \"eu-west-1\",\n  endpoint: \"http://localhost:8000\",\n});\n\nConfig for timeouts\n\nDynamoDB uses HTTPS for client-server communication. You can control some aspects of the HTTP layer by providing a NodeHttpHandler object. For example, you can adjust the key timeout values connectionTimeout and requestTimeout. The connectionTimeout is the maximum duration, in milliseconds, that the client will wait while trying to establish a connection before giving up.\n\nThe requestTimeout defines how long the client will wait for a response after a request has been sent, also in milliseconds. The defaults for both are zero, meaning the timeout is disabled and there's no limit on how long the client will wait if the response does not arrive. You should set the timeouts to something reasonable so in the event of a network issue the request will error out and a new request can be initiated. For example:\n\nimport { DynamoDBClient } from \"@aws-sdk/client-dynamodb\";\nimport { NodeHttpHandler } from \"@smithy/node-http-handler\";\n\nconst requestHandler = new NodeHttpHandler({\n  connectionTimeout: 2000,\n  requestTimeout: 2000,\n});\n\nconst client = new DynamoDBClient({\n  requestHandler\n});\n\nNote\n\nThe example provided uses the Smithy import. Smithy is a language for defining services and SDKs, open-source and maintained by AWS.\n\nIn addition to configuring timeout values, you can set the maximum number of sockets, which allows for an increased number of concurrent connections per origin. The developer guide includes details on configuring the maxSockets parameter.\n\nConfig for keep-alive\n\nWhen using HTTPS, the first request always takes some back-and-forth communication to establish a secure connection. HTTP Keep-Alive allows subsequent requests to reuse the already-established connection, making the requests more efficient and lowering latency. HTTP Keep-Alive is enabled by default with JavaScript V3.\n\nThere's a limit to how long an idle connection can be kept alive. Consider sending periodic requests, maybe every minute, if you have an idle connection but want the next request to use an already-established connection.\n\nNote\n\nNote that in the older V2 of the SDK, keep-alive was off by default, meaning each connection would get closed immediately after use. If using V2, you can override this setting.\n\nConfig for retries\n\nWhen the SDK receives an error response and the error is resumable as determined by the SDK, such as a throttling exception or a temporary service exception, it will retry again. This happens invisibly to you as the caller, except that you might notice the request took longer to succeed.\n\nThe SDK for JavaScript V3 will make 3 total requests, by default, before giving up and passing the error into the calling context. You can adjust the number and frequency of these retries.\n\nThe DynamoDBClient constructor accepts a maxAttempts setting that limits how many attempts will happen. The below example raises the value from the default of 3 to a total of 5. If you set it to 0 or 1, that indicates you don't want any automatic retries and want to handle any resumable errors yourself within your catch block.\n\nconst client = new DynamoDBClient({\n  maxAttempts: 5,\n});\n\n\nYou can also control the timing of the retries with a custom retry strategy. To do this, import the util-retry utility package and create a custom backoff function that calculates the wait time between retries based on the current retry count.\n\nThe example below says to make a maximum of 5 attempts with delays of 15, 30, 90, and 360 milliseconds should the first attempt fail. The custom backoff function, calculateRetryBackoff, calculates the delays by accepting the retry attempt number (starts with 1 for the first retry) and returns how many milliseconds to wait for that request.\n\nconst { ConfiguredRetryStrategy } = require(\"@aws-sdk/util-retry\");\n\nconst calculateRetryBackoff = (attempt) => {\n  const backoffTimes = [15, 30, 90, 360];\n  return backoffTimes[attempt - 1] || 0;\n};\n\nconst client = new DynamoDBClient({\n  retryStrategy: new ConfiguredRetryStrategy(\n    5, // max attempts.\n    calculateRetryBackoff // backoff function.\n  ),\n});\n\nWaiters\n\nThe DynamoDB client includes two useful waiter functions that can be used when creating, modifying, or deleting tables when you want your code to wait to proceed until the table modification has finished. For example, you can deploy a table, call the waitUntilTableExists function, and the code will block until the table has been made ACTIVE. The waiter internally polls the DynamoDB service with a describe-table every 20 seconds.\n\nimport {waitUntilTableExists, waitUntilTableNotExists} from \"@aws-sdk/client-dynamodb\";\n\n… <create table details>\n\nconst results = await waitUntilTableExists({client: client, maxWaitTime: 180}, {TableName: \"products\"});\nif (results.state == 'SUCCESS') {\n  return results.reason.Table\n}\nconsole.error(`${results.state} ${results.reason}`);\n\n\nThe waitUntilTableExists feature returns control only when it can perform a describe-table command that shows the table status ACTIVE. This ensures that you can use waitUntilTableExists to wait for the completion of creation, as well as modifications such as adding a GSI index, which may take some time to apply before the table returns to ACTIVE status.\n\nError handling\n\nIn the early examples here, we've caught all errors broadly. However, in practical applications, it's important to discern between various error types and implement more precise error handling.\n\nDynamoDB error responses contain metadata, including the name of the error. You can catch errors then match against the possible string names of error conditions to determine how to proceed. For server-side errors, you can leverage the instanceof operator with the error types exported by the @aws-sdk/client-dynamodb package to manage error handling efficiently.\n\nIt's important to note that these errors only manifest after all retries have been exhausted. If an error is retried and is eventually followed by a successful call, from the code's perspective, there's no error just a slightly elevated latency. Retries will show up in Amazon CloudWatch charts as unsuccessful requests, such as throttle or error requests. If the client reaches the maximum retry count, it will give up and generate an exception. This is the client's way of saying it's not going to retry.\n\nBelow is a snippet to catch the error and take action based on the type of error that was returned.\n\nimport {\n  ResourceNotFoundException\n  ProvisionedThroughputExceededException,\n  DynamoDBServiceException,\n} from \"@aws-sdk/client-dynamodb\";\n\ntry {\n  await client.send(someCommand);\n} catch (e) {\n    if (e instanceof ResourceNotFoundException) {\n      // Handle ResourceNotFoundException\n    } else if (e instanceof ProvisionedThroughputExceededException) {\n      // Handle ProvisionedThroughputExceededException\n    } else if (e instanceof DynamoDBServiceException) {\n      // Handle DynamoDBServiceException\n    } else {\n      // Other errors such as those from the SDK\n      if (e.name === \"TimeoutError\") {\n        // Handle SDK TimeoutError.\n      } else {\n        // Handle other errors.\n      }\n    }\n}\n\n\nSee Error handling with DynamoDB for common error strings in the DynamoDB Developer Guide. The exact errors possible with any particular API call can be found in the documentation for that API call, such as the Query API docs.\n\nThe metadata of errors include additional properties, depending on the error. For a TimeoutError, the metadata includes the number of attempts that were made and the totalRetryDelay, as shown below.\n\n{\n  \"name\": \"TimeoutError\",\n  \"$metadata\": {\n    \"attempts\": 3,\n    \"totalRetryDelay\": 199\n  }\n}\n\n\nIf you manage your own retry policy, you'll want to differentiate between throttles and errors:\n\nA throttle (indicated by a ProvisionedThroughputExceededException or ThrottlingException) indicates a healthy service that's informing you that you've exceeded your read or write capacity on a DynamoDB table or partition. Every millisecond that passes, a bit more read or write capacity is made available, and so you can retry quickly, such as every 50ms, to attempt to access that newly released capacity.\n\nWith throttles you don't especially need exponential backoff because throttles are lightweight for DynamoDB to return and incur no per-request charge to you. Exponential backoff assigns longer delays to client threads that have already waited the longest, which statistically extends the p50 and p99 outward.\n\nAn error (indicated by an InternalServerError or a ServiceUnavailable, among others) indicates a transient issue with the service, possibly the whole table or just the partition you're reading from or writing to. With errors, you can pause longer before retries, such as 250ms or 500ms, and use jitter to stagger the retries.\n\nLogging\n\nTurn on logging to get more details about what the SDK is doing. You can set a parameter on the DynamoDBClient as shown in the example below. More log information will appear in the console and includes metadata such as the status code and the consumed capacity. If you run the code locally in a terminal window, the logs appear there. If you run the code in AWS Lambda, and you have Amazon CloudWatch logs set up, then the console output will be written there.\n\nconst client = new DynamoDBClient({\n  logger: console\n});\n\n\nYou can also hook into the internal SDK activities and perform custom logging as certain events happen. The example below uses the client's middlewareStack to intercept each request as it's being sent from the SDK and logs it as it's happening.\n\nconst client = new DynamoDBClient({});\n\nclient.middlewareStack.add(\n  (next) => async (args) => {\n    console.log(\"Sending request from AWS SDK\", { request: args.request });\n    return next(args);\n  },\n  {\n    step: \"build\",\n    name: \"log-ddb-calls\",\n  }\n);\n\n\nThe MiddlewareStack provides a powerful hook for observing and controlling SDK behavior. See the blog Introducing Middleware Stack in Modular AWS SDK for JavaScript, for more information.\n\nConsiderations\n\nWhen implementing the AWS SDK for JavaScript in your project, here are some further factors to consider.\n\nModule systems\n\nThe SDK supports two module systems, CommonJS and ES (ECMAScript). CommonJS uses the require function, while ES uses the import keyword.\n\nCommon JS – const { DynamoDBClient, PutItemCommand } = require(\"@aws-sdk/client-dynamodb\");\n\nES (ECMAScript – import { DynamoDBClient, PutItemCommand } from \"@aws-sdk/client-dynamodb\";\n\nThe project type dictates the module system to be used and is specified in the type section of your package.json file. The default is CommonJS. Use \"type\": \"module\" to indicate an ES project. If you have an existing Node.JS project that uses the CommonJS package format, you can still add functions with the more modern SDK V3 Import syntax by naming your function files with the .mjs extension. This will allow the code file to be treated as ES (ECMAScript).\n\nAsynchronous operations\n\nYou'll see many code samples using callbacks and promises to handle the result of DynamoDB operations. With modern JavaScript this complexity is no longer needed and developers can take advantage of the more succinct and readable async/await syntax for asynchronous operations.\n\nWeb browser runtime\n\nWeb and mobile developers building with React or React Native can use the SDK for JavaScript in their projects. With the earlier V2 of the SDK, web developers would have to load the full SDK into the browser, referencing an SDK image hosted at https://sdk.amazonaws.com/js/.\n\nWith V3, it's possible to bundle just the required V3 client modules and all required JavaScript functions into a single JavaScript file using Webpack, and add it in a script tag in the <head> of your HTML pages, as explained in the Getting started in a browser script section of the SDK documentation.\n\nDAX data plane operations\n\nThe SDK for JavaScript V3 does not at this time provide support for the Amazon DynamoDB Streams Accelerator (DAX) data plane operations. If you request DAX support, consider using the SDK for JavaScript V2 which supports DAX data plane operations."
  },
  {
    "title": "Programming Amazon DynamoDB with Python and Boto3 - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/programming-with-python.html",
    "html": "Programming Amazon DynamoDB with Python and Boto3\nPDF\nRSS\n\nThis guide provides an orientation to programmers wanting to use Amazon DynamoDB with Python. Learn about the different abstraction layers, configuration management, error handling, controlling retry policies, managing keep-alive, and more.\n\nTopics\nAbout Boto\nUsing the Boto documentation\nUnderstanding the client and resource abstraction layers\nUsing the table resource batch_writer\nAdditional code examples that explore the client and resource layers\nUnderstanding how the Client and Resource objects interact with sessions and threads\nCustomizing the Config object\nError handling\nLogging\nEvent hooks\nPagination and the Paginator\nWaiters\nAbout Boto\n\nYou can access DynamoDB from Python by using the official AWS SDK for Python, commonly referred to as Boto3. The name Boto (pronounced boh-toh) comes from a freshwater dolphin native to the Amazon River. The Boto3 library is the library’s third major version, first released in 2015. The Boto3 library is quite large, as it supports all AWS services, not just DynamoDB. This orientation targets only the parts of Boto3 relevant to DynamoDB.\n\nBoto is maintained and published by AWS as open-source project hosted on GitHub. It’s split into two packages: Botocore and Boto3.\n\nBotocore provides the low-level functionality. In Botocore you’ll find the client, session, credentials, config, and exception classes.\n\nBoto3 builds on top of Botocore. It offers a higher-level, more Pythonic interface. Specifically, it exposes a DynamoDB table as a Resource and offers a simpler, more elegant interface compared to the lower-level, service-oriented client interface.\n\nBecause these projects are hosted on GitHub, you can view the source code, track open issues, or submit your own issues.\n\nUsing the Boto documentation\n\nGet started with the Boto documentation with the following resources:\n\nBegin with the Quickstart section that provides a solid starting point for the package installation. Go there for instructions on getting Boto3 installed if it’s not already (Boto3 is often automatically available within AWS services such as AWS Lambda).\n\nAfter that, focus on the documentation’s DynamoDB guide. It shows you how to perform the basic DynamoDB activities: create and delete a table, manipulate items, run batch operations, run a query, and perform a scan. Its examples use the resource interface. When you see boto3.resource('dynamodb') that indicates you’re using the higher-level resource interface.\n\nAfter the guide, you can review the DynamoDB reference. This landing page provides an exhaustive list of the classes and methods available to you. At the top, you’ll see the DynamoDB.Client class. This provides low-level access to all the control-plane and data-plane operations. At the bottom, look at the DynamoDB.ServiceResource class. This is the higher-level Pythonic interface. With it you can create a table, do batch operations across tables, or obtain a DynamoDB.ServiceResource.Table instance for table-specific actions.\n\nUnderstanding the client and resource abstraction layers\n\nThe two interfaces you'll be working with are the client interface and the resource interface.\n\nThe low-level client interface provides a 1-to-1 mapping to the underlying service API. Every API offered by DynamoDB is available through the client. This means the client interface can provide complete functionality, but it's often more verbose and complex to use.\n\nThe higher-level resource interface does not provide a 1-to-1 mapping of the underlying service API. However, it provides methods that make it more convenient for you to access the service such as batch_writer.\n\nHere’s an example of inserting an item using the client interface. Notice how all values are passed as a map with the key indicating their type ('S' for string, 'N' for number) and their value as a string. This is known as DynamoDB JSON format.\n\nimport boto3\n\ndynamodb = boto3.client('dynamodb')\n\ndynamodb.put_item(\n    TableName='YourTableName',\n    Item={\n        'pk': {'S': 'id#1'},\n        'sk': {'S': 'cart#123'},\n        'name': {'S': 'SomeName'},\n        'inventory': {'N': '500'},\n        # ... more attributes ...\n    }\n)\n\n\nHere's the same PutItem operation using the resource interface. The data typing is implicit:\n\nimport boto3\n\ndynamodb = boto3.resource('dynamodb')\n\ntable = dynamodb.Table('YourTableName')\n\ntable.put_item(\n    Item={\n        'pk': 'id#1',\n        'sk': 'cart#123',\n        'name': 'SomeName',\n        'inventory': 500,\n        # ... more attributes ...\n    }\n)\n\n\n\nIf needed, you can convert between regular JSON and DynamoDB JSON using the TypeSerializer and TypeDeserializer classes provided with boto3:\n\ndef dynamo_to_python(dynamo_object: dict) -> dict:\n    deserializer = TypeDeserializer()\n    return {\n        k: deserializer.deserialize(v) \n        for k, v in dynamo_object.items()\n    }  \n  \ndef python_to_dynamo(python_object: dict) -> dict:\n    serializer = TypeSerializer()\n    return {\n        k: serializer.serialize(v)\n        for k, v in python_object.items()\n    }\n\n\nHere is how to perform a query using the client interface. It expresses the query as a JSON construct. It uses a KeyConditionExpression string which requires variable substitution to handle any potential keyword conflicts:\n\nimport boto3\n\nclient = boto3.client('dynamodb')\n\n# Construct the query\nresponse = client.query(\n    TableName='YourTableName',\n    KeyConditionExpression='pk = :pk_val AND begins_with(sk, :sk_val)',\n    FilterExpression='#name = :name_val',\n    ExpressionAttributeValues={\n        ':pk_val': {'S': 'id#1'},\n        ':sk_val': {'S': 'cart#'},\n        ':name_val': {'S': 'SomeName'},\n    },\n    ExpressionAttributeNames={\n        '#name': 'name',\n    }\n)\n\n\nThe same query operation using the resource interface can be shortened and simplified:\n\nimport boto3\nfrom boto3.dynamodb.conditions import Key, Attr\n\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('YourTableName')\n\nresponse = table.query(\n    KeyConditionExpression=Key('pk').eq('id#1') & Key('sk').begins_with('cart#'),\n    FilterExpression=Attr('name').eq('SomeName')\n)\n\n\nAs a final example, imagine you want to get the approximate size of a table (which is metadata kept on the table that is updated about every 6 hours). With the client interface, you do a describe_table() operation and pull the answer from the JSON structure returned:\n\nimport boto3\n\ndynamodb = boto3.client('dynamodb')\n\nresponse = dynamodb.describe_table(TableName='YourTableName')\nsize = response['Table']['TableSizeBytes']\n\n\n\nWith the resource interface, the table performs the describe operation implicitly and presents the data directly as an attribute:\n\nimport boto3\n\ndynamodb = boto3.resource('dynamodb')\n\ntable = dynamodb.Table('YourTableName')\nsize = table.table_size_bytes\n\nNote\n\nWhen considering whether to develop using the client or resource interface, be aware that new features will not be added to the resource interface per the resource documentation: “The AWS Python SDK team does not intend to add new features to the resources interface in boto3. Existing interfaces will continue to operate during boto3’s lifecycle. Customers can find access to newer service features through the client interface.”\n\nUsing the table resource batch_writer\n\nOne convenience available only with the higher-level table resource is the batch_writer. DynamoDB supports batch write operations allowing up to 25 put or delete operations in one network request. Batching like this improves efficiency by minimizing network round trips.\n\nWith the low-level client library, you use the client.batch_write_item() operation to run batches. You must manually split your work into batches of 25. After each operation, you also have to request to receive a list of unprocessed items (some of the write operations may succeed while others could fail). You then have to pass those unprocessed items again into a later batch_write_item() operation. There's a significant amount of boilerplate code.\n\nThe Table.batch_writer method creates a context manager for writing objects in a batch. It presents an interface where it seems as if you're writing items one at a time, but internally it's buffering and sending the items in batches. It also handles unprocessed item retries implicitly.\n\ndynamodb = boto3.resource('dynamodb')\n\ntable = dynamodb.Table('YourTableName')\n\nmovies = # long list of movies in {'pk': 'val', 'sk': 'val', etc} format\nwith table.batch_writer() as writer:\n    for movie in movies:\n        writer.put_item(Item=movie)\n\nAdditional code examples that explore the client and resource layers\n\nYou can also refer to the following code sample repositories that explore usage of the various functions, using both client and resource:\n\nOfficial AWS single-action code examples.\n\nOfficial AWS scenario-oriented code examples.\n\nCommunity-maintained single-action code examples.\n\nUnderstanding how the Client and Resource objects interact with sessions and threads\n\nThe Resource object is not thread safe and should not be shared across threads or processes. Refer to the guide on Resource for more details.\n\nThe Client object, in contrast, is generally thread safe, except for specific advanced features. Refer to the guide on Clients for more details.\n\nThe Session object is not thread safe. So, each time you make a Client or Resource in a multi-threaded environment you should create a new Session first and then make the Client or Resource from the Session. Refer to the guide on Sessions for more details.\n\nWhen you call the boto3.resource(), you’re implicitly using the default Session. This is convenient for writing single-threaded code. When writing multi-threaded code, you’ll want to first construct a new Session for each thread and then retrieve the resource from that Session:\n\n# Explicitly create a new Session for this thread \nsession = boto3.Session()\ndynamodb = session.resource('dynamodb')\n\nCustomizing the Config object\n\nWhen constructing a Client or Resource object, you can pass optional named parameters to customize behavior. The parameter named config unlocks a variety of functionality. It’s an instance of botocore.client.Config and the reference documentation for Config shows everything it exposes for you to control. The guide to Configuration provides a good overview.\n\nNote\n\nYou can modify many of these behavioral settings at the Session level, within the AWS configuration file, or as environment variables.\n\nConfig for timeouts\n\nOne use of a custom config is to adjust networking behaviors:\n\nconnect_timeout (float or int) – The time in seconds till a timeout exception is thrown when attempting to make a connection. The default is 60 seconds.\n\nread_timeout (float or int) – The time in seconds till a timeout exception is thrown when attempting to read from a connection. The default is 60 seconds.\n\nTimeouts of 60 seconds are excessive for DynamoDB. It means a transient network glitch will cause a minute’s delay for the client before it can try again. The following code shortens the timeouts to a second:\n\nimport boto3\nfrom botocore.config import Config\n\nmy_config = Config(\n   connect_timeout = 1.0,\n   read_timeout = 1.0\n)\ndynamodb = boto3.resource('dynamodb', config=my_config)\n\n\nFor more discussion about timeouts, see Tuning AWS Java SDK HTTP request settings for latency-aware DynamoDB applications. Note the Java SDK has more timeout configurations than Python.\n\nConfig for keep-alive\n\nIf you're using botocore 1.27.84 or later, you can also control TCP Keep-Alive:\n\ntcp_keepalive (bool) - Enables the TCP Keep-Alive socket option used when creating new connections if set to True ( defaults to False). This is only available starting with botocore 1.27.84.\n\nSetting TCP Keep-Alive to True can reduce average latencies. Here's sample code that conditionally sets TCP Keep-Alive to true when you have the right botocore version:\n\nimport botocore\nimport boto3\nfrom botocore.config import Config\nfrom distutils.version import LooseVersion\n\nrequired_version = \"1.27.84\"\ncurrent_version = botocore.__version__\n\nmy_config = Config(\n   connect_timeout = 0.5,\n   read_timeout = 0.5\n)\nif LooseVersion(current_version) > LooseVersion(required_version):\n    my_config = my_config.merge(Config(tcp_keepalive = True))\n\ndynamodb = boto3.resource('dynamodb', config=my_config)\n\nNote\n\nTCP Keep-Alive is different than HTTP Keep-Alive. With TCP Keep-Alive, small packets are sent by the underlying operating system over the socket connection to keep the connection alive and immediately detect any drops. With HTTP Keep-Alive, the web connection built on the underlying socket gets reused. HTTP Keep-Alive is always enabled with boto3.\n\nThere's a limit to how long an idle connection can be kept alive. Consider sending periodic requests (say every minute) if you have an idle connection but want the next request to use an already-established connection.\n\nConfig for retries\n\nThe config also accepts a dictionary called retries where you can specify your desired retry behavior. Retries happen within the SDK when the SDK receives an error and the error is of a transient type. If an error is retried internally (and a retry eventually produces a successful response), there's no error seen from the calling code's perspective, just a slightly elevated latency. Here are the values you can specify:\n\nmax_attempts – An integer representing the maximum number of retry attempts that will be made on a single request. For example, setting this value to 2 will result in the request being retried at most two times after the initial request. Setting this value to 0 will result in no retries ever being attempted after the initial request.\n\ntotal_max_attempts – An integer representing the maximum number of total attempts that will be made on a single request. This includes the initial request, so a value of 1 indicates that no requests will be retried. If total_max_attempts and max_attempts are both provided, total_max_attempts takes precedence. total_max_attempts is preferred over max_attempts because it maps to the AWS_MAX_ATTEMPTS environment variable and the max_attempts config file value.\n\nmode – A string representing the type of retry mode botocore should use. Valid values are:\n\nlegacy – The default mode. Waits 50ms the first retry, then uses exponential backoff with a base factor of 2. For DynamoDB, it performs up to 10 total max attempts (unless overridden with the above).\n\nNote\n\nWith exponential backoff, the last attempt will wait almost 13 seconds.\n\nstandard – Named standard because it’s more consistent with other AWS SDKs. Waits a random time from 0ms to 1,000ms for the first retry. If another retry is necessary, it picks another random time from 0ms to 1,000ms and multiplies it by 2. If an additional retry is necessary, it does the same random pick multiplied by 4, and so on. Each wait is capped at 20 seconds. This mode will perform retries on more detected failure conditions than the legacy mode. For DynamoDB, it performs up to 3 total max attempts (unless overridden with the above).\n\nadaptive - An experimental retry mode that includes all the functionality of standard mode but adds automatic client-side throttling. With adaptive rate limiting, SDKs can slow down the rate at which requests are sent to better accommodate the capacity of AWS services. This is a provisional mode whose behavior might change.\n\nAn expanded definition of these retry modes can be found in the guide to retries as well as in the Retry behavior topic in the SDK reference.\n\nHere’s an example that explicitly uses the legacy retry policy with a maximum of 3 total requests (2 retries):\n\nimport boto3\nfrom botocore.config import Config\n\nmy_config = Config(\n   connect_timeout = 1.0,\n   read_timeout = 1.0,\n   retries = {\n     'mode': 'legacy',\n     'total_max_attempts': 3\n   }\n)\ndynamodb = boto3.resource('dynamodb', config=my_config)\n\n\nBecause DynamoDB is a highly-available, low-latency system, you may want to be more aggressive with the speed of retries than the built-in retry policies allow. You can implement your own retry policy by setting the max attempts to 0, catching the exceptions yourself, and retrying as appropriate from your own code instead of relying on boto3 to do implicit retries.\n\nIf you manage your own retry policy, you'll want to differentiate between throttles and errors:\n\nA throttle (indicated by a ProvisionedThroughputExceededException or ThrottlingException) indicates a healthy service that's informing you that you've exceeded your read or write capacity on a DynamoDB table or partition. Every millisecond that passes, a bit more read or write capacity is made available, so you can retry quickly (such as every 50ms) to attempt to access that newly released capacity. With throttles, you don't especially need exponential backoff because throttles are lightweight for DynamoDB to return and incur no per-request charge to you. Exponential backoff assigns longer delays to client threads that have already waited the longest, which statistically extends the p50 and p99 outward.\n\nAn error (indicated by an InternalServerError or a ServiceUnavailable, among others) indicates a transient issue with the service. This can be for the whole table or possibly just the partition you're reading from or writing to. With errors, you can pause longer before retries (such as 250ms or 500ms) and use jitter to stagger the retries.\n\nConfig for max pool connections\n\nLastly, the config lets you control the connection pool size:\n\nmax_pool_connections (int) – The maximum number of connections to keep in a connection pool. If this value is not set, the default value of 10 is used.\n\nThis option controls the maximum number of HTTP connections to keep pooled for reuse. A different pool is kept per Session. If you anticipate more than 10 threads going against clients or resources built off the same Session, you should consider raising this, so threads don't have to wait on other threads using a pooled connection.\n\nimport boto3\nfrom botocore.config import Config\n\nmy_config = Config(\n   max_pool_connections = 20\n)\n\n# Setup a single session holding up to 20 pooled connections\nsession = boto3.Session(my_config)\n\n# Create up to 20 resources against that session for handing to threads\n# Notice the single-threaded access to the Session and each Resource\nresource1 = session.resource('dynamodb')\nresource2 = session.resource('dynamodb')\n# etc\n\nError handling\n\nAWS service exceptions aren’t all statically defined in Boto3. This is because errors and exceptions from AWS services vary widely and are subject to change. Boto3 wraps all service exceptions as a ClientError and exposes the details as structured JSON. For example, an error response might be structured like this:\n\n{\n    'Error': {\n        'Code': 'SomeServiceException',\n        'Message': 'Details/context around the exception or error'\n    },\n    'ResponseMetadata': {\n        'RequestId': '1234567890ABCDEF',\n        'HostId': 'host ID data will appear here as a hash',\n        'HTTPStatusCode': 400,\n        'HTTPHeaders': {'header metadata key/values will appear here'},\n        'RetryAttempts': 0\n    }\n}\n\n\nThe following code catches any ClientError exceptions and looks at the string value of the Code within the Error to determine what action to take:\n\nimport botocore\nimport boto3\n\ndynamodb = boto3.client('dynamodb')\n\ntry:\n    response = dynamodb.put_item(...)\n\nexcept botocore.exceptions.ClientError as err:\n    print('Error Code: {}'.format(err.response['Error']['Code']))\n    print('Error Message: {}'.format(err.response['Error']['Message']))\n    print('Http Code: {}'.format(err.response['ResponseMetadata']['HTTPStatusCode']))\n    print('Request ID: {}'.format(err.response['ResponseMetadata']['RequestId']))\n\n    if err.response['Error']['Code'] in ('ProvisionedThroughputExceededException', 'ThrottlingException'):\n        print(\"Received a throttle\")\n    elif err.response['Error']['Code'] == 'InternalServerError':\n        print(\"Received a server error\")\n    else:\n        raise err\n\n\nSome (but not all) exception codes have been materialized as top-level classes. You can choose to handle these directly. When using the Client interface, these exceptions are dynamically populated on your client and you catch these exceptions using your client instance, like this:\n\nexcept ddb_client.exceptions.ProvisionedThroughputExceededException:\n\nWhen using the Resource interface, you have to use .meta.client to traverse from the resource to the underlying Client to access the exceptions, like this:\n\nexcept ddb_resource.meta.client.exceptions.ProvisionedThroughputExceededException:\n\nTo review the list of materialized exception types, you can generate the list dynamically:\n\nddb = boto3.client(\"dynamodb\")\nprint([e for e in dir(ddb.exceptions) if e.endswith('Exception') or e.endswith('Error')])\n\n\nWhen doing a write operation with a condition expression, you can request that if the expression fails the value of the item should be returned in the error response.\n\ntry:\n    response = table.put_item(\n        Item=item,\n        ConditionExpression='attribute_not_exists(pk)',\n        ReturnValuesOnConditionCheckFailure='ALL_OLD'\n    )\nexcept table.meta.client.exceptions.ConditionalCheckFailedException as e:\n    print('Item already exists:', e.response['Item'])\n\n\nFor further reading on error handling and exceptions:\n\nThe boto3 guide on error handling has more information on error handling techniques.\n\nThe DynamoDB developer guide section on programming errors lists what errors you might encounter.\n\nThe Common Errors section in the API reference .\n\nThe documentation on each API operation lists what errors that call might generate (for example BatchWriteItem).\n\nLogging\n\nThe boto3 library integrates with Python's built-in logging module for tracking what happens during a session. To control logging levels, you can configure the logging module:\n\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\n\n\nThis configures the root logger to log INFO and above level messages. Logging messages which are less severe than level will be ignored. Logging levels include DEBUG, INFO, WARNING, ERROR, and CRITICAL. The default is WARNING.\n\nLoggers in boto3 are hierarchical. The library uses a few different loggers, each corresponding to different parts of the library. You can separately control the behavior of each:\n\nboto3: The main logger for the boto3 module.\n\nbotocore: The main logger for the botocore package.\n\nbotocore.auth: Used for logging AWS signature creation for requests.\n\nbotocore.credentials: Used for logging the process of credential fetching and refresh.\n\nbotocore.endpoint: Used for logging request creation before it's sent over the network.\n\nbotocore.hooks: Used for logging events triggered in the library.\n\nbotocore.loaders: Used for logging when parts of AWS service models are loaded.\n\nbotocore.parsers: Used for logging AWS service responses before they're parsed.\n\nbotocore.retryhandler: Used for logging the processing of AWS service request retries (legacy mode).\n\nbotocore.retries.standard: Used for logging the processing of AWS service request retries (standard or adaptive mode).\n\nbotocore.utils: Used for logging miscellaneous activities in the library.\n\nbotocore.waiter: Used for logging the functionality of waiters, which poll an AWS service until a certain state is reached.\n\nOther libraries log as well. Internally, boto3 uses the third party urllib3 for HTTP connection handling. When latency is important, you can watch its logs to ensure your pool is being well utilized by seeing when urllib3 establishes a new connection or closes an idle one down.\n\nurllib3.connectionpool: Use for logging connection pool handling events.\n\nThe following code snippet sets most logging to INFO with DEBUG logging for endpoint and connection pool activity:\n\nimport logging\n\nlogging.getLogger('boto3').setLevel(logging.INFO)\nlogging.getLogger('botocore').setLevel(logging.INFO)\nlogging.getLogger('botocore.endpoint').setLevel(logging.DEBUG)\nlogging.getLogger('urllib3.connectionpool').setLevel(logging.DEBUG)\n\nEvent hooks\n\nBotocore emits events during various parts of its execution. You can register handlers for these events so that whenever an event is emitted, your handler will be called. This lets you extend the behavior of botocore without having to modify the internals.\n\nFor instance, let's say you want to keep track of every time a PutItem operation is called on any DynamoDB table in your application. You might register on the 'provide-client-params.dynamodb.PutItem' event to catch and log every time a PutItem operation is invoked on the associated Session. Here's an example:\n\nimport boto3\nimport botocore\nimport logging\n\ndef log_put_params(params, **kwargs):\n    if 'TableName' in params and 'Item' in params:\n        logging.info(f\"PutItem on table {params['TableName']}: {params['Item']}\")\n\nlogging.basicConfig(level=logging.INFO)\n\nsession = boto3.Session()\nevent_system = session.events\n\n# Register our interest in hooking in when the parameters are provided to PutItem\nevent_system.register('provide-client-params.dynamodb.PutItem', log_put_params)\n\n# Now, every time you use this session to put an item in DynamoDB,\n# it will log the table name and item data.\ndynamodb = session.resource('dynamodb')\ntable = dynamodb.Table('YourTableName')\ntable.put_item(\n    Item={\n        'pk': '123',\n        'sk': 'cart#123',\n        'item_data': 'YourItemData',\n        # ... more attributes ...\n    }\n)\n\n\nWithin the handler, you can even manipulate the params programmatically to change behavior:\n\nparams['TableName'] = \"NewTableName\"\n\nFor more information on events, see the botocore documentation on events and the boto3 documentation on events.\n\nPagination and the Paginator\n\nSome requests, such as Query and Scan, limit the size of data returned on a single request and require you to make repeated requests to pull subsequent pages.\n\nYou can control the maximum number of items to be read for each page with the limit parameter. For example, if you want the last 10 items, you can use limit to retrieve only the last 10. Note the limit is how much should be read from the table before any filtering is applied. There's no way to specify you want exactly 10 after filtering; you can only control the pre-filtered count and check client-side when you've actually retrieved 10. Regardless of the limit, every response always has a maximum size of 1 MB.\n\nIf the response includes a LastEvaluatedKey, it indicates the response ended because it hit a count or size limit. The key is the last key evaluated for the response. You can retrieve this LastEvaluatedKey and pass it to a follow-up call as ExclusiveStartKey to read the next chunk from that starting point. When there's no LastEvaluatedKey returned that, means there are no more items matching the Query or Scan.\n\nHere's a simple example (using the Resource interface, but the Client interface has the same pattern) that reads at most 100 items per page and loops until all items have been read.\n\nimport boto3\n\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('YourTableName')\n\nquery_params = {\n    'KeyConditionExpression': Key('pk').eq('123') & Key('sk').gt(1000),\n    'Limit': 100\n}\n\nwhile True:\n    response = table.query(**query_params)\n\n    # Process the items however you like\n    for item in response['Items']:\n        print(item)\n\n    # No LastEvaluatedKey means no more items to retrieve\n    if 'LastEvaluatedKey' not in response:\n        break\n\n    # If there are possibly more items, update the start key for the next page\n    query_params['ExclusiveStartKey'] = response['LastEvaluatedKey']\n\n\nFor convenience, boto3 can do this for you with Paginators. However, it only works with the Client interface. Here's the code rewritten to use Paginators:\n\nimport boto3\n\ndynamodb = boto3.client('dynamodb')\n\npaginator = dynamodb.get_paginator('query')\n\nquery_params = {\n    'TableName': 'YourTableName',\n    'KeyConditionExpression': 'pk = :pk_val AND sk > :sk_val',\n    'ExpressionAttributeValues': {\n        ':pk_val': {'S': '123'},\n        ':sk_val': {'N': '1000'},\n    },\n    'Limit': 100\n}\n\npage_iterator = paginator.paginate(**query_params)\n\nfor page in page_iterator:\n    # Process the items however you like\n    for item in page['Items']:\n        print(item)\n\n\nFor more information, see the Guide on Paginators and the API reference for DynamoDB.Paginator.Query.\n\nNote\n\nPaginators also have their own configuration settings named MaxItems, StartingToken, and PageSize. For paginating with DynamoDB, you should ignore these settings.\n\nWaiters\n\nWaiters provide the ability to wait for something to complete before proceeding. At present, they only support waiting for a table to be created or deleted. In the background, the waiter operation does a check for you every 20 seconds up to 25 times. You could do this yourself, but using a waiter is elegant when writing automation.\n\nThis code shows how to wait for a particular table to have been created:\n\n# Create a table, wait until it exists, and print its ARN\nresponse = client.create_table(...)\nwaiter = client.get_waiter('table_exists')\nwaiter.wait(TableName='YourTableName')\nprint('Table created:', response['TableDescription']['TableArn']\n\n\nFor more information, see the Guide to Waiters and Reference on Waiters."
  },
  {
    "title": ".NET code examples - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CodeSamples.DotNet.html",
    "html": ".NET code examples\nPDF\nRSS\nTopics\n.NET: Setting your AWS credentials\n.NET: Setting the AWS Region and endpoint\n\nThis guide contains .NET code snippets and ready-to-run programs. You can find these code examples in the following sections:\n\nWorking with items and attributes\n\nWorking with tables and data in DynamoDB\n\nQuery operations in DynamoDB\n\nWorking with scans in DynamoDB\n\nImproving data access with secondary indexes\n\n.NET: Document model\n\n.NET: Object persistence model\n\nChange data capture for DynamoDB Streams\n\nYou can get started quickly by using the AWS SDK for .NET with the Toolkit for Visual Studio.\n\nTo run the .NET code examples (using Visual Studio)\n\nDownload and install Microsoft Visual Studio.\n\nDownload and install the Toolkit for Visual Studio.\n\nStart Visual Studio. Choose File, New, Project.\n\nIn New Project, choose AWS Empty Project, and then choose OK.\n\nIn AWS Access Credentials, choose Use existing profile, choose your credentials profile from the list, and then choose OK.\n\nIf this is your first time using Toolkit for Visual Studio, choose Use a new profile to set up your AWS credentials.\n\nIn your Visual Studio project, choose the tab for your program's source code (Program.cs). Copy the code example from the documentation page into the Visual Studio editor, replacing any other code that you see in the editor.\n\nIf you see error messages of the form The type or namespace name...could not be found, you need to install the AWS SDK assembly for DynamoDB as follows:\n\nIn Solution Explorer, open the context (right-click) menu for your project, and then choose Manage NuGet Packages.\n\nIn NuGet Package Manager, choose Browse.\n\nIn the search box, enter AWSSDK.DynamoDBv2, and wait for the search to complete.\n\nChoose AWSSDK.DynamoDBv2, and then choose Install.\n\nWhen the installation is complete, choose the Program.cs tab to return to your program.\n\nTo run the code, choose Start in the Visual Studio toolbar.\n\nThe AWS SDK for .NET provides thread-safe clients for working with DynamoDB. As a best practice, your applications should create one client and reuse the client between threads.\n\nFor more information, see AWS SDK for .NET.\n\nNote\n\nThe code examples in this guide are intended for use with the latest version of the AWS SDK for .NET.\n\n.NET: Setting your AWS credentials\n\nThe AWS SDK for .NET requires that you provide AWS credentials to your application at runtime. The code examples in this guide assume that you are using the SDK Store to manage your AWS credentials file, as described in Using the SDK store in the AWS SDK for .NET Developer Guide.\n\nThe Toolkit for Visual Studio supports multiple sets of credentials from any number of accounts. Each set is referred to as a profile. Visual Studio adds entries to the project's App.config file so that your application can find the AWS credentials at runtime.\n\nThe following example shows the default App.config file that is generated when you create a new project using Toolkit for Visual Studio.\n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<configuration>\n    <appSettings>\n    <add key=\"AWSProfileName\" value=\"default\"/>\n    <add key=\"AWSRegion\" value=\"us-west-2\" />\n </appSettings>\n</configuration>\n\nAt runtime, the program uses the default set of AWS credentials, as specified by the AWSProfileName entry. The AWS credentials themselves are kept in the SDK Store in encrypted form. The Toolkit for Visual Studio provides a graphical user interface for managing your credentials, all from within Visual Studio. For more information, see Specifying credentials in the AWS Toolkit for Visual Studio User Guide.\n\nNote\n\nBy default, the code examples access DynamoDB in the US West (Oregon) Region. You can change the Region by modifying the AWSRegion entry in the App.config file. You can set AWSRegion to any Region where DynamoDB is available. For a complete list, see AWS regions and endpoints in the Amazon Web Services General Reference.\n\n.NET: Setting the AWS Region and endpoint\n\nBy default, the code examples access DynamoDB in the US West (Oregon) Region. You can change the Region by modifying the AWSRegion entry in the App.config file. Or, you can change the Region by modifying the AmazonDynamoDBClient properties.\n\nThe following code example instantiates a new AmazonDynamoDBClient. The client is modified so that the code runs against DynamoDB in a different Region.\n\nAmazonDynamoDBConfig clientConfig = new AmazonDynamoDBConfig();\n// This client will access the US East 1 region.\nclientConfig.RegionEndpoint = RegionEndpoint.USEast1;\nAmazonDynamoDBClient client = new AmazonDynamoDBClient(clientConfig); \n\nFor a complete list of Regions, see AWS regions and endpoints in the Amazon Web Services General Reference.\n\nIf you want to run the code examples using DynamoDB locally on your computer, set the endpoint as follows.\n\nAmazonDynamoDBConfig clientConfig = new AmazonDynamoDBConfig();\n// Set the endpoint URL\nclientConfig.ServiceURL = \"http://localhost:8000\";\nAmazonDynamoDBClient client = new AmazonDynamoDBClient(clientConfig); "
  },
  {
    "title": "Java code examples - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CodeSamples.Java.html",
    "html": "Java code examples\nPDF\nRSS\nTopics\nJava: Setting your AWS credentials\nJava: Setting the AWS Region and endpoint\n\nThis Developer Guide contains Java code snippets and ready-to-run programs. You can find these code examples in the following sections:\n\nWorking with items and attributes\n\nWorking with tables and data in DynamoDB\n\nQuery operations in DynamoDB\n\nWorking with scans in DynamoDB\n\nImproving data access with secondary indexes\n\nJava 1.x: DynamoDBMapper\n\nChange data capture for DynamoDB Streams\n\nYou can get started quickly by using Eclipse with the AWS Toolkit for Eclipse. In addition to a full-featured IDE, you also get the AWS SDK for Java with automatic updates, and preconfigured templates for building AWS applications.\n\nTo run the Java code examples (using Eclipse)\n\nDownload and install the Eclipse IDE.\n\nDownload and install the AWS Toolkit for Eclipse.\n\nStart Eclipse, and on the Eclipse menu, choose File, New, and then Other.\n\nIn Select a wizard, choose AWS, choose AWS Java Project, and then choose Next.\n\nIn Create an AWS Java, do the following:\n\nIn Project name, enter a name for your project.\n\nIn Select Account, choose your credentials profile from the list.\n\nIf this is your first time using the AWS Toolkit for Eclipse, choose Configure AWS Accounts to set up your AWS credentials.\n\nChoose Finish to create the project.\n\nFrom the Eclipse menu, choose File, New, and then Class.\n\nIn Java Class, enter a name for your class in Name (use the same name as the code example that you want to run), and then choose Finish to create the class.\n\nCopy the code example from the documentation page into the Eclipse editor.\n\nTo run the code, choose Run on the Eclipse menu.\n\nThe SDK for Java provides thread-safe clients for working with DynamoDB. As a best practice, your applications should create one client and reuse the client between threads.\n\nFor more information, see the AWS SDK for Java.\n\nNote\n\nThe code examples in this guide are intended for use with the latest version of the AWS SDK for Java.\n\nIf you are using the AWS Toolkit for Eclipse, you can configure automatic updates for the SDK for Java. To do this in Eclipse, go to Preferences and choose AWS Toolkit, AWS SDK for Java, Download new SDKs automatically.\n\nJava: Setting your AWS credentials\n\nThe SDK for Java requires that you provide AWS credentials to your application at runtime. The code examples in this guide assume that you are using an AWS credentials file, as described in Set up your AWS credentials in the AWS SDK for Java Developer Guide.\n\nThe following is an example of an AWS credentials file named ~/.aws/credentials, where the tilde character (~) represents your home directory.\n\n[default]\naws_access_key_id = AWS access key ID goes here\naws_secret_access_key = Secret key goes here         \nJava: Setting the AWS Region and endpoint\n\nBy default, the code examples access DynamoDB in the US West (Oregon) Region. You can change the Region by modifying the AmazonDynamoDB properties.\n\nThe following code example instantiates a new AmazonDynamoDB.\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.regions.Regions;\n...\n// This client will default to US West (Oregon)\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()\n.withRegion(Regions.US_WEST_2)\n.build();  \n\nYou can use the withRegion method to run your code against DynamoDB in any Region where it is available. For a complete list, see AWS regions and endpoints in the Amazon Web Services General Reference.\n\nIf you want to run the code examples using DynamoDB locally on your computer, set the endpoint as follows.\n\nAWS SDK V1\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().withEndpointConfiguration(\nnew AwsClientBuilder.EndpointConfiguration(\"http://localhost:8000\", \"us-west-2\"))\n.build(); \nAWS SDK V2\nDynamoDbClient client = DynamoDbClient.builder()\n    .endpointOverride(URI.create(\"http://localhost:8000\"))\n    // The region is meaningless for local DynamoDb but required for client builder validation\n    .region(Region.US_EAST_1)\n    .credentialsProvider(StaticCredentialsProvider.create(\n    AwsBasicCredentials.create(\"dummy-key\", \"dummy-secret\")))\n    .build();"
  },
  {
    "title": "Creating tables and loading data for code examples in DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SampleData.html",
    "html": "Creating tables and loading data for code examples in DynamoDB\nPDF\nRSS\n\nSee below for the basics on creating tables in DynamoDB, loading in a sample dataset, querying the data, and updating the data.\n\nStep 1: Create a table\n\nStep 2: Write data to a table using the console or AWS CLI\n\nStep 3: Read data from a table\n\nStep 4: Update data in a table"
  },
  {
    "title": "Example: Query and scan in DynamoDB using the AWS SDK for .NET object persistence model - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBContext.QueryScan.html",
    "html": "Example: Query and scan in DynamoDB using the AWS SDK for .NET object persistence model\nPDF\nRSS\n\nThe C# example in this section defines the following classes and maps them to the tables in DynamoDB. For more information about creating the tables used in this example, see Creating tables and loading data for code examples in DynamoDB.\n\nThe Book class maps to the ProductCatalog table.\n\nThe Forum, Thread, and Reply classes map to tables of the same name.\n\nThe example then runs the following query and scan operations using DynamoDBContext.\n\nGet a book by Id.\n\nThe ProductCatalog table has Id as its primary key. It does not have a sort key as part of its primary key. Therefore, you cannot query the table. You can get an item using its Id value.\n\nRun the following queries against the Reply table. (The Reply table's primary key is composed of Id and ReplyDateTime attributes. The ReplyDateTime is a sort key. Therefore, you can query this table.)\n\nFind replies to a forum thread posted in the last 15 days.\n\nFind replies to a forum thread posted in a specific date range.\n\nScan the ProductCatalog table to find books whose price is less than zero.\n\nFor performance reasons, you should use a query operation instead of a scan operation. However, there are times you might need to scan a table. Suppose that there was a data entry error and one of the book prices is set to less than 0. This example scans the ProductCategory table to find book items (the ProductCategory is book) at price of less than 0.\n\nFor instructions about creating a working sample, see .NET code examples.\n\nNote\n\nThe following example does not work with .NET core because it does not support synchronous methods. For more information, see AWS asynchronous APIs for .NET.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing System.Configuration;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.DataModel;\nusing Amazon.DynamoDBv2.DocumentModel;\nusing Amazon.Runtime;\n\nnamespace com.amazonaws.codesamples\n{\n    class HighLevelQueryAndScan\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                DynamoDBContext context = new DynamoDBContext(client);\n                // Get an item.\n                GetBook(context, 101);\n\n                // Sample forum and thread to test queries.\n                string forumName = \"Amazon DynamoDB\";\n                string threadSubject = \"DynamoDB Thread 1\";\n                // Sample queries.\n                FindRepliesInLast15Days(context, forumName, threadSubject);\n                FindRepliesPostedWithinTimePeriod(context, forumName, threadSubject);\n\n                // Scan table.\n                FindProductsPricedLessThanZero(context);\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (AmazonDynamoDBException e) { Console.WriteLine(e.Message); }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n        }\n\n        private static void GetBook(DynamoDBContext context, int productId)\n        {\n            Book bookItem = context.Load<Book>(productId);\n\n            Console.WriteLine(\"\\nGetBook: Printing result.....\");\n            Console.WriteLine(\"Title: {0} \\n No.Of threads:{1} \\n No. of messages: {2}\",\n                      bookItem.Title, bookItem.ISBN, bookItem.PageCount);\n        }\n\n        private static void FindRepliesInLast15Days(DynamoDBContext context,\n                                string forumName,\n                                string threadSubject)\n        {\n            string replyId = forumName + \"#\" + threadSubject;\n            DateTime twoWeeksAgoDate = DateTime.UtcNow - TimeSpan.FromDays(15);\n            IEnumerable<Reply> latestReplies =\n                context.Query<Reply>(replyId, QueryOperator.GreaterThan, twoWeeksAgoDate);\n            Console.WriteLine(\"\\nFindRepliesInLast15Days: Printing result.....\");\n            foreach (Reply r in latestReplies)\n                Console.WriteLine(\"{0}\\t{1}\\t{2}\\t{3}\", r.Id, r.PostedBy, r.Message, r.ReplyDateTime);\n        }\n\n        private static void FindRepliesPostedWithinTimePeriod(DynamoDBContext context,\n                                      string forumName,\n                                      string threadSubject)\n        {\n            string forumId = forumName + \"#\" + threadSubject;\n            Console.WriteLine(\"\\nFindRepliesPostedWithinTimePeriod: Printing result.....\");\n\n            DateTime startDate = DateTime.UtcNow - TimeSpan.FromDays(30);\n            DateTime endDate = DateTime.UtcNow - TimeSpan.FromDays(1);\n\n            IEnumerable<Reply> repliesInAPeriod = context.Query<Reply>(forumId,\n                                           QueryOperator.Between, startDate, endDate);\n            foreach (Reply r in repliesInAPeriod)\n                Console.WriteLine(\"{0}\\t{1}\\t{2}\\t{3}\", r.Id, r.PostedBy, r.Message, r.ReplyDateTime);\n        }\n\n        private static void FindProductsPricedLessThanZero(DynamoDBContext context)\n        {\n            int price = 0;\n            IEnumerable<Book> itemsWithWrongPrice = context.Scan<Book>(\n                new ScanCondition(\"Price\", ScanOperator.LessThan, price),\n                new ScanCondition(\"ProductCategory\", ScanOperator.Equal, \"Book\")\n                );\n            Console.WriteLine(\"\\nFindProductsPricedLessThanZero: Printing result.....\");\n            foreach (Book r in itemsWithWrongPrice)\n                Console.WriteLine(\"{0}\\t{1}\\t{2}\\t{3}\", r.Id, r.Title, r.Price, r.ISBN);\n        }\n    }\n\n    [DynamoDBTable(\"Reply\")]\n    public class Reply\n    {\n        [DynamoDBHashKey] //Partition key\n        public string Id\n        {\n            get; set;\n        }\n\n        [DynamoDBRangeKey] //Sort key\n        public DateTime ReplyDateTime\n        {\n            get; set;\n        }\n\n        // Properties included implicitly.\n        public string Message\n        {\n            get; set;\n        }\n        // Explicit property mapping with object persistence model attributes.\n        [DynamoDBProperty(\"LastPostedBy\")]\n        public string PostedBy\n        {\n            get; set;\n        }\n        // Property to store version number for optimistic locking.\n        [DynamoDBVersion]\n        public int? Version\n        {\n            get; set;\n        }\n    }\n\n    [DynamoDBTable(\"Thread\")]\n    public class Thread\n    {\n        // Partition key mapping.\n        [DynamoDBHashKey] //Partition key\n        public string ForumName\n        {\n            get; set;\n        }\n        [DynamoDBRangeKey] //Sort key\n        public DateTime Subject\n        {\n            get; set;\n        }\n        // Implicit mapping.\n        public string Message\n        {\n            get; set;\n        }\n        public string LastPostedBy\n        {\n            get; set;\n        }\n        public int Views\n        {\n            get; set;\n        }\n        public int Replies\n        {\n            get; set;\n        }\n        public bool Answered\n        {\n            get; set;\n        }\n        public DateTime LastPostedDateTime\n        {\n            get; set;\n        }\n        // Explicit mapping (property and table attribute names are different).\n        [DynamoDBProperty(\"Tags\")]\n        public List<string> KeywordTags\n        {\n            get; set;\n        }\n        // Property to store version number for optimistic locking.\n        [DynamoDBVersion]\n        public int? Version\n        {\n            get; set;\n        }\n    }\n\n    [DynamoDBTable(\"Forum\")]\n    public class Forum\n    {\n        [DynamoDBHashKey]\n        public string Name\n        {\n            get; set;\n        }\n        // All the following properties are explicitly mapped\n        // to show how to provide mapping.\n        [DynamoDBProperty]\n        public int Threads\n        {\n            get; set;\n        }\n        [DynamoDBProperty]\n        public int Views\n        {\n            get; set;\n        }\n        [DynamoDBProperty]\n        public string LastPostBy\n        {\n            get; set;\n        }\n        [DynamoDBProperty]\n        public DateTime LastPostDateTime\n        {\n            get; set;\n        }\n        [DynamoDBProperty]\n        public int Messages\n        {\n            get; set;\n        }\n    }\n\n    [DynamoDBTable(\"ProductCatalog\")]\n    public class Book\n    {\n        [DynamoDBHashKey] //Partition key\n        public int Id\n        {\n            get; set;\n        }\n        public string Title\n        {\n            get; set;\n        }\n        public string ISBN\n        {\n            get; set;\n        }\n        public int Price\n        {\n            get; set;\n        }\n        public string PageCount\n        {\n            get; set;\n        }\n        public string ProductCategory\n        {\n            get; set;\n        }\n        public bool InPublication\n        {\n            get; set;\n        }\n    }\n}\n"
  },
  {
    "title": "Running the code examples in this Developer Guide - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CodeSamples.html",
    "html": "Running the code examples in this Developer Guide\nPDF\nRSS\n\nThe AWS SDKs provide broad support for Amazon DynamoDB in the following languages:\n\nJava\n\nJavaScript in the browser\n\n.NET\n\nNode.js\n\nPHP\n\nPython\n\nRuby\n\nC++\n\nGo\n\nAndroid\n\niOS\n\nTo get started quickly with these languages, see Getting started with DynamoDB and the AWS SDKs.\n\nThe code examples in this developer guide provide more in-depth coverage of DynamoDB operations, using the following programming languages:\n\nJava code examples\n\n.NET code examples\n\nBefore you can begin with this exercise, you need to create an AWS account, get your access key and secret key, and set up the AWS Command Line Interface (AWS CLI) on your computer. For more information, see Setting up DynamoDB (web service) .\n\nNote\n\nIf you are using the downloadable version of DynamoDB, you need to use the AWS CLI to create the tables and sample data. You also need to specify the --endpoint-url parameter with each AWS CLI command. For more information, see Setting the local endpoint ."
  },
  {
    "title": "Example: Batch write operation using the AWS SDK for .NET object persistence model - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/orm-dotnet-batchoperations-example.html",
    "html": "Example: Batch write operation using the AWS SDK for .NET object persistence model\nPDF\nRSS\n\nThe following C# code example declares Book, Forum, Thread, and Reply classes and maps them to Amazon DynamoDB tables using the object persistence model attributes.\n\nThe example then uses the DynamoDBContext to illustrate the following batch write operations:\n\nBatchWrite object to put and delete book items from the ProductCatalog table.\n\nMultiTableBatchWrite object to put and delete items from the Forum and the Thread tables.\n\nFor more information about the tables used in this example, see Creating tables and loading data for code examples in DynamoDB. For step-by-step instructions to test the following example, see .NET code examples.\n\nNote\n\nThe following example doesn't work with .NET core because it doesn't support synchronous methods. For more information, see AWS asynchronous APIs for .NET.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.DataModel;\nusing Amazon.Runtime;\nusing Amazon.SecurityToken;\n\nnamespace com.amazonaws.codesamples\n{\n    class HighLevelBatchWriteItem\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                DynamoDBContext context = new DynamoDBContext(client);\n                SingleTableBatchWrite(context);\n                MultiTableBatchWrite(context);\n            }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n\n            Console.WriteLine(\"To continue, press Enter\");\n            Console.ReadLine();\n        }\n\n        private static void SingleTableBatchWrite(DynamoDBContext context)\n        {\n            Book book1 = new Book\n            {\n                Id = 902,\n                InPublication = true,\n                ISBN = \"902-11-11-1111\",\n                PageCount = \"100\",\n                Price = 10,\n                ProductCategory = \"Book\",\n                Title = \"My book3 in batch write\"\n            };\n            Book book2 = new Book\n            {\n                Id = 903,\n                InPublication = true,\n                ISBN = \"903-11-11-1111\",\n                PageCount = \"200\",\n                Price = 10,\n                ProductCategory = \"Book\",\n                Title = \"My book4 in batch write\"\n            };\n\n            var bookBatch = context.CreateBatchWrite<Book>();\n            bookBatch.AddPutItems(new List<Book> { book1, book2 });\n\n            Console.WriteLine(\"Performing batch write in SingleTableBatchWrite().\");\n            bookBatch.Execute();\n        }\n\n        private static void MultiTableBatchWrite(DynamoDBContext context)\n        {\n            // 1. New Forum item.\n            Forum newForum = new Forum\n            {\n                Name = \"Test BatchWrite Forum\",\n                Threads = 0\n            };\n            var forumBatch = context.CreateBatchWrite<Forum>();\n            forumBatch.AddPutItem(newForum);\n\n            // 2. New Thread item.\n            Thread newThread = new Thread\n            {\n                ForumName = \"S3 forum\",\n                Subject = \"My sample question\",\n                KeywordTags = new List<string> { \"S3\", \"Bucket\" },\n                Message = \"Message text\"\n            };\n\n            DynamoDBOperationConfig config = new DynamoDBOperationConfig();\n            config.SkipVersionCheck = true;\n            var threadBatch = context.CreateBatchWrite<Thread>(config);\n            threadBatch.AddPutItem(newThread);\n            threadBatch.AddDeleteKey(\"some partition key value\", \"some sort key value\");\n\n            var superBatch = new MultiTableBatchWrite(forumBatch, threadBatch);\n            Console.WriteLine(\"Performing batch write in MultiTableBatchWrite().\");\n            superBatch.Execute();\n        }\n    }\n\n    [DynamoDBTable(\"Reply\")]\n    public class Reply\n    {\n        [DynamoDBHashKey] //Partition key\n        public string Id\n        {\n            get; set;\n        }\n\n        [DynamoDBRangeKey] //Sort key\n        public DateTime ReplyDateTime\n        {\n            get; set;\n        }\n\n        // Properties included implicitly.\n        public string Message\n        {\n            get; set;\n        }\n        // Explicit property mapping with object persistence model attributes.\n        [DynamoDBProperty(\"LastPostedBy\")]\n        public string PostedBy\n        {\n            get; set;\n        }\n        // Property to store version number for optimistic locking.\n        [DynamoDBVersion]\n        public int? Version\n        {\n            get; set;\n        }\n    }\n\n    [DynamoDBTable(\"Thread\")]\n    public class Thread\n    {\n        // PK mapping.\n        [DynamoDBHashKey]      //Partition key\n        public string ForumName\n        {\n            get; set;\n        }\n        [DynamoDBRangeKey]      //Sort key\n        public String Subject\n        {\n            get; set;\n        }\n        // Implicit mapping.\n        public string Message\n        {\n            get; set;\n        }\n        public string LastPostedBy\n        {\n            get; set;\n        }\n        public int Views\n        {\n            get; set;\n        }\n        public int Replies\n        {\n            get; set;\n        }\n        public bool Answered\n        {\n            get; set;\n        }\n        public DateTime LastPostedDateTime\n        {\n            get; set;\n        }\n        // Explicit mapping (property and table attribute names are different.\n        [DynamoDBProperty(\"Tags\")]\n        public List<string> KeywordTags\n        {\n            get; set;\n        }\n        // Property to store version number for optimistic locking.\n        [DynamoDBVersion]\n        public int? Version\n        {\n            get; set;\n        }\n    }\n\n    [DynamoDBTable(\"Forum\")]\n    public class Forum\n    {\n        [DynamoDBHashKey]      //Partition key\n        public string Name\n        {\n            get; set;\n        }\n        // All the following properties are explicitly mapped,\n        // only to show how to provide mapping.\n        [DynamoDBProperty]\n        public int Threads\n        {\n            get; set;\n        }\n        [DynamoDBProperty]\n        public int Views\n        {\n            get; set;\n        }\n        [DynamoDBProperty]\n        public string LastPostBy\n        {\n            get; set;\n        }\n        [DynamoDBProperty]\n        public DateTime LastPostDateTime\n        {\n            get; set;\n        }\n        [DynamoDBProperty]\n        public int Messages\n        {\n            get; set;\n        }\n    }\n\n    [DynamoDBTable(\"ProductCatalog\")]\n    public class Book\n    {\n        [DynamoDBHashKey] //Partition key\n        public int Id\n        {\n            get; set;\n        }\n        public string Title\n        {\n            get; set;\n        }\n        public string ISBN\n        {\n            get; set;\n        }\n        public int Price\n        {\n            get; set;\n        }\n        public string PageCount\n        {\n            get; set;\n        }\n        public string ProductCategory\n        {\n            get; set;\n        }\n        public bool InPublication\n        {\n            get; set;\n        }\n    }\n}\n"
  },
  {
    "title": "Example: CRUD operations using the AWS SDK for .NET object persistence model - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CRUDHighLevelExample1.html",
    "html": "Example: CRUD operations using the AWS SDK for .NET object persistence model\nPDF\nRSS\n\nThe following C# code example declares a Book class with Id, Title, Isbn, and BookAuthors properties. The example uses object persistence attributes to map these properties to the ProductCatalog table in Amazon DynamoDB. The example then uses the DynamoDBContext class to illustrate typical create, read, update, and delete (CRUD) operations. The example creates a sample Book instance and saves it to the ProductCatalog table. It then retrieves the book item and updates its Isbn and BookAuthors properties. Note that the update replaces the existing authors list. Finally, the example deletes the book item.\n\nFor more information about the ProductCatalog table used in this example, see Creating tables and loading data for code examples in DynamoDB. For step-by-step instructions to test the following example, see .NET code examples.\n\nNote\n\nThe following example doesn't work with .NET core because it doesn't support synchronous methods. For more information, see AWS asynchronous APIs for .NET.\n\nExample CRUD operations using the DynamoDBContext class\n\n    /// <summary>\n    /// Shows how to perform high-level CRUD operations on an Amazon DynamoDB\n    /// table.\n    /// </summary>\n    public class HighLevelItemCrud\n    {\n        public static async Task Main()\n        {\n            var client = new AmazonDynamoDBClient();\n            DynamoDBContext context = new DynamoDBContext(client);\n            await PerformCRUDOperations(context);\n        }\n\n        public static async Task PerformCRUDOperations(IDynamoDBContext context)\n        {\n            int bookId = 1001; // Some unique value.\n            Book myBook = new Book\n            {\n                Id = bookId,\n                Title = \"object persistence-AWS SDK for.NET SDK-Book 1001\",\n                Isbn = \"111-1111111001\",\n                BookAuthors = new List<string> { \"Author 1\", \"Author 2\" },\n            };\n\n            // Save the book to the ProductCatalog table.\n            await context.SaveAsync(myBook);\n\n            // Retrieve the book from the ProductCatalog table.\n            Book bookRetrieved = await context.LoadAsync<Book>(bookId);\n\n            // Update some properties.\n            bookRetrieved.Isbn = \"222-2222221001\";\n\n            // Update existing authors list with the following values.\n            bookRetrieved.BookAuthors = new List<string> { \" Author 1\", \"Author x\" };\n            await context.SaveAsync(bookRetrieved);\n\n            // Retrieve the updated book. This time, add the optional\n            // ConsistentRead parameter using DynamoDBContextConfig object.\n            await context.LoadAsync<Book>(bookId, new DynamoDBContextConfig\n            {\n                ConsistentRead = true,\n            });\n\n            // Delete the book.\n            await context.DeleteAsync<Book>(bookId);\n\n            // Try to retrieve deleted book. It should return null.\n            Book deletedBook = await context.LoadAsync<Book>(bookId, new DynamoDBContextConfig\n            {\n                ConsistentRead = true,\n            });\n\n            if (deletedBook == null)\n            {\n                Console.WriteLine(\"Book is deleted\");\n            }\n        }\n    }\n\n\nExample\nBook class information to add to the ProductCatalog table\n\n    /// <summary>\n    /// A class representing book information to be added to the Amazon DynamoDB\n    /// ProductCatalog table.\n    /// </summary>\n    [DynamoDBTable(\"ProductCatalog\")]\n    public class Book\n    {\n        [DynamoDBHashKey] // Partition key\n        public int Id { get; set; }\n\n        [DynamoDBProperty]\n        public string Title { get; set; }\n\n        [DynamoDBProperty]\n        public string Isbn { get; set; }\n\n        [DynamoDBProperty(\"Authors\")] // String Set datatype\n        public List<string> BookAuthors { get; set; }\n    }\n\n"
  },
  {
    "title": "Batch operations using the AWS SDK for .NET object persistence model - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DotNetDynamoDBContext.BatchOperations.html",
    "html": "Batch operations using the AWS SDK for .NET object persistence model\nPDF\nRSS\nBatch write: Putting and deleting multiple items\n\nTo put or delete multiple objects from a table in a single request, do the following:\n\nRun the createBatchWrite method of the DynamoDBContext, and create an instance of the BatchWrite class.\n\nSpecify the items that you want to put or delete.\n\nTo put one or more items, use either the AddPutItem or the AddPutItems method.\n\nTo delete one or more items, you can specify either the primary key of the item or a client-side object that maps to the item that you want to delete. Use the AddDeleteItem, AddDeleteItems, and the AddDeleteKey methods to specify the list of items to delete.\n\nCall the BatchWrite.Execute method to put and delete all the specified items from the table.\n\nNote\n\nWhen using the object persistence model, you can specify any number of operations in a batch. However, note that Amazon DynamoDB limits the number of operations in a batch and the total size of the batch in a batch operation. For more information about the specific limits, see BatchWriteItem. If the API detects that your batch write request exceeded the allowed number of write requests or exceeded the maximum allowed HTTP payload size, it breaks the batch into several smaller batches. Additionally, if a response to a batch write returns unprocessed items, the API automatically sends another batch request with those unprocessed items.\n\nSuppose that you defined a C# class Book class that maps to the ProductCatalog table in DynamoDB. The following C# code example uses the BatchWrite object to upload two items and delete one item from the ProductCatalog table.\n\nExample\nDynamoDBContext context = new DynamoDBContext(client);\nvar bookBatch = context.CreateBatchWrite<Book>();\n\n// 1. Specify two books to add.\nBook book1 = new Book\n{\n  Id = 902,\n  ISBN = \"902-11-11-1111\",\n  ProductCategory = \"Book\",\n  Title = \"My book3 in batch write\"\n};\nBook book2 = new Book\n{\n  Id = 903,\n  ISBN = \"903-11-11-1111\",\n  ProductCategory = \"Book\",\n  Title = \"My book4 in batch write\"\n};\n\n\nbookBatch.AddPutItems(new List<Book> { book1, book2 });\n\n// 2. Specify one book to delete.\nbookBatch.AddDeleteKey(111);\n\nbookBatch.Execute();\n\nTo put or delete objects from multiple tables, do the following:\n\nCreate one instance of the BatchWrite class for each type and specify the items you want to put or delete as described in the preceding section.\n\nCreate an instance of MultiTableBatchWrite using one of the following methods:\n\nRun the Combine method on one of the BatchWrite objects that you created in the preceding step.\n\nCreate an instance of the MultiTableBatchWrite type by providing a list of BatchWrite objects.\n\nRun the CreateMultiTableBatchWrite method of DynamoDBContext and pass in your list of BatchWrite objects.\n\nCall the Execute method of MultiTableBatchWrite, which performs the specified put and delete operations on various tables.\n\nSuppose that you defined Forum and Thread C# classes that map to the Forum and Thread tables in DynamoDB. Also, suppose that the Thread class has versioning enabled. Because versioning is not supported when using batch operations, you must explicitly disable versioning as shown in the following C# code example. The example uses the MultiTableBatchWrite object to perform a multi-table update.\n\nExample\nDynamoDBContext context = new DynamoDBContext(client);\n// Create BatchWrite objects for each of the Forum and Thread classes.\nvar forumBatch = context.CreateBatchWrite<Forum>();\n\nDynamoDBOperationConfig config = new DynamoDBOperationConfig();\nconfig.SkipVersionCheck = true;\nvar threadBatch = context.CreateBatchWrite<Thread>(config);\n\n// 1. New Forum item.\nForum newForum = new Forum\n{\n  Name = \"Test BatchWrite Forum\",\n  Threads = 0\n};\nforumBatch.AddPutItem(newForum);\n\n// 2. Specify a forum to delete by specifying its primary key.\nforumBatch.AddDeleteKey(\"Some forum\");\n\n// 3. New Thread item.\nThread newThread = new Thread\n{\n  ForumName = \"Amazon S3 forum\",\n  Subject = \"My sample question\",\n  KeywordTags = new List<string> { \"Amazon S3\", \"Bucket\" },\n   Message = \"Message text\"\n};\n\nthreadBatch.AddPutItem(newThread);\n\n// Now run multi-table batch write.\nvar superBatch = new MultiTableBatchWrite(forumBatch, threadBatch);\nsuperBatch.Execute();\n\nFor a working example, see Example: Batch write operation using the AWS SDK for .NET object persistence model.\n\nNote\n\nThe DynamoDB batch API limits the number of writes in a batch and also limits the size of the batch. For more information, see BatchWriteItem. When using the .NET object persistence model API, you can specify any number of operations. However, if either the number of operations in a batch or the size exceeds the limit, the .NET API breaks the batch write request into smaller batches and sends multiple batch write requests to DynamoDB.\n\nBatch get: Getting multiple items\n\nTo retrieve multiple items from a table in a single request, do the following:\n\nCreate an instance of the CreateBatchGet class.\n\nSpecify a list of primary keys to retrieve.\n\nCall the Execute method. The response returns the items in the Results property.\n\nThe following C# code example retrieves three items from the ProductCatalog table. The items in the result are not necessarily in the same order in which you specified the primary keys.\n\nExample\nDynamoDBContext context = new DynamoDBContext(client);\nvar bookBatch = context.CreateBatchGet<ProductCatalog>();\nbookBatch.AddKey(101);\nbookBatch.AddKey(102);\nbookBatch.AddKey(103);\nbookBatch.Execute();\n// Process result.\nConsole.WriteLine(bookBatch.Results.Count);\nBook book1 = bookBatch.Results[0];\nBook book2 = bookBatch.Results[1];\nBook book3 = bookBatch.Results[2];\n\nTo retrieve objects from multiple tables, do the following:\n\nFor each type, create an instance of the CreateBatchGet type and provide the primary key values you want to retrieve from each table.\n\nCreate an instance of the MultiTableBatchGet class using one of the following methods:\n\nRun the Combine method on one of the BatchGet objects you created in the preceding step.\n\nCreate an instance of the MultiBatchGet type by providing a list of BatchGet objects.\n\nRun the CreateMultiTableBatchGet method of DynamoDBContext and pass in your list of BatchGet objects.\n\nCall the Execute method of MultiTableBatchGet, which returns the typed results in the individual BatchGet objects.\n\nThe following C# code example retrieves multiple items from the Order and OrderDetail tables using the CreateBatchGet method.\n\nExample\nvar orderBatch = context.CreateBatchGet<Order>();\norderBatch.AddKey(101);\norderBatch.AddKey(102);\n\nvar orderDetailBatch = context.CreateBatchGet<OrderDetail>();\norderDetailBatch.AddKey(101, \"P1\");\norderDetailBatch.AddKey(101, \"P2\");\norderDetailBatch.AddKey(102, \"P3\");\norderDetailBatch.AddKey(102, \"P1\");\n\nvar orderAndDetailSuperBatch = orderBatch.Combine(orderDetailBatch);\norderAndDetailSuperBatch.Execute();\n\nConsole.WriteLine(orderBatch.Results.Count);\nConsole.WriteLine(orderDetailBatch.Results.Count);\n\nOrder order1 = orderBatch.Results[0];\nOrder order2 = orderBatch.Results[1];\nOrderDetail orderDetail1 = orderDetailBatch.Results[0];"
  },
  {
    "title": "Mapping arbitrary data with DynamoDB using the AWS SDK for .NET object persistence model - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBContext.ArbitraryDataMapping.html",
    "html": "Mapping arbitrary data with DynamoDB using the AWS SDK for .NET object persistence model\nPDF\nRSS\n\nIn addition to the supported .NET types (see Supported data types), you can use types in your application for which there is no direct mapping to the Amazon DynamoDB types. The object persistence model supports storing data of arbitrary types as long as you provide the converter to convert data from the arbitrary type to the DynamoDB type and vice versa. The converter code transforms data during both the saving and loading of the objects.\n\nYou can create any types on the client-side. However the data stored in the tables is one of the DynamoDB types, and during query and scan, any data comparisons made are against the data stored in DynamoDB.\n\nThe following C# code example defines a Book class with Id, Title, ISBN, and Dimension properties. The Dimension property is of the DimensionType that describes Height, Width, and Thickness properties. The example code provides the converter methods ToEntry and FromEntry to convert data between the DimensionType and the DynamoDB string types. For example, when saving a Book instance, the converter creates a book Dimension string such as \"8.5x11x.05\". When you retrieve a book, it converts the string to a DimensionType instance.\n\nThe example maps the Book type to the ProductCatalog table. It saves a sample Book instance, retrieves it, updates its dimensions, and saves the updated Book again.\n\nFor step-by-step instructions for testing the following example, see .NET code examples.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.DataModel;\nusing Amazon.DynamoDBv2.DocumentModel;\nusing Amazon.Runtime;\nusing Amazon.SecurityToken;\n\nnamespace com.amazonaws.codesamples\n{\n    class HighLevelMappingArbitraryData\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                DynamoDBContext context = new DynamoDBContext(client);\n\n                // 1. Create a book.\n                DimensionType myBookDimensions = new DimensionType()\n                {\n                    Length = 8M,\n                    Height = 11M,\n                    Thickness = 0.5M\n                };\n\n                Book myBook = new Book\n                {\n                    Id = 501,\n                    Title = \"AWS SDK for .NET Object Persistence Model Handling Arbitrary Data\",\n                    ISBN = \"999-9999999999\",\n                    BookAuthors = new List<string> { \"Author 1\", \"Author 2\" },\n                    Dimensions = myBookDimensions\n                };\n\n                context.Save(myBook);\n\n                // 2. Retrieve the book.\n                Book bookRetrieved = context.Load<Book>(501);\n\n                // 3. Update property (book dimensions).\n                bookRetrieved.Dimensions.Height += 1;\n                bookRetrieved.Dimensions.Length += 1;\n                bookRetrieved.Dimensions.Thickness += 0.2M;\n                // Update the book.\n                context.Save(bookRetrieved);\n\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (AmazonDynamoDBException e) { Console.WriteLine(e.Message); }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n        }\n    }\n    [DynamoDBTable(\"ProductCatalog\")]\n    public class Book\n    {\n        [DynamoDBHashKey] //Partition key\n        public int Id\n        {\n            get; set;\n        }\n        [DynamoDBProperty]\n        public string Title\n        {\n            get; set;\n        }\n        [DynamoDBProperty]\n        public string ISBN\n        {\n            get; set;\n        }\n        // Multi-valued (set type) attribute.\n        [DynamoDBProperty(\"Authors\")]\n        public List<string> BookAuthors\n        {\n            get; set;\n        }\n        // Arbitrary type, with a converter to map it to DynamoDB type.\n        [DynamoDBProperty(typeof(DimensionTypeConverter))]\n        public DimensionType Dimensions\n        {\n            get; set;\n        }\n    }\n\n    public class DimensionType\n    {\n        public decimal Length\n        {\n            get; set;\n        }\n        public decimal Height\n        {\n            get; set;\n        }\n        public decimal Thickness\n        {\n            get; set;\n        }\n    }\n\n    // Converts the complex type DimensionType to string and vice-versa.\n    public class DimensionTypeConverter : IPropertyConverter\n    {\n        public DynamoDBEntry ToEntry(object value)\n        {\n            DimensionType bookDimensions = value as DimensionType;\n            if (bookDimensions == null) throw new ArgumentOutOfRangeException();\n\n            string data = string.Format(\"{1}{0}{2}{0}{3}\", \" x \",\n                            bookDimensions.Length, bookDimensions.Height, bookDimensions.Thickness);\n\n            DynamoDBEntry entry = new Primitive\n            {\n                Value = data\n            };\n            return entry;\n        }\n\n        public object FromEntry(DynamoDBEntry entry)\n        {\n            Primitive primitive = entry as Primitive;\n            if (primitive == null || !(primitive.Value is String) || string.IsNullOrEmpty((string)primitive.Value))\n                throw new ArgumentOutOfRangeException();\n\n            string[] data = ((string)(primitive.Value)).Split(new string[] { \" x \" }, StringSplitOptions.None);\n            if (data.Length != 3) throw new ArgumentOutOfRangeException();\n\n            DimensionType complexData = new DimensionType\n            {\n                Length = Convert.ToDecimal(data[0]),\n                Height = Convert.ToDecimal(data[1]),\n                Thickness = Convert.ToDecimal(data[2])\n            };\n            return complexData;\n        }\n    }\n}\n"
  },
  {
    "title": "Optimistic locking using a version number with DynamoDB using the AWS SDK for .NET object persistence model - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBContext.VersionSupport.html",
    "html": "Optimistic locking using a version number with DynamoDB using the AWS SDK for .NET object persistence model\nPDF\nRSS\n\nOptimistic locking support in the object persistence model ensures that the item version for your application is the same as the item version on the server side before updating or deleting the item. Suppose that you retrieve an item for update. However, before you send your updates back, some other application updates the same item. Now your application has a stale copy of the item. Without optimistic locking, any update you perform will overwrite the update made by the other application.\n\nThe optimistic locking feature of the object persistence model provides the DynamoDBVersion tag that you can use to enable optimistic locking. To use this feature, you add a property to your class for storing the version number. You add the DynamoDBVersion attribute to the property. When you first save the object, the DynamoDBContext assigns a version number and increments this value each time you update the item.\n\nYour update or delete request succeeds only if the client-side object version matches the corresponding version number of the item on the server side. If your application has a stale copy, it must get the latest version from the server before it can update or delete that item.\n\nThe following C# code example defines a Book class with object persistence attributes mapping it to the ProductCatalog table. The VersionNumber property in the class decorated with the DynamoDBVersion attribute stores the version number value.\n\nExample\n[DynamoDBTable(\"ProductCatalog\")]\n  public class Book\n  {\n    [DynamoDBHashKey]   //Partition key\n    public int Id { get; set; }\n    [DynamoDBProperty]\n    public string Title { get; set; }\n    [DynamoDBProperty]\n    public string ISBN { get; set; }\n    [DynamoDBProperty(\"Authors\")]\n    public List<string> BookAuthors { get; set; }\n    [DynamoDBVersion]\n    public int? VersionNumber { get; set; }\n  }\nNote\n\nYou can apply the DynamoDBVersion attribute only to a nullable numeric primitive type (such as int?).\n\nOptimistic locking has the following impact on DynamoDBContext operations:\n\nFor a new item, DynamoDBContext assigns initial version number 0. If you retrieve an existing item, update one or more of its properties, and try to save the changes, the save operation succeeds only if the version number on the client side and the server side match. DynamoDBContext increments the version number. You don't need to set the version number.\n\nThe Delete method provides overloads that can take either a primary key value or an object as parameter, as shown in the following C# code example.\n\nExample\nDynamoDBContext context = new DynamoDBContext(client);\n...\n// Load a book.\nBook book = context.Load<ProductCatalog>(111);\n// Do other operations.\n// Delete 1 - Pass in the book object.\ncontext.Delete<ProductCatalog>(book);\n\n// Delete 2 - Pass in the Id (primary key)\ncontext.Delete<ProductCatalog>(222);\n\nIf you provide an object as the parameter, the delete succeeds only if the object version matches the corresponding server-side item version. However, if you provide a primary key value as the parameter, DynamoDBContext is unaware of any version numbers, and it deletes the item without making the version check.\n\nNote that the internal implementation of optimistic locking in the object persistence model code uses the conditional update and the conditional delete API actions in DynamoDB.\n\nDisabling optimistic locking\n\nTo disable optimistic locking, you use the SkipVersionCheck configuration property. You can set this property when creating DynamoDBContext. In this case, optimistic locking is disabled for any requests that you make using the context. For more information, see Specifying optional parameters for DynamoDBContext .\n\nInstead of setting the property at the context level, you can disable optimistic locking for a specific operation, as shown in the following C# code example. The example uses the context to delete a book item. The Delete method sets the optional SkipVersionCheck property to true, disabling version checking.\n\nExample\nDynamoDBContext context = new DynamoDBContext(client);\n// Load a book.\nBook book = context.Load<ProductCatalog>(111);\n...\n// Delete the book.\ncontext.Delete<Book>(book, new DynamoDBContextConfig { SkipVersionCheck = true });"
  },
  {
    "title": "DynamoDBContext class - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DotNetDynamoDBContext.html",
    "html": "DynamoDBContext class\nPDF\nRSS\n\nThe DynamoDBContext class is the entry point to the Amazon DynamoDB database. It provides a connection to DynamoDB and enables you to access your data in various tables, perform various CRUD operations, and run queries. The DynamoDBContext class provides the following methods.\n\nTopics\nCreate​MultiTable​BatchGet\nCreate​MultiTable​BatchWrite\nCreateBatchGet\ncreateBatchWrite\nDelete\nDispose\nExecute​batch​get\nExecute​batch​write\nFromDocument\nFromQuery\nFromScan\nGet​target​table\nLoad\nQuery\nSave\nScan\nToDocument\nSpecifying optional parameters for DynamoDBContext\nCreate​MultiTable​BatchGet\n\nCreates a MultiTableBatchGet object, composed of multiple individual BatchGet objects. Each of these BatchGet objects can be used for retrieving items from a single DynamoDB table.\n\nTo retrieve the items from tables, use the ExecuteBatchGet method, passing the MultiTableBatchGet object as a parameter.\n\nCreate​MultiTable​BatchWrite\n\nCreates a MultiTableBatchWrite object, composed of multiple individual BatchWrite objects. Each of these BatchWrite objects can be used for writing or deleting items in a single DynamoDB table.\n\nTo write to tables, use the ExecuteBatchWrite method, passing the MultiTableBatchWrite object as a parameter.\n\nCreateBatchGet\n\nCreates a BatchGet object that you can use to retrieve multiple items from a table. For more information, see Batch get: Getting multiple items .\n\ncreateBatchWrite\n\nCreates a BatchWrite object that you can use to put multiple items into a table, or to delete multiple items from a table. For more information, see Batch write: Putting and deleting multiple items .\n\nDelete\n\nDeletes an item from the table. The method requires the primary key of the item you want to delete. You can provide either the primary key value or a client-side object containing a primary key value as a parameter to this method.\n\nIf you specify a client-side object as a parameter and you have enabled optimistic locking, the delete succeeds only if the client-side and the server-side versions of the object match.\n\nIf you specify only the primary key value as a parameter, the delete succeeds regardless of whether you have enabled optimistic locking or not.\n\nNote\n\nTo perform this operation in the background, use the DeleteAsync method instead.\n\nDispose\n\nDisposes of all managed and unmanaged resources.\n\nExecute​batch​get\n\nReads data from one or more tables, processing all of the BatchGet objects in a MultiTableBatchGet.\n\nNote\n\nTo perform this operation in the background, use the ExecuteBatchGetAsync method instead.\n\nExecute​batch​write\n\nWrites or deletes data in one or more tables, processing all of the BatchWrite objects in a MultiTableBatchWrite.\n\nNote\n\nTo perform this operation in the background, use the ExecuteBatchWriteAsync method instead.\n\nFromDocument\n\nGiven an instance of a Document, the FromDocument method returns an instance of a client-side class.\n\nThis is helpful if you want to use the document model classes along with the object persistence model to perform any data operations. For more information about the document model classes provided by the AWS SDK for .NET, see .NET: Document model.\n\nSuppose that you have a Document object named doc, that contains a representation of a Forum item. (To see how to construct this object, see the description for the ToDocument method later in this topic.) You can use FromDocument to retrieve the Forum item from the Document, as shown in the following C# code example.\n\nExample\nforum101 = context.FromDocument<Forum>(101);\nNote\n\nIf your Document object implements the IEnumerable interface, you can use the FromDocuments method instead. This allows you to iterate over all of the class instances in the Document.\n\nFromQuery\n\nRuns a Query operation, with the query parameters defined in a QueryOperationConfig object.\n\nNote\n\nTo perform this operation in the background, use the FromQueryAsync method instead.\n\nFromScan\n\nRuns a Scan operation, with the scan parameters defined in a ScanOperationConfig object.\n\nNote\n\nTo perform this operation in the background, use the FromScanAsync method instead.\n\nGet​target​table\n\nRetrieves the target table for the specified type. This is useful if you are writing a custom converter for mapping arbitrary data to a DynamoDB table, and you need to determine which table is associated with a custom data type.\n\nLoad\n\nRetrieves an item from a table. The method requires only the primary key of the item you want to retrieve.\n\nBy default, DynamoDB returns the item with values that are eventually consistent. For information about the eventual consistency model, see Read consistency.\n\nLoad or LoadAsync method calls the GetItem operation, which requires you to specify the primary key for the table. Because GetItem ignores the IndexName parameter, you can’t load an item using an index’s partition or sort key. Therefore, you must use the table's primary key to load an item.\n\nNote\n\nTo perform this operation in the background, use the LoadAsync method instead. To view an example of using the LoadAsync method to perform high-level CRUD operations on a DynamoDB table, see the following example.\n\n\n    /// <summary>\n    /// Shows how to perform high-level CRUD operations on an Amazon DynamoDB\n    /// table.\n    /// </summary>\n    public class HighLevelItemCrud\n    {\n        public static async Task Main()\n        {\n            var client = new AmazonDynamoDBClient();\n            DynamoDBContext context = new DynamoDBContext(client);\n            await PerformCRUDOperations(context);\n        }\n\n        public static async Task PerformCRUDOperations(IDynamoDBContext context)\n        {\n            int bookId = 1001; // Some unique value.\n            Book myBook = new Book\n            {\n                Id = bookId,\n                Title = \"object persistence-AWS SDK for.NET SDK-Book 1001\",\n                Isbn = \"111-1111111001\",\n                BookAuthors = new List<string> { \"Author 1\", \"Author 2\" },\n            };\n\n            // Save the book to the ProductCatalog table.\n            await context.SaveAsync(myBook);\n\n            // Retrieve the book from the ProductCatalog table.\n            Book bookRetrieved = await context.LoadAsync<Book>(bookId);\n\n            // Update some properties.\n            bookRetrieved.Isbn = \"222-2222221001\";\n\n            // Update existing authors list with the following values.\n            bookRetrieved.BookAuthors = new List<string> { \" Author 1\", \"Author x\" };\n            await context.SaveAsync(bookRetrieved);\n\n            // Retrieve the updated book. This time, add the optional\n            // ConsistentRead parameter using DynamoDBContextConfig object.\n            await context.LoadAsync<Book>(bookId, new DynamoDBContextConfig\n            {\n                ConsistentRead = true,\n            });\n\n            // Delete the book.\n            await context.DeleteAsync<Book>(bookId);\n\n            // Try to retrieve deleted book. It should return null.\n            Book deletedBook = await context.LoadAsync<Book>(bookId, new DynamoDBContextConfig\n            {\n                ConsistentRead = true,\n            });\n\n            if (deletedBook == null)\n            {\n                Console.WriteLine(\"Book is deleted\");\n            }\n        }\n    }\n\n\nQuery\n\nQueries a table based on query parameters you provide.\n\nYou can query a table only if it has a composite primary key (partition key and sort key). When querying, you must specify a partition key and a condition that applies to the sort key.\n\nSuppose that you have a client-side Reply class mapped to the Reply table in DynamoDB. The following C# code example queries the Reply table to find forum thread replies posted in the past 15 days. The Reply table has a primary key that has the Id partition key and the ReplyDateTime sort key. For more information about the Reply table, see Creating tables and loading data for code examples in DynamoDB.\n\nExample\nDynamoDBContext context = new DynamoDBContext(client);\n\nstring replyId = \"DynamoDB#DynamoDB Thread 1\"; //Partition key\nDateTime twoWeeksAgoDate = DateTime.UtcNow.Subtract(new TimeSpan(14, 0, 0, 0)); // Date to compare.\nIEnumerable<Reply> latestReplies = context.Query<Reply>(replyId, QueryOperator.GreaterThan, twoWeeksAgoDate);\n\nThis returns a collection of Reply objects.\n\nThe Query method returns a \"lazy-loaded\" IEnumerable collection. It initially returns only one page of results, and then makes a service call for the next page if needed. To obtain all the matching items, you need to iterate only over the IEnumerable.\n\nIf your table has a simple primary key (partition key), you can't use the Query method. Instead, you can use the Load method and provide the partition key to retrieve the item.\n\nNote\n\nTo perform this operation in the background, use the QueryAsync method instead.\n\nSave\n\nSaves the specified object to the table. If the primary key specified in the input object doesn't exist in the table, the method adds a new item to the table. If the primary key exists, the method updates the existing item.\n\nIf you have optimistic locking configured, the update succeeds only if the client and the server-side versions of the item match. For more information, see Optimistic locking using a version number with DynamoDB using the AWS SDK for .NET object persistence model.\n\nNote\n\nTo perform this operation in the background, use the SaveAsync method instead.\n\nScan\n\nPerforms an entire table scan.\n\nYou can filter scan results by specifying a scan condition. The condition can be evaluated on any attributes in the table. Suppose that you have a client-side class Book mapped to the ProductCatalog table in DynamoDB. The following C# example scans the table and returns only the book items priced less than 0.\n\nExample\nIEnumerable<Book> itemsWithWrongPrice = context.Scan<Book>(\n                    new ScanCondition(\"Price\", ScanOperator.LessThan, price),\n                    new ScanCondition(\"ProductCategory\", ScanOperator.Equal, \"Book\")\n      );\n\nThe Scan method returns a \"lazy-loaded\" IEnumerable collection. It initially returns only one page of results, and then makes a service call for the next page if needed. To obtain all the matching items, you only need to iterate over the IEnumerable.\n\nFor performance reasons, you should query your tables and avoid a table scan.\n\nNote\n\nTo perform this operation in the background, use the ScanAsync method instead.\n\nToDocument\n\nReturns an instance of the Document document model class from your class instance.\n\nThis is helpful if you want to use the document model classes along with the object persistence model to perform any data operations. For more information about the document model classes provided by the AWS SDK for .NET, see .NET: Document model.\n\nSuppose that you have a client-side class mapped to the sample Forum table. You can then use a DynamoDBContext to get an item as a Document object from the Forum table, as shown in the following C# code example.\n\nExample\nDynamoDBContext context = new DynamoDBContext(client);\n\nForum forum101 = context.Load<Forum>(101); // Retrieve a forum by primary key.\nDocument doc = context.ToDocument<Forum>(forum101);\nSpecifying optional parameters for DynamoDBContext\n\nWhen using the object persistence model, you can specify the following optional parameters for the DynamoDBContext.\n\nConsistentRead—When retrieving data using the Load, Query, or Scan operations, you can add this optional parameter to request the latest values for the data.\n\nIgnoreNullValues—This parameter informs DynamoDBContext to ignore null values on attributes during a Save operation. If this parameter is false (or if it is not set), then a null value is interpreted as a directive to delete the specific attribute.\n\nSkipVersionCheck— This parameter informs DynamoDBContext not to compare versions when saving or deleting an item. For more information about versioning, see Optimistic locking using a version number with DynamoDB using the AWS SDK for .NET object persistence model.\n\nTableNamePrefix— Prefixes all table names with a specific string. If this parameter is null (or if it is not set), then no prefix is used.\n\nThe following C# example creates a new DynamoDBContext by specifying two of the preceding optional parameters.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\n...\nDynamoDBContext context =\n       new DynamoDBContext(client, new DynamoDBContextConfig { ConsistentRead = true, SkipVersionCheck = true});\n\nDynamoDBContext includes these optional parameters with each request that you send using this context.\n\nInstead of setting these parameters at the DynamoDBContext level, you can specify them for individual operations you run using DynamoDBContext, as shown in the following C# code example. The example loads a specific book item. The Load method of DynamoDBContext specifies the preceding optional parameters.\n\nExample\nAmazonDynamoDBClient client = new AmazonDynamoDBClient();\n...\nDynamoDBContext context = new DynamoDBContext(client);\nBook bookItem = context.Load<Book>(productId,new DynamoDBContextConfig{ ConsistentRead = true, SkipVersionCheck = true });\n\nIn this case, DynamoDBContext includes these parameters only when sending the Get request."
  },
  {
    "title": "DynamoDB attributes - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DeclarativeTagsList.html",
    "html": "DynamoDB attributes\nPDF\nRSS\n\nThis section describes the attributes that the object persistence model offers so that you can map your classes and properties to DynamoDB tables and attributes.\n\nNote\n\nIn the following attributes, only DynamoDBTable and DynamoDBHashKey are required.\n\nDynamoDBGlobalSecondaryIndexHashKey\n\nMaps a class property to the partition key of a global secondary index. Use this attribute if you need to Query a global secondary index.\n\nDynamoDBGlobalSecondaryIndexRangeKey\n\nMaps a class property to the sort key of a global secondary index. Use this attribute if you need to Query a global secondary index and want to refine your results using the index sort key.\n\nDynamoDBHashKey\n\nMaps a class property to the partition key of the table's primary key. The primary key attributes cannot be a collection type.\n\nThe following C# code example maps the Book class to the ProductCatalog table, and the Id property to the table's primary key partition key.\n\n[DynamoDBTable(\"ProductCatalog\")]\npublic class Book \n{\n    [DynamoDBHashKey]\n    public int Id { get; set; }\n\n    // Additional properties go here.\n}\nDynamoDBIgnore\n\nIndicates that the associated property should be ignored. If you don't want to save any of your class properties, you can add this attribute to instruct DynamoDBContext not to include this property when saving objects to the table.\n\nDynamoDBLocalSecondaryIndexRangeKey\n\nMaps a class property to the sort key of a local secondary index. Use this attribute if you need to Query a local secondary index and want to refine your results using the index sort key.\n\nDynamoDBProperty\n\nMaps a class property to a table attribute. If the class property maps to a table attribute of the same name, you don't need to specify this attribute. However, if the names are not the same, you can use this tag to provide the mapping. In the following C# statement, the DynamoDBProperty maps the BookAuthors property to the Authors attribute in the table.\n\n[DynamoDBProperty(\"Authors\")]\npublic List<string> BookAuthors { get; set; }\n\nDynamoDBContext uses this mapping information to create the Authors attribute when saving object data to the corresponding table.\n\nDynamoDBRenamable\n\nSpecifies an alternative name for a class property. This is useful if you are writing a custom converter for mapping arbitrary data to a DynamoDB table where the name of a class property is different from a table attribute.\n\nDynamoDBRangeKey\n\nMaps a class property to the sort key of the table's primary key. If the table has a composite primary key (partition key and sort key), you must specify both the DynamoDBHashKey and DynamoDBRangeKey attributes in your class mapping.\n\nFor example, the sample table Reply has a primary key made of the Id partition key and Replenishment sort key. The following C# code example maps the Reply class to the Reply table. The class definition also indicates that two of its properties map to the primary key.\n\nFor more information about sample tables, see Creating tables and loading data for code examples in DynamoDB.\n\n[DynamoDBTable(\"Reply\")]\npublic class Reply \n{\n   [DynamoDBHashKey]\n   public int ThreadId { get; set; }\n   [DynamoDBRangeKey]\n   public string Replenishment { get; set; }\n   \n   // Additional properties go here.\n}\nDynamoDBTable\n\nIdentifies the target table in DynamoDB to which the class maps. For example, the following C# code example maps the Developer class to the People table in DynamoDB.\n\n[DynamoDBTable(\"People\")]\npublic class Developer { ...}\n\nThis attribute can be inherited or overridden.\n\nThe DynamoDBTable attribute can be inherited. In the preceding example, if you add a new class, Lead, that inherits from the Developer class, it also maps to the People table. Both the Developer and Lead objects are stored in the People table.\n\nThe DynamoDBTable attribute can also be overridden. In the following C# code example, the Manager class inherits from the Developer class. However, the explicit addition of the DynamoDBTable attribute maps the class to another table (Managers).\n\n[DynamoDBTable(\"Managers\")]\npublic class Manager : Developer { ...}\n\nYou can add the optional parameter, LowerCamelCaseProperties, to request DynamoDB to make the first letter of the property name lowercase when storing the objects to a table, as shown in the following C# example.\n\n[DynamoDBTable(\"People\", LowerCamelCaseProperties=true)]\npublic class Developer \n{\n    string DeveloperName;\n    ...\n}\n\nWhen saving instances of the Developer class, DynamoDBContext saves the DeveloperName property as the developerName.\n\nDynamoDBVersion\n\nIdentifies a class property for storing the item version number. For more information about versioning, see Optimistic locking using a version number with DynamoDB using the AWS SDK for .NET object persistence model."
  },
  {
    "title": ".NET: Object persistence model - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DotNetSDKHighLevel.html",
    "html": ".NET: Object persistence model\nPDF\nRSS\nTopics\nDynamoDB attributes\nDynamoDBContext class\nSupported data types\nOptimistic locking using a version number with DynamoDB using the AWS SDK for .NET object persistence model\nMapping arbitrary data with DynamoDB using the AWS SDK for .NET object persistence model\nBatch operations using the AWS SDK for .NET object persistence model\nExample: CRUD operations using the AWS SDK for .NET object persistence model\nExample: Batch write operation using the AWS SDK for .NET object persistence model\nExample: Query and scan in DynamoDB using the AWS SDK for .NET object persistence model\n\nThe AWS SDK for .NET provides an object persistence model that enables you to map your client-side classes to Amazon DynamoDB tables. Each object instance then maps to an item in the corresponding tables. To save your client-side objects to the tables, the object persistence model provides the DynamoDBContext class, an entry point to DynamoDB. This class provides you a connection to DynamoDB and enables you to access tables, perform various CRUD operations, and run queries.\n\nThe object persistence model provides a set of attributes to map client-side classes to tables, and properties/fields to table attributes.\n\nNote\n\nThe object persistence model does not provide an API to create, update, or delete tables. It provides only data operations. You can use only the AWS SDK for .NET low-level API to create, update, and delete tables. For more information, see Working with DynamoDB tables in .NET.\n\nThe following example shows how the object persistence model works. It starts with the ProductCatalog table. It has Id as the primary key.\n\nProductCatalog(Id, ...)\n\nSuppose that you have a Book class with Title, ISBN, and Authors properties. You can map the Book class to the ProductCatalog table by adding the attributes defined by the object persistence model, as shown in the following C# code example.\n\nExample\n[DynamoDBTable(\"ProductCatalog\")]\n  public class Book\n  {\n    [DynamoDBHashKey]\n    public int Id { get; set; }\n\n    public string Title { get; set; }\n    public int ISBN { get; set; }\n\n    [DynamoDBProperty(\"Authors\")]\n    public List<string> BookAuthors { get; set; }\n\n    [DynamoDBIgnore]\n    public string CoverPage { get; set; }\n  }\n\nIn the preceding example, the DynamoDBTable attribute maps the Book class to the ProductCatalog table.\n\nThe object persistence model supports both the explicit and default mapping between class properties and table attributes.\n\nExplicit mapping—To map a property to a primary key, you must use the DynamoDBHashKey and DynamoDBRangeKey object persistence model attributes. Additionally, for the nonprimary key attributes, if a property name in your class and the corresponding table attribute to which you want to map it are not the same, you must define the mapping by explicitly adding the DynamoDBProperty attribute.\n\nIn the preceding example, the Id property maps to the primary key with the same name, and the BookAuthors property maps to the Authors attribute in the ProductCatalog table.\n\nDefault mapping—By default, the object persistence model maps the class properties to the attributes with the same name in the table.\n\nIn the preceding example, the properties Title and ISBN map to the attributes with the same name in the ProductCatalog table.\n\nYou don't have to map every single class property. You identify these properties by adding the DynamoDBIgnore attribute. When you save a Book instance to the table, the DynamoDBContext does not include the CoverPage property. It also does not return this property when you retrieve the book instance.\n\nYou can map properties of .NET primitive types such as int and string. You also can map any arbitrary data types as long as you provide an appropriate converter to map the arbitrary data to one of the DynamoDB types. To learn about mapping arbitrary types, see Mapping arbitrary data with DynamoDB using the AWS SDK for .NET object persistence model.\n\nThe object persistence model supports optimistic locking. During an update operation, this ensures that you have the latest copy of the item you are about to update. For more information, see Optimistic locking using a version number with DynamoDB using the AWS SDK for .NET object persistence model.\n\nSupported data types\n\nThe object persistence model supports a set of primitive .NET data types, collections, and arbitrary data types. The model supports the following primitive data types.\n\nbool\n\nbyte\n\nchar\n\nDateTime\n\ndecimal\n\ndouble\n\nfloat\n\nInt16\n\nInt32\n\nInt64\n\nSByte\n\nstring\n\nUInt16\n\nUInt32\n\nUInt64\n\nThe object persistence model also supports the .NET collection types. DynamoDBContext is able to convert concrete collection types and simple Plain Old CLR Objects (POCOs).\n\nThe following table summarizes the mapping of the preceding .NET types to the DynamoDB types.\n\n.NET primitive type\tDynamoDB type\n\n\nAll number types\n\n\t\n\nN (number type)\n\n\n\n\nAll string types\n\n\t\n\nS (string type)\n\n\n\n\nMemoryStream, byte[]\n\n\t\n\nB (binary type)\n\n\nbool\tN (number type). 0 represents false and 1 represents true.\nCollection types\tBS (binary set) type, SS (string set) type, and NS (number set) type\nDateTime\tS (string type). The DateTime values are stored as ISO-8601 formatted strings.\n\nThe object persistence model also supports arbitrary data types. However, you must provide converter code to map the complex types to the DynamoDB types.\n\nNote\n\nEmpty binary values are supported.\n\nReading of empty string values is supported. Empty string attribute values are supported within attribute values of string Set type while writing to DynamoDB. Empty string attribute values of string type and empty string values contained within List or Map type are dropped from write requests"
  },
  {
    "title": "Table.Scan method in the AWS SDK for .NET - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ScanMidLevelDotNet.html",
    "html": "Table.Scan method in the AWS SDK for .NET\nPDF\nRSS\n\nThe Scan method performs a full table scan. It provides two overloads. The only parameter required by the Scan method is the scan filter, which you can provide using the following overload.\n\nExample\nScan(ScanFilter filter);\n\nFor example, assume that you maintain a table of forum threads tracking information such as thread subject (primary), the related message, forum Id to which the thread belongs, Tags, and other information. Assume that the subject is the primary key.\n\nExample\nThread(Subject, Message, ForumId, Tags, LastPostedDateTime, .... )\n\nThis is a simplified version of forums and threads that you see on AWS forums (see Discussion forums). The following C# code example queries all threads in a specific forum (ForumId = 101) that are tagged \"sortkey\". Because the ForumId is not a primary key, the example scans the table. The ScanFilter includes two conditions. The query returns all the threads that satisfy both of the conditions.\n\nExample\nstring tableName = \"Thread\";\nTable ThreadTable = Table.LoadTable(client, tableName);\n\nScanFilter scanFilter = new ScanFilter();\nscanFilter.AddCondition(\"ForumId\", ScanOperator.Equal, 101);\nscanFilter.AddCondition(\"Tags\", ScanOperator.Contains, \"sortkey\");\n\nSearch search = ThreadTable.Scan(scanFilter);\nSpecifying optional parameters\n\nYou also can specify optional parameters to Scan, such as a specific list of attributes to retrieve or whether to perform a strongly consistent read. To specify optional parameters, you must create a ScanOperationConfig object that includes both the required and optional parameters and use the following overload.\n\nExample\nScan(ScanOperationConfig config);\n\nThe following C# code example runs the same preceding query (find forum threads in which the ForumId is 101 and the Tag attribute contains the \"sortkey\" keyword). Assume that you want to add an optional parameter to retrieve only a specific attribute list. In this case, you must create a ScanOperationConfig object by providing all the parameters, required and optional parameters, as shown in the following code example.\n\nExample\nstring tableName = \"Thread\";\nTable ThreadTable = Table.LoadTable(client, tableName);\n\nScanFilter scanFilter = new ScanFilter();\nscanFilter.AddCondition(\"ForumId\", ScanOperator.Equal, forumId);\nscanFilter.AddCondition(\"Tags\", ScanOperator.Contains, \"sortkey\");\n\nScanOperationConfig config = new ScanOperationConfig()\n{\n  AttributesToGet = new List<string> { \"Subject\", \"Message\" } ,\n  Filter = scanFilter\n};\n\nSearch search = ThreadTable.Scan(config);\nExample: Scan using the Table.Scan method\n\nThe Scan operation performs a full table scan making it a potentially expensive operation. You should use queries instead. However, there are times when you might need to run a scan against a table. For example, you might have a data entry error in the product pricing, and you must scan the table as shown in the following C# code example. The example scans the ProductCatalog table to find products for which the price value is less than 0. The example illustrates the use of the two Table.Scan overloads.\n\nTable.Scan that takes the ScanFilter object as a parameter.\n\nYou can pass the ScanFilter parameter when passing in only the required parameters.\n\nTable.Scan that takes the ScanOperationConfig object as a parameter.\n\nYou must use the ScanOperationConfig parameter if you want to pass any optional parameters to the Scan method.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.DocumentModel;\n\nnamespace com.amazonaws.codesamples\n{\n    class MidLevelScanOnly\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            Table productCatalogTable = Table.LoadTable(client, \"ProductCatalog\");\n            // Scan example.\n            FindProductsWithNegativePrice(productCatalogTable);\n            FindProductsWithNegativePriceWithConfig(productCatalogTable);\n\n            Console.WriteLine(\"To continue, press Enter\");\n            Console.ReadLine();\n        }\n\n        private static void FindProductsWithNegativePrice(Table productCatalogTable)\n        {\n            // Assume there is a price error. So we scan to find items priced < 0.\n            ScanFilter scanFilter = new ScanFilter();\n            scanFilter.AddCondition(\"Price\", ScanOperator.LessThan, 0);\n\n            Search search = productCatalogTable.Scan(scanFilter);\n\n            List<Document> documentList = new List<Document>();\n            do\n            {\n                documentList = search.GetNextSet();\n                Console.WriteLine(\"\\nFindProductsWithNegativePrice: printing ............\");\n                foreach (var document in documentList)\n                    PrintDocument(document);\n            } while (!search.IsDone);\n        }\n\n        private static void FindProductsWithNegativePriceWithConfig(Table productCatalogTable)\n        {\n            // Assume there is a price error. So we scan to find items priced < 0.\n            ScanFilter scanFilter = new ScanFilter();\n            scanFilter.AddCondition(\"Price\", ScanOperator.LessThan, 0);\n\n            ScanOperationConfig config = new ScanOperationConfig()\n            {\n                Filter = scanFilter,\n                Select = SelectValues.SpecificAttributes,\n                AttributesToGet = new List<string> { \"Title\", \"Id\" }\n            };\n\n            Search search = productCatalogTable.Scan(config);\n\n            List<Document> documentList = new List<Document>();\n            do\n            {\n                documentList = search.GetNextSet();\n                Console.WriteLine(\"\\nFindProductsWithNegativePriceWithConfig: printing ............\");\n                foreach (var document in documentList)\n                    PrintDocument(document);\n            } while (!search.IsDone);\n        }\n\n        private static void PrintDocument(Document document)\n        {\n            //   count++;\n            Console.WriteLine();\n            foreach (var attribute in document.GetAttributeNames())\n            {\n                string stringValue = null;\n                var value = document[attribute];\n                if (value is Primitive)\n                    stringValue = value.AsPrimitive().Value.ToString();\n                else if (value is PrimitiveList)\n                    stringValue = string.Join(\",\", (from primitive\n                                    in value.AsPrimitiveList().Entries\n                                                    select primitive.Value).ToArray());\n                Console.WriteLine(\"{0} - {1}\", attribute, stringValue);\n            }\n        }\n    }\n}\n"
  },
  {
    "title": "Table.Query method in the AWS SDK for .NET - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/QueryMidLevelDotNet.html",
    "html": "Table.Query method in the AWS SDK for .NET\nPDF\nRSS\n\nThe Query method enables you to query your tables. You can only query the tables that have a composite primary key (partition key and sort key). If your table's primary key is made of only a partition key, then the Query operation is not supported. By default, Query internally performs queries that are eventually consistent. To learn about the consistency model, see Read consistency.\n\nThe Query method provides two overloads. The minimum required parameters to the Query method are a partition key value and a sort key filter. You can use the following overload to provide these minimum required parameters.\n\nExample\nQuery(Primitive partitionKey, RangeFilter Filter);\n\nFor example, the following C# code queries for all forum replies that were posted in the last 15 days.\n\nExample\nstring tableName = \"Reply\";\nTable table = Table.LoadTable(client, tableName);\n\nDateTime twoWeeksAgoDate = DateTime.UtcNow - TimeSpan.FromDays(15);\nRangeFilter filter = new RangeFilter(QueryOperator.GreaterThan, twoWeeksAgoDate);\nSearch search = table.Query(\"DynamoDB Thread 2\", filter);\n\nThis creates a Search object. You can now call the Search.GetNextSet method iteratively to retrieve one page of results at a time, as shown in the following C# code example. The code prints the attribute values for each item that the query returns.\n\nExample\n\nList<Document> documentSet = new List<Document>();\ndo\n{\n  documentSet = search.GetNextSet();\n  foreach (var document in documentSet)\n    PrintDocument(document);\n} while (!search.IsDone);\n\n    private static void PrintDocument(Document document)\n{\n  Console.WriteLine();\n  foreach (var attribute in document.GetAttributeNames())\n  {\n    string stringValue = null;\n    var value = document[attribute];\n    if (value is Primitive)\n      stringValue = value.AsPrimitive().Value;\n    else if (value is PrimitiveList)\n      stringValue = string.Join(\",\", (from primitive\n                                        in value.AsPrimitiveList().Entries\n                                      select primitive.Value).ToArray());\n    Console.WriteLine(\"{0} - {1}\", attribute, stringValue);\n  }\n}\n\nSpecifying optional parameters\n\nYou can also specify optional parameters for Query, such as specifying a list of attributes to retrieve, strongly consistent reads, page size, and the number of items returned per page. For a complete list of parameters, see Query. To specify optional parameters, you must use the following overload in which you provide the QueryOperationConfig object.\n\nExample\nQuery(QueryOperationConfig config);\n\nAssume that you want to run the query in the preceding example (retrieve forum replies posted in the last 15 days). However, assume that you want to provide optional query parameters to retrieve only specific attributes and also request a strongly consistent read. The following C# code example constructs the request using the QueryOperationConfig object.\n\nExample\nTable table = Table.LoadTable(client, \"Reply\");\nDateTime twoWeeksAgoDate = DateTime.UtcNow - TimeSpan.FromDays(15);\nQueryOperationConfig config = new QueryOperationConfig()\n{\n  HashKey = \"DynamoDB Thread 2\", //Partition key\n  AttributesToGet = new List<string>\n    { \"Subject\", \"ReplyDateTime\", \"PostedBy\" },\n  ConsistentRead = true,\n  Filter = new RangeFilter(QueryOperator.GreaterThan, twoWeeksAgoDate)\n};\n\nSearch search = table.Query(config);\nExample: Query using the Table.Query method\n\nThe following C# code example uses the Table.Query method to run the following sample queries.\n\nThe following queries are run against the Reply table.\n\nFind forum thread replies that were posted in the last 15 days.\n\nThis query is run twice. In the first Table.Query call, the example provides only the required query parameters. In the second Table.Query call, you provide optional query parameters to request a strongly consistent read and a list of attributes to retrieve.\n\nFind forum thread replies posted during a period of time.\n\nThis query uses the Between query operator to find replies posted in between two dates.\n\nGet a product from the ProductCatalog table.\n\nBecause the ProductCatalog table has a primary key that is only a partition key, you can only get items; you cannot query the table. The example retrieves a specific product item using the item Id.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.DocumentModel;\nusing Amazon.Runtime;\nusing Amazon.SecurityToken;\n\nnamespace com.amazonaws.codesamples\n{\n    class MidLevelQueryAndScan\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                // Query examples.\n                Table replyTable = Table.LoadTable(client, \"Reply\");\n                string forumName = \"Amazon DynamoDB\";\n                string threadSubject = \"DynamoDB Thread 2\";\n                FindRepliesInLast15Days(replyTable, forumName, threadSubject);\n                FindRepliesInLast15DaysWithConfig(replyTable, forumName, threadSubject);\n                FindRepliesPostedWithinTimePeriod(replyTable, forumName, threadSubject);\n\n                // Get Example.\n                Table productCatalogTable = Table.LoadTable(client, \"ProductCatalog\");\n                int productId = 101;\n                GetProduct(productCatalogTable, productId);\n\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (AmazonDynamoDBException e) { Console.WriteLine(e.Message); }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n        }\n\n        private static void GetProduct(Table tableName, int productId)\n        {\n            Console.WriteLine(\"*** Executing GetProduct() ***\");\n            Document productDocument = tableName.GetItem(productId);\n            if (productDocument != null)\n            {\n                PrintDocument(productDocument);\n            }\n            else\n            {\n                Console.WriteLine(\"Error: product \" + productId + \" does not exist\");\n            }\n        }\n\n        private static void FindRepliesInLast15Days(Table table, string forumName, string threadSubject)\n        {\n            string Attribute = forumName + \"#\" + threadSubject;\n\n            DateTime twoWeeksAgoDate = DateTime.UtcNow - TimeSpan.FromDays(15);\n            QueryFilter filter = new QueryFilter(\"Id\", QueryOperator.Equal, partitionKey);\n            filter.AddCondition(\"ReplyDateTime\", QueryOperator.GreaterThan, twoWeeksAgoDate);\n\n            // Use Query overloads that takes the minimum required query parameters.\n            Search search = table.Query(filter);\n\n            List<Document> documentSet = new List<Document>();\n            do\n            {\n                documentSet = search.GetNextSet();\n                Console.WriteLine(\"\\nFindRepliesInLast15Days: printing ............\");\n                foreach (var document in documentSet)\n                    PrintDocument(document);\n            } while (!search.IsDone);\n        }\n\n        private static void FindRepliesPostedWithinTimePeriod(Table table, string forumName, string threadSubject)\n        {\n            DateTime startDate = DateTime.UtcNow.Subtract(new TimeSpan(21, 0, 0, 0));\n            DateTime endDate = DateTime.UtcNow.Subtract(new TimeSpan(1, 0, 0, 0));\n\n            QueryFilter filter = new QueryFilter(\"Id\", QueryOperator.Equal, forumName + \"#\" + threadSubject);\n            filter.AddCondition(\"ReplyDateTime\", QueryOperator.Between, startDate, endDate);\n\n            QueryOperationConfig config = new QueryOperationConfig()\n            {\n                Limit = 2, // 2 items/page.\n                Select = SelectValues.SpecificAttributes,\n                AttributesToGet = new List<string> { \"Message\",\n                                 \"ReplyDateTime\",\n                                 \"PostedBy\" },\n                ConsistentRead = true,\n                Filter = filter\n            };\n\n            Search search = table.Query(config);\n\n            List<Document> documentList = new List<Document>();\n\n            do\n            {\n                documentList = search.GetNextSet();\n                Console.WriteLine(\"\\nFindRepliesPostedWithinTimePeriod: printing replies posted within dates: {0} and {1} ............\", startDate, endDate);\n                foreach (var document in documentList)\n                {\n                    PrintDocument(document);\n                }\n            } while (!search.IsDone);\n        }\n\n        private static void FindRepliesInLast15DaysWithConfig(Table table, string forumName, string threadName)\n        {\n            DateTime twoWeeksAgoDate = DateTime.UtcNow - TimeSpan.FromDays(15);\n            QueryFilter filter = new QueryFilter(\"Id\", QueryOperator.Equal, forumName + \"#\" + threadName);\n            filter.AddCondition(\"ReplyDateTime\", QueryOperator.GreaterThan, twoWeeksAgoDate);\n            // You are specifying optional parameters so use QueryOperationConfig.\n            QueryOperationConfig config = new QueryOperationConfig()\n            {\n                Filter = filter,\n                // Optional parameters.\n                Select = SelectValues.SpecificAttributes,\n                AttributesToGet = new List<string> { \"Message\", \"ReplyDateTime\",\n                                 \"PostedBy\" },\n                ConsistentRead = true\n            };\n\n            Search search = table.Query(config);\n\n            List<Document> documentSet = new List<Document>();\n            do\n            {\n                documentSet = search.GetNextSet();\n                Console.WriteLine(\"\\nFindRepliesInLast15DaysWithConfig: printing ............\");\n                foreach (var document in documentSet)\n                    PrintDocument(document);\n            } while (!search.IsDone);\n        }\n\n        private static void PrintDocument(Document document)\n        {\n            //   count++;\n            Console.WriteLine();\n            foreach (var attribute in document.GetAttributeNames())\n            {\n                string stringValue = null;\n                var value = document[attribute];\n                if (value is Primitive)\n                    stringValue = value.AsPrimitive().Value.ToString();\n                else if (value is PrimitiveList)\n                    stringValue = string.Join(\",\", (from primitive\n                                    in value.AsPrimitiveList().Entries\n                                                    select primitive.Value).ToArray());\n                Console.WriteLine(\"{0} - {1}\", attribute, stringValue);\n            }\n        }\n    }\n}\n"
  },
  {
    "title": "Example: Batch operations using the AWS SDK for .NET document model API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/example-batch-operations-net-doc-model.html",
    "html": "Example: Batch operations using the AWS SDK for .NET document model API\nPDF\nRSS\nTopics\nExample: Batch write using the AWS SDK for .NET document model\nExample: Batch write using the AWS SDK for .NET document model\n\nThe following C# code example illustrates single table and multi-table batch write operations. The example performs the following tasks:\n\nIllustrates a single table batch write. It adds two items to the ProductCatalog table.\n\nIllustrates a multi-table batch write. It adds an item to both the Forum and Thread tables and deletes an item from the Thread table.\n\nIf you followed the steps in Creating tables and loading data for code examples in DynamoDB, you already have the ProductCatalog, Forum, and Thread tables created. You can also create these sample tables programmatically. For more information, see Creating example tables and uploading data using the AWS SDK for .NET. For step-by-step instructions for testing the following example, see .NET code examples.\n\nExample\nusing System;\nusing System.Collections.Generic;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.DocumentModel;\nusing Amazon.Runtime;\n\nnamespace com.amazonaws.codesamples\n{\n    class MidLevelBatchWriteItem\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n        static void Main(string[] args)\n        {\n            try\n            {\n                SingleTableBatchWrite();\n                MultiTableBatchWrite();\n            }\n            catch (AmazonDynamoDBException e) { Console.WriteLine(e.Message); }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n\n            Console.WriteLine(\"To continue, press Enter\");\n            Console.ReadLine();\n        }\n\n        private static void SingleTableBatchWrite()\n        {\n            Table productCatalog = Table.LoadTable(client, \"ProductCatalog\");\n            var batchWrite = productCatalog.CreateBatchWrite();\n\n            var book1 = new Document();\n            book1[\"Id\"] = 902;\n            book1[\"Title\"] = \"My book1 in batch write using .NET helper classes\";\n            book1[\"ISBN\"] = \"902-11-11-1111\";\n            book1[\"Price\"] = 10;\n            book1[\"ProductCategory\"] = \"Book\";\n            book1[\"Authors\"] = new List<string> { \"Author 1\", \"Author 2\", \"Author 3\" };\n            book1[\"Dimensions\"] = \"8.5x11x.5\";\n            book1[\"InStock\"] = new DynamoDBBool(true);\n            book1[\"QuantityOnHand\"] = new DynamoDBNull(); //Quantity is unknown at this time\n\n            batchWrite.AddDocumentToPut(book1);\n            // Specify delete item using overload that takes PK.\n            batchWrite.AddKeyToDelete(12345);\n            Console.WriteLine(\"Performing batch write in SingleTableBatchWrite()\");\n            batchWrite.Execute();\n        }\n\n        private static void MultiTableBatchWrite()\n        {\n            // 1. Specify item to add in the Forum table.\n            Table forum = Table.LoadTable(client, \"Forum\");\n            var forumBatchWrite = forum.CreateBatchWrite();\n\n            var forum1 = new Document();\n            forum1[\"Name\"] = \"Test BatchWrite Forum\";\n            forum1[\"Threads\"] = 0;\n            forumBatchWrite.AddDocumentToPut(forum1);\n\n\n            // 2a. Specify item to add in the Thread table.\n            Table thread = Table.LoadTable(client, \"Thread\");\n            var threadBatchWrite = thread.CreateBatchWrite();\n\n            var thread1 = new Document();\n            thread1[\"ForumName\"] = \"S3 forum\";\n            thread1[\"Subject\"] = \"My sample question\";\n            thread1[\"Message\"] = \"Message text\";\n            thread1[\"KeywordTags\"] = new List<string> { \"S3\", \"Bucket\" };\n            threadBatchWrite.AddDocumentToPut(thread1);\n\n            // 2b. Specify item to delete from the Thread table.\n            threadBatchWrite.AddKeyToDelete(\"someForumName\", \"someSubject\");\n\n            // 3. Create multi-table batch.\n            var superBatch = new MultiTableDocumentBatchWrite();\n            superBatch.AddBatch(forumBatchWrite);\n            superBatch.AddBatch(threadBatchWrite);\n            Console.WriteLine(\"Performing batch write in MultiTableBatchWrite()\");\n            superBatch.Execute();\n        }\n    }\n}\n"
  },
  {
    "title": "Example: CRUD operations using the AWS SDK for .NET document model - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ItemCRUDDotNetDocumentAPI.html",
    "html": "Example: CRUD operations using the AWS SDK for .NET document model\nPDF\nRSS\n\nThe following C# code example performs the following actions:\n\nCreates a book item in the ProductCatalog table.\n\nRetrieves the book item.\n\nUpdates the book item. The code example shows a normal update that adds new attributes and updates existing attributes. It also shows a conditional update that updates the book price only if the existing price value is as specified in the code.\n\nDeletes the book item.\n\nFor step-by-step instructions to test the following example, see .NET code examples.\n\nExample\n\nThe following works for .NET Framework, but for .NET Core you must use the PutItemAsync() method.\n\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.DocumentModel;\nusing Amazon.Runtime;\n\nnamespace com.amazonaws.codesamples\n{\n    class MidlevelItemCRUD\n    {\n        private static AmazonDynamoDBClient client = new AmazonDynamoDBClient();\n        private static string tableName = \"ProductCatalog\";\n        // The sample uses the following id PK value to add book item.\n        private static int sampleBookId = 555;\n\n        static void Main(string[] args)\n        {\n            try\n            {\n                Table productCatalog = Table.LoadTable(client, tableName);\n                CreateBookItem(productCatalog);\n                RetrieveBook(productCatalog);\n                // Couple of sample updates.\n                UpdateMultipleAttributes(productCatalog);\n                UpdateBookPriceConditionally(productCatalog);\n\n                // Delete.\n                DeleteBook(productCatalog);\n                Console.WriteLine(\"To continue, press Enter\");\n                Console.ReadLine();\n            }\n            catch (AmazonDynamoDBException e) { Console.WriteLine(e.Message); }\n            catch (AmazonServiceException e) { Console.WriteLine(e.Message); }\n            catch (Exception e) { Console.WriteLine(e.Message); }\n        }\n\n        // Creates a sample book item.\n        private static void CreateBookItem(Table productCatalog)\n        {\n            Console.WriteLine(\"\\n*** Executing CreateBookItem() ***\");\n            var book = new Document();\n            book[\"Id\"] = sampleBookId;\n            book[\"Title\"] = \"Book \" + sampleBookId;\n            book[\"Price\"] = 19.99;\n            book[\"ISBN\"] = \"111-1111111111\";\n            book[\"Authors\"] = new List<string> { \"Author 1\", \"Author 2\", \"Author 3\" };\n            book[\"PageCount\"] = 500;\n            book[\"Dimensions\"] = \"8.5x11x.5\";\n            book[\"InPublication\"] = new DynamoDBBool(true);\n            book[\"InStock\"] = new DynamoDBBool(false);\n            book[\"QuantityOnHand\"] = 0;\n\n            productCatalog.PutItem(book);\n        }\n\n        private static void RetrieveBook(Table productCatalog)\n        {\n            Console.WriteLine(\"\\n*** Executing RetrieveBook() ***\");\n            // Optional configuration.\n            GetItemOperationConfig config = new GetItemOperationConfig\n            {\n                AttributesToGet = new List<string> { \"Id\", \"ISBN\", \"Title\", \"Authors\", \"Price\" },\n                ConsistentRead = true\n            };\n            Document document = productCatalog.GetItem(sampleBookId, config);\n            Console.WriteLine(\"RetrieveBook: Printing book retrieved...\");\n            PrintDocument(document);\n        }\n\n        private static void UpdateMultipleAttributes(Table productCatalog)\n        {\n            Console.WriteLine(\"\\n*** Executing UpdateMultipleAttributes() ***\");\n            Console.WriteLine(\"\\nUpdating multiple attributes....\");\n            int partitionKey = sampleBookId;\n\n            var book = new Document();\n            book[\"Id\"] = partitionKey;\n            // List of attribute updates.\n            // The following replaces the existing authors list.\n            book[\"Authors\"] = new List<string> { \"Author x\", \"Author y\" };\n            book[\"newAttribute\"] = \"New Value\";\n            book[\"ISBN\"] = null; // Remove it.\n\n            // Optional parameters.\n            UpdateItemOperationConfig config = new UpdateItemOperationConfig\n            {\n                // Get updated item in response.\n                ReturnValues = ReturnValues.AllNewAttributes\n            };\n            Document updatedBook = productCatalog.UpdateItem(book, config);\n            Console.WriteLine(\"UpdateMultipleAttributes: Printing item after updates ...\");\n            PrintDocument(updatedBook);\n        }\n\n        private static void UpdateBookPriceConditionally(Table productCatalog)\n        {\n            Console.WriteLine(\"\\n*** Executing UpdateBookPriceConditionally() ***\");\n\n            int partitionKey = sampleBookId;\n\n            var book = new Document();\n            book[\"Id\"] = partitionKey;\n            book[\"Price\"] = 29.99;\n\n            // For conditional price update, creating a condition expression.\n            Expression expr = new Expression();\n            expr.ExpressionStatement = \"Price = :val\";\n            expr.ExpressionAttributeValues[\":val\"] = 19.00;\n\n            // Optional parameters.\n            UpdateItemOperationConfig config = new UpdateItemOperationConfig\n            {\n                ConditionalExpression = expr,\n                ReturnValues = ReturnValues.AllNewAttributes\n            };\n            Document updatedBook = productCatalog.UpdateItem(book, config);\n            Console.WriteLine(\"UpdateBookPriceConditionally: Printing item whose price was conditionally updated\");\n            PrintDocument(updatedBook);\n        }\n\n        private static void DeleteBook(Table productCatalog)\n        {\n            Console.WriteLine(\"\\n*** Executing DeleteBook() ***\");\n            // Optional configuration.\n            DeleteItemOperationConfig config = new DeleteItemOperationConfig\n            {\n                // Return the deleted item.\n                ReturnValues = ReturnValues.AllOldAttributes\n            };\n            Document document = productCatalog.DeleteItem(sampleBookId, config);\n            Console.WriteLine(\"DeleteBook: Printing deleted just deleted...\");\n            PrintDocument(document);\n        }\n\n        private static void PrintDocument(Document updatedDocument)\n        {\n            foreach (var attribute in updatedDocument.GetAttributeNames())\n            {\n                string stringValue = null;\n                var value = updatedDocument[attribute];\n                if (value is Primitive)\n                    stringValue = value.AsPrimitive().Value.ToString();\n                else if (value is PrimitiveList)\n                    stringValue = string.Join(\",\", (from primitive\n                                    in value.AsPrimitiveList().Entries\n                                                    select primitive.Value).ToArray());\n                Console.WriteLine(\"{0} - {1}\", attribute, stringValue);\n            }\n        }\n    }\n}\n"
  },
  {
    "title": "Working with items in DynamoDB using the AWS SDK for .NET document model - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItemsDocumentClasses.html",
    "html": "Working with items in DynamoDB using the AWS SDK for .NET document model\nPDF\nRSS\n\nThe following code examples demonstrate how to perform a variety of operations with the AWS SDK for .NET document model. You can use these examples to perform CRUD, batch, and transaction operations.\n\nTopics\nPutting an item - Table.PutItem method\nSpecifying optional parameters\nGetting an item - Table.GetItem\nDeleting an item - Table.DeleteItem\nUpdating an item - Table.UpdateItem\nBatch write - putting and deleting multiple items\n\nTo perform data operations using the document model, you must first call the Table.LoadTable method, which creates an instance of the Table class that represents a specific table. The following C# example creates a Table object that represents the ProductCatalog table in Amazon DynamoDB.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\nNote\n\nIn general, you use the LoadTable method once at the beginning of your application because it makes a DescribeTable call that adds to the round trip to DynamoDB.\n\nYou can then use the Table object to perform various data operations. Each data operation has two types of overloads: One takes the minimum required parameters and the other takes optional, operation-specific configuration information. For example, to retrieve an item, you must provide the table's primary key value, in which case you can use the following GetItem overload.\n\nExample\n// Get the item from a table that has a primary key that is composed of only a partition key.\nTable.GetItem(Primitive partitionKey);\n// Get the item from a table whose primary key is composed of both a partition key and sort key.\nTable.GetItem(Primitive partitionKey, Primitive sortKey);\n\nYou also can pass optional parameters to these methods. For example, the preceding GetItem returns the entire item including all its attributes. You can optionally specify a list of attributes to retrieve. In this case, you use the following GetItem overload that takes in the operation-specific configuration object parameter.\n\nExample\n\n// Configuration object that specifies optional parameters.\nGetItemOperationConfig config = new GetItemOperationConfig()\n{\n  AttributesToGet = new List<string>() { \"Id\", \"Title\" },\n};\n// Pass in the configuration to the GetItem method.\n// 1. Table that has only a partition key as primary key.\nTable.GetItem(Primitive partitionKey, GetItemOperationConfig config);\n// 2. Table that has both a partition key and a sort key.\nTable.GetItem(Primitive partitionKey, Primitive sortKey, GetItemOperationConfig config);\n\n\nYou can use the configuration object to specify several optional parameters such as request a specific list of attributes or specify the page size (number of items per page). Each data operation method has its own configuration class. For example, you can use the GetItemOperationConfig class to provide options for the GetItem operation. You can use the PutItemOperationConfig class to provide optional parameters for the PutItem operation.\n\nThe following sections discuss each of the data operations that are supported by the Table class.\n\nPutting an item - Table.PutItem method\n\nThe PutItem method uploads the input Document instance to the table. If an item that has a primary key that is specified in the input Document exists in the table, the PutItem operation replaces the entire existing item. The new item is identical to the Document object that you provided to the PutItem method. If your original item had any extra attributes, they are no longer present in the new item.\n\nThe following are the steps to put a new item into a table using the AWS SDK for .NET document model.\n\nRun the Table.LoadTable method that provides the table name in which you want to put an item.\n\nCreate a Document object that has a list of attribute names and their values.\n\nRun Table.PutItem by providing the Document instance as a parameter.\n\nThe following C# code example demonstrates the preceding tasks. The example uploads an item to the ProductCatalog table.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\n\nvar book = new Document();\nbook[\"Id\"] = 101;\nbook[\"Title\"] = \"Book 101 Title\";\nbook[\"ISBN\"] = \"11-11-11-11\";\nbook[\"Authors\"] = new List<string> { \"Author 1\", \"Author 2\" };\nbook[\"InStock\"] = new DynamoDBBool(true);\nbook[\"QuantityOnHand\"] = new DynamoDBNull();\n\ntable.PutItem(book);\n\nIn the preceding example, the Document instance creates an item that has Number, String, String Set, Boolean, and Null attributes. (Null is used to indicate that the QuantityOnHand for this product is unknown.) For Boolean and Null, use the constructor methods DynamoDBBool and DynamoDBNull.\n\nIn DynamoDB, the List and Map data types can contain elements composed of other data types. Here is how to map these data types to the document model API:\n\nList — use the DynamoDBList constructor.\n\nMap — use the Document constructor.\n\nYou can modify the preceding example to add a List attribute to the item. To do this, use a DynamoDBList constructor, as shown in the following code example.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\n\nvar book = new Document();\nbook[\"Id\"] = 101;\n\n/*other attributes omitted for brevity...*/\n\nvar relatedItems = new DynamoDBList();\nrelatedItems.Add(341);\nrelatedItems.Add(472);\nrelatedItems.Add(649);\nbook.Add(\"RelatedItems\", relatedItems);\n\ntable.PutItem(book);\n\nTo add a Map attribute to the book, you define another Document. The following code example illustrates how to do this.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\n\nvar book = new Document();\nbook[\"Id\"] = 101;\n\n/*other attributes omitted for brevity...*/\n\nvar pictures = new Document();\npictures.Add(\"FrontView\", \"http://example.com/products/101_front.jpg\" );\npictures.Add(\"RearView\", \"http://example.com/products/101_rear.jpg\" );\n\nbook.Add(\"Pictures\", pictures);\n\ntable.PutItem(book);\n\nThese examples are based on the item shown in Specifying item attributes when using expressions. The document model lets you create complex nested attributes, such as the ProductReviews attribute shown in the case study.\n\nSpecifying optional parameters\n\nYou can configure optional parameters for the PutItem operation by adding the PutItemOperationConfig parameter. For a complete list of optional parameters, see PutItem. The following C# code example puts an item in the ProductCatalog table. It specifies the following optional parameter:\n\nThe ConditionalExpression parameter to make this a conditional put request. The example creates an expression that specifies the ISBN attribute must have a specific value that has to be present in the item that you are replacing.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\n\nvar book = new Document();\nbook[\"Id\"] = 555;\nbook[\"Title\"] = \"Book 555 Title\";\nbook[\"Price\"] = \"25.00\";\nbook[\"ISBN\"] = \"55-55-55-55\";\nbook[\"Name\"] = \"Item 1 updated\";\nbook[\"Authors\"] = new List<string> { \"Author x\", \"Author y\" };\nbook[\"InStock\"] = new DynamoDBBool(true);\nbook[\"QuantityOnHand\"] = new DynamoDBNull();\n\n// Create a condition expression for the optional conditional put operation.\nExpression expr = new Expression();\nexpr.ExpressionStatement = \"ISBN = :val\";\nexpr.ExpressionAttributeValues[\":val\"] = \"55-55-55-55\";\n\nPutItemOperationConfig config = new PutItemOperationConfig()\n{\n  // Optional parameter.\n     ConditionalExpression = expr\n};\n\ntable.PutItem(book, config);\nGetting an item - Table.GetItem\n\nThe GetItem operation retrieves an item as a Document instance. You must provide the primary key of the item that you want to retrieve as shown in the following C# code example.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\nDocument document = table.GetItem(101); // Primary key 101.\n\nThe GetItem operation returns all the attributes of the item and performs an eventually consistent read (see Read consistency) by default.\n\nSpecifying optional parameters\n\nYou can configure additional options for the GetItem operation by adding the GetItemOperationConfig parameter. For a complete list of optional parameters, see GetItem. The following C# code example retrieves an item from the ProductCatalog table. It specifies the GetItemOperationConfig to provide the following optional parameters:\n\nThe AttributesToGet parameter to retrieve only the specified attributes.\n\nThe ConsistentRead parameter to request the latest values for all the specified attributes. To learn more about data consistency, see Read consistency.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\n\nGetItemOperationConfig config = new GetItemOperationConfig()\n{\n  AttributesToGet = new List<string>() { \"Id\", \"Title\", \"Authors\", \"InStock\", \"QuantityOnHand\" },\n  ConsistentRead = true\n};\nDocument doc = table.GetItem(101, config);\n\nWhen you retrieve an item using the document model API, you can access individual elements within the Document object is returned, as shown in the following example.\n\nExample\nint id = doc[\"Id\"].AsInt();\nstring title = doc[\"Title\"].AsString();\nList<string> authors = doc[\"Authors\"].AsListOfString();\nbool inStock = doc[\"InStock\"].AsBoolean();\nDynamoDBNull quantityOnHand = doc[\"QuantityOnHand\"].AsDynamoDBNull();\n\nFor attributes that are of type List or Map, here is how to map these attributes to the document model API:\n\nList — Use the AsDynamoDBList method.\n\nMap — Use the AsDocument method.\n\nThe following code example shows how to retrieve a List (RelatedItems) and a Map (Pictures) from the Document object:\n\nExample\nDynamoDBList relatedItems = doc[\"RelatedItems\"].AsDynamoDBList();\n\nDocument pictures = doc[\"Pictures\"].AsDocument();\nDeleting an item - Table.DeleteItem\n\nThe DeleteItem operation deletes an item from a table. You can pass the item's primary key as a parameter. Or, if you've already read an item and have the corresponding Document object, you can pass it as a parameter to the DeleteItem method, as shown in the following C# code example.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\n\n// Retrieve a book (a Document instance)\nDocument document = table.GetItem(111);\n\n// 1) Delete using the Document instance.\n table.DeleteItem(document);\n\n// 2) Delete using the primary key.\nint partitionKey = 222;\ntable.DeleteItem(partitionKey)\nSpecifying optional parameters\n\nYou can configure additional options for the Delete operation by adding the DeleteItemOperationConfig parameter. For a complete list of optional parameters, see DeleteTable. The following C# code example specifies the two following optional parameters:\n\nThe ConditionalExpression parameter to ensure that the book item being deleted has a specific value for the ISBN attribute.\n\nThe ReturnValues parameter to request that the Delete method return the item that it deleted.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\nint partitionKey = 111;\n\nExpression expr = new Expression();\nexpr.ExpressionStatement = \"ISBN = :val\";\nexpr.ExpressionAttributeValues[\":val\"] = \"11-11-11-11\";\n\n// Specify optional parameters for Delete operation.\nDeleteItemOperationConfig config = new DeleteItemOperationConfig\n{\n     ConditionalExpression = expr,\n     ReturnValues = ReturnValues.AllOldAttributes // This is the only supported value when using the document model.\n};\n\n// Delete the book.\nDocument d = table.DeleteItem(partitionKey, config);\nUpdating an item - Table.UpdateItem\n\nThe UpdateItem operation updates an existing item if it is present. If the item that has the specified primary key is not found, the UpdateItem operation adds a new item.\n\nYou can use the UpdateItem operation to update existing attribute values, add new attributes to the existing collection, or delete attributes from the existing collection. You provide these updates by creating a Document instance that describes the updates that you want to perform.\n\nThe UpdateItem action uses the following guidelines:\n\nIf the item does not exist, UpdateItem adds a new item using the primary key that is specified in the input.\n\nIf the item exists, UpdateItem applies the updates as follows:\n\nReplaces the existing attribute values with the values in the update.\n\nIf an attribute that you provide in the input does not exist, it adds a new attribute to the item.\n\nIf the input attribute value is null, it deletes the attributes, if it is present.\n\nNote\n\nThis midlevel UpdateItem operation does not support the Add action (see UpdateItem) that is supported by the underlying DynamoDB operation.\n\nNote\n\nThe PutItem operation (Putting an item - Table.PutItem method) can also perform an update. If you call PutItem to upload an item and the primary key exists, the PutItem operation replaces the entire item. If there are attributes in the existing item and those attributes are not specified on the Document that is being put, the PutItem operation deletes those attributes. However, UpdateItem only updates the specified input attributes. Any other existing attributes of that item remain unchanged.\n\nThe following are the steps to update an item using the AWS SDK for .NET document model:\n\nRun the Table.LoadTable method by providing the name of the table in which you want to perform the update operation.\n\nCreate a Document instance by providing all the updates that you want to perform.\n\nTo delete an existing attribute, specify the attribute value as null.\n\nCall the Table.UpdateItem method and provide the Document instance as an input parameter.\n\nYou must provide the primary key either in the Document instance or explicitly as a parameter.\n\nThe following C# code example demonstrates the preceding tasks. The code example updates an item in the Book table. The UpdateItem operation updates the existing Authors attribute, deletes the PageCount attribute, and adds a new XYZ attribute. The Document instance includes the primary key of the book to update.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\n\nvar book = new Document();\n\n// Set the attributes that you wish to update.\nbook[\"Id\"] = 111; // Primary key.\n// Replace the authors attribute.\nbook[\"Authors\"] = new List<string> { \"Author x\", \"Author y\" };\n// Add a new attribute.\nbook[\"XYZ\"] = 12345;\n// Delete the existing PageCount attribute.\nbook[\"PageCount\"] = null;\n\ntable.Update(book);\nSpecifying optional parameters\n\nYou can configure additional options for the UpdateItem operation by adding the UpdateItemOperationConfig parameter. For a complete list of optional parameters, see UpdateItem.\n\nThe following C# code example updates a book item price to 25. It specifies the two following optional parameters:\n\nThe ConditionalExpression parameter that identifies the Price attribute with value 20 that you expect to be present.\n\nThe ReturnValues parameter to request the UpdateItem operation to return the item that is updated.\n\nExample\nTable table = Table.LoadTable(client, \"ProductCatalog\");\nstring partitionKey = \"111\";\n\nvar book = new Document();\nbook[\"Id\"] = partitionKey;\nbook[\"Price\"] = 25;\n\nExpression expr = new Expression();\nexpr.ExpressionStatement = \"Price = :val\";\nexpr.ExpressionAttributeValues[\":val\"] = \"20\";\n\nUpdateItemOperationConfig config = new UpdateItemOperationConfig()\n{\n    ConditionalExpression = expr,\n    ReturnValues = ReturnValues.AllOldAttributes\n};\n\nDocument d1 = table.Update(book, config);\nBatch write - putting and deleting multiple items\n\nBatch write refers to putting and deleting multiple items in a batch. The operation enables you to put and delete multiple items from one or more tables in a single call. The following are the steps to put or delete multiple items from a table using the AWS SDK for .NET document model API.\n\nCreate a Table object by executing the Table.LoadTable method by providing the name of the table in which you want to perform the batch operation.\n\nRun the createBatchWrite method on the table instance you created in the preceding step and create a DocumentBatchWrite object.\n\nUse the DocumentBatchWrite object methods to specify the documents that you want to upload or delete.\n\nCall the DocumentBatchWrite.Execute method to run the batch operation.\n\nWhen using the document model API, you can specify any number of operations in a batch. However, DynamoDB limits the number of operations in a batch and the total size of the batch in a batch operation. For more information about the specific limits, see BatchWriteItem. If the document model API detects that your batch write request exceeded the number of allowed write requests, or the HTTP payload size of a batch exceeded the limit allowed by BatchWriteItem, it breaks the batch into several smaller batches. Additionally, if a response to a batch write returns unprocessed items, the document model API automatically sends another batch request with those unprocessed items.\n\nThe following C# code example demonstrates the preceding steps. The example uses batch write operation to perform two writes; upload a book item and delete another book item.\n\n\nTable productCatalog = Table.LoadTable(client, \"ProductCatalog\");\nvar batchWrite = productCatalog.CreateBatchWrite();\n\nvar book1 = new Document();\nbook1[\"Id\"] = 902;\nbook1[\"Title\"] = \"My book1 in batch write using .NET document model\";\nbook1[\"Price\"] = 10;\nbook1[\"Authors\"] = new List<string> { \"Author 1\", \"Author 2\", \"Author 3\" };\nbook1[\"InStock\"] = new DynamoDBBool(true);\nbook1[\"QuantityOnHand\"] = 5;\n\nbatchWrite.AddDocumentToPut(book1);\n// specify delete item using overload that takes PK.\nbatchWrite.AddKeyToDelete(12345);\n\nbatchWrite.Execute();\n\n\nFor a working example, see Example: Batch operations using the AWS SDK for .NET document model API.\n\nYou can use the batchWrite operation to perform put and delete operations on multiple tables. The following are the steps to put or delete multiple items from multiple tables using the AWS SDK for .NET document model.\n\nYou create a DocumentBatchWrite instance for each table in which you want to put or delete multiple items, as described in the preceding procedure.\n\nCreate an instance of the MultiTableDocumentBatchWrite and add the individual DocumentBatchWrite objects to it.\n\nRun the MultiTableDocumentBatchWrite.Execute method.\n\nThe following C# code example demonstrates the preceding steps. The example uses the batch write operation to perform the following write operations:\n\nPut a new item in the Forum table item.\n\nPut an item in the Thread table and delete an item from the same table.\n\n\n// 1. Specify item to add in the Forum table.\nTable forum = Table.LoadTable(client, \"Forum\");\nvar forumBatchWrite = forum.CreateBatchWrite();\n\nvar forum1 = new Document();\nforum1[\"Name\"] = \"Test BatchWrite Forum\";\nforum1[\"Threads\"] = 0;\nforumBatchWrite.AddDocumentToPut(forum1);\n\n\n// 2a. Specify item to add in the Thread table.\nTable thread = Table.LoadTable(client, \"Thread\");\nvar threadBatchWrite = thread.CreateBatchWrite();\n\nvar thread1 = new Document();\nthread1[\"ForumName\"] = \"Amazon S3 forum\";\nthread1[\"Subject\"] = \"My sample question\";\nthread1[\"Message\"] = \"Message text\";\nthread1[\"KeywordTags\"] = new List<string>{ \"Amazon S3\", \"Bucket\" };\nthreadBatchWrite.AddDocumentToPut(thread1);\n\n// 2b. Specify item to delete from the Thread table.\nthreadBatchWrite.AddKeyToDelete(\"someForumName\", \"someSubject\");\n\n// 3. Create multi-table batch.\nvar superBatch = new MultiTableDocumentBatchWrite();\nsuperBatch.AddBatch(forumBatchWrite);\nsuperBatch.AddBatch(threadBatchWrite);\n\nsuperBatch.Execute();\n"
  },
  {
    "title": "Supported data types - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/MidLevelAPILimitations.SupportedTypes.html",
    "html": "Supported data types\nPDF\nRSS\n\nThe document model supports a set of primitive .NET data types and collections data types. The model supports the following primitive data types.\n\nbool\n\nbyte\n\nchar\n\nDateTime\n\ndecimal\n\ndouble\n\nfloat\n\nGuid\n\nInt16\n\nInt32\n\nInt64\n\nSByte\n\nstring\n\nUInt16\n\nUInt32\n\nUInt64\n\nThe following table summarizes the mapping of the preceding .NET types to the DynamoDB types.\n\n.NET primitive type\tDynamoDB type\n\n\nAll number types\n\n\t\n\nN (number type)\n\n\n\n\nAll string types\n\n\t\n\nS (string type)\n\n\n\n\nMemoryStream, byte[]\n\n\t\n\nB (binary type)\n\n\nbool\tN (number type). 0 represents false and 1 represents true.\nDateTime\tS (string type). The DateTime values are stored as ISO-8601 formatted strings.\nGuid\tS (string type).\nCollection types (List, HashSet, and array)\tBS (binary set) type, SS (string set) type, and NS (number set) type\n\nAWS SDK for .NET defines types for mapping DynamoDB's Boolean, null, list and map types to .NET document model API:\n\nUse DynamoDBBool for Boolean type.\n\nUse DynamoDBNull for null type.\n\nUse DynamoDBList for list type.\n\nUse Document for map type.\n\nNote\n\nEmpty binary values are supported.\n\nReading of empty string values is supported. Empty string attribute values are supported within attribute values of string Set type while writing to DynamoDB. Empty string attribute values of string type and empty string values contained within List or Map type are dropped from write requests"
  },
  {
    "title": ".NET: Document model - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DotNetSDKMidLevel.html",
    "html": ".NET: Document model\nPDF\nRSS\n\nThe AWS SDK for .NET provides document model classes that wrap some of the low-level Amazon DynamoDB operations, further simplifying your coding. In the document model, the primary classes are Table and Document. The Table class provides data operation methods such as PutItem, GetItem, and DeleteItem. It also provides the Query and the Scan methods. The Document class represents a single item in a table.\n\nThe preceding document model classes are available in the Amazon.DynamoDBv2.DocumentModel namespace.\n\nNote\n\nYou can't use the document model classes to create, update, and delete tables. However, the document model does support most common data operations.\n\nTopics\nSupported data types\nWorking with items in DynamoDB using the AWS SDK for .NET document model\nExample: CRUD operations using the AWS SDK for .NET document model\nExample: Batch operations using the AWS SDK for .NET document model API\nWorking with tables in DynamoDB using the AWS SDK for .NET document model"
  },
  {
    "title": "DynamoDBMapper Transaction operations - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.Transactions.html",
    "html": "DynamoDBMapper Transaction operations\nPDF\nRSS\n\nThe following Java code example declares a Forum and a Thread class and maps them to the DynamoDB tables using the DynamoDBMapper class.\n\nThe code illustrates the following transactional operations:\n\ntransactionWrite to add, update, and delete multiple items from one or more tables in one transaction.\n\ntransactionLoad to retrieve multiple items from one or more tables in one transaction.\n\nImports\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Set;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBAttribute;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBHashKey;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapper;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMappingException;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBRangeKey;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTable;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTransactionLoadExpression;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTransactionWriteExpression;\nimport com.amazonaws.services.dynamodbv2.datamodeling.TransactionLoadRequest;\nimport com.amazonaws.services.dynamodbv2.datamodeling.TransactionWriteRequest;\nimport com.amazonaws.services.dynamodbv2.model.InternalServerErrorException;\nimport com.amazonaws.services.dynamodbv2.model.ResourceNotFoundException;\nimport com.amazonaws.services.dynamodbv2.model.TransactionCanceledException;\n\n\nCode\n\npublic class DynamoDBMapperTransactionExample {\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n    static DynamoDBMapper mapper;\n\n    public static void main(String[] args) throws Exception {\n        try {\n\n            mapper = new DynamoDBMapper(client);\n\n            testPutAndUpdateInTransactionWrite();\n            testPutWithConditionalUpdateInTransactionWrite();\n            testPutWithConditionCheckInTransactionWrite();\n            testMixedOperationsInTransactionWrite();\n            testTransactionLoadWithSave();\n            testTransactionLoadWithTransactionWrite();\n            System.out.println(\"Example complete\");\n\n        } catch (Throwable t) {\n            System.err.println(\"Error running the DynamoDBMapperTransactionWriteExample: \" + t);\n            t.printStackTrace();\n        }\n    }\n\n    private static void testTransactionLoadWithSave() {\n        // Create new Forum item for DynamoDB using save\n        Forum dynamodbForum = new Forum();\n        dynamodbForum.setName(\"DynamoDB Forum\");\n        dynamodbForum.setCategory(\"Amazon Web Services\");\n        dynamodbForum.setThreads(0);\n        mapper.save(dynamodbForum);\n\n        // Add a thread to DynamoDB Forum\n        Thread dynamodbForumThread = new Thread();\n        dynamodbForumThread.setForumName(\"DynamoDB Forum\");\n        dynamodbForumThread.setSubject(\"Sample Subject 1\");\n        dynamodbForumThread.setMessage(\"Sample Question 1\");\n        mapper.save(dynamodbForumThread);\n\n        // Update DynamoDB Forum to reflect updated thread count\n        dynamodbForum.setThreads(1);\n        mapper.save(dynamodbForum);\n\n        // Read DynamoDB Forum item and Thread item at the same time in a serializable\n        // manner\n        TransactionLoadRequest transactionLoadRequest = new TransactionLoadRequest();\n\n        // Read entire item for DynamoDB Forum\n        transactionLoadRequest.addLoad(dynamodbForum);\n\n        // Only read subject and message attributes from Thread item\n        DynamoDBTransactionLoadExpression loadExpressionForThread = new DynamoDBTransactionLoadExpression()\n                .withProjectionExpression(\"Subject, Message\");\n        transactionLoadRequest.addLoad(dynamodbForumThread, loadExpressionForThread);\n\n        // Loaded objects are guaranteed to be in same order as the order in which they\n        // are\n        // added to TransactionLoadRequest\n        List<Object> loadedObjects = executeTransactionLoad(transactionLoadRequest);\n        Forum loadedDynamoDBForum = (Forum) loadedObjects.get(0);\n        System.out.println(\"Forum: \" + loadedDynamoDBForum.getName());\n        System.out.println(\"Threads: \" + loadedDynamoDBForum.getThreads());\n        Thread loadedDynamodbForumThread = (Thread) loadedObjects.get(1);\n        System.out.println(\"Subject: \" + loadedDynamodbForumThread.getSubject());\n        System.out.println(\"Message: \" + loadedDynamodbForumThread.getMessage());\n    }\n\n    private static void testTransactionLoadWithTransactionWrite() {\n        // Create new Forum item for DynamoDB using save\n        Forum dynamodbForum = new Forum();\n        dynamodbForum.setName(\"DynamoDB New Forum\");\n        dynamodbForum.setCategory(\"Amazon Web Services\");\n        dynamodbForum.setThreads(0);\n        mapper.save(dynamodbForum);\n\n        // Update Forum item for DynamoDB and add a thread to DynamoDB Forum, in\n        // an ACID manner using transactionWrite\n\n        dynamodbForum.setThreads(1);\n        Thread dynamodbForumThread = new Thread();\n        dynamodbForumThread.setForumName(\"DynamoDB New Forum\");\n        dynamodbForumThread.setSubject(\"Sample Subject 2\");\n        dynamodbForumThread.setMessage(\"Sample Question 2\");\n        TransactionWriteRequest transactionWriteRequest = new TransactionWriteRequest();\n        transactionWriteRequest.addPut(dynamodbForumThread);\n        transactionWriteRequest.addUpdate(dynamodbForum);\n        executeTransactionWrite(transactionWriteRequest);\n\n        // Read DynamoDB Forum item and Thread item at the same time in a serializable\n        // manner\n        TransactionLoadRequest transactionLoadRequest = new TransactionLoadRequest();\n\n        // Read entire item for DynamoDB Forum\n        transactionLoadRequest.addLoad(dynamodbForum);\n\n        // Only read subject and message attributes from Thread item\n        DynamoDBTransactionLoadExpression loadExpressionForThread = new DynamoDBTransactionLoadExpression()\n                .withProjectionExpression(\"Subject, Message\");\n        transactionLoadRequest.addLoad(dynamodbForumThread, loadExpressionForThread);\n\n        // Loaded objects are guaranteed to be in same order as the order in which they\n        // are\n        // added to TransactionLoadRequest\n        List<Object> loadedObjects = executeTransactionLoad(transactionLoadRequest);\n        Forum loadedDynamoDBForum = (Forum) loadedObjects.get(0);\n        System.out.println(\"Forum: \" + loadedDynamoDBForum.getName());\n        System.out.println(\"Threads: \" + loadedDynamoDBForum.getThreads());\n        Thread loadedDynamodbForumThread = (Thread) loadedObjects.get(1);\n        System.out.println(\"Subject: \" + loadedDynamodbForumThread.getSubject());\n        System.out.println(\"Message: \" + loadedDynamodbForumThread.getMessage());\n    }\n\n    private static void testPutAndUpdateInTransactionWrite() {\n        // Create new Forum item for S3 using save\n        Forum s3Forum = new Forum();\n        s3Forum.setName(\"S3 Forum\");\n        s3Forum.setCategory(\"Core Amazon Web Services\");\n        s3Forum.setThreads(0);\n        mapper.save(s3Forum);\n\n        // Update Forum item for S3 and Create new Forum item for DynamoDB using\n        // transactionWrite\n        s3Forum.setCategory(\"Amazon Web Services\");\n        Forum dynamodbForum = new Forum();\n        dynamodbForum.setName(\"DynamoDB Forum\");\n        dynamodbForum.setCategory(\"Amazon Web Services\");\n        dynamodbForum.setThreads(0);\n        TransactionWriteRequest transactionWriteRequest = new TransactionWriteRequest();\n        transactionWriteRequest.addUpdate(s3Forum);\n        transactionWriteRequest.addPut(dynamodbForum);\n        executeTransactionWrite(transactionWriteRequest);\n    }\n\n    private static void testPutWithConditionalUpdateInTransactionWrite() {\n        // Create new Thread item for DynamoDB forum and update thread count in DynamoDB\n        // forum\n        // if the DynamoDB Forum exists\n        Thread dynamodbForumThread = new Thread();\n        dynamodbForumThread.setForumName(\"DynamoDB Forum\");\n        dynamodbForumThread.setSubject(\"Sample Subject 1\");\n        dynamodbForumThread.setMessage(\"Sample Question 1\");\n\n        Forum dynamodbForum = new Forum();\n        dynamodbForum.setName(\"DynamoDB Forum\");\n        dynamodbForum.setCategory(\"Amazon Web Services\");\n        dynamodbForum.setThreads(1);\n\n        DynamoDBTransactionWriteExpression transactionWriteExpression = new DynamoDBTransactionWriteExpression()\n                .withConditionExpression(\"attribute_exists(Category)\");\n\n        TransactionWriteRequest transactionWriteRequest = new TransactionWriteRequest();\n        transactionWriteRequest.addPut(dynamodbForumThread);\n        transactionWriteRequest.addUpdate(dynamodbForum, transactionWriteExpression);\n        executeTransactionWrite(transactionWriteRequest);\n    }\n\n    private static void testPutWithConditionCheckInTransactionWrite() {\n        // Create new Thread item for DynamoDB forum and update thread count in DynamoDB\n        // forum if a thread already exists\n        Thread dynamodbForumThread2 = new Thread();\n        dynamodbForumThread2.setForumName(\"DynamoDB Forum\");\n        dynamodbForumThread2.setSubject(\"Sample Subject 2\");\n        dynamodbForumThread2.setMessage(\"Sample Question 2\");\n\n        Thread dynamodbForumThread1 = new Thread();\n        dynamodbForumThread1.setForumName(\"DynamoDB Forum\");\n        dynamodbForumThread1.setSubject(\"Sample Subject 1\");\n        DynamoDBTransactionWriteExpression conditionExpressionForConditionCheck = new DynamoDBTransactionWriteExpression()\n                .withConditionExpression(\"attribute_exists(Subject)\");\n\n        Forum dynamodbForum = new Forum();\n        dynamodbForum.setName(\"DynamoDB Forum\");\n        dynamodbForum.setCategory(\"Amazon Web Services\");\n        dynamodbForum.setThreads(2);\n\n        TransactionWriteRequest transactionWriteRequest = new TransactionWriteRequest();\n        transactionWriteRequest.addPut(dynamodbForumThread2);\n        transactionWriteRequest.addConditionCheck(dynamodbForumThread1, conditionExpressionForConditionCheck);\n        transactionWriteRequest.addUpdate(dynamodbForum);\n        executeTransactionWrite(transactionWriteRequest);\n    }\n\n    private static void testMixedOperationsInTransactionWrite() {\n        // Create new Thread item for S3 forum and delete \"Sample Subject 1\" Thread from\n        // DynamoDB forum if\n        // \"Sample Subject 2\" Thread exists in DynamoDB forum\n        Thread s3ForumThread = new Thread();\n        s3ForumThread.setForumName(\"S3 Forum\");\n        s3ForumThread.setSubject(\"Sample Subject 1\");\n        s3ForumThread.setMessage(\"Sample Question 1\");\n\n        Forum s3Forum = new Forum();\n        s3Forum.setName(\"S3 Forum\");\n        s3Forum.setCategory(\"Amazon Web Services\");\n        s3Forum.setThreads(1);\n\n        Thread dynamodbForumThread1 = new Thread();\n        dynamodbForumThread1.setForumName(\"DynamoDB Forum\");\n        dynamodbForumThread1.setSubject(\"Sample Subject 1\");\n\n        Thread dynamodbForumThread2 = new Thread();\n        dynamodbForumThread2.setForumName(\"DynamoDB Forum\");\n        dynamodbForumThread2.setSubject(\"Sample Subject 2\");\n        DynamoDBTransactionWriteExpression conditionExpressionForConditionCheck = new DynamoDBTransactionWriteExpression()\n                .withConditionExpression(\"attribute_exists(Subject)\");\n\n        Forum dynamodbForum = new Forum();\n        dynamodbForum.setName(\"DynamoDB Forum\");\n        dynamodbForum.setCategory(\"Amazon Web Services\");\n        dynamodbForum.setThreads(1);\n\n        TransactionWriteRequest transactionWriteRequest = new TransactionWriteRequest();\n        transactionWriteRequest.addPut(s3ForumThread);\n        transactionWriteRequest.addUpdate(s3Forum);\n        transactionWriteRequest.addDelete(dynamodbForumThread1);\n        transactionWriteRequest.addConditionCheck(dynamodbForumThread2, conditionExpressionForConditionCheck);\n        transactionWriteRequest.addUpdate(dynamodbForum);\n        executeTransactionWrite(transactionWriteRequest);\n    }\n\n    private static List<Object> executeTransactionLoad(TransactionLoadRequest transactionLoadRequest) {\n        List<Object> loadedObjects = new ArrayList<Object>();\n        try {\n            loadedObjects = mapper.transactionLoad(transactionLoadRequest);\n        } catch (DynamoDBMappingException ddbme) {\n            System.err.println(\"Client side error in Mapper, fix before retrying. Error: \" + ddbme.getMessage());\n        } catch (ResourceNotFoundException rnfe) {\n            System.err.println(\"One of the tables was not found, verify table exists before retrying. Error: \"\n                    + rnfe.getMessage());\n        } catch (InternalServerErrorException ise) {\n            System.err.println(\n                    \"Internal Server Error, generally safe to retry with back-off. Error: \" + ise.getMessage());\n        } catch (TransactionCanceledException tce) {\n            System.err.println(\n                    \"Transaction Canceled, implies a client issue, fix before retrying. Error: \" + tce.getMessage());\n        } catch (Exception ex) {\n            System.err.println(\n                    \"An exception occurred, investigate and configure retry strategy. Error: \" + ex.getMessage());\n        }\n        return loadedObjects;\n    }\n\n    private static void executeTransactionWrite(TransactionWriteRequest transactionWriteRequest) {\n        try {\n            mapper.transactionWrite(transactionWriteRequest);\n        } catch (DynamoDBMappingException ddbme) {\n            System.err.println(\"Client side error in Mapper, fix before retrying. Error: \" + ddbme.getMessage());\n        } catch (ResourceNotFoundException rnfe) {\n            System.err.println(\"One of the tables was not found, verify table exists before retrying. Error: \"\n                    + rnfe.getMessage());\n        } catch (InternalServerErrorException ise) {\n            System.err.println(\n                    \"Internal Server Error, generally safe to retry with back-off. Error: \" + ise.getMessage());\n        } catch (TransactionCanceledException tce) {\n            System.err.println(\n                    \"Transaction Canceled, implies a client issue, fix before retrying. Error: \" + tce.getMessage());\n        } catch (Exception ex) {\n            System.err.println(\n                    \"An exception occurred, investigate and configure retry strategy. Error: \" + ex.getMessage());\n        }\n    }\n\n    @DynamoDBTable(tableName = \"Thread\")\n    public static class Thread {\n        private String forumName;\n        private String subject;\n        private String message;\n        private String lastPostedDateTime;\n        private String lastPostedBy;\n        private Set<String> tags;\n        private int answered;\n        private int views;\n        private int replies;\n\n        // Partition key\n        @DynamoDBHashKey(attributeName = \"ForumName\")\n        public String getForumName() {\n            return forumName;\n        }\n\n        public void setForumName(String forumName) {\n            this.forumName = forumName;\n        }\n\n        // Sort key\n        @DynamoDBRangeKey(attributeName = \"Subject\")\n        public String getSubject() {\n            return subject;\n        }\n\n        public void setSubject(String subject) {\n            this.subject = subject;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Message\")\n        public String getMessage() {\n            return message;\n        }\n\n        public void setMessage(String message) {\n            this.message = message;\n        }\n\n        @DynamoDBAttribute(attributeName = \"LastPostedDateTime\")\n        public String getLastPostedDateTime() {\n            return lastPostedDateTime;\n        }\n\n        public void setLastPostedDateTime(String lastPostedDateTime) {\n            this.lastPostedDateTime = lastPostedDateTime;\n        }\n\n        @DynamoDBAttribute(attributeName = \"LastPostedBy\")\n        public String getLastPostedBy() {\n            return lastPostedBy;\n        }\n\n        public void setLastPostedBy(String lastPostedBy) {\n            this.lastPostedBy = lastPostedBy;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Tags\")\n        public Set<String> getTags() {\n            return tags;\n        }\n\n        public void setTags(Set<String> tags) {\n            this.tags = tags;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Answered\")\n        public int getAnswered() {\n            return answered;\n        }\n\n        public void setAnswered(int answered) {\n            this.answered = answered;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Views\")\n        public int getViews() {\n            return views;\n        }\n\n        public void setViews(int views) {\n            this.views = views;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Replies\")\n        public int getReplies() {\n            return replies;\n        }\n\n        public void setReplies(int replies) {\n            this.replies = replies;\n        }\n\n    }\n\n    @DynamoDBTable(tableName = \"Forum\")\n    public static class Forum {\n        private String name;\n        private String category;\n        private int threads;\n\n        // Partition key\n        @DynamoDBHashKey(attributeName = \"Name\")\n        public String getName() {\n            return name;\n        }\n\n        public void setName(String name) {\n            this.name = name;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Category\")\n        public String getCategory() {\n            return category;\n        }\n\n        public void setCategory(String category) {\n            this.category = category;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Threads\")\n        public int getThreads() {\n            return threads;\n        }\n\n        public void setThreads(int threads) {\n            this.threads = threads;\n        }\n    }\n}\n"
  },
  {
    "title": "DynamoDBMapper batch operations - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.Batch.html",
    "html": "DynamoDBMapper batch operations\nPDF\nRSS\n\nThe following Java code example declares Book, Forum, Thread, and Reply classes and maps them to the Amazon DynamoDB tables using the DynamoDBMapper class.\n\nThe code illustrates the following batch write operations:\n\nbatchSave to put book items in the ProductCatalog table.\n\nbatchDelete to delete items from the ProductCatalog table.\n\nbatchWrite to put and delete items from the Forum and the Thread tables.\n\nFor more information about the tables used in this example, see Creating tables and loading data for code examples in DynamoDB. For step-by-step instructions for testing the following example, see Java code examples.\n\nImports\n\nimport java.text.SimpleDateFormat;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Set;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBAttribute;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBHashKey;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapper;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapperConfig;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBRangeKey;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTable;\n\n\nCode\n\npublic class DynamoDBMapperBatchWriteExample {\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n\n    public static void main(String[] args) throws Exception {\n        try {\n\n            DynamoDBMapper mapper = new DynamoDBMapper(client);\n\n            testBatchSave(mapper);\n            testBatchDelete(mapper);\n            testBatchWrite(mapper);\n\n            System.out.println(\"Example complete!\");\n\n        } catch (Throwable t) {\n            System.err.println(\"Error running the DynamoDBMapperBatchWriteExample: \" + t);\n            t.printStackTrace();\n        }\n    }\n\n    private static void testBatchSave(DynamoDBMapper mapper) {\n\n        Book book1 = new Book();\n        book1.setId(901);\n        book1.setInPublication(true);\n        book1.setISBN(\"902-11-11-1111\");\n        book1.setPageCount(100);\n        book1.setPrice(10);\n        book1.setProductCategory(\"Book\");\n        book1.setTitle(\"My book created in batch write\");\n\n        Book book2 = new Book();\n        book2.setId(902);\n        book2.setInPublication(true);\n        book2.setISBN(\"902-11-12-1111\");\n        book2.setPageCount(200);\n        book2.setPrice(20);\n        book2.setProductCategory(\"Book\");\n        book2.setTitle(\"My second book created in batch write\");\n\n        Book book3 = new Book();\n        book3.setId(903);\n        book3.setInPublication(false);\n        book3.setISBN(\"902-11-13-1111\");\n        book3.setPageCount(300);\n        book3.setPrice(25);\n        book3.setProductCategory(\"Book\");\n        book3.setTitle(\"My third book created in batch write\");\n\n        System.out.println(\"Adding three books to ProductCatalog table.\");\n        mapper.batchSave(Arrays.asList(book1, book2, book3));\n    }\n\n    private static void testBatchDelete(DynamoDBMapper mapper) {\n\n        Book book1 = mapper.load(Book.class, 901);\n        Book book2 = mapper.load(Book.class, 902);\n        System.out.println(\"Deleting two books from the ProductCatalog table.\");\n        mapper.batchDelete(Arrays.asList(book1, book2));\n    }\n\n    private static void testBatchWrite(DynamoDBMapper mapper) {\n\n        // Create Forum item to save\n        Forum forumItem = new Forum();\n        forumItem.setName(\"Test BatchWrite Forum\");\n        forumItem.setThreads(0);\n        forumItem.setCategory(\"Amazon Web Services\");\n\n        // Create Thread item to save\n        Thread threadItem = new Thread();\n        threadItem.setForumName(\"AmazonDynamoDB\");\n        threadItem.setSubject(\"My sample question\");\n        threadItem.setMessage(\"BatchWrite message\");\n        List<String> tags = new ArrayList<String>();\n        tags.add(\"batch operations\");\n        tags.add(\"write\");\n        threadItem.setTags(new HashSet<String>(tags));\n\n        // Load ProductCatalog item to delete\n        Book book3 = mapper.load(Book.class, 903);\n\n        List<Object> objectsToWrite = Arrays.asList(forumItem, threadItem);\n        List<Book> objectsToDelete = Arrays.asList(book3);\n\n        DynamoDBMapperConfig config = DynamoDBMapperConfig.builder()\n                .withSaveBehavior(DynamoDBMapperConfig.SaveBehavior.CLOBBER)\n                .build();\n\n        mapper.batchWrite(objectsToWrite, objectsToDelete, config);\n    }\n\n    @DynamoDBTable(tableName = \"ProductCatalog\")\n    public static class Book {\n        private int id;\n        private String title;\n        private String ISBN;\n        private int price;\n        private int pageCount;\n        private String productCategory;\n        private boolean inPublication;\n\n        // Partition key\n        @DynamoDBHashKey(attributeName = \"Id\")\n        public int getId() {\n            return id;\n        }\n\n        public void setId(int id) {\n            this.id = id;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Title\")\n        public String getTitle() {\n            return title;\n        }\n\n        public void setTitle(String title) {\n            this.title = title;\n        }\n\n        @DynamoDBAttribute(attributeName = \"ISBN\")\n        public String getISBN() {\n            return ISBN;\n        }\n\n        public void setISBN(String ISBN) {\n            this.ISBN = ISBN;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Price\")\n        public int getPrice() {\n            return price;\n        }\n\n        public void setPrice(int price) {\n            this.price = price;\n        }\n\n        @DynamoDBAttribute(attributeName = \"PageCount\")\n        public int getPageCount() {\n            return pageCount;\n        }\n\n        public void setPageCount(int pageCount) {\n            this.pageCount = pageCount;\n        }\n\n        @DynamoDBAttribute(attributeName = \"ProductCategory\")\n        public String getProductCategory() {\n            return productCategory;\n        }\n\n        public void setProductCategory(String productCategory) {\n            this.productCategory = productCategory;\n        }\n\n        @DynamoDBAttribute(attributeName = \"InPublication\")\n        public boolean getInPublication() {\n            return inPublication;\n        }\n\n        public void setInPublication(boolean inPublication) {\n            this.inPublication = inPublication;\n        }\n\n        @Override\n        public String toString() {\n            return \"Book [ISBN=\" + ISBN + \", price=\" + price + \", product category=\" + productCategory + \", id=\" + id\n                    + \", title=\" + title + \"]\";\n        }\n\n    }\n\n    @DynamoDBTable(tableName = \"Reply\")\n    public static class Reply {\n        private String id;\n        private String replyDateTime;\n        private String message;\n        private String postedBy;\n\n        // Partition key\n        @DynamoDBHashKey(attributeName = \"Id\")\n        public String getId() {\n            return id;\n        }\n\n        public void setId(String id) {\n            this.id = id;\n        }\n\n        // Sort key\n        @DynamoDBRangeKey(attributeName = \"ReplyDateTime\")\n        public String getReplyDateTime() {\n            return replyDateTime;\n        }\n\n        public void setReplyDateTime(String replyDateTime) {\n            this.replyDateTime = replyDateTime;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Message\")\n        public String getMessage() {\n            return message;\n        }\n\n        public void setMessage(String message) {\n            this.message = message;\n        }\n\n        @DynamoDBAttribute(attributeName = \"PostedBy\")\n        public String getPostedBy() {\n            return postedBy;\n        }\n\n        public void setPostedBy(String postedBy) {\n            this.postedBy = postedBy;\n        }\n    }\n\n    @DynamoDBTable(tableName = \"Thread\")\n    public static class Thread {\n        private String forumName;\n        private String subject;\n        private String message;\n        private String lastPostedDateTime;\n        private String lastPostedBy;\n        private Set<String> tags;\n        private int answered;\n        private int views;\n        private int replies;\n\n        // Partition key\n        @DynamoDBHashKey(attributeName = \"ForumName\")\n        public String getForumName() {\n            return forumName;\n        }\n\n        public void setForumName(String forumName) {\n            this.forumName = forumName;\n        }\n\n        // Sort key\n        @DynamoDBRangeKey(attributeName = \"Subject\")\n        public String getSubject() {\n            return subject;\n        }\n\n        public void setSubject(String subject) {\n            this.subject = subject;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Message\")\n        public String getMessage() {\n            return message;\n        }\n\n        public void setMessage(String message) {\n            this.message = message;\n        }\n\n        @DynamoDBAttribute(attributeName = \"LastPostedDateTime\")\n        public String getLastPostedDateTime() {\n            return lastPostedDateTime;\n        }\n\n        public void setLastPostedDateTime(String lastPostedDateTime) {\n            this.lastPostedDateTime = lastPostedDateTime;\n        }\n\n        @DynamoDBAttribute(attributeName = \"LastPostedBy\")\n        public String getLastPostedBy() {\n            return lastPostedBy;\n        }\n\n        public void setLastPostedBy(String lastPostedBy) {\n            this.lastPostedBy = lastPostedBy;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Tags\")\n        public Set<String> getTags() {\n            return tags;\n        }\n\n        public void setTags(Set<String> tags) {\n            this.tags = tags;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Answered\")\n        public int getAnswered() {\n            return answered;\n        }\n\n        public void setAnswered(int answered) {\n            this.answered = answered;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Views\")\n        public int getViews() {\n            return views;\n        }\n\n        public void setViews(int views) {\n            this.views = views;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Replies\")\n        public int getReplies() {\n            return replies;\n        }\n\n        public void setReplies(int replies) {\n            this.replies = replies;\n        }\n\n    }\n\n    @DynamoDBTable(tableName = \"Forum\")\n    public static class Forum {\n        private String name;\n        private String category;\n        private int threads;\n\n        // Partition key\n        @DynamoDBHashKey(attributeName = \"Name\")\n        public String getName() {\n            return name;\n        }\n\n        public void setName(String name) {\n            this.name = name;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Category\")\n        public String getCategory() {\n            return category;\n        }\n\n        public void setCategory(String category) {\n            this.category = category;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Threads\")\n        public int getThreads() {\n            return threads;\n        }\n\n        public void setThreads(int threads) {\n            this.threads = threads;\n        }\n    }\n}\n\n"
  },
  {
    "title": "DynamoDBMapper Query and scan operations - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.QueryScanExample.html",
    "html": "DynamoDBMapper Query and scan operations\nPDF\nRSS\n\nThe Java example in this section defines the following classes and maps them to the tables in Amazon DynamoDB. For more information about creating sample tables, see Creating tables and loading data for code examples in DynamoDB.\n\nThe Book class maps to ProductCatalog table\n\nThe Forum, Thread, and Reply classes map to tables of the same name.\n\nThe example then runs the following query and scan operations using a DynamoDBMapper instance.\n\nGet a book by Id.\n\nThe ProductCatalog table has Id as its primary key. It does not have a sort key as part of its primary key. Therefore, you cannot query the table. You can get an item using its Id value.\n\nRun the following queries against the Reply table.\n\nThe Reply table's primary key is composed of Id and ReplyDateTime attributes. ReplyDateTime is a sort key. Therefore, you can query this table.\n\nFind replies to a forum thread posted in the last 15 days.\n\nFind replies to a forum thread posted in a specific date range.\n\nScan the ProductCatalog table to find books whose price is less than a specified value.\n\nFor performance reasons, you should use the query operation instead of the scan operation. However, there are times you might need to scan a table. Suppose that there was a data entry error and one of the book prices was set to less than 0. This example scans the ProductCategory table to find book items (ProductCategory is book) whose price is less than 0.\n\nPerform a parallel scan of the ProductCatalog table to find bicycles of a specific type.\n\nNote\n\nThis code example assumes that you have already loaded data into DynamoDB for your account by following the instructions in the Creating tables and loading data for code examples in DynamoDB section.\n\nFor step-by-step instructions to run the following example, see Java code examples.\n\nImports\n\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.TimeZone;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBAttribute;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBHashKey;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapper;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBQueryExpression;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBRangeKey;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBScanExpression;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTable;\nimport com.amazonaws.services.dynamodbv2.model.AttributeValue;\n\n\nCode\n\npublic class DynamoDBMapperQueryScanExample {\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n\n    public static void main(String[] args) throws Exception {\n        try {\n\n            DynamoDBMapper mapper = new DynamoDBMapper(client);\n\n            // Get a book - Id=101\n            GetBook(mapper, 101);\n            // Sample forum and thread to test queries.\n            String forumName = \"Amazon DynamoDB\";\n            String threadSubject = \"DynamoDB Thread 1\";\n            // Sample queries.\n            FindRepliesInLast15Days(mapper, forumName, threadSubject);\n            FindRepliesPostedWithinTimePeriod(mapper, forumName, threadSubject);\n\n            // Scan a table and find book items priced less than specified\n            // value.\n            FindBooksPricedLessThanSpecifiedValue(mapper, \"20\");\n\n            // Scan a table with multiple threads and find bicycle items with a\n            // specified bicycle type\n            int numberOfThreads = 16;\n            FindBicyclesOfSpecificTypeWithMultipleThreads(mapper, numberOfThreads, \"Road\");\n\n            System.out.println(\"Example complete!\");\n\n        } catch (Throwable t) {\n            System.err.println(\"Error running the DynamoDBMapperQueryScanExample: \" + t);\n            t.printStackTrace();\n        }\n    }\n\n    private static void GetBook(DynamoDBMapper mapper, int id) throws Exception {\n        System.out.println(\"GetBook: Get book Id='101' \");\n        System.out.println(\"Book table has no sort key. You can do GetItem, but not Query.\");\n        Book book = mapper.load(Book.class, id);\n        System.out.format(\"Id = %s Title = %s, ISBN = %s %n\", book.getId(), book.getTitle(), book.getISBN());\n    }\n\n    private static void FindRepliesInLast15Days(DynamoDBMapper mapper, String forumName, String threadSubject)\n            throws Exception {\n        System.out.println(\"FindRepliesInLast15Days: Replies within last 15 days.\");\n\n        String partitionKey = forumName + \"#\" + threadSubject;\n\n        long twoWeeksAgoMilli = (new Date()).getTime() - (15L * 24L * 60L * 60L * 1000L);\n        Date twoWeeksAgo = new Date();\n        twoWeeksAgo.setTime(twoWeeksAgoMilli);\n        SimpleDateFormat dateFormatter = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\n        dateFormatter.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n        String twoWeeksAgoStr = dateFormatter.format(twoWeeksAgo);\n\n        Map<String, AttributeValue> eav = new HashMap<String, AttributeValue>();\n        eav.put(\":val1\", new AttributeValue().withS(partitionKey));\n        eav.put(\":val2\", new AttributeValue().withS(twoWeeksAgoStr.toString()));\n\n        DynamoDBQueryExpression<Reply> queryExpression = new DynamoDBQueryExpression<Reply>()\n                .withKeyConditionExpression(\"Id = :val1 and ReplyDateTime > :val2\").withExpressionAttributeValues(eav);\n\n        List<Reply> latestReplies = mapper.query(Reply.class, queryExpression);\n\n        for (Reply reply : latestReplies) {\n            System.out.format(\"Id=%s, Message=%s, PostedBy=%s %n, ReplyDateTime=%s %n\", reply.getId(),\n                    reply.getMessage(), reply.getPostedBy(), reply.getReplyDateTime());\n        }\n    }\n\n    private static void FindRepliesPostedWithinTimePeriod(DynamoDBMapper mapper, String forumName, String threadSubject)\n            throws Exception {\n        String partitionKey = forumName + \"#\" + threadSubject;\n\n        System.out.println(\n                \"FindRepliesPostedWithinTimePeriod: Find replies for thread Message = 'DynamoDB Thread 2' posted within a period.\");\n        long startDateMilli = (new Date()).getTime() - (14L * 24L * 60L * 60L * 1000L); // Two\n                                                                                        // weeks\n                                                                                        // ago.\n        long endDateMilli = (new Date()).getTime() - (7L * 24L * 60L * 60L * 1000L); // One\n                                                                                     // week\n                                                                                     // ago.\n        SimpleDateFormat dateFormatter = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\n        dateFormatter.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n        String startDate = dateFormatter.format(startDateMilli);\n        String endDate = dateFormatter.format(endDateMilli);\n\n        Map<String, AttributeValue> eav = new HashMap<String, AttributeValue>();\n        eav.put(\":val1\", new AttributeValue().withS(partitionKey));\n        eav.put(\":val2\", new AttributeValue().withS(startDate));\n        eav.put(\":val3\", new AttributeValue().withS(endDate));\n\n        DynamoDBQueryExpression<Reply> queryExpression = new DynamoDBQueryExpression<Reply>()\n                .withKeyConditionExpression(\"Id = :val1 and ReplyDateTime between :val2 and :val3\")\n                .withExpressionAttributeValues(eav);\n\n        List<Reply> betweenReplies = mapper.query(Reply.class, queryExpression);\n\n        for (Reply reply : betweenReplies) {\n            System.out.format(\"Id=%s, Message=%s, PostedBy=%s %n, PostedDateTime=%s %n\", reply.getId(),\n                    reply.getMessage(), reply.getPostedBy(), reply.getReplyDateTime());\n        }\n\n    }\n\n    private static void FindBooksPricedLessThanSpecifiedValue(DynamoDBMapper mapper, String value) throws Exception {\n\n        System.out.println(\"FindBooksPricedLessThanSpecifiedValue: Scan ProductCatalog.\");\n\n        Map<String, AttributeValue> eav = new HashMap<String, AttributeValue>();\n        eav.put(\":val1\", new AttributeValue().withN(value));\n        eav.put(\":val2\", new AttributeValue().withS(\"Book\"));\n\n        DynamoDBScanExpression scanExpression = new DynamoDBScanExpression()\n                .withFilterExpression(\"Price < :val1 and ProductCategory = :val2\").withExpressionAttributeValues(eav);\n\n        List<Book> scanResult = mapper.scan(Book.class, scanExpression);\n\n        for (Book book : scanResult) {\n            System.out.println(book);\n        }\n    }\n\n    private static void FindBicyclesOfSpecificTypeWithMultipleThreads(DynamoDBMapper mapper, int numberOfThreads,\n            String bicycleType) throws Exception {\n\n        System.out.println(\"FindBicyclesOfSpecificTypeWithMultipleThreads: Scan ProductCatalog With Multiple Threads.\");\n        Map<String, AttributeValue> eav = new HashMap<String, AttributeValue>();\n        eav.put(\":val1\", new AttributeValue().withS(\"Bicycle\"));\n        eav.put(\":val2\", new AttributeValue().withS(bicycleType));\n\n        DynamoDBScanExpression scanExpression = new DynamoDBScanExpression()\n                .withFilterExpression(\"ProductCategory = :val1 and BicycleType = :val2\")\n                .withExpressionAttributeValues(eav);\n\n        List<Bicycle> scanResult = mapper.parallelScan(Bicycle.class, scanExpression, numberOfThreads);\n        for (Bicycle bicycle : scanResult) {\n            System.out.println(bicycle);\n        }\n    }\n\n    @DynamoDBTable(tableName = \"ProductCatalog\")\n    public static class Book {\n        private int id;\n        private String title;\n        private String ISBN;\n        private int price;\n        private int pageCount;\n        private String productCategory;\n        private boolean inPublication;\n\n        @DynamoDBHashKey(attributeName = \"Id\")\n        public int getId() {\n            return id;\n        }\n\n        public void setId(int id) {\n            this.id = id;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Title\")\n        public String getTitle() {\n            return title;\n        }\n\n        public void setTitle(String title) {\n            this.title = title;\n        }\n\n        @DynamoDBAttribute(attributeName = \"ISBN\")\n        public String getISBN() {\n            return ISBN;\n        }\n\n        public void setISBN(String ISBN) {\n            this.ISBN = ISBN;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Price\")\n        public int getPrice() {\n            return price;\n        }\n\n        public void setPrice(int price) {\n            this.price = price;\n        }\n\n        @DynamoDBAttribute(attributeName = \"PageCount\")\n        public int getPageCount() {\n            return pageCount;\n        }\n\n        public void setPageCount(int pageCount) {\n            this.pageCount = pageCount;\n        }\n\n        @DynamoDBAttribute(attributeName = \"ProductCategory\")\n        public String getProductCategory() {\n            return productCategory;\n        }\n\n        public void setProductCategory(String productCategory) {\n            this.productCategory = productCategory;\n        }\n\n        @DynamoDBAttribute(attributeName = \"InPublication\")\n        public boolean getInPublication() {\n            return inPublication;\n        }\n\n        public void setInPublication(boolean inPublication) {\n            this.inPublication = inPublication;\n        }\n\n        @Override\n        public String toString() {\n            return \"Book [ISBN=\" + ISBN + \", price=\" + price + \", product category=\" + productCategory + \", id=\" + id\n                    + \", title=\" + title + \"]\";\n        }\n\n    }\n\n    @DynamoDBTable(tableName = \"ProductCatalog\")\n    public static class Bicycle {\n        private int id;\n        private String title;\n        private String description;\n        private String bicycleType;\n        private String brand;\n        private int price;\n        private List<String> color;\n        private String productCategory;\n\n        @DynamoDBHashKey(attributeName = \"Id\")\n        public int getId() {\n            return id;\n        }\n\n        public void setId(int id) {\n            this.id = id;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Title\")\n        public String getTitle() {\n            return title;\n        }\n\n        public void setTitle(String title) {\n            this.title = title;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Description\")\n        public String getDescription() {\n            return description;\n        }\n\n        public void setDescription(String description) {\n            this.description = description;\n        }\n\n        @DynamoDBAttribute(attributeName = \"BicycleType\")\n        public String getBicycleType() {\n            return bicycleType;\n        }\n\n        public void setBicycleType(String bicycleType) {\n            this.bicycleType = bicycleType;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Brand\")\n        public String getBrand() {\n            return brand;\n        }\n\n        public void setBrand(String brand) {\n            this.brand = brand;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Price\")\n        public int getPrice() {\n            return price;\n        }\n\n        public void setPrice(int price) {\n            this.price = price;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Color\")\n        public List<String> getColor() {\n            return color;\n        }\n\n        public void setColor(List<String> color) {\n            this.color = color;\n        }\n\n        @DynamoDBAttribute(attributeName = \"ProductCategory\")\n        public String getProductCategory() {\n            return productCategory;\n        }\n\n        public void setProductCategory(String productCategory) {\n            this.productCategory = productCategory;\n        }\n\n        @Override\n        public String toString() {\n            return \"Bicycle [Type=\" + bicycleType + \", color=\" + color + \", price=\" + price + \", product category=\"\n                    + productCategory + \", id=\" + id + \", title=\" + title + \"]\";\n        }\n\n    }\n\n    @DynamoDBTable(tableName = \"Reply\")\n    public static class Reply {\n        private String id;\n        private String replyDateTime;\n        private String message;\n        private String postedBy;\n\n        // Partition key\n        @DynamoDBHashKey(attributeName = \"Id\")\n        public String getId() {\n            return id;\n        }\n\n        public void setId(String id) {\n            this.id = id;\n        }\n\n        // Range key\n        @DynamoDBRangeKey(attributeName = \"ReplyDateTime\")\n        public String getReplyDateTime() {\n            return replyDateTime;\n        }\n\n        public void setReplyDateTime(String replyDateTime) {\n            this.replyDateTime = replyDateTime;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Message\")\n        public String getMessage() {\n            return message;\n        }\n\n        public void setMessage(String message) {\n            this.message = message;\n        }\n\n        @DynamoDBAttribute(attributeName = \"PostedBy\")\n        public String getPostedBy() {\n            return postedBy;\n        }\n\n        public void setPostedBy(String postedBy) {\n            this.postedBy = postedBy;\n        }\n    }\n\n    @DynamoDBTable(tableName = \"Thread\")\n    public static class Thread {\n        private String forumName;\n        private String subject;\n        private String message;\n        private String lastPostedDateTime;\n        private String lastPostedBy;\n        private Set<String> tags;\n        private int answered;\n        private int views;\n        private int replies;\n\n        // Partition key\n        @DynamoDBHashKey(attributeName = \"ForumName\")\n        public String getForumName() {\n            return forumName;\n        }\n\n        public void setForumName(String forumName) {\n            this.forumName = forumName;\n        }\n\n        // Range key\n        @DynamoDBRangeKey(attributeName = \"Subject\")\n        public String getSubject() {\n            return subject;\n        }\n\n        public void setSubject(String subject) {\n            this.subject = subject;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Message\")\n        public String getMessage() {\n            return message;\n        }\n\n        public void setMessage(String message) {\n            this.message = message;\n        }\n\n        @DynamoDBAttribute(attributeName = \"LastPostedDateTime\")\n        public String getLastPostedDateTime() {\n            return lastPostedDateTime;\n        }\n\n        public void setLastPostedDateTime(String lastPostedDateTime) {\n            this.lastPostedDateTime = lastPostedDateTime;\n        }\n\n        @DynamoDBAttribute(attributeName = \"LastPostedBy\")\n        public String getLastPostedBy() {\n            return lastPostedBy;\n        }\n\n        public void setLastPostedBy(String lastPostedBy) {\n            this.lastPostedBy = lastPostedBy;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Tags\")\n        public Set<String> getTags() {\n            return tags;\n        }\n\n        public void setTags(Set<String> tags) {\n            this.tags = tags;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Answered\")\n        public int getAnswered() {\n            return answered;\n        }\n\n        public void setAnswered(int answered) {\n            this.answered = answered;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Views\")\n        public int getViews() {\n            return views;\n        }\n\n        public void setViews(int views) {\n            this.views = views;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Replies\")\n        public int getReplies() {\n            return replies;\n        }\n\n        public void setReplies(int replies) {\n            this.replies = replies;\n        }\n\n    }\n\n    @DynamoDBTable(tableName = \"Forum\")\n    public static class Forum {\n        private String name;\n        private String category;\n        private int threads;\n\n        @DynamoDBHashKey(attributeName = \"Name\")\n        public String getName() {\n            return name;\n        }\n\n        public void setName(String name) {\n            this.name = name;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Category\")\n        public String getCategory() {\n            return category;\n        }\n\n        public void setCategory(String category) {\n            this.category = category;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Threads\")\n        public int getThreads() {\n            return threads;\n        }\n\n        public void setThreads(int threads) {\n            this.threads = threads;\n        }\n    }\n}\n\n"
  },
  {
    "title": "DynamoDBMapper Examples - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.Examples.html",
    "html": "DynamoDBMapper Examples\nPDF\nRSS\n\nThe following Java code examples demonstrate how to perform a variety of operations with the DynamoDBMapper class. You can use these examples to perform CRUD, query, scan, batch, and transaction operations.\n\nTopics\nDynamoDBMapper CRUD operations\nDynamoDBMapper Query and scan operations\nDynamoDBMapper batch operations\nDynamoDBMapper Transaction operations"
  },
  {
    "title": "DynamoDBMapper CRUD operations - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.CRUDExample1.html",
    "html": "DynamoDBMapper CRUD operations\nPDF\nRSS\n\nThe following Java code example declares a CatalogItem class that has Id, Title, ISBN, and Authors properties. It uses the annotations to map these properties to the ProductCatalog table in DynamoDB. The example then uses the DynamoDBMapper to save a book object, retrieve it, update it, and then delete the book item.\n\nNote\n\nThis code example assumes that you have already loaded data into DynamoDB for your account by following the instructions in the Creating tables and loading data for code examples in DynamoDB section.\n\nFor step-by-step instructions to run the following example, see Java code examples.\n\nImports\n\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.HashSet;\nimport java.util.Set;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBAttribute;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBHashKey;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapper;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapperConfig;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTable;\n\n\nCode\n\npublic class DynamoDBMapperCRUDExample {\n\n    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n\n    public static void main(String[] args) throws IOException {\n        testCRUDOperations();\n        System.out.println(\"Example complete!\");\n    }\n\n    @DynamoDBTable(tableName = \"ProductCatalog\")\n    public static class CatalogItem {\n        private Integer id;\n        private String title;\n        private String ISBN;\n        private Set<String> bookAuthors;\n\n        // Partition key\n        @DynamoDBHashKey(attributeName = \"Id\")\n        public Integer getId() {\n            return id;\n        }\n\n        public void setId(Integer id) {\n            this.id = id;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Title\")\n        public String getTitle() {\n            return title;\n        }\n\n        public void setTitle(String title) {\n            this.title = title;\n        }\n\n        @DynamoDBAttribute(attributeName = \"ISBN\")\n        public String getISBN() {\n            return ISBN;\n        }\n\n        public void setISBN(String ISBN) {\n            this.ISBN = ISBN;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Authors\")\n        public Set<String> getBookAuthors() {\n            return bookAuthors;\n        }\n\n        public void setBookAuthors(Set<String> bookAuthors) {\n            this.bookAuthors = bookAuthors;\n        }\n\n        @Override\n        public String toString() {\n            return \"Book [ISBN=\" + ISBN + \", bookAuthors=\" + bookAuthors + \", id=\" + id + \", title=\" + title + \"]\";\n        }\n    }\n\n    private static void testCRUDOperations() {\n\n        CatalogItem item = new CatalogItem();\n        item.setId(601);\n        item.setTitle(\"Book 601\");\n        item.setISBN(\"611-1111111111\");\n        item.setBookAuthors(new HashSet<String>(Arrays.asList(\"Author1\", \"Author2\")));\n\n        // Save the item (book).\n        DynamoDBMapper mapper = new DynamoDBMapper(client);\n        mapper.save(item);\n\n        // Retrieve the item.\n        CatalogItem itemRetrieved = mapper.load(CatalogItem.class, 601);\n        System.out.println(\"Item retrieved:\");\n        System.out.println(itemRetrieved);\n\n        // Update the item.\n        itemRetrieved.setISBN(\"622-2222222222\");\n        itemRetrieved.setBookAuthors(new HashSet<String>(Arrays.asList(\"Author1\", \"Author3\")));\n        mapper.save(itemRetrieved);\n        System.out.println(\"Item updated:\");\n        System.out.println(itemRetrieved);\n\n        // Retrieve the updated item.\n        DynamoDBMapperConfig config = DynamoDBMapperConfig.builder()\n                .withConsistentReads(DynamoDBMapperConfig.ConsistentReads.CONSISTENT)\n                .build();\n        CatalogItem updatedItem = mapper.load(CatalogItem.class, 601, config);\n        System.out.println(\"Retrieved the previously updated item:\");\n        System.out.println(updatedItem);\n\n        // Delete the item.\n        mapper.delete(updatedItem);\n\n        // Try to retrieve deleted item.\n        CatalogItem deletedItem = mapper.load(CatalogItem.class, updatedItem.getId(), config);\n        if (deletedItem == null) {\n            System.out.println(\"Done - Sample item is deleted.\");\n        }\n    }\n}\n\n"
  },
  {
    "title": "Mapping arbitrary data - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.ArbitraryDataMapping.html",
    "html": "Mapping arbitrary data\nPDF\nRSS\n\nIn addition to the supported Java types (see Supported data types for DynamoDB Mapper for Java), you can use types in your application for which there is no direct mapping to the Amazon DynamoDB types. To map these types, you must provide an implementation that converts your complex type to a DynamoDB supported type and vice versa, and annotate the complex type accessor method using the @DynamoDBTypeConverted annotation. The converter code transforms data when objects are saved or loaded. It is also used for all operations that consume complex types. Note that when comparing data during query and scan operations, the comparisons are made against the data stored in DynamoDB.\n\nFor example, consider the following CatalogItem class that defines a property, Dimension, that is of DimensionType. This property stores the item dimensions as height, width, and thickness. Assume that you decide to store these item dimensions as a string (such as 8.5x11x.05) in DynamoDB. The following example provides converter code that converts the DimensionType object to a string and a string to the DimensionType.\n\nNote\n\nThis code example assumes that you have already loaded data into DynamoDB for your account by following the instructions in the Creating tables and loading data for code examples in DynamoDB section.\n\nFor step-by-step instructions to run the following example, see Java code examples.\n\nExample\npublic class DynamoDBMapperExample {\n\n    static AmazonDynamoDB client;\n\n    public static void main(String[] args) throws IOException {\n\n        // Set the AWS region you want to access.\n        Regions usWest2 = Regions.US_WEST_2;\n        client = AmazonDynamoDBClientBuilder.standard().withRegion(usWest2).build();\n\n        DimensionType dimType = new DimensionType();\n        dimType.setHeight(\"8.00\");\n        dimType.setLength(\"11.0\");\n        dimType.setThickness(\"1.0\");\n\n        Book book = new Book();\n        book.setId(502);\n        book.setTitle(\"Book 502\");\n        book.setISBN(\"555-5555555555\");\n        book.setBookAuthors(new HashSet<String>(Arrays.asList(\"Author1\", \"Author2\")));\n        book.setDimensions(dimType);\n\n        DynamoDBMapper mapper = new DynamoDBMapper(client);\n        mapper.save(book);\n\n        Book bookRetrieved = mapper.load(Book.class, 502);\n        System.out.println(\"Book info: \" + \"\\n\" + bookRetrieved);\n\n        bookRetrieved.getDimensions().setHeight(\"9.0\");\n        bookRetrieved.getDimensions().setLength(\"12.0\");\n        bookRetrieved.getDimensions().setThickness(\"2.0\");\n\n        mapper.save(bookRetrieved);\n\n        bookRetrieved = mapper.load(Book.class, 502);\n        System.out.println(\"Updated book info: \" + \"\\n\" + bookRetrieved);\n    }\n\n    @DynamoDBTable(tableName = \"ProductCatalog\")\n    public static class Book {\n        private int id;\n        private String title;\n        private String ISBN;\n        private Set<String> bookAuthors;\n        private DimensionType dimensionType;\n\n        // Partition key\n        @DynamoDBHashKey(attributeName = \"Id\")\n        public int getId() {\n            return id;\n        }\n\n        public void setId(int id) {\n            this.id = id;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Title\")\n        public String getTitle() {\n            return title;\n        }\n\n        public void setTitle(String title) {\n            this.title = title;\n        }\n\n        @DynamoDBAttribute(attributeName = \"ISBN\")\n        public String getISBN() {\n            return ISBN;\n        }\n\n        public void setISBN(String ISBN) {\n            this.ISBN = ISBN;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Authors\")\n        public Set<String> getBookAuthors() {\n            return bookAuthors;\n        }\n\n        public void setBookAuthors(Set<String> bookAuthors) {\n            this.bookAuthors = bookAuthors;\n        }\n\n        @DynamoDBTypeConverted(converter = DimensionTypeConverter.class)\n        @DynamoDBAttribute(attributeName = \"Dimensions\")\n        public DimensionType getDimensions() {\n            return dimensionType;\n        }\n\n        @DynamoDBAttribute(attributeName = \"Dimensions\")\n        public void setDimensions(DimensionType dimensionType) {\n            this.dimensionType = dimensionType;\n        }\n\n        @Override\n        public String toString() {\n            return \"Book [ISBN=\" + ISBN + \", bookAuthors=\" + bookAuthors + \", dimensionType= \"\n                    + dimensionType.getHeight() + \" X \" + dimensionType.getLength() + \" X \"\n                    + dimensionType.getThickness()\n                    + \", Id=\" + id + \", Title=\" + title + \"]\";\n        }\n    }\n\n    static public class DimensionType {\n\n        private String length;\n        private String height;\n        private String thickness;\n\n        public String getLength() {\n            return length;\n        }\n\n        public void setLength(String length) {\n            this.length = length;\n        }\n\n        public String getHeight() {\n            return height;\n        }\n\n        public void setHeight(String height) {\n            this.height = height;\n        }\n\n        public String getThickness() {\n            return thickness;\n        }\n\n        public void setThickness(String thickness) {\n            this.thickness = thickness;\n        }\n    }\n\n    // Converts the complex type DimensionType to a string and vice-versa.\n    static public class DimensionTypeConverter implements DynamoDBTypeConverter<String, DimensionType> {\n\n        @Override\n        public String convert(DimensionType object) {\n            DimensionType itemDimensions = (DimensionType) object;\n            String dimension = null;\n            try {\n                if (itemDimensions != null) {\n                    dimension = String.format(\"%s x %s x %s\", itemDimensions.getLength(), itemDimensions.getHeight(),\n                            itemDimensions.getThickness());\n                }\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n            return dimension;\n        }\n\n        @Override\n        public DimensionType unconvert(String s) {\n\n            DimensionType itemDimension = new DimensionType();\n            try {\n                if (s != null && s.length() != 0) {\n                    String[] data = s.split(\"x\");\n                    itemDimension.setLength(data[0].trim());\n                    itemDimension.setHeight(data[1].trim());\n                    itemDimension.setThickness(data[2].trim());\n                }\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n\n            return itemDimension;\n        }\n    }\n}\n"
  },
  {
    "title": "Optional configuration settings for DynamoDBMapper - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.OptionalConfig.html",
    "html": "Optional configuration settings for DynamoDBMapper\nPDF\nRSS\n\nWhen you create an instance of DynamoDBMapper, it has certain default behaviors; you can override these defaults by using the DynamoDBMapperConfig class.\n\nThe following code snippet creates a DynamoDBMapper with custom settings:\n\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n\nDynamoDBMapperConfig mapperConfig = DynamoDBMapperConfig.builder()\n        .withSaveBehavior(DynamoDBMapperConfig.SaveBehavior.CLOBBER)\n        .withConsistentReads(DynamoDBMapperConfig.ConsistentReads.CONSISTENT)\n        .withTableNameOverride(null)\n        .withPaginationLoadingStrategy(DynamoDBMapperConfig.PaginationLoadingStrategy.EAGER_LOADING)\n    .build();\n\nDynamoDBMapper mapper = new DynamoDBMapper(client, mapperConfig);\n\nFor more information, see DynamoDBMapperConfig in the AWS SDK for Java API Reference.\n\nYou can use the following arguments for an instance of DynamoDBMapperConfig:\n\nA DynamoDBMapperConfig.ConsistentReads enumeration value:\n\nEVENTUAL—the mapper instance uses an eventually consistent read request.\n\nCONSISTENT—the mapper instance uses a strongly consistent read request. You can use this optional setting with load, query, or scan operations. Strongly consistent reads have implications for performance and billing; see the DynamoDB product detail page for more information.\n\nIf you do not specify a read consistency setting for your mapper instance, the default is EVENTUAL.\n\nNote\n\nThis value is applied in the query, querypage, load, and batch load operations of the DynamoDBMapper.\n\nA DynamoDBMapperConfig.PaginationLoadingStrategy enumeration value—Controls how the mapper instance processes a paginated list of data, such as the results from a query or scan:\n\nLAZY_LOADING—the mapper instance loads data when possible, and keeps all loaded results in memory.\n\nEAGER_LOADING—the mapper instance loads the data as soon as the list is initialized.\n\nITERATION_ONLY—you can only use an Iterator to read from the list. During the iteration, the list will clear all the previous results before loading the next page, so that the list will keep at most one page of the loaded results in memory. This also means the list can only be iterated once. This strategy is recommended when handling large items, in order to reduce memory overhead.\n\nIf you do not specify a pagination loading strategy for your mapper instance, the default is LAZY_LOADING.\n\nA DynamoDBMapperConfig.SaveBehavior enumeration value - Specifies how the mapper instance should deal with attributes during save operations:\n\nUPDATE—during a save operation, all modeled attributes are updated, and unmodeled attributes are unaffected. Primitive number types (byte, int, long) are set to 0. Object types are set to null.\n\nCLOBBER—clears and replaces all attributes, included unmodeled ones, during a save operation. This is done by deleting the item and re-creating it. Versioned field constraints are also disregarded.\n\nIf you do not specify the save behavior for your mapper instance, the default is UPDATE.\n\nNote\n\nDynamoDBMapper transactional operations do not support DynamoDBMapperConfig.SaveBehavior enumeration.\n\nA DynamoDBMapperConfig.TableNameOverride object—Instructs the mapper instance to ignore the table name specified by a class's DynamoDBTable annotation, and instead use a different table name that you supply. This is useful when partitioning your data into multiple tables at runtime.\n\nYou can override the default configuration object for DynamoDBMapper per operation, as needed."
  },
  {
    "title": "Optimistic locking with version number - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.OptimisticLocking.html",
    "html": "Optimistic locking with version number\nPDF\nRSS\n\nOptimistic locking is a strategy to ensure that the client-side item that you are updating (or deleting) is the same as the item in Amazon DynamoDB. If you use this strategy, your database writes are protected from being overwritten by the writes of others, and vice versa.\n\nWith optimistic locking, each item has an attribute that acts as a version number. If you retrieve an item from a table, the application records the version number of that item. You can update the item, but only if the version number on the server side has not changed. If there is a version mismatch, it means that someone else has modified the item before you did. The update attempt fails, because you have a stale version of the item. If this happens, try again by retrieving the item and then trying to update it. Optimistic locking prevents you from accidentally overwriting changes that were made by others. It also prevents others from accidentally overwriting your changes.\n\nWhile you can implement your own optimistic locking strategy, the AWS SDK for Java provides the @DynamoDBVersionAttribute annotation. In the mapping class for your table, you designate one property to store the version number, and mark it using this annotation. When you save an object, the corresponding item in the DynamoDB table will have an attribute that stores the version number. The DynamoDBMapper assigns a version number when you first save the object, and it automatically increments the version number each time you update the item. Your update or delete requests succeed only if the client-side object version matches the corresponding version number of the item in the DynamoDB table.\n\nConditionalCheckFailedException is thrown if:\n\nYou use optimistic locking with @DynamoDBVersionAttribute and the version value on the server is different from the value on the client side.\n\nYou specify your own conditional constraints while saving data by using DynamoDBMapper with DynamoDBSaveExpression and these constraints failed.\n\nNote\n\nDynamoDB global tables use a “last writer wins” reconciliation between concurrent updates. If you use global tables, last writer policy wins. So in this case, the locking strategy does not work as expected.\n\nDynamoDBMapper transactional write operations do not support @DynamoDBVersionAttribute annotation and condition expressions on the same object. If an object within a transactional write is annotated with @DynamoDBVersionAttribute and also has a condition expression, then an SdkClientException will be thrown.\n\nFor example, the following Java code defines a CatalogItem class that has several properties. The Version property is tagged with the @DynamoDBVersionAttribute annotation.\n\nExample\n@DynamoDBTable(tableName=\"ProductCatalog\")\npublic class CatalogItem {\n\n    private Integer id;\n    private String title;\n    private String ISBN;\n    private Set<String> bookAuthors;\n    private String someProp;\n    private Long version;\n\n    @DynamoDBHashKey(attributeName=\"Id\")\n    public Integer getId() { return id; }\n    public void setId(Integer Id) { this.id = Id; }\n\n    @DynamoDBAttribute(attributeName=\"Title\")\n    public String getTitle() { return title; }\n    public void setTitle(String title) { this.title = title; }\n\n    @DynamoDBAttribute(attributeName=\"ISBN\")\n    public String getISBN() { return ISBN; }\n    public void setISBN(String ISBN) { this.ISBN = ISBN;}\n\n    @DynamoDBAttribute(attributeName = \"Authors\")\n    public Set<String> getBookAuthors() { return bookAuthors; }\n    public void setBookAuthors(Set<String> bookAuthors) { this.bookAuthors = bookAuthors; }\n\n    @DynamoDBIgnore\n    public String getSomeProp() { return someProp;}\n    public void setSomeProp(String someProp) {this.someProp = someProp;}\n\n    @DynamoDBVersionAttribute\n    public Long getVersion() { return version; }\n    public void setVersion(Long version) { this.version = version;}\n}\n\nYou can apply the @DynamoDBVersionAttribute annotation to nullable types provided by the primitive wrappers classes that provide a nullable type, such as Long and Integer.\n\nOptimistic locking has the following impact on these DynamoDBMapper methods:\n\nsave — For a new item, the DynamoDBMapper assigns an initial version number of 1. If you retrieve an item, update one or more of its properties, and attempt to save the changes, the save operation succeeds only if the version number on the client side and the server side match. The DynamoDBMapper increments the version number automatically.\n\ndelete — The delete method takes an object as a parameter, and the DynamoDBMapper performs a version check before deleting the item. The version check can be disabled if DynamoDBMapperConfig.SaveBehavior.CLOBBER is specified in the request.\n\nThe internal implementation of optimistic locking within DynamoDBMapper uses conditional update and conditional delete support provided by DynamoDB.\n\ntransactionWrite —\n\nPut — For a new item, the DynamoDBMapper assigns an initial version number of 1. If you retrieve an item, update one or more of its properties, and attempt to save the changes, the put operation succeeds only if the version number on the client side and the server side match. The DynamoDBMapper increments the version number automatically.\n\nUpdate — For a new item, the DynamoDBMapper assigns an initial version number of 1. If you retrieve an item, update one or more of its properties, and attempt to save the changes, the update operation succeeds only if the version number on the client side and the server side match. The DynamoDBMapper increments the version number automatically.\n\nDelete — The DynamoDBMapper performs a version check before deleting the item. The delete operation succeeds only if the version number on the client side and the server side match.\n\nConditionCheck — The @DynamoDBVersionAttribute annotation is not supported for ConditionCheck operations. An SdkClientException will be thrown when a ConditionCheck item is annotated with @DynamoDBVersionAttribute.\n\nDisabling optimistic locking\n\nTo disable optimistic locking, you can change the DynamoDBMapperConfig.SaveBehavior enumeration value from UPDATE to CLOBBER. You can do this by creating a DynamoDBMapperConfig instance that skips version checking and use this instance for all your requests. For information about DynamoDBMapperConfig.SaveBehavior and other optional DynamoDBMapper parameters, see Optional configuration settings for DynamoDBMapper .\n\nYou can also set locking behavior for a specific operation only. For example, the following Java snippet uses the DynamoDBMapper to save a catalog item. It specifies DynamoDBMapperConfig.SaveBehavior by adding the optional DynamoDBMapperConfig parameter to the save method.\n\nNote\n\nThe transactionWrite method does not support DynamoDBMapperConfig.SaveBehavior configuration. Disabling optimistic locking for transactionWrite is not supported.\n\nExample\nDynamoDBMapper mapper = new DynamoDBMapper(client);\n\n// Load a catalog item.\nCatalogItem item = mapper.load(CatalogItem.class, 101);\nitem.setTitle(\"This is a new title for the item\");\n...\n// Save the item.\nmapper.save(item,\n    new DynamoDBMapperConfig(\n        DynamoDBMapperConfig.SaveBehavior.CLOBBER));"
  },
  {
    "title": "DynamoDBMapper Class - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.Methods.html",
    "html": "DynamoDBMapper Class\nPDF\nRSS\n\nThe DynamoDBMapper class is the entry point to Amazon DynamoDB. It provides access to a DynamoDB endpoint and enables you to access your data in various tables. It also enables you to perform various create, read, update, and delete (CRUD) operations on items, and run queries and scans against tables. This class provides the following methods for working with DynamoDB.\n\nFor the corresponding Javadoc documentation, see DynamoDBMapper in the AWS SDK for Java API Reference.\n\nTopics\nsave\nload\ndelete\nquery\nqueryPage\nscan\nscanPage\nparallelScan\nbatchSave\nbatchLoad\nbatchDelete\nbatchWrite\ntransactionWrite\ntransactionLoad\ncount\ngenerateCreateTableRequest\ncreateS3Link\ngetS3ClientCache\nsave\n\nSaves the specified object to the table. The object that you want to save is the only required parameter for this method. You can provide optional configuration parameters using the DynamoDBMapperConfig object.\n\nIf an item that has the same primary key does not exist, this method creates a new item in the table. If an item that has the same primary key exists, it updates the existing item. If the partition key and sort key are of type String and are annotated with @DynamoDBAutoGeneratedKey, they are given a random universally unique identifier (UUID) if left uninitialized. Version fields that are annotated with @DynamoDBVersionAttribute are incremented by one. Additionally, if a version field is updated or a key generated, the object passed in is updated as a result of the operation.\n\nBy default, only attributes corresponding to mapped class properties are updated. Any additional existing attributes on an item are unaffected. However, if you specify SaveBehavior.CLOBBER, you can force the item to be completely overwritten.\n\nDynamoDBMapperConfig config = DynamoDBMapperConfig.builder()\n    .withSaveBehavior(DynamoDBMapperConfig.SaveBehavior.CLOBBER).build();\n        \nmapper.save(item, config);\n\nIf you have versioning enabled, the client-side and server-side item versions must match. However, the version does not need to match if the SaveBehavior.CLOBBER option is used. For more information about versioning, see Optimistic locking with version number.\n\nload\n\nRetrieves an item from a table. You must provide the primary key of the item that you want to retrieve. You can provide optional configuration parameters using the DynamoDBMapperConfig object. For example, you can optionally request strongly consistent reads to ensure that this method retrieves only the latest item values as shown in the following Java statement.\n\nDynamoDBMapperConfig config = DynamoDBMapperConfig.builder()\n    .withConsistentReads(DynamoDBMapperConfig.ConsistentReads.CONSISTENT).build();\n\nCatalogItem item = mapper.load(CatalogItem.class, item.getId(), config);\n\nBy default, DynamoDB returns the item that has values that are eventually consistent. For information about the eventual consistency model of DynamoDB, see Read consistency.\n\ndelete\n\nDeletes an item from the table. You must pass in an object instance of the mapped class.\n\nIf you have versioning enabled, the client-side and server-side item versions must match. However, the version does not need to match if the SaveBehavior.CLOBBER option is used. For more information about versioning, see Optimistic locking with version number.\n\nquery\n\nQueries a table or a secondary index.\n\nAssume that you have a table, Reply, that stores forum thread replies. Each thread subject can have zero or more replies. The primary key of the Reply table consists of the Id and ReplyDateTime fields, where Id is the partition key and ReplyDateTime is the sort key of the primary key.\n\nReply ( Id, ReplyDateTime, ... )\n\nAssume that you created a mapping between a Reply class and the corresponding Reply table in DynamoDB. The following Java code uses DynamoDBMapper to find all replies in the past two weeks for a specific thread subject.\n\nExample\nString forumName = \"&DDB;\";\nString forumSubject = \"&DDB; Thread 1\";\nString partitionKey = forumName + \"#\" + forumSubject;\n\nlong twoWeeksAgoMilli = (new Date()).getTime() - (14L*24L*60L*60L*1000L);\nDate twoWeeksAgo = new Date();\ntwoWeeksAgo.setTime(twoWeeksAgoMilli);\nSimpleDateFormat df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\nString twoWeeksAgoStr = df.format(twoWeeksAgo);\n\nMap<String, AttributeValue> eav = new HashMap<String, AttributeValue>();\neav.put(\":v1\", new AttributeValue().withS(partitionKey));\neav.put(\":v2\",new AttributeValue().withS(twoWeeksAgoStr.toString()));\n\nDynamoDBQueryExpression<Reply> queryExpression = new DynamoDBQueryExpression<Reply>()\n    .withKeyConditionExpression(\"Id = :v1 and ReplyDateTime > :v2\")\n    .withExpressionAttributeValues(eav);\n\nList<Reply> latestReplies = mapper.query(Reply.class, queryExpression);\n\nThe query returns a collection of Reply objects.\n\nBy default, the query method returns a \"lazy-loaded\" collection. It initially returns only one page of results, and then makes a service call for the next page if needed. To obtain all the matching items, iterate over the latestReplies collection.\n\nNote that calling the size() method on the collection will load every result in order to provide an accurate count. This can result in a lot of provisioned throughput being consumed, and on a very large table could even exhaust all the memory in your JVM.\n\nTo query an index, you must first model the index as a mapper class. Suppose that the Reply table has a global secondary index named PostedBy-Message-Index. The partition key for this index is PostedBy, and the sort key is Message. The class definition for an item in the index would look like the following.\n\n@DynamoDBTable(tableName=\"Reply\")\npublic class PostedByMessage {\n    private String postedBy;\n    private String message;\n\n    @DynamoDBIndexHashKey(globalSecondaryIndexName = \"PostedBy-Message-Index\", attributeName = \"PostedBy\")\n    public String getPostedBy() { return postedBy; }\n    public void setPostedBy(String postedBy) { this.postedBy = postedBy; }\n\n    @DynamoDBIndexRangeKey(globalSecondaryIndexName = \"PostedBy-Message-Index\", attributeName = \"Message\")\n    public String getMessage() { return message; }\n    public void setMessage(String message) { this.message = message; }\n\n   // Additional properties go here.\n}\n\nThe @DynamoDBTable annotation indicates that this index is associated with the Reply table. The @DynamoDBIndexHashKey annotation denotes the partition key (PostedBy) of the index, and @DynamoDBIndexRangeKey denotes the sort key (Message) of the index.\n\nNow you can use DynamoDBMapper to query the index, retrieving a subset of messages that were posted by a particular user. You do not need to specify the index name if you do not have conflicting mappings across tables and indexes and the mappings are already made in the mapper. The mapper will infer based on the primary key and sort key. The following code queries a global secondary index. Because global secondary indexes support eventually consistent reads but not strongly consistent reads, you must specify withConsistentRead(false).\n\nHashMap<String, AttributeValue> eav = new HashMap<String, AttributeValue>();\neav.put(\":v1\",  new AttributeValue().withS(\"User A\"));\neav.put(\":v2\",  new AttributeValue().withS(\"DynamoDB\"));\n\nDynamoDBQueryExpression<PostedByMessage> queryExpression = new DynamoDBQueryExpression<PostedByMessage>()\n    .withIndexName(\"PostedBy-Message-Index\")\n    .withConsistentRead(false)\n    .withKeyConditionExpression(\"PostedBy = :v1 and begins_with(Message, :v2)\")\n    .withExpressionAttributeValues(eav);\n\nList<PostedByMessage> iList =  mapper.query(PostedByMessage.class, queryExpression);\n\nThe query returns a collection of PostedByMessage objects.\n\nqueryPage\n\nQueries a table or secondary index and returns a single page of matching results. As with the query method, you must specify a partition key value and a query filter that is applied on the sort key attribute. However, queryPage returns only the first \"page\" of data, that is, the amount of data that fits in 1 MB\n\nscan\n\nScans an entire table or a secondary index. You can optionally specify a FilterExpression to filter the result set.\n\nAssume that you have a table, Reply, that stores forum thread replies. Each thread subject can have zero or more replies. The primary key of the Reply table consists of the Id and ReplyDateTime fields, where Id is the partition key and ReplyDateTime is the sort key of the primary key.\n\nReply ( Id, ReplyDateTime, ... )\n\nIf you mapped a Java class to the Reply table, you can use the DynamoDBMapper to scan the table. For example, the following Java code scans the entire Reply table, returning only the replies for a particular year.\n\nExample\nHashMap<String, AttributeValue> eav = new HashMap<String, AttributeValue>();\neav.put(\":v1\", new AttributeValue().withS(\"2015\"));\n\nDynamoDBScanExpression scanExpression = new DynamoDBScanExpression()\n    .withFilterExpression(\"begins_with(ReplyDateTime,:v1)\")\n    .withExpressionAttributeValues(eav);\n\nList<Reply> replies =  mapper.scan(Reply.class, scanExpression);\n\nBy default, the scan method returns a \"lazy-loaded\" collection. It initially returns only one page of results, and then makes a service call for the next page if needed. To obtain all the matching items, iterate over the replies collection.\n\nNote that calling the size() method on the collection will load every result in order to provide an accurate count. This can result in a lot of provisioned throughput being consumed, and on a very large table could even exhaust all the memory in your JVM.\n\nTo scan an index, you must first model the index as a mapper class. Suppose that the Reply table has a global secondary index named PostedBy-Message-Index. The partition key for this index is PostedBy, and the sort key is Message. A mapper class for this index is shown in the query section. It uses the @DynamoDBIndexHashKey and @DynamoDBIndexRangeKey annotations to specify the index partition key and sort key.\n\nThe following code example scans PostedBy-Message-Index. It does not use a scan filter, so all of the items in the index are returned to you.\n\nDynamoDBScanExpression scanExpression = new DynamoDBScanExpression()\n    .withIndexName(\"PostedBy-Message-Index\")\n    .withConsistentRead(false);\n\n    List<PostedByMessage> iList =  mapper.scan(PostedByMessage.class, scanExpression);\n    Iterator<PostedByMessage> indexItems = iList.iterator();\nscanPage\n\nScans a table or secondary index and returns a single page of matching results. As with the scan method, you can optionally specify a FilterExpression to filter the result set. However, scanPage only returns the first \"page\" of data, that is, the amount of data that fits within 1 MB.\n\nparallelScan\n\nPerforms a parallel scan of an entire table or secondary index. You specify a number of logical segments for the table, along with a scan expression to filter the results. The parallelScan divides the scan task among multiple workers, one for each logical segment; the workers process the data in parallel and return the results.\n\nThe following Java code example performs a parallel scan on the Product table.\n\nint numberOfThreads = 4;\n\nMap<String, AttributeValue> eav = new HashMap<String, AttributeValue>();\neav.put(\":n\", new AttributeValue().withN(\"100\"));\n\nDynamoDBScanExpression scanExpression = new DynamoDBScanExpression()\n    .withFilterExpression(\"Price <= :n\")\n    .withExpressionAttributeValues(eav);\n\nList<Product> scanResult = mapper.parallelScan(Product.class, scanExpression, numberOfThreads);\n\nFor a Java code example illustrating the usage of parallelScan, see DynamoDBMapper Query and scan operations.\n\nbatchSave\n\nSaves objects to one or more tables using one or more calls to the AmazonDynamoDB.batchWriteItem method. This method does not provide transaction guarantees.\n\nThe following Java code saves two items (books) to the ProductCatalog table.\n\nBook book1 = new Book();\nbook1.setId(901);\nbook1.setProductCategory(\"Book\");\nbook1.setTitle(\"Book 901 Title\");\n\nBook book2 = new Book();\nbook2.setId(902);\nbook2.setProductCategory(\"Book\");\nbook2.setTitle(\"Book 902 Title\");\n\nmapper.batchSave(Arrays.asList(book1, book2));\nbatchLoad\n\nRetrieves multiple items from one or more tables using their primary keys.\n\nThe following Java code retrieves two items from two different tables.\n\nArrayList<Object> itemsToGet = new ArrayList<Object>();\n\nForumItem forumItem = new ForumItem();\nforumItem.setForumName(\"Amazon DynamoDB\");\nitemsToGet.add(forumItem);\n\nThreadItem threadItem = new ThreadItem();\nthreadItem.setForumName(\"Amazon DynamoDB\");\nthreadItem.setSubject(\"Amazon DynamoDB thread 1 message text\");\nitemsToGet.add(threadItem);\n\nMap<String, List<Object>> items = mapper.batchLoad(itemsToGet);\nbatchDelete\n\nDeletes objects from one or more tables using one or more calls to the AmazonDynamoDB.batchWriteItem method. This method does not provide transaction guarantees.\n\nThe following Java code deletes two items (books) from the ProductCatalog table.\n\nBook book1 = mapper.load(Book.class, 901);\nBook book2 = mapper.load(Book.class, 902);\nmapper.batchDelete(Arrays.asList(book1, book2));\nbatchWrite\n\nSaves objects to and deletes objects from one or more tables using one or more calls to the AmazonDynamoDB.batchWriteItem method. This method does not provide transaction guarantees or support versioning (conditional puts or deletes).\n\nThe following Java code writes a new item to the Forum table, writes a new item to the Thread table, and deletes an item from the ProductCatalog table.\n\n// Create a Forum item to save\nForum forumItem = new Forum();\nforumItem.setName(\"Test BatchWrite Forum\");\n\n// Create a Thread item to save\nThread threadItem = new Thread();\nthreadItem.setForumName(\"AmazonDynamoDB\");\nthreadItem.setSubject(\"My sample question\");\n\n// Load a ProductCatalog item to delete\nBook book3 = mapper.load(Book.class, 903);\n\nList<Object> objectsToWrite = Arrays.asList(forumItem, threadItem);\nList<Book> objectsToDelete = Arrays.asList(book3);\n\nmapper.batchWrite(objectsToWrite, objectsToDelete);\ntransactionWrite\n\nSaves objects to and deletes objects from one or more tables using one call to the AmazonDynamoDB.transactWriteItems method.\n\nFor a list of transaction-specific exceptions, see TransactWriteItems errors.\n\nFor more information about DynamoDB transactions and the provided atomicity, consistency, isolation, and durability (ACID) guarantees see Amazon DynamoDB Transactions.\n\nNote\n\nThis method does not support the following:\n\nDynamoDBMapperConfig.SaveBehavior.\n\nThe following Java code writes a new item to each of the Forum and Thread tables, transactionally.\n\nThread s3ForumThread = new Thread();\ns3ForumThread.setForumName(\"S3 Forum\");\ns3ForumThread.setSubject(\"Sample Subject 1\");\ns3ForumThread.setMessage(\"Sample Question 1\");\n\nForum s3Forum = new Forum();\ns3Forum.setName(\"S3 Forum\");\ns3Forum.setCategory(\"Amazon Web Services\");\ns3Forum.setThreads(1);\n\nTransactionWriteRequest transactionWriteRequest = new TransactionWriteRequest();\ntransactionWriteRequest.addPut(s3Forum);\ntransactionWriteRequest.addPut(s3ForumThread);\nmapper.transactionWrite(transactionWriteRequest);\ntransactionLoad\n\nLoads objects from one or more tables using one call to the AmazonDynamoDB.transactGetItems method.\n\nFor a list of transaction-specific exceptions, see TransactGetItems errors.\n\nFor more information about DynamoDB transactions and the provided atomicity, consistency, isolation, and durability (ACID) guarantees see Amazon DynamoDB Transactions.\n\nThe following Java code loads one item from each of the Forum and Thread tables, transactionally.\n\nForum dynamodbForum = new Forum();\ndynamodbForum.setName(\"DynamoDB Forum\");\nThread dynamodbForumThread = new Thread();\ndynamodbForumThread.setForumName(\"DynamoDB Forum\");\n\nTransactionLoadRequest transactionLoadRequest = new TransactionLoadRequest();\ntransactionLoadRequest.addLoad(dynamodbForum);\ntransactionLoadRequest.addLoad(dynamodbForumThread);\nmapper.transactionLoad(transactionLoadRequest);\ncount\n\nEvaluates the specified scan expression and returns the count of matching items. No item data is returned.\n\ngenerateCreateTableRequest\n\nParses a POJO class that represents a DynamoDB table, and returns a CreateTableRequest for that table.\n\ncreateS3Link\n\nCreates a link to an object in Amazon S3. You must specify a bucket name and a key name, which uniquely identifies the object in the bucket.\n\nTo use createS3Link, your mapper class must define getter and setter methods. The following code example illustrates this by adding a new attribute and getter/setter methods to the CatalogItem class.\n\n@DynamoDBTable(tableName=\"ProductCatalog\")\npublic class CatalogItem {\n\n    ...\n\n    public S3Link productImage;\n\n    ....\n\n    @DynamoDBAttribute(attributeName = \"ProductImage\")\n    public S3Link getProductImage() {\n            return productImage;\n    }\n\n    public void setProductImage(S3Link productImage) {\n        this.productImage = productImage;\n    }\n\n...\n}\n\nThe following Java code defines a new item to be written to the Product table. The item includes a link to a product image; the image data is uploaded to Amazon S3.\n\nCatalogItem item = new CatalogItem();\n\nitem.setId(150);\nitem.setTitle(\"Book 150 Title\");\n\nString myS3Bucket = \"myS3bucket\";\nString myS3Key = \"productImages/book_150_cover.jpg\";\nitem.setProductImage(mapper.createS3Link(myS3Bucket, myS3Key));\n\nitem.getProductImage().uploadFrom(new File(\"/file/path/book_150_cover.jpg\"));\n\nmapper.save(item);\n\nThe S3Link class provides many other methods for manipulating objects in Amazon S3. For more information, see the Javadocs for S3Link.\n\ngetS3ClientCache\n\nReturns the underlying S3ClientCache for accessing Amazon S3. An S3ClientCache is a smart Map for AmazonS3Client objects. If you have multiple clients, an S3ClientCache can help you keep the clients organized by AWS Region, and can create new Amazon S3 clients on demand."
  },
  {
    "title": "Java 1.x: DynamoDBMapper - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.html",
    "html": "Java 1.x: DynamoDBMapper\nPDF\nRSS\n\nThe AWS SDK for Java provides a DynamoDBMapper class, allowing you to map your client-side classes to Amazon DynamoDB tables. To use DynamoDBMapper, you define the relationship between items in a DynamoDB table and their corresponding object instances in your code. The DynamoDBMapper class enables you to perform various create, read, update, and delete (CRUD) operations on items, and run queries and scans against tables.\n\nTopics\nSupported data types for DynamoDB Mapper for Java\nJava Annotations for DynamoDB\nDynamoDBMapper Class\nOptional configuration settings for DynamoDBMapper\nOptimistic locking with version number\nMapping arbitrary data\nDynamoDBMapper Examples\nNote\n\nThe DynamoDBMapper class does not allow you to create, update, or delete tables. To perform those tasks, use the low-level SDK for Java interface instead. For more information, see Working with DynamoDB tables in Java.\n\nThe SDK for Java provides a set of annotation types so that you can map your classes to tables. For example, consider a ProductCatalog table that has Id as the partition key.\n\nProductCatalog(Id, ...)\n\nYou can map a class in your client application to the ProductCatalog table as shown in the following Java code. This code defines a plain old Java object (POJO) named CatalogItem, which uses annotations to map object fields to DynamoDB attribute names.\n\nExample\npackage com.amazonaws.codesamples;\n\nimport java.util.Set;\n\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBAttribute;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBHashKey;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBIgnore;\nimport com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTable;\n\n@DynamoDBTable(tableName=\"ProductCatalog\")\npublic class CatalogItem {\n\n    private Integer id;\n    private String title;\n    private String ISBN;\n    private Set<String> bookAuthors;\n    private String someProp;\n\n    @DynamoDBHashKey(attributeName=\"Id\")\n    public Integer getId() { return id; }\n    public void setId(Integer id) {this.id = id; }\n\n    @DynamoDBAttribute(attributeName=\"Title\")\n    public String getTitle() {return title; }\n    public void setTitle(String title) { this.title = title; }\n\n    @DynamoDBAttribute(attributeName=\"ISBN\")\n    public String getISBN() { return ISBN; }\n    public void setISBN(String ISBN) { this.ISBN = ISBN; }\n\n    @DynamoDBAttribute(attributeName=\"Authors\")\n    public Set<String> getBookAuthors() { return bookAuthors; }\n    public void setBookAuthors(Set<String> bookAuthors) { this.bookAuthors = bookAuthors; }\n\n    @DynamoDBIgnore\n    public String getSomeProp() { return someProp; }\n    public void setSomeProp(String someProp) { this.someProp = someProp; }\n}\n\nIn the preceding code, the @DynamoDBTable annotation maps the CatalogItem class to the ProductCatalog table. You can store individual class instances as items in the table. In the class definition, the @DynamoDBHashKey annotation maps the Id property to the primary key.\n\nBy default, the class properties map to the same name attributes in the table. The properties Title and ISBN map to the same name attributes in the table.\n\nThe @DynamoDBAttribute annotation is optional when the name of the DynamoDB attribute matches the name of the property declared in the class. When they differ, use this annotation with the attributeName parameter to specify which DynamoDB attribute this property corresponds to.\n\nIn the preceding example, the @DynamoDBAttribute annotation is added to each property to ensure that the property names match exactly with the tables created in Creating tables and loading data for code examples in DynamoDB, and to be consistent with the attribute names used in other code examples in this guide.\n\nYour class definition can have properties that don't map to any attributes in the table. You identify these properties by adding the @DynamoDBIgnore annotation. In the preceding example, the SomeProp property is marked with the @DynamoDBIgnore annotation. When you upload a CatalogItem instance to the table, your DynamoDBMapper instance does not include the SomeProp property. In addition, the mapper does not return this attribute when you retrieve an item from the table.\n\nAfter you define your mapping class, you can use DynamoDBMapper methods to write an instance of that class to a corresponding item in the Catalog table. The following code example demonstrates this technique.\n\nAmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n\nDynamoDBMapper mapper = new DynamoDBMapper(client);\n\nCatalogItem item = new CatalogItem();\nitem.setId(102);\nitem.setTitle(\"Book 102 Title\");\nitem.setISBN(\"222-2222222222\");\nitem.setBookAuthors(new HashSet<String>(Arrays.asList(\"Author 1\", \"Author 2\")));\nitem.setSomeProp(\"Test\");\n\nmapper.save(item);\n\nThe following code example shows how to retrieve the item and access some of its attributes.\n\nCatalogItem partitionKey = new CatalogItem();\n\npartitionKey.setId(102);\nDynamoDBQueryExpression<CatalogItem> queryExpression = new DynamoDBQueryExpression<CatalogItem>()\n    .withHashKeyValues(partitionKey);\n\nList<CatalogItem> itemList = mapper.query(CatalogItem.class, queryExpression);\n\nfor (int i = 0; i < itemList.size(); i++) {\n    System.out.println(itemList.get(i).getTitle());\n    System.out.println(itemList.get(i).getBookAuthors());\n}\n\nDynamoDBMapper offers an intuitive, natural way of working with DynamoDB data within Java. It also provides several built-in features, such as optimistic locking, ACID transactions, autogenerated partition key and sort key values, and object versioning."
  },
  {
    "title": "Java Annotations for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.Annotations.html",
    "html": "Java Annotations for DynamoDB\nPDF\nRSS\n\nThis section describes the annotations that are available for mapping your classes and properties to tables and attributes in Amazon DynamoDB.\n\nFor the corresponding Javadoc documentation, see Annotation Types Summary in the AWS SDK for Java API Reference.\n\nNote\n\nIn the following annotations, only DynamoDBTable and the DynamoDBHashKey are required.\n\nTopics\nDynamoDBAttribute\nDynamoDBAutoGeneratedKey\nDynamoDBAutoGeneratedTimestamp\nDynamoDBDocument\nDynamoDBHashKey\nDynamoDBIgnore\nDynamoDBIndexHashKey\nDynamoDBIndexRangeKey\nDynamoDBRangeKey\nDynamoDBTable\nDynamoDBTypeConverted\nDynamoDBTyped\nDynamoDBVersionAttribute\nDynamoDBAttribute\n\nMaps a property to a table attribute. By default, each class property maps to an item attribute with the same name. However, if the names are not the same, you can use this annotation to map a property to the attribute. In the following Java snippet, the DynamoDBAttribute maps the BookAuthors property to the Authors attribute name in the table.\n\n@DynamoDBAttribute(attributeName = \"Authors\")\npublic List<String> getBookAuthors() { return BookAuthors; }\npublic void setBookAuthors(List<String> BookAuthors) { this.BookAuthors = BookAuthors; }\n\nThe DynamoDBMapper uses Authors as the attribute name when saving the object to the table.\n\nDynamoDBAutoGeneratedKey\n\nMarks a partition key or sort key property as being autogenerated. DynamoDBMapper generates a random UUID when saving these attributes. Only String properties can be marked as autogenerated keys.\n\nThe following example demonstrates using autogenerated keys.\n\n@DynamoDBTable(tableName=\"AutoGeneratedKeysExample\")\npublic class AutoGeneratedKeys {\n    private String id;\n    private String payload;\n\n    @DynamoDBHashKey(attributeName = \"Id\")\n    @DynamoDBAutoGeneratedKey\n    public String getId() { return id; }\n    public void setId(String id) { this.id = id; }\n\n    @DynamoDBAttribute(attributeName=\"payload\")\n    public String getPayload() { return this.payload; }\n    public void setPayload(String payload) { this.payload = payload; }\n\n    public static void saveItem() {\n        AutoGeneratedKeys obj = new AutoGeneratedKeys();\n        obj.setPayload(\"abc123\");\n\n        // id field is null at this point\n        DynamoDBMapper mapper = new DynamoDBMapper(dynamoDBClient);\n        mapper.save(obj);\n\n        System.out.println(\"Object was saved with id \" + obj.getId());\n    }\n}\nDynamoDBAutoGeneratedTimestamp\n\nAutomatically generates a timestamp.\n\n@DynamoDBAutoGeneratedTimestamp(strategy=DynamoDBAutoGenerateStrategy.ALWAYS)\npublic Date getLastUpdatedDate() { return lastUpdatedDate; }\npublic void setLastUpdatedDate(Date lastUpdatedDate) { this.lastUpdatedDate = lastUpdatedDate; }\n\nOptionally, the auto-generation strategy can be defined by providing a strategy attribute. The default is ALWAYS.\n\nDynamoDBDocument\n\nIndicates that a class can be serialized as an Amazon DynamoDB document.\n\nFor example, suppose that you wanted to map a JSON document to a DynamoDB attribute of type Map (M). The following code example defines an item containing a nested attribute (Pictures) of type Map.\n\npublic class ProductCatalogItem {\n\n    private Integer id;  //partition key\n    private Pictures pictures;\n    /* ...other attributes omitted... */\n\n    @DynamoDBHashKey(attributeName=\"Id\")\n    public Integer getId() { return id;}\n    public void setId(Integer id) {this.id = id;}\n\n    @DynamoDBAttribute(attributeName=\"Pictures\")\n    public Pictures getPictures() { return pictures;}\n    public void setPictures(Pictures pictures) {this.pictures = pictures;}\n\n    // Additional properties go here.\n\n    @DynamoDBDocument\n    public static class Pictures {\n        private String frontView;\n        private String rearView;\n        private String sideView;\n\n        @DynamoDBAttribute(attributeName = \"FrontView\")\n        public String getFrontView() { return frontView; }\n        public void setFrontView(String frontView) { this.frontView = frontView; }\n\n        @DynamoDBAttribute(attributeName = \"RearView\")\n        public String getRearView() { return rearView; }\n        public void setRearView(String rearView) { this.rearView = rearView; }\n\n        @DynamoDBAttribute(attributeName = \"SideView\")\n        public String getSideView() { return sideView; }\n        public void setSideView(String sideView) { this.sideView = sideView; }\n\n     }\n}\n\n\nYou could then save a new ProductCatalog item, with Pictures, as shown in the following example.\n\nProductCatalogItem item = new ProductCatalogItem();\n\nPictures pix = new Pictures();\npix.setFrontView(\"http://example.com/products/123_front.jpg\");\npix.setRearView(\"http://example.com/products/123_rear.jpg\");\npix.setSideView(\"http://example.com/products/123_left_side.jpg\");\nitem.setPictures(pix);\n\nitem.setId(123);\n\nmapper.save(item); \n\nThe resulting ProductCatalog item would look like the following (in JSON format).\n\n{\n  \"Id\" : 123\n  \"Pictures\" : {\n    \"SideView\" : \"http://example.com/products/123_left_side.jpg\",\n    \"RearView\" : \"http://example.com/products/123_rear.jpg\",\n    \"FrontView\" : \"http://example.com/products/123_front.jpg\"\n  }\n} \nDynamoDBHashKey\n\nMaps a class property to the partition key of the table. The property must be one of the scalar string, number, or binary types. The property can't be a collection type.\n\nAssume that you have a table, ProductCatalog, that has Id as the primary key. The following Java code defines a CatalogItem class and maps its Id property to the primary key of the ProductCatalog table using the @DynamoDBHashKey tag.\n\n@DynamoDBTable(tableName=\"ProductCatalog\")\npublic class CatalogItem {\n    private Integer Id;\n   @DynamoDBHashKey(attributeName=\"Id\")\n   public Integer getId() {\n        return Id;\n   }\n   public void setId(Integer Id) {\n        this.Id = Id;\n   }\n   // Additional properties go here.\n}\nDynamoDBIgnore\n\nIndicates to the DynamoDBMapper instance that the associated property should be ignored. When saving data to the table, the DynamoDBMapper does not save this property to the table.\n\nApplied to the getter method or the class field for a non-modeled property. If the annotation is applied directly to the class field, the corresponding getter and setter must be declared in the same class.\n\nDynamoDBIndexHashKey\n\nMaps a class property to the partition key of a global secondary index. The property must be one of the scalar string, number, or binary types. The property can't be a collection type.\n\nUse this annotation if you need to Query a global secondary index. You must specify the index name (globalSecondaryIndexName). If the name of the class property is different from the index partition key, you also must specify the name of that index attribute (attributeName).\n\nDynamoDBIndexRangeKey\n\nMaps a class property to the sort key of a global secondary index or a local secondary index. The property must be one of the scalar string, number, or binary types. The property can't be a collection type.\n\nUse this annotation if you need to Query a local secondary index or a global secondary index and want to refine your results using the index sort key. You must specify the index name (either globalSecondaryIndexName or localSecondaryIndexName). If the name of the class property is different from the index sort key, you must also specify the name of that index attribute (attributeName).\n\nDynamoDBRangeKey\n\nMaps a class property to the sort key of the table. The property must be one of the scalar string, number, or binary types. It cannot be a collection type.\n\nIf the primary key is composite (partition key and sort key), you can use this tag to map your class field to the sort key. For example, assume that you have a Reply table that stores replies for forum threads. Each thread can have many replies. So the primary key of this table is both the ThreadId and ReplyDateTime. The ThreadId is the partition key, and ReplyDateTime is the sort key.\n\nThe following Java code defines a Reply class and maps it to the Reply table. It uses both the @DynamoDBHashKey and @DynamoDBRangeKey tags to identify class properties that map to the primary key.\n\n@DynamoDBTable(tableName=\"Reply\")\npublic class Reply {\n    private Integer id;\n    private String replyDateTime;\n\n    @DynamoDBHashKey(attributeName=\"Id\")\n    public Integer getId() { return id; }\n    public void setId(Integer id) { this.id = id; }\n\n    @DynamoDBRangeKey(attributeName=\"ReplyDateTime\")\n    public String getReplyDateTime() { return replyDateTime; }\n    public void setReplyDateTime(String replyDateTime) { this.replyDateTime = replyDateTime; }\n\n   // Additional properties go here.\n}\nDynamoDBTable\n\nIdentifies the target table in DynamoDB. For example, the following Java code defines a class Developer and maps it to the People table in DynamoDB.\n\n@DynamoDBTable(tableName=\"People\")\npublic class Developer { ...} \n\nThe @DynamoDBTable annotation can be inherited. Any new class that inherits from the Developer class also maps to the People table. For example, assume that you create a Lead class that inherits from the Developer class. Because you mapped the Developer class to the People table, the Lead class objects are also stored in the same table.\n\nThe @DynamoDBTable can also be overridden. Any new class that inherits from the Developer class by default maps to the same People table. However, you can override this default mapping. For example, if you create a class that inherits from the Developer class, you can explicitly map it to another table by adding the @DynamoDBTable annotation as shown in the following Java code example.\n\n@DynamoDBTable(tableName=\"Managers\")\npublic class Manager extends Developer { ...} \nDynamoDBTypeConverted\n\nAn annotation to mark a property as using a custom type converter. Can be annotated on a user-defined annotation to pass additional properties to the DynamoDBTypeConverter.\n\nThe DynamoDBTypeConverter interface lets you map your own arbitrary data types to a data type that is natively supported by DynamoDB. For more information, see Mapping arbitrary data.\n\nDynamoDBTyped\n\nAn annotation to override the standard attribute type binding. Standard types do not require the annotation if applying the default attribute binding for that type.\n\nDynamoDBVersionAttribute\n\nIdentifies a class property for storing an optimistic locking version number. DynamoDBMapper assigns a version number to this property when it saves a new item, and increments it each time you update the item. Only number scalar types are supported. For more information about data types, see Data types. For more information about versioning, see Optimistic locking with version number."
  },
  {
    "title": "Supported data types for DynamoDB Mapper for Java - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.DataTypes.html",
    "html": "Supported data types for DynamoDB Mapper for Java\nPDF\nRSS\n\nThis section describes the supported primitive Java data types, collections, and arbitrary data types in Amazon DynamoDB.\n\nAmazon DynamoDB supports the following primitive Java data types and primitive wrapper classes.\n\nString\n\nBoolean, boolean\n\nByte, byte\n\nDate (as ISO_8601 millisecond-precision string, shifted to UTC)\n\nCalendar (as ISO_8601 millisecond-precision string, shifted to UTC)\n\nLong, long\n\nInteger, int\n\nDouble, double\n\nFloat, float\n\nBigDecimal\n\nBigInteger\n\nNote\n\nFor more information about DynamoDB naming rules and the various supported data types, see Supported data types and naming rules in Amazon DynamoDB.\n\nEmpty Binary values are supported by the DynamoDBMapper.\n\nEmpty String values are supported by AWS SDK for Java 2.x.\n\nIn AWS SDK for Java 1.x, DynamoDBMapper supports reading of empty String attribute values, however, it will not write empty String attribute values because these attributes are dropped from the request.\n\nDynamoDB supports the Java Set, List, and Map collection types. The following table summarizes how these Java types map to the DynamoDB types.\n\nJava type\tDynamoDB type\n\n\nAll number types\n\n\t\n\nN (number type)\n\n\n\n\nStrings\n\n\t\n\nS (string type)\n\n\nBoolean\tBOOL (Boolean type), 0 or 1.\nByteBuffer\tB (binary type)\nDate\tS (string type). The Date values are stored as ISO-8601 formatted strings.\nSet collection types\tSS (string set) type, NS (number set) type, or BS (binary set) type.\n\nThe DynamoDBTypeConverter interface lets you map your own arbitrary data types to a data type that is natively supported by DynamoDB. For more information, see Mapping arbitrary data."
  },
  {
    "title": "Higher-level programming interfaces for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HigherLevelInterfaces.html",
    "html": "Higher-level programming interfaces for DynamoDB\nPDF\nRSS\n\nThe AWS SDKs provide applications with low-level interfaces for working with Amazon DynamoDB. These client-side classes and methods correspond directly to the low-level DynamoDB API. However, many developers experience a sense of disconnect, or impedance mismatch, when they need to map complex data types to items in a database table. With a low-level database interface, developers must write methods for reading or writing object data to database tables, and vice versa. The amount of extra code required for each combination of object type and database table can seem overwhelming.\n\nTo simplify development, the AWS SDKs for Java and .NET provide additional interfaces with higher levels of abstraction. The higher-level interfaces for DynamoDB let you define the relationships between objects in your program and the database tables that store those objects' data. After you define this mapping, you call simple object methods such as save, load, or delete, and the underlying low-level DynamoDB operations are automatically invoked on your behalf. This allows you to write object-centric code, rather than database-centric code.\n\nThe higher-level programming interfaces for DynamoDB are available in the AWS SDKs for Java and .NET.\n\nJava\n\nJava 1.x: DynamoDBMapper\n\nJava 2.x: DynamoDB Enhanced Client\n\n.NET\n\n.NET: Document model\n\n.NET: Object persistence model"
  },
  {
    "title": "Error handling with DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html",
    "html": "Error handling with DynamoDB\nPDF\nRSS\n\nThis section describes runtime errors and how to handle them. It also describes error messages and codes that are specific to Amazon DynamoDB. For a list of common errors that apply to all AWS services, see Access Management\n\nTopics\nError components\nTransactional errors\nError messages and codes\nError handling in your application\nError retries and exponential backoff\nBatch operations and error handling\nError components\n\nWhen your program sends a request, DynamoDB attempts to process it. If the request is successful, DynamoDB returns an HTTP success status code (200 OK), along with the results from the requested operation.\n\nIf the request is unsuccessful, DynamoDB returns an error. Each error has three components:\n\nAn HTTP status code (such as 400).\n\nAn exception name (such as ResourceNotFoundException).\n\nAn error message (such as Requested resource not found: Table: tablename not found).\n\nThe AWS SDKs take care of propagating errors to your application so that you can take appropriate action. For example, in a Java program, you can write try-catch logic to handle a ResourceNotFoundException.\n\nIf you are not using an AWS SDK, you need to parse the content of the low-level response from DynamoDB. The following is an example of such a response.\n\nHTTP/1.1 400 Bad Request\nx-amzn-RequestId: LDM6CJP8RMQ1FHKSC1RBVJFPNVV4KQNSO5AEMF66Q9ASUAAJG\nContent-Type: application/x-amz-json-1.0\nContent-Length: 240\nDate: Thu, 15 Mar 2012 23:56:23 GMT\n\n{\"__type\":\"com.amazonaws.dynamodb.v20120810#ResourceNotFoundException\",\n\"message\":\"Requested resource not found: Table: tablename not found\"}\nTransactional errors\n\nFor information on transactional errors, please see Transaction conflict handling in DynamoDB\n\nError messages and codes\n\nThe following is a list of exceptions returned by DynamoDB, grouped by HTTP status code. If OK to retry? is Yes, you can submit the same request again. If OK to retry? is No, you need to fix the problem on the client side before you submit a new request.\n\nHTTP status code 400\n\nAn HTTP 400 status code indicates a problem with your request, such as authentication failure, missing required parameters, or exceeding a table's provisioned throughput. You have to fix the issue in your application before submitting the request again.\n\nAccessDeniedException\n\nMessage: Access denied.\n\nThe client did not correctly sign the request. If you are using an AWS SDK, requests are signed for you automatically; otherwise, go to the Signature version 4 signing process in the AWS General Reference.\n\nOK to retry? No\n\nConditionalCheckFailedException\n\nMessage: The conditional request failed.\n\nYou specified a condition that evaluated to false. For example, you might have tried to perform a conditional update on an item, but the actual value of the attribute did not match the expected value in the condition.\n\nOK to retry? No\n\nIncompleteSignatureException\n\nMessage: The request signature does not conform to AWS standards.\n\nThe request signature did not include all of the required components. If you are using an AWS SDK, requests are signed for you automatically; otherwise, go to the Signature Version 4 signing process in the AWS General Reference.\n\nOK to retry? No\n\nItemCollectionSizeLimitExceededException\n\nMessage: Collection size exceeded.\n\nFor a table with a local secondary index, a group of items with the same partition key value has exceeded the maximum size limit of 10 GB. For more information on item collections, see Item collections in Local Secondary Indexes.\n\nOK to retry? Yes\n\nLimitExceededException\n\nMessage: Too many operations for a given subscriber.\n\nThere are too many concurrent control plane operations. The cumulative number of tables and indexes in the CREATING, DELETING, or UPDATING state cannot exceed 500.\n\nOK to retry? Yes\n\nMissingAuthenticationTokenException\n\nMessage: Request must contain a valid (registered) AWS Access Key ID.\n\nThe request did not include the required authorization header, or it was malformed. See DynamoDB low-level API.\n\nOK to retry? No\n\nProvisionedThroughputExceededException\n\nMessage: You exceeded your maximum allowed provisioned throughput for a table or for one or more global secondary indexes. To view performance metrics for provisioned throughput vs. consumed throughput, open the Amazon CloudWatch console.\n\nExample: Your request rate is too high. The AWS SDKs for DynamoDB automatically retry requests that receive this exception. Your request is eventually successful, unless your retry queue is too large to finish. Reduce the frequency of requests using Error retries and exponential backoff.\n\nOK to retry? Yes\n\nRequestLimitExceeded\n\nMessage: Throughput exceeds the current throughput limit for your account. To request a limit increase, contact AWS Support at https://aws.amazon.com/support.\n\nExample: Rate of on-demand requests exceeds the allowed account throughput and the table cannot be scaled further.\n\nOK to retry? Yes\n\nResourceInUseException\n\nMessage: The resource which you are attempting to change is in use.\n\nExample: You tried to re-create an existing table, or delete a table currently in the CREATING state.\n\nOK to retry? No\n\nResourceNotFoundException\n\nMessage: Requested resource not found.\n\nExample: The table that is being requested does not exist, or is too early in the CREATING state.\n\nOK to retry? No\n\nThrottlingException\n\nMessage: Rate of requests exceeds the allowed throughput.\n\nThis exception is returned as an AmazonServiceException response with a THROTTLING_EXCEPTION status code. This exception might be returned if you perform control plane API operations too rapidly.\n\nFor tables using on-demand mode, this exception might be returned for any data plane API operation if your request rate is too high. To learn more about on-demand scaling, see Initial throughput and scaling properties.\n\nOK to retry? Yes\n\nUnrecognizedClientException\n\nMessage: The Access Key ID or security token is invalid.\n\nThe request signature is incorrect. The most likely cause is an invalid AWS access key ID or secret key.\n\nOK to retry? Yes\n\nValidationException\n\nMessage: Varies, depending upon the specific error(s) encountered\n\nThis error can occur for several reasons, such as a required parameter that is missing, a value that is out of range, or mismatched data types. The error message contains details about the specific part of the request that caused the error.\n\nOK to retry? No\n\nHTTP status code 5xx\n\nAn HTTP 5xx status code indicates a problem that must be resolved by AWS. This might be a transient error, in which case you can retry your request until it succeeds. Otherwise, go to the AWS Service Health Dashboard to see if there are any operational issues with the service.\n\nFor more information, see How do I resolve HTTP 5xx errors in Amazon DynamoDB?\n\nInternalServerError (HTTP 500)\n\nDynamoDB could not process your request.\n\nOK to retry? Yes\n\nNote\n\nYou might encounter internal server errors while working with items. These are expected during the lifetime of a table. Any failed requests can be retried immediately.\n\nWhen you receive a status code 500 on a write operation, the operation may have succeeded or failed. If the write operation is a TransactWriteItem request, then it is OK to retry the operation. If the write operation is a single-item write request such as PutItem, UpdateItem, or DeleteItem, then your application should read the state of the item before retrying the operation, and/or use Condition expressions to ensure that the item remains in a correct state after retrying regardless of whether the prior operation succeeded or failed. If idempotency is a requirement for the write operation, please use TransactWriteItem, which supports idempotent requests by automatically specifying a ClientRequestToken to disambiguate multiple attempts to perform the same action.\n\nServiceUnavailable (HTTP 503)\n\nDynamoDB is currently unavailable. (This should be a temporary state.)\n\nOK to retry? Yes\n\nError handling in your application\n\nFor your application to run smoothly, you need to add logic to catch and respond to errors. Typical approaches include using try-catch blocks or if-then statements.\n\nThe AWS SDKs perform their own retries and error checking. If you encounter an error while using one of the AWS SDKs, the error code and description can help you troubleshoot it.\n\nYou should also see a Request ID in the response. The Request ID can be helpful if you need to work with AWS Support to diagnose an issue.\n\nError retries and exponential backoff\n\nNumerous components on a network, such as DNS servers, switches, load balancers, and others, can generate errors anywhere in the life of a given request. The usual technique for dealing with these error responses in a networked environment is to implement retries in the client application. This technique increases the reliability of the application.\n\nEach AWS SDK implements retry logic automatically. You can modify the retry parameters to your needs. For example, consider a Java application that requires a fail-fast strategy, with no retries allowed in case of an error. With the AWS SDK for Java, you could use the ClientConfiguration class and provide a maxErrorRetry value of 0 to turn off the retries. For more information, see the AWS SDK documentation for your programming language.\n\nIf you're not using an AWS SDK, you should retry original requests that receive server errors (5xx). However, client errors (4xx, other than a ThrottlingException or a ProvisionedThroughputExceededException) indicate that you need to revise the request itself to correct the problem before trying again.\n\nIn addition to simple retries, each AWS SDK implements an exponential backoff algorithm for better flow control. The concept behind exponential backoff is to use progressively longer waits between retries for consecutive error responses. For example, up to 50 milliseconds before the first retry, up to 100 milliseconds before the second, up to 200 milliseconds before third, and so on. However, after a minute, if the request has not succeeded, the problem might be the request size exceeding your provisioned throughput, and not the request rate. Set the maximum number of retries to stop around one minute. If the request is not successful, investigate your provisioned throughput options.\n\nNote\n\nThe AWS SDKs implement automatic retry logic and exponential backoff.\n\nMost exponential backoff algorithms use jitter (randomized delay) to prevent successive collisions. Because you aren't trying to avoid such collisions in these cases, you do not need to use this random number. However, if you use concurrent clients, jitter can help your requests succeed faster. For more information, see the blog post about Exponential backoff and jitter.\n\nBatch operations and error handling\n\nThe DynamoDB low-level API supports batch operations for reads and writes. BatchGetItem reads items from one or more tables, and BatchWriteItem puts or deletes items in one or more tables. These batch operations are implemented as wrappers around other non-batch DynamoDB operations. In other words, BatchGetItem invokes GetItem once for each item in the batch. Similarly,BatchWriteItem invokes DeleteItem or PutItem, as appropriate, for each item in the batch.\n\nA batch operation can tolerate the failure of individual requests in the batch. For example, consider a BatchGetItem request to read five items. Even if some of the underlying GetItem requests fail, this does not cause the entire BatchGetItem operation to fail. However, if all five read operations fail, then the entire BatchGetItem fails.\n\nThe batch operations return information about individual requests that fail so that you can diagnose the problem and retry the operation. For BatchGetItem, the tables and primary keys in question are returned in the UnprocessedKeys value of the response. For BatchWriteItem, similar information is returned in UnprocessedItems.\n\nThe most likely cause of a failed read or a failed write is throttling. For BatchGetItem, one or more of the tables in the batch request does not have enough provisioned read capacity to support the operation. For BatchWriteItem, one or more of the tables does not have enough provisioned write capacity.\n\nIf DynamoDB returns any unprocessed items, you should retry the batch operation on those items. However, we strongly recommend that you use an exponential backoff algorithm. If you retry the batch operation immediately, the underlying read or write requests can still fail due to throttling on the individual tables. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed."
  },
  {
    "title": "DynamoDB low-level API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.LowLevelAPI.html",
    "html": "DynamoDB low-level API\nPDF\nRSS\n\nThe Amazon DynamoDB low-level API is the protocol-level interface for DynamoDB. At this level, every HTTP(S) request must be correctly formatted and carry a valid digital signature.\n\nThe AWS SDKs construct low-level DynamoDB API requests on your behalf and process the responses from DynamoDB. This lets you focus on your application logic, instead of low-level details. However, you can still benefit from a basic knowledge of how the low-level DynamoDB API works.\n\nFor more information about the low-level DynamoDB API, see Amazon DynamoDB API Reference.\n\nNote\n\nDynamoDB Streams has its own low-level API, which is separate from that of DynamoDB and is fully supported by the AWS SDKs.\n\nFor more information, see Change data capture for DynamoDB Streams. For the low-level DynamoDB Streams API, see the Amazon DynamoDB Streams API Reference.\n\nThe low-level DynamoDB API uses JavaScript Object Notation (JSON) as a wire protocol format. JSON presents data in a hierarchy so that both data values and data structure are conveyed simultaneously. Name-value pairs are defined in the format name:value. The data hierarchy is defined by nested brackets of name-value pairs.\n\nDynamoDB uses JSON only as a transport protocol, not as a storage format. The AWS SDKs use JSON to send data to DynamoDB, and DynamoDB responds with JSON. DynamoDB does not store data persistently in JSON format.\n\nNote\n\nFor more information about JSON, see Introducing JSON on the JSON.org website.\n\nTopics\nRequest format\nResponse format\nData type descriptors\nNumeric data\nBinary data\nRequest format\n\nThe DynamoDB low-level API accepts HTTP(S) POST requests as input. The AWS SDKs construct these requests for you.\n\nSuppose that you have a table named Pets, with a key schema consisting of AnimalType (partition key) and Name (sort key). Both of these attributes are of type string. To retrieve an item from Pets, the AWS SDK constructs the following request.\n\nPOST / HTTP/1.1\nHost: dynamodb.<region>.<domain>;\nAccept-Encoding: identity\nContent-Length: <PayloadSizeBytes>\nUser-Agent: <UserAgentString>\nContent-Type: application/x-amz-json-1.0\nAuthorization: AWS4-HMAC-SHA256 Credential=<Credential>, SignedHeaders=<Headers>, Signature=<Signature>\nX-Amz-Date: <Date> \nX-Amz-Target: DynamoDB_20120810.GetItem\n\n{\n    \"TableName\": \"Pets\",\n    \"Key\": {\n        \"AnimalType\": {\"S\": \"Dog\"},\n        \"Name\": {\"S\": \"Fido\"}\n    }\n}\n\nNote the following about this request:\n\nThe Authorization header contains information required for DynamoDB to authenticate the request. For more information, see Signing AWS API requests and Signature Version 4 signing process in the Amazon Web Services General Reference.\n\nThe X-Amz-Target header contains the name of a DynamoDB operation: GetItem. (This is also accompanied by the low-level API version, in this case 20120810.)\n\nThe payload (body) of the request contains the parameters for the operation, in JSON format. For the GetItem operation, the parameters are TableName and Key.\n\nResponse format\n\nUpon receipt of the request, DynamoDB processes it and returns a response. For the request shown previously, the HTTP(S) response payload contains the results from the operation, as shown in the following example.\n\nHTTP/1.1 200 OK\nx-amzn-RequestId: <RequestId>\nx-amz-crc32: <Checksum>\nContent-Type: application/x-amz-json-1.0\nContent-Length: <PayloadSizeBytes>\nDate: <Date>\n{\n    \"Item\": {\n        \"Age\": {\"N\": \"8\"},\n        \"Colors\": {\n            \"L\": [\n                {\"S\": \"White\"},\n                {\"S\": \"Brown\"},\n                {\"S\": \"Black\"}\n            ]\n        },\n        \"Name\": {\"S\": \"Fido\"},\n        \"Vaccinations\": {\n            \"M\": {\n                \"Rabies\": {\n                    \"L\": [\n                        {\"S\": \"2009-03-17\"},\n                        {\"S\": \"2011-09-21\"},\n                        {\"S\": \"2014-07-08\"}\n                    ]\n                },\n                \"Distemper\": {\"S\": \"2015-10-13\"}\n            }\n        },\n        \"Breed\": {\"S\": \"Beagle\"},\n        \"AnimalType\": {\"S\": \"Dog\"}\n    }\n}\n\n\nAt this point, the AWS SDK returns the response data to your application for further processing.\n\nNote\n\nIf DynamoDB can't process a request, it returns an HTTP error code and message. The AWS SDK propagates these to your application in the form of exceptions. For more information, see Error handling with DynamoDB.\n\nData type descriptors\n\nThe low-level DynamoDB API protocol requires each attribute to be accompanied by a data type descriptor. Data type descriptors are tokens that tell DynamoDB how to interpret each attribute.\n\nThe examples in Request format and Response format show examples of how data type descriptors are used. The GetItem request specifies S for the Pets key schema attributes (AnimalType and Name), which are of type string. The GetItem response contains a Pets item with attributes of type string (S), number (N), map (M), and list (L).\n\nThe following is a complete list of DynamoDB data type descriptors:\n\nS – String\n\nN – Number\n\nB – Binary\n\nBOOL – Boolean\n\nNULL – Null\n\nM – Map\n\nL – List\n\nSS – String Set\n\nNS – Number Set\n\nBS – Binary Set\n\nNote\n\nFor detailed descriptions of DynamoDB data types, see Data types.\n\nNumeric data\n\nDifferent programming languages offer different levels of support for JSON. In some cases, you might decide to use a third-party library for validating and parsing JSON documents.\n\nSome third-party libraries build upon the JSON number type, providing their own types such as int, long, or double. However, the native number data type in DynamoDB does not map exactly to these other data types, so these type distinctions can cause conflicts. In addition, many JSON libraries do not handle fixed-precision numeric values, and they automatically infer a double data type for digit sequences that contain a decimal point.\n\nTo solve these problems, DynamoDB provides a single numeric type with no data loss. To avoid unwanted implicit conversions to a double value, DynamoDB uses strings for the data transfer of numeric values. This approach provides flexibility for updating attribute values while maintaining proper sorting semantics, such as putting the values \"01\", \"2\", and \"03\" in the proper sequence.\n\nIf number precision is important to your application, you should convert numeric values to strings before you pass them to DynamoDB.\n\nBinary data\n\nDynamoDB supports binary attributes. However, JSON does not natively support encoding binary data. To send binary data in a request, you will need to encode it in base64 format. Upon receiving the request, DynamoDB decodes the base64 data back to binary.\n\nThe base64 encoding scheme used by DynamoDB is described at RFC 4648 on the Internet Engineering Task Force (IETF) website."
  },
  {
    "title": "Document interfaces - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.SDKs.Interfaces.Document.html",
    "html": "Document interfaces\nPDF\nRSS\n\nMany AWS SDKs provide a document interface, allowing you to perform data plane operations (create, read, update, delete) on tables and indexes. With a document interface, you do not need to specify Data type descriptors. The data types are implied by the semantics of the data itself. These AWS SDKs also provide methods to easily convert JSON documents to and from native Amazon DynamoDB data types.\n\nNote\n\nDocument interfaces are available in the AWS SDKs for Java, .NET, Node.js, and JavaScript in the browser.\n\nThe following Java program uses the document interface of the AWS SDK for Java. The program creates a Table object that represents the Music table, and then asks that object to use GetItem to retrieve a song. The program then prints the year that the song was released.\n\nThe com.amazonaws.services.dynamodbv2.document.DynamoDB class implements the DynamoDB document interface. Note how DynamoDB acts as a wrapper around the low-level client (AmazonDynamoDB).\n\npackage com.amazonaws.codesamples.gsg;\n\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDB;\nimport com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;\nimport com.amazonaws.services.dynamodbv2.document.DynamoDB;\nimport com.amazonaws.services.dynamodbv2.document.GetItemOutcome;\nimport com.amazonaws.services.dynamodbv2.document.Table;\n\npublic class MusicDocumentDemo {\n\n    public static void main(String[] args) {\n\n        AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();\n        DynamoDB docClient = new DynamoDB(client);\n\n        Table table = docClient.getTable(\"Music\");\n        GetItemOutcome outcome = table.getItemOutcome(\n                \"Artist\", \"No One You Know\",\n                \"SongTitle\", \"Call Me Today\");\n\n        int year = outcome.getItem().getInt(\"Year\");\n        System.out.println(\"The song was released in \" + year);\n\n    }\n}\n"
  },
  {
    "title": "Low-level interfaces - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.SDKs.Interfaces.LowLevel.html",
    "html": "Low-level interfaces\nPDF\nRSS\n\nEvery language-specific AWS SDK provides a low-level interface for Amazon DynamoDB, with methods that closely resemble low-level DynamoDB API requests.\n\nIn some cases, you will need to identify the data types of the attributes using Data type descriptors, such as S for string or N for number.\n\nNote\n\nA low-level interface is available in every language-specific AWS SDK.\n\nThe following Java program uses the low-level interface of the AWS SDK for Java.\n\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.dynamodb.model.DynamoDbException;\nimport software.amazon.awssdk.services.dynamodb.DynamoDbClient;\nimport software.amazon.awssdk.services.dynamodb.model.AttributeValue;\nimport software.amazon.awssdk.services.dynamodb.model.GetItemRequest;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Set;\n\n/**\n * Before running this Java V2 code example, set up your development\n * environment, including your credentials.\n *\n * For more information, see the following documentation topic:\n *\n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-started.html\n *\n * To get an item from an Amazon DynamoDB table using the AWS SDK for Java V2,\n * its better practice to use the\n * Enhanced Client, see the EnhancedGetItem example.\n */\npublic class GetItem {\n    public static void main(String[] args) {\n        final String usage = \"\"\"\n\n                Usage:\n                    <tableName> <key> <keyVal>\n\n                Where:\n                    tableName - The Amazon DynamoDB table from which an item is retrieved (for example, Music3).\\s\n                    key - The key used in the Amazon DynamoDB table (for example, Artist).\\s\n                    keyval - The key value that represents the item to get (for example, Famous Band).\n                \"\"\";\n\n        if (args.length != 3) {\n            System.out.println(usage);\n            System.exit(1);\n        }\n\n        String tableName = args[0];\n        String key = args[1];\n        String keyVal = args[2];\n        System.out.format(\"Retrieving item \\\"%s\\\" from \\\"%s\\\"\\n\", keyVal, tableName);\n        Region region = Region.US_EAST_1;\n        DynamoDbClient ddb = DynamoDbClient.builder()\n                .region(region)\n                .build();\n\n        getDynamoDBItem(ddb, tableName, key, keyVal);\n        ddb.close();\n    }\n\n    public static void getDynamoDBItem(DynamoDbClient ddb, String tableName, String key, String keyVal) {\n        HashMap<String, AttributeValue> keyToGet = new HashMap<>();\n        keyToGet.put(key, AttributeValue.builder()\n                .s(keyVal)\n                .build());\n\n        GetItemRequest request = GetItemRequest.builder()\n                .key(keyToGet)\n                .tableName(tableName)\n                .build();\n\n        try {\n            // If there is no matching item, GetItem does not return any data.\n            Map<String, AttributeValue> returnedItem = ddb.getItem(request).item();\n            if (returnedItem.isEmpty())\n                System.out.format(\"No item found with the key %s!\\n\", key);\n            else {\n                Set<String> keys = returnedItem.keySet();\n                System.out.println(\"Amazon DynamoDB table attributes: \\n\");\n                for (String key1 : keys) {\n                    System.out.format(\"%s: %s\\n\", key1, returnedItem.get(key1).toString());\n                }\n            }\n\n        } catch (DynamoDbException e) {\n            System.err.println(e.getMessage());\n            System.exit(1);\n        }\n    }\n}\n"
  },
  {
    "title": "Using DynamoDB with an AWS SDK - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/sdk-general-information-section.html",
    "html": "Using DynamoDB with an AWS SDK\nPDF\nRSS\n\nAWS software development kits (SDKs) are available for many popular programming languages. Each SDK provides an API, code examples, and documentation that make it easier for developers to build applications in their preferred language.\n\nSDK documentation\tCode examples\n\n\nAWS SDK for C++\n\n\t\n\nAWS SDK for C++ code examples\n\n\n\n\nAWS CLI\n\n\t\n\nAWS CLI code examples\n\n\n\n\nAWS SDK for Go\n\n\t\n\nAWS SDK for Go code examples\n\n\n\n\nAWS SDK for Java\n\n\t\n\nAWS SDK for Java code examples\n\n\n\n\nAWS SDK for JavaScript\n\n\t\n\nAWS SDK for JavaScript code examples\n\n\n\n\nAWS SDK for Kotlin\n\n\t\n\nAWS SDK for Kotlin code examples\n\n\n\n\nAWS SDK for .NET\n\n\t\n\nAWS SDK for .NET code examples\n\n\n\n\nAWS SDK for PHP\n\n\t\n\nAWS SDK for PHP code examples\n\n\n\n\nAWS Tools for PowerShell\n\n\t\n\nTools for PowerShell code examples\n\n\n\n\nAWS SDK for Python (Boto3)\n\n\t\n\nAWS SDK for Python (Boto3) code examples\n\n\n\n\nAWS SDK for Ruby\n\n\t\n\nAWS SDK for Ruby code examples\n\n\n\n\nAWS SDK for Rust\n\n\t\n\nAWS SDK for Rust code examples\n\n\n\n\nAWS SDK for SAP ABAP\n\n\t\n\nAWS SDK for SAP ABAP code examples\n\n\n\n\nAWS SDK for Swift\n\n\t\n\nAWS SDK for Swift code examples\n\nFor examples specific to DynamoDB, see Code examples for DynamoDB using AWS SDKs.\n\nExample availability\n\nCan't find what you need? Request a code example by using the Provide feedback link at the bottom of this page."
  },
  {
    "title": "Scan a DynamoDB table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.Scan.html",
    "html": "Scan a DynamoDB table\nPDF\nRSS\n\nYou can perform a scan on a DynamoDB table using the AWS Management Console, the AWS CLI, or an AWS SDK. For more information on scans, see Working with scans in DynamoDB.\n\nScan a DynamoDB table using an AWS SDK\n\nThe following code examples show how to scan a DynamoDB table using an AWS SDK.\n\n.NET\nBash\nC++\nCLI\nGo\nJava\nJavaScript\nKotlin\nPHP\nPowerShell\nPython\nRuby\nRust\nSAP ABAP\nSwift\nAWS SDK for .NET\nNote\n\nThere's more on GitHub. Find the complete example and learn how to set up and run in the AWS Code Examples Repository.\n\n        public static async Task<int> ScanTableAsync(\n            AmazonDynamoDBClient client,\n            string tableName,\n            int startYear,\n            int endYear)\n        {\n            var request = new ScanRequest\n            {\n                TableName = tableName,\n                ExpressionAttributeNames = new Dictionary<string, string>\n                {\n                  { \"#yr\", \"year\" },\n                },\n                ExpressionAttributeValues = new Dictionary<string, AttributeValue>\n                {\n                    { \":y_a\", new AttributeValue { N = startYear.ToString() } },\n                    { \":y_z\", new AttributeValue { N = endYear.ToString() } },\n                },\n                FilterExpression = \"#yr between :y_a and :y_z\",\n                ProjectionExpression = \"#yr, title, info.actors[0], info.directors, info.running_time_secs\",\n                Limit = 10 // Set a limit to demonstrate using the LastEvaluatedKey.\n            };\n\n            // Keep track of how many movies were found.\n            int foundCount = 0;\n\n            var response = new ScanResponse();\n            do\n            {\n                response = await client.ScanAsync(request);\n                foundCount += response.Items.Count;\n                response.Items.ForEach(i => DisplayItem(i));\n                request.ExclusiveStartKey = response.LastEvaluatedKey;\n            }\n            while (response.LastEvaluatedKey.Count > 0);\n            return foundCount;\n        }\n\n\n\n\nFor API details, see Scan in AWS SDK for .NET API Reference.\n\nFor more DynamoDB examples, see Code examples for DynamoDB using AWS SDKs."
  },
  {
    "title": "Query a DynamoDB table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.Query.html",
    "html": "Query a DynamoDB table\nPDF\nRSS\n\nYou can perform a query on a DynamoDB table using the AWS Management Console, the AWS CLI, or an AWS SDK. For more information on queries, see Query operations in DynamoDB.\n\nQuery a DynamoDB table using an AWS SDK\n\nThe following code examples show how to query a DynamoDB table using an AWS SDK.\n\n.NET\nBash\nC++\nCLI\nGo\nJava\nJavaScript\nKotlin\nPHP\nPowerShell\nPython\nRuby\nRust\nSAP ABAP\nSwift\nAWS SDK for .NET\nNote\n\nThere's more on GitHub. Find the complete example and learn how to set up and run in the AWS Code Examples Repository.\n\n\n        /// <summary>\n        /// Queries the table for movies released in a particular year and\n        /// then displays the information for the movies returned.\n        /// </summary>\n        /// <param name=\"client\">The initialized DynamoDB client object.</param>\n        /// <param name=\"tableName\">The name of the table to query.</param>\n        /// <param name=\"year\">The release year for which we want to\n        /// view movies.</param>\n        /// <returns>The number of movies that match the query.</returns>\n        public static async Task<int> QueryMoviesAsync(AmazonDynamoDBClient client, string tableName, int year)\n        {\n            var movieTable = Table.LoadTable(client, tableName);\n            var filter = new QueryFilter(\"year\", QueryOperator.Equal, year);\n\n            Console.WriteLine(\"\\nFind movies released in: {year}:\");\n\n            var config = new QueryOperationConfig()\n            {\n                Limit = 10, // 10 items per page.\n                Select = SelectValues.SpecificAttributes,\n                AttributesToGet = new List<string>\n                {\n                  \"title\",\n                  \"year\",\n                },\n                ConsistentRead = true,\n                Filter = filter,\n            };\n\n            // Value used to track how many movies match the\n            // supplied criteria.\n            var moviesFound = 0;\n\n            Search search = movieTable.Query(config);\n            do\n            {\n                var movieList = await search.GetNextSetAsync();\n                moviesFound += movieList.Count;\n\n                foreach (var movie in movieList)\n                {\n                    DisplayDocument(movie);\n                }\n            }\n            while (!search.IsDone);\n\n            return moviesFound;\n        }\n\n\n\n\nFor API details, see Query in AWS SDK for .NET API Reference.\n\nFor more DynamoDB examples, see Code examples for DynamoDB using AWS SDKs."
  },
  {
    "title": "Delete an item in a DynamoDB table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.DeleteItem.html",
    "html": "Delete an item in a DynamoDB table\nPDF\nRSS\n\nYou can delete items from DynamoDB tables using the AWS Management Console, the AWS CLI, or an AWS SDK. For more information on items, see Core components of Amazon DynamoDB.\n\nDelete an item in a DynamoDB table using an AWS SDK\n\nThe following code examples show how to delete an item in a DynamoDB table using an AWS SDK.\n\n.NET\nBash\nC++\nCLI\nGo\nJava\nJavaScript\nKotlin\nPHP\nPowerShell\nPython\nRuby\nRust\nSAP ABAP\nSwift\nAWS SDK for .NET\nNote\n\nThere's more on GitHub. Find the complete example and learn how to set up and run in the AWS Code Examples Repository.\n\n\n        /// <summary>\n        /// Deletes a single item from a DynamoDB table.\n        /// </summary>\n        /// <param name=\"client\">The initialized DynamoDB client object.</param>\n        /// <param name=\"tableName\">The name of the table from which the item\n        /// will be deleted.</param>\n        /// <param name=\"movieToDelete\">A movie object containing the title and\n        /// year of the movie to delete.</param>\n        /// <returns>A Boolean value indicating the success or failure of the\n        /// delete operation.</returns>\n        public static async Task<bool> DeleteItemAsync(\n            AmazonDynamoDBClient client,\n            string tableName,\n            Movie movieToDelete)\n        {\n            var key = new Dictionary<string, AttributeValue>\n            {\n                [\"title\"] = new AttributeValue { S = movieToDelete.Title },\n                [\"year\"] = new AttributeValue { N = movieToDelete.Year.ToString() },\n            };\n\n            var request = new DeleteItemRequest\n            {\n                TableName = tableName,\n                Key = key,\n            };\n\n            var response = await client.DeleteItemAsync(request);\n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n        }\n\n\n\n\nFor API details, see DeleteItem in AWS SDK for .NET API Reference.\n\nFor more DynamoDB examples, see Code examples for DynamoDB using AWS SDKs."
  },
  {
    "title": "Update an item in a DynamoDB table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.UpdateItem.html",
    "html": "Update an item in a DynamoDB table\nPDF\nRSS\n\nYou can update items from DynamoDB tables using the AWS Management Console, the AWS CLI, or an AWS SDK. For more information on items, see Core components of Amazon DynamoDB.\n\nUpdate an item in a DynamoDB table using an AWS SDK\n\nThe following code examples show how to update an item in a DynamoDB table using an AWS SDK.\n\n.NET\nBash\nC++\nCLI\nGo\nJava\nJavaScript\nKotlin\nPHP\nPowerShell\nPython\nRuby\nSAP ABAP\nSwift\nAWS SDK for .NET\nNote\n\nThere's more on GitHub. Find the complete example and learn how to set up and run in the AWS Code Examples Repository.\n\n\n        /// <summary>\n        /// Updates an existing item in the movies table.\n        /// </summary>\n        /// <param name=\"client\">An initialized Amazon DynamoDB client object.</param>\n        /// <param name=\"newMovie\">A Movie object containing information for\n        /// the movie to update.</param>\n        /// <param name=\"newInfo\">A MovieInfo object that contains the\n        /// information that will be changed.</param>\n        /// <param name=\"tableName\">The name of the table that contains the movie.</param>\n        /// <returns>A Boolean value that indicates the success of the operation.</returns>\n        public static async Task<bool> UpdateItemAsync(\n            AmazonDynamoDBClient client,\n            Movie newMovie,\n            MovieInfo newInfo,\n            string tableName)\n        {\n            var key = new Dictionary<string, AttributeValue>\n            {\n                [\"title\"] = new AttributeValue { S = newMovie.Title },\n                [\"year\"] = new AttributeValue { N = newMovie.Year.ToString() },\n            };\n            var updates = new Dictionary<string, AttributeValueUpdate>\n            {\n                [\"info.plot\"] = new AttributeValueUpdate\n                {\n                    Action = AttributeAction.PUT,\n                    Value = new AttributeValue { S = newInfo.Plot },\n                },\n\n                [\"info.rating\"] = new AttributeValueUpdate\n                {\n                    Action = AttributeAction.PUT,\n                    Value = new AttributeValue { N = newInfo.Rank.ToString() },\n                },\n            };\n\n            var request = new UpdateItemRequest\n            {\n                AttributeUpdates = updates,\n                Key = key,\n                TableName = tableName,\n            };\n\n            var response = await client.UpdateItemAsync(request);\n\n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n        }\n\n\n\n\nFor API details, see UpdateItem in AWS SDK for .NET API Reference.\n\nFor more DynamoDB examples, see Code examples for DynamoDB using AWS SDKs."
  },
  {
    "title": "Read an item from a DynamoDB table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.ReadItem.html",
    "html": "Read an item from a DynamoDB table\nPDF\nRSS\n\nYou can read items from DynamoDB tables using the AWS Management Console, the AWS CLI, or an AWS SDK. For more information on items, see Core components of Amazon DynamoDB.\n\nRead an item from a DynamoDB table using an AWS SDK\n\nThe following code examples show how to read an item from a DynamoDB table using an AWS SDK.\n\n.NET\nBash\nC++\nCLI\nGo\nJava\nJavaScript\nKotlin\nPHP\nPowerShell\nPython\nRuby\nSAP ABAP\nSwift\nAWS SDK for .NET\nNote\n\nThere's more on GitHub. Find the complete example and learn how to set up and run in the AWS Code Examples Repository.\n\n\n        /// <summary>\n        /// Gets information about an existing movie from the table.\n        /// </summary>\n        /// <param name=\"client\">An initialized Amazon DynamoDB client object.</param>\n        /// <param name=\"newMovie\">A Movie object containing information about\n        /// the movie to retrieve.</param>\n        /// <param name=\"tableName\">The name of the table containing the movie.</param>\n        /// <returns>A Dictionary object containing information about the item\n        /// retrieved.</returns>\n        public static async Task<Dictionary<string, AttributeValue>> GetItemAsync(AmazonDynamoDBClient client, Movie newMovie, string tableName)\n        {\n            var key = new Dictionary<string, AttributeValue>\n            {\n                [\"title\"] = new AttributeValue { S = newMovie.Title },\n                [\"year\"] = new AttributeValue { N = newMovie.Year.ToString() },\n            };\n\n            var request = new GetItemRequest\n            {\n                Key = key,\n                TableName = tableName,\n            };\n\n            var response = await client.GetItemAsync(request);\n            return response.Item;\n        }\n\n\n\n\nFor API details, see GetItem in AWS SDK for .NET API Reference.\n\nFor more DynamoDB examples, see Code examples for DynamoDB using AWS SDKs."
  },
  {
    "title": "Write an item to a DynamoDB table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.WriteItem.html",
    "html": "Write an item to a DynamoDB table\nPDF\nRSS\n\nYou can write items to DynamoDB tables using the AWS Management Console, the AWS CLI, or an AWS SDK. For more information on items, see Core components of Amazon DynamoDB.\n\nWrite an item to a DynamoDB table using an AWS SDK\n\nThe following code examples show how to write an item to a DynamoDB table using an AWS SDK.\n\n.NET\nBash\nC++\nCLI\nGo\nJava\nJavaScript\nKotlin\nPHP\nPowerShell\nPython\nRuby\nRust\nSAP ABAP\nSwift\nAWS SDK for .NET\nNote\n\nThere's more on GitHub. Find the complete example and learn how to set up and run in the AWS Code Examples Repository.\n\n\n        /// <summary>\n        /// Adds a new item to the table.\n        /// </summary>\n        /// <param name=\"client\">An initialized Amazon DynamoDB client object.</param>\n        /// <param name=\"newMovie\">A Movie object containing informtation for\n        /// the movie to add to the table.</param>\n        /// <param name=\"tableName\">The name of the table where the item will be added.</param>\n        /// <returns>A Boolean value that indicates the results of adding the item.</returns>\n        public static async Task<bool> PutItemAsync(AmazonDynamoDBClient client, Movie newMovie, string tableName)\n        {\n            var item = new Dictionary<string, AttributeValue>\n            {\n                [\"title\"] = new AttributeValue { S = newMovie.Title },\n                [\"year\"] = new AttributeValue { N = newMovie.Year.ToString() },\n            };\n\n            var request = new PutItemRequest\n            {\n                TableName = tableName,\n                Item = item,\n            };\n\n            var response = await client.PutItemAsync(request);\n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n        }\n\n\n\n\nFor API details, see PutItem in AWS SDK for .NET API Reference.\n\nFor more DynamoDB examples, see Code examples for DynamoDB using AWS SDKs."
  },
  {
    "title": "Create a DynamoDB table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.CreateTable.html",
    "html": "Create a DynamoDB table\nPDF\nRSS\n\nYou can create a table using the AWS Management Console, the AWS CLI, or an AWS SDK. For more information on tables, see Core components of Amazon DynamoDB.\n\nCreate a DynamoDB table using an AWS SDK\n\nThe following code examples show how to create a DynamoDB table using an AWS SDK.\n\n.NET\nBash\nC++\nCLI\nGo\nJava\nJavaScript\nKotlin\nPHP\nPowerShell\nPython\nRuby\nRust\nSAP ABAP\nSwift\nAWS SDK for .NET\nNote\n\nThere's more on GitHub. Find the complete example and learn how to set up and run in the AWS Code Examples Repository.\n\n\n        /// <summary>\n        /// Creates a new Amazon DynamoDB table and then waits for the new\n        /// table to become active.\n        /// </summary>\n        /// <param name=\"client\">An initialized Amazon DynamoDB client object.</param>\n        /// <param name=\"tableName\">The name of the table to create.</param>\n        /// <returns>A Boolean value indicating the success of the operation.</returns>\n        public static async Task<bool> CreateMovieTableAsync(AmazonDynamoDBClient client, string tableName)\n        {\n            var response = await client.CreateTableAsync(new CreateTableRequest\n            {\n                TableName = tableName,\n                AttributeDefinitions = new List<AttributeDefinition>()\n                {\n                    new AttributeDefinition\n                    {\n                        AttributeName = \"title\",\n                        AttributeType = ScalarAttributeType.S,\n                    },\n                    new AttributeDefinition\n                    {\n                        AttributeName = \"year\",\n                        AttributeType = ScalarAttributeType.N,\n                    },\n                },\n                KeySchema = new List<KeySchemaElement>()\n                {\n                    new KeySchemaElement\n                    {\n                        AttributeName = \"year\",\n                        KeyType = KeyType.HASH,\n                    },\n                    new KeySchemaElement\n                    {\n                        AttributeName = \"title\",\n                        KeyType = KeyType.RANGE,\n                    },\n                },\n                ProvisionedThroughput = new ProvisionedThroughput\n                {\n                    ReadCapacityUnits = 5,\n                    WriteCapacityUnits = 5,\n                },\n            });\n\n            // Wait until the table is ACTIVE and then report success.\n            Console.Write(\"Waiting for table to become active...\");\n\n            var request = new DescribeTableRequest\n            {\n                TableName = response.TableDescription.TableName,\n            };\n\n            TableStatus status;\n\n            int sleepDuration = 2000;\n\n            do\n            {\n                System.Threading.Thread.Sleep(sleepDuration);\n\n                var describeTableResponse = await client.DescribeTableAsync(request);\n                status = describeTableResponse.Table.TableStatus;\n\n                Console.Write(\".\");\n            }\n            while (status != \"ACTIVE\");\n\n            return status == TableStatus.ACTIVE;\n        }\n\n\n\n\nFor API details, see CreateTable in AWS SDK for .NET API Reference.\n\nFor more DynamoDB examples, see Code examples for DynamoDB using AWS SDKs."
  },
  {
    "title": "Getting started with DynamoDB and the AWS SDKs - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.html",
    "html": "Getting started with DynamoDB and the AWS SDKs\nPDF\nRSS\n\nUse the hands-on tutorials in this section to get started with Amazon DynamoDB and the AWS SDKs. You can run the code examples on either the downloadable version of DynamoDB or the DynamoDB web service.\n\nTopics\nCreate a DynamoDB table\nWrite an item to a DynamoDB table\nRead an item from a DynamoDB table\nUpdate an item in a DynamoDB table\nDelete an item in a DynamoDB table\nQuery a DynamoDB table\nScan a DynamoDB table\nUsing DynamoDB with an AWS SDK"
  },
  {
    "title": "Step 7: Query the global secondary index - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/getting-started-step-7.html",
    "html": "Step 7: Query the global secondary index\nPDF\nRSS\n\nIn this step, you query a global secondary index on the Music table using the Amazon DynamoDB console or the AWS CLI.\n\nFor more information about global secondary indexes, see Using Global Secondary Indexes in DynamoDB.\n\nAWS Management Console\nAWS CLI"
  },
  {
    "title": "Step 6: Create a global secondary index - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/getting-started-step-6.html",
    "html": "Step 6: Create a global secondary index\nPDF\nRSS\n\nIn this step, you create a global secondary index for the Music table that you created in Step 1: Create a table.\n\nFor more information about global secondary indexes, see Using Global Secondary Indexes in DynamoDB.\n\nAWS Management Console\nAWS CLI\n\nNext, you can query the global secondary index. For details, see Step 7: Query the global secondary index."
  },
  {
    "title": "Step 5: Query data in a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/getting-started-step-5.html",
    "html": "Step 5: Query data in a table\nPDF\nRSS\n\nIn this step, you query the data that you wrote to the Music table in Step 2: Write data to a table using the console or AWS CLI by specifying Artist. This will display all songs that are associated with the partition key: Artist.\n\nFor more information about query operations, see Query operations in DynamoDB.\n\nAWS Management Console\nAWS CLI\n\nTo create a global secondary index for your table, proceed to Step 6: Create a global secondary index."
  },
  {
    "title": "Step 2: Write data to a table using the console or AWS CLI - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/getting-started-step-2.html",
    "html": "Step 2: Write data to a table using the console or AWS CLI\nPDF\nRSS\n\nIn this step, you insert several items into the Music table that you created in Step 1: Create a table.\n\nFor more information about write operations, see Writing an item.\n\nAWS Management Console\nAWS CLI\n\nAfter writing data to your table, proceed to Step 3: Read data from a table."
  },
  {
    "title": "Step 3: Read data from a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/getting-started-step-3.html",
    "html": "Step 3: Read data from a table\nPDF\nRSS\n\nIn this step, you'll read back one of the items that you created in Step 2: Write data to a table using the console or AWS CLI. You can use the DynamoDB console or the AWS CLI to read an item from the Music table by specifying Artist and SongTitle.\n\nFor more information about read operations in DynamoDB, see Reading an item.\n\nAWS Management Console\nAWS CLI\n\nTo update the data in your table, proceed to Step 4: Update data in a table."
  },
  {
    "title": "Step 4: Update data in a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/getting-started-step-4.html",
    "html": "Step 4: Update data in a table\nPDF\nRSS\n\nIn this step, you update an item that you created in Step 2: Write data to a table using the console or AWS CLI. You can use the DynamoDB console or the AWS CLI to update the AlbumTitle of an item in the Music table by specifying Artist, SongTitle, and the updated AlbumTitle.\n\nFor more information about write operations, see Writing an item.\n\nAWS Management Console\nAWS CLI\n\nTo query the data in the Music table, proceed to Step 5: Query data in a table."
  },
  {
    "title": "Step 1: Create a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/getting-started-step-1.html",
    "html": "Step 1: Create a table\nPDF\nRSS\n\nIn this step, you create a Music table in Amazon DynamoDB. The table has the following details:\n\nPartition key — Artist\n\nSort key — SongTitle\n\nFor more information about table operations, see Working with tables and data in DynamoDB.\n\nNote\n\nBefore you begin, make sure that you followed the steps in Prerequisites - getting started tutorial.\n\nAWS Management Console\nAWS CLI\n\nAfter creating the new table, proceed to Step 2: Write data to a table using the console or AWS CLI."
  },
  {
    "title": "Using the API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Using.API.html",
    "html": "Using the API\nPDF\nRSS\n\nYou can use the AWS Management Console and the AWS Command Line Interface to work interactively with Amazon DynamoDB. However, to get the most out of DynamoDB, you can write application code using the AWS SDKs.\n\nThe AWS SDKs provide broad support for DynamoDB in Java, JavaScript in the browser, .NET, Node.js, PHP, Python, Ruby, C++, Go, Android, and iOS. To get started quickly with these languages, see Getting started with DynamoDB and the AWS SDKs.\n\nBefore you can use the AWS SDKs with DynamoDB, you must get an AWS access key ID and secret access key. For more information, see Setting up DynamoDB (web service) .\n\nFor a high-level overview of DynamoDB application programming with the AWS SDKs, see Programming with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Using the AWS CLI - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Tools.CLI.html",
    "html": "Using the AWS CLI\nPDF\nRSS\n\nYou can use the AWS Command Line Interface (AWS CLI) to control multiple AWS services from the command line and automate them through scripts. You can use the AWS CLI for ad hoc operations, such as creating a table. You can also use it to embed Amazon DynamoDB operations within utility scripts.\n\nBefore you can use the AWS CLI with DynamoDB, you must get an access key ID and secret access key. For more information, see Granting programmatic access .\n\nFor a complete listing of all the commands available for DynamoDB in the AWS CLI, see the AWS CLI command reference.\n\nTopics\nDownloading and configuring the AWS CLI\nUsing the AWS CLI with DynamoDB\nUsing the AWS CLI with DynamoDB local\nDownloading and configuring the AWS CLI\n\nThe AWS CLI is available at http://aws.amazon.com/cli. It runs on Windows, macOS, or Linux. After you download the AWS CLI, follow these steps to install and configure it:\n\nGo to the AWS Command Line Interface User Guide.\n\nFollow the instructions for Installing the AWS CLI and Configuring the AWS CLI.\n\nUsing the AWS CLI with DynamoDB\n\nThe command line format consists of a DynamoDB operation name followed by the parameters for that operation. The AWS CLI supports a shorthand syntax for the parameter values, as well as JSON.\n\nFor example, the following command creates a table named Music. The partition key is Artist, and the sort key is SongTitle. (For easier readability, long commands in this section are broken into separate lines.)\n\naws dynamodb create-table \\\n    --table-name Music \\\n    --attribute-definitions \\\n        AttributeName=Artist,AttributeType=S \\\n        AttributeName=SongTitle,AttributeType=S \\\n    --key-schema AttributeName=Artist,KeyType=HASH AttributeName=SongTitle,KeyType=RANGE \\\n    --provisioned-throughput ReadCapacityUnits=1,WriteCapacityUnits=1 \\\n    --table-class STANDARD\n\nThe following commands add new items to the table. These examples use a combination of shorthand syntax and JSON.\n\naws dynamodb put-item \\\n    --table-name Music \\\n    --item \\\n        '{\"Artist\": {\"S\": \"No One You Know\"}, \"SongTitle\": {\"S\": \"Call Me Today\"}, \"AlbumTitle\": {\"S\": \"Somewhat Famous\"}}' \\\n    --return-consumed-capacity TOTAL  \n\naws dynamodb put-item \\\n    --table-name Music \\\n    --item '{\n        \"Artist\": {\"S\": \"Acme Band\"},\n        \"SongTitle\": {\"S\": \"Happy Day\"},\n        \"AlbumTitle\": {\"S\": \"Songs About Life\"} }' \\\n    --return-consumed-capacity TOTAL\n\nOn the command line, it can be difficult to compose valid JSON. However, the AWS CLI can read JSON files. For example, consider the following JSON code snippet, which is stored in a file named key-conditions.json.\n\n{\n    \"Artist\": {\n        \"AttributeValueList\": [\n            {   \n                \"S\": \"No One You Know\"\n            }   \n        ],  \n        \"ComparisonOperator\": \"EQ\"\n    },  \n    \"SongTitle\": {\n        \"AttributeValueList\": [\n            {   \n                \"S\": \"Call Me Today\"\n            }   \n        ],  \n        \"ComparisonOperator\": \"EQ\"\n    }\n}\n\nYou can now issue a Query request using the AWS CLI. In this example, the contents of the key-conditions.json file are used for the --key-conditions parameter.\n\naws dynamodb query --table-name Music --key-conditions file://key-conditions.json\nUsing the AWS CLI with DynamoDB local\n\nThe AWS CLI can also interact with DynamoDB local (downloadable version) that runs on your computer. To enable this, add the following parameter to each command:\n\n--endpoint-url http://localhost:8000\n\nThe following example uses the AWS CLI to list the tables in a local database.\n\naws dynamodb list-tables --endpoint-url http://localhost:8000\n\nIf DynamoDB is using a port number other than the default (8000), modify the --endpoint-url value accordingly.\n\nNote\n\nThe AWS CLI can't use the DynamoDB local (downloadable version) as a default endpoint. Therefore, you must specify --endpoint-url with each command."
  },
  {
    "title": "Setting up DynamoDB (web service) - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SettingUp.DynamoWebService.html",
    "html": "Setting up DynamoDB (web service)\nPDF\nRSS\n\nTo use the Amazon DynamoDB web service:\n\nSign up for AWS.\n\nGet an AWS access key (used to access DynamoDB programmatically).\n\nNote\n\nIf you plan to interact with DynamoDB only through the AWS Management Console, you don't need an AWS access key, and you can skip ahead to Using the console.\n\nConfigure your credentials (used to access DynamoDB programmatically).\n\nSigning up for AWS\n\nTo use the DynamoDB service, you must have an AWS account. If you don't already have an account, you are prompted to create one when you sign up. You're not charged for any AWS services that you sign up for unless you use them.\n\nTo sign up for AWS\n\nOpen https://portal.aws.amazon.com/billing/signup.\n\nFollow the online instructions.\n\nPart of the sign-up procedure involves receiving a phone call and entering a verification code on the phone keypad.\n\nWhen you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.\n\nGranting programmatic access\n\nBefore you can access DynamoDB programmatically or through the AWS Command Line Interface (AWS CLI), you must have programmatic access. You don't need programmatic access if you plan to use the DynamoDB console only.\n\nUsers need programmatic access if they want to interact with AWS outside of the AWS Management Console. The way to grant programmatic access depends on the type of user that's accessing AWS.\n\nTo grant users programmatic access, choose one of the following options.\n\nWhich user needs programmatic access?\tTo\tBy\n\n\nWorkforce identity\n\n(Users managed in IAM Identity Center)\n\n\tUse temporary credentials to sign programmatic requests to the AWS CLI, AWS SDKs, or AWS APIs.\t\n\nFollowing the instructions for the interface that you want to use.\n\nFor the AWS CLI, see Configuring the AWS CLI to use AWS IAM Identity Center in the AWS Command Line Interface User Guide.\n\nFor AWS SDKs, tools, and AWS APIs, see IAM Identity Center authentication in the AWS SDKs and Tools Reference Guide.\n\n\nIAM\tUse temporary credentials to sign programmatic requests to the AWS CLI, AWS SDKs, or AWS APIs.\tFollowing the instructions in Using temporary credentials with AWS resources in the IAM User Guide.\nIAM\t\n\n(Not recommended)\n\nUse long-term credentials to sign programmatic requests to the AWS CLI, AWS SDKs, or AWS APIs.\t\n\nFollowing the instructions for the interface that you want to use.\n\nFor the AWS CLI, see Authenticating using IAM user credentials in the AWS Command Line Interface User Guide.\n\nFor AWS SDKs and tools, see Authenticate using long-term credentials in the AWS SDKs and Tools Reference Guide.\n\nFor AWS APIs, see Managing access keys for IAM users in the IAM User Guide.\n\nConfiguring your credentials\n\nBefore you can access DynamoDB programmatically or through the AWS CLI, you must configure your credentials to enable authorization for your applications.\n\nThere are several ways to do this. For example, you can manually create the credentials file to store your access key ID and secret access key. You also can use the AWS CLI command aws configure to automatically create the file. Alternatively, you can use environment variables. For more information about configuring your credentials, see the programming-specific AWS SDK developer guide.\n\nTo install and configure the AWS CLI, see Using the AWS CLI.\n\nIntegrating with other DynamoDB services\n\nYou can integrate DynamoDB with many other AWS services. For more information, see the following:\n\nUsing DynamoDB with other AWS services\n\nAWS CloudFormation for DynamoDB\n\nUsing AWS Backup with DynamoDB\n\nAWS Identity and Access Management (IAM)\n\nUsing AWS Lambda with Amazon DynamoDB"
  },
  {
    "title": "Telemetry in DynamoDB local - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocalTelemetry.html",
    "html": "Telemetry in DynamoDB local\nPDF\nRSS\n\nAt AWS, we develop and launch services based on what we learn from interactions with customers, and we use customer feedback to iterate on our products. Telemetry is additional information that helps us to better understand our customers needs, diagnose issues, and deliver features that improve the customer experience.\n\nDynamoDB local collects telemetry, such as generic usage metrics, systems and environment information, and errors. For details about the types of telemetry collected, see Types of information collected.\n\nDynamoDB local does not collect personal information, such as user names or email addresses. It also does not extract sensitive project-level information.\n\nAs a customer, you control whether telemetry is turned on, and you can change your settings at any point in time. If telemetry remains on, DynamoDB local sends telemetry data in the background without requiring any additional customer interaction.\n\nTurn off telemetry using command line options\n\nYou can turn off telemetry using command line options when starting DynamoDB local using the option -disableTelemetry. For more information, see Command line options .\n\nTurn off telemetry for a single session\n\nIn macOS and Linux operating systems, you can turn off telemetry for a single session. To turn off telemetry for your current session, run the following command to set the environment variable DDB_LOCAL_TELEMETRY to false. Repeat the command for each new terminal or session.\n\nexport DDB_LOCAL_TELEMETRY=0\nTurn off telemetry for your profile in all sessions\n\nRun the following commands to turn off telemetry for all sessions when you're running DynamoDB local on your operating system.\n\nTo turn off telemetry in Linux\n\nRun:\n\necho \"export DDB_LOCAL_TELEMETRY=0\" >>~/.profile\n\nRun:\n\nsource ~/.profile\nTo turn off telemetry in macOS\n\nRun:\n\necho \"export DDB_LOCAL_TELEMETRY=0\" >>~/.profile\n\nRun:\n\nsource ~/.profile\nTo turn off telemetry in Windows\n\nRun:\n\nsetx DDB_LOCAL_TELEMETRY 0\n\nRun:\n\nrefreshenv\nTurn off telemetry using DynamoDB local embedded on Maven projects\n\nYou can turn off telemetry using DynamoDB local embedded on Maven projects.\n\nboolean disableTelemetry = true;\n// AWS SDK v1\n AmazonDynamoDB amazonDynamoDB = DynamoDBEmbedded.create(disableTelemetry).amazonDynamoDB();\n\n// AWS SDK v2\nDynamoDbClient ddbClientSDKv2Local = DynamoDBEmbedded.create(disableTelemetry).dynamoDbClient();\nTypes of information collected\n\nUsage information — The generic telemetry like server start/stop and the API or Operation called.\n\nSystem and environment information — The Java version, operating system (Windows, Linux or macOS), the environment in which DynamoDB local runs (for example, Stand alone JAR, Docker container, or as a Maven Dependency), and hash values of usage attributes.\n\nLearn more\n\nThe telemetry data that DynamoDB local collects adheres to the AWS data privacy policies. For more information, see the following:\n\nAWS service terms\n\nData privacy FAQ"
  },
  {
    "title": "Release history for DynamoDB local - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocalHistory.html",
    "html": "Release history for DynamoDB local\nPDF\nRSS\n\nThe following table describes the important changes in each release of DynamoDB local.\n\nVersion\tChange\tDescription\tDate\n2.5.0\t\n\nSupport for configurable maximum throughput for on-demand tables, ReturnValuesOnConditionCheckFailure, BatchExecuteStatement, and ExecuteTransactionRequest\n\n\t\n\nAdding telemetry to Embedded Mode\n\nFixing the SDKv2 translation for ConditionalCheckException\n\n\t\n\nMay 28, 2024\n\n\n2.4.0\t\n\nSupport for ReturnValuesOnConditionCheckFailure - Embedded Mode\n\n\t\n\nEmbedded Mode Fix for TrimmedDataAccessException for Operation on Multiple Streams\n\nFixing exception translation for SDKv2 in Embedded Mode\n\n\t\n\nApril 17, 2024\n\n\n2.3.0\t\n\nJetty and JDK Upgrade\n\n\t\n\nUpgrading to Jetty 12.0.2\n\nUpgrading to JDK 17\n\nUpgrading ANTLR4 to 4.10.1\n\n\t\n\nMarch 14, 2024\n\n\n2.2.0\t\n\nAdded support for table deletion protection and the ReturnValuesOnConditionCheckFailure parameter\n\n\t\n\nAdded support of Table delete protection\n\nAdded support for ReturnValuesOnConditionCheckFailure\n\nAdded support for -version flag\n\n\t\n\nDecember 14, 2023\n\n\n2.1.0\t\n\nSupport for SQLLite Native Libraries for Maven projects and adding telemetry\n\n\t\n\nAdding telemetry to DynamoDB local\n\nDynamically copy SQLLite Native Libraries for Maven projects\n\nRemoved io.github.ganadist.sqlite4java library from Maven dependency\n\nUpgrading GoogleGuava to 32.1.1-jre\n\n\t\n\nOctober 23, 2023\n\n\n2.0.0\t\n\nMigrating from javax to jakarta namespace and JDK11 Support\n\n\t\n\nMigrating from javax to jakarta namespace and JDK11 support\n\nFix for handling invalid access and secret key while server startup\n\nFixing Maven identified vulnerabilities by updating dependencies\n\n\t\n\nJuly 5, 2023\n\n\n1.25.0\t\n\nAdded support for table deletion protection and the ReturnValuesOnConditionCheckFailure parameter\n\n\t\n\nAdded support of Table delete protection\n\nAdded support for ReturnValuesOnConditionCheckFailure\n\nAdded support for -version flag\n\n\t\n\nDecember 18, 2023\n\n\n1.24.0\t\n\nSupport for SQLLite Native Libraries for Maven projects and adding telemetry\n\n\t\n\nAdding telemetry to DynamoDB local\n\nDynamically copy SQLLite Native Libraries for Maven projects\n\nRemoved io.github.ganadist.sqlite4java library from Maven dependency\n\nUpgrading GoogleGuava to 32.1.1-jre\n\n\t\n\nOctober 23, 2023\n\n\n1.23.0\t\n\nHandle invalid access and secret key while server startup\n\n\t\n\nFix for handling invalid access and secret key while server startup\n\nFixing Maven identified vulnerabilities by updating dependencies\n\n\t\n\nJune 28, 2023\n\n\n1.22.0\t\n\nSupport of Limit Operation for PartiQL\n\n\t\n\nOptimize IN clause for PartiQL\n\nSupport for Limit Operation\n\nM1 support for Maven projects\n\n\t\n\nJune 8, 2023\n\n\n1.21.0\t\n\nSupport for 100 actions per transaction\n\n\t\n\nIncreased actions per transaction from 25 to 100\n\nUpgrading docker image Open JDK to 11\n\nFixing the parity for exception thrown when duplicate items in BatchExecuteStatement\n\n\t\n\nJanuary 26, 2023\n\n\n1.20.0\t\n\nAdded support for M1 Mac\n\n\t\n\nAdded support for M1 Mac\n\nUpgrading Jetty dependency to 9.4.48.v20220622\n\n\t\n\nSeptember 12, 2022\n\n\n1.19.0\t\n\nUpgraded the PartiQL Parser\n\n\t\n\nUpgraded the PartiQL Parser and other related libraries\n\n\t\n\nJuly 27, 2022\n\n\n1.18.0\t\n\nUpgraded log4j-core and Jackson-core\n\n\t\n\nUpgraded log4j-core to 2.17.1 and Jackson-core 2.10.x to 2.12.0\n\n\t\n\nJanuary 10, 2022\n\n\n1.17.2\t\n\nUpgraded log4j-core\n\n\t\n\nUpgraded log4j-core dependency to version 2.16\n\n\t\n\nJanuary 16, 2021\n\n\n1.17.1\t\n\nUpgraded log4j-core\n\n\t\n\nUpdated log4j-core dependency to patch zero-day exploit to prevent remote code execution - Log4Shel\n\n\t\n\nJanuary 10, 2021\n\n\n1.17.0\t\n\nDeprecated Javascript Web Shell\n\n\t\n\nUpdated the AWS SDK dependency to AWS SDK for Java 1.12.x\n\nDeprecated Javascript Web Shell\n\n\t\n\nJanuary 8, 2021"
  },
  {
    "title": "DynamoDB local usage notes - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.UsageNotes.html",
    "html": "DynamoDB local usage notes\nPDF\nRSS\n\nExcept for the endpoint, applications that run with the downloadable version of Amazon DynamoDB should also work with the DynamoDB web service. However, when using DynamoDB locally, you should be aware of the following:\n\nIf you use the -sharedDb option, DynamoDB creates a single database file named shared-local-instance.db. Every program that connects to DynamoDB accesses this file. If you delete the file, you lose any data that you have stored in it.\n\nIf you omit -sharedDb, the database file is named myaccesskeyid_region.db, with the AWS access key ID and AWS Region as they appear in your application configuration. If you delete the file, you lose any data that you have stored in it.\n\nIf you use the -inMemory option, DynamoDB doesn't write any database files at all. Instead, all data is written to memory, and the data is not saved when you terminate DynamoDB.\n\nIf you use the -inMemory option, the -sharedDb option is also required.\n\nIf you use the -optimizeDbBeforeStartup option, you must also specify the -dbPath parameter so that DynamoDB can find its database file.\n\nThe AWS SDKs for DynamoDB require that your application configuration specify an access key value and an AWS Region value. Unless you're using the -sharedDb or the -inMemory option, DynamoDB uses these values to name the local database file. These values don't have to be valid AWS values to run locally. However, you might find it convenient to use valid values so that you can run your code in the cloud later by changing the endpoint you're using.\n\nDynamoDB local always returns null for billingModeSummary.\n\nDynamoDB local AWS_ACCESS_KEY_ID can contain only letters (A–Z, a–z) and numbers (0–9).\n\nDynamoDB local doesn't support Point-in-time recovery (PITR).\n\nTopics\nCommand line options\nSetting the local endpoint\nDifferences between downloadable DynamoDB and the DynamoDB web service\nCommand line options\n\nYou can use the following command line options with the downloadable version of DynamoDB:\n\n-cors value — Enables support for cross-origin resource sharing (CORS) for JavaScript. You must provide a comma-separated \"allow\" list of specific domains. The default setting for -cors is an asterisk (*), which allows public access.\n\n-dbPath value — The directory where DynamoDB writes its database file. If you don't specify this option, the file is written to the current directory. You can't specify both -dbPath and -inMemory at once.\n\n-delayTransientStatuses — Causes DynamoDB to introduce delays for certain operations. DynamoDB (downloadable version) can perform some tasks almost instantaneously, such as create/update/delete operations on tables and indexes. However, the DynamoDB service requires more time for these tasks. Setting this parameter helps DynamoDB running on your computer simulate the behavior of the DynamoDB web service more closely. (Currently, this parameter introduces delays only for global secondary indexes that are in either CREATING or DELETING status.)\n\n-help — Prints a usage summary and options.\n\n-inMemory — DynamoDB runs in memory instead of using a database file. When you stop DynamoDB, none of the data is saved. You can't specify both -dbPath and -inMemory at once.\n\n-optimizeDbBeforeStartup — Optimizes the underlying database tables before starting DynamoDB on your computer. You also must specify -dbPath when you use this parameter.\n\n-port value — The port number that DynamoDB uses to communicate with your application. If you don't specify this option, the default port is 8000.\n\nNote\n\nDynamoDB uses port 8000 by default. If port 8000 is unavailable, this command throws an exception. You can use the -port option to specify a different port number. For a complete list of DynamoDB runtime options, including -port , type this command:\n\njava -Djava.library.path=./DynamoDBLocal_lib -jar DynamoDBLocal.jar -help\n\n-sharedDb — If you specify -sharedDb, DynamoDB uses a single database file instead of separate files for each credential and Region.\n\n-disableTelemetry — When specified, DynamoDB local will not send any telemetry.\n\n-version — Prints the version of DynamoDB local.\n\nSetting the local endpoint\n\nBy default, the AWS SDKs and tools use endpoints for the Amazon DynamoDB web service. To use the SDKs and tools with the downloadable version of DynamoDB, you must specify the local endpoint:\n\nhttp://localhost:8000\n\nAWS Command Line Interface\n\nYou can use the AWS Command Line Interface (AWS CLI) to interact with downloadable DynamoDB. For example, you can use it to perform all the steps in Creating tables and loading data for code examples in DynamoDB.\n\nTo access DynamoDB running locally, use the --endpoint-url parameter. The following is an example of using the AWS CLI to list the tables in DynamoDB on your computer.\n\naws dynamodb list-tables --endpoint-url http://localhost:8000\nNote\n\nThe AWS CLI can't use the downloadable version of DynamoDB as a default endpoint. Therefore, you must specify --endpoint-url with each AWS CLI command.\n\nAWS SDKs\n\nThe way you specify an endpoint depends on the programming language and AWS SDK you're using. The following sections describe how to do this:\n\nJava: Setting the AWS Region and endpoint (DynamoDB local supports the AWS SDK for Java V1 and V2)\n\n.NET: Setting the AWS Region and endpoint\n\nNote\n\nFor examples in other programming languages, see Getting started with DynamoDB and the AWS SDKs.\n\nDifferences between downloadable DynamoDB and the DynamoDB web service\n\nThe downloadable version of DynamoDB is intended for development and testing purposes only. By comparison, the DynamoDB web service is a managed service with scalability, availability, and durability features that make it ideal for production use.\n\nThe downloadable version of DynamoDB differs from the web service in the following ways:\n\nAWS Regions and distinct AWS accounts are not supported at the client level.\n\nProvisioned throughput settings are ignored in downloadable DynamoDB, even though the CreateTable operation requires them. For CreateTable, you can specify any numbers you want for provisioned read and write throughput, even though these numbers are not used. You can call UpdateTable as many times as you want per day. However, any changes to provisioned throughput values are ignored.\n\nScan operations are performed sequentially. Parallel scans are not supported. The Segment and TotalSegments parameters of the Scan operation are ignored.\n\nThe speed of read and write operations on table data is limited only by the speed of your computer. CreateTable, UpdateTable, and DeleteTable operations occur immediately, and table state is always ACTIVE. UpdateTable operations that change only the provisioned throughput settings on tables or global secondary indexes occur immediately. If an UpdateTable operation creates or deletes any global secondary indexes, then those indexes transition through normal states (such as CREATING and DELETING, respectively) before they become an ACTIVE state. The table remains ACTIVE during this time.\n\nRead operations are eventually consistent. However, due to the speed of DynamoDB running on your computer, most reads appear to be strongly consistent.\n\nItem collection metrics and item collection sizes are not tracked. In operation responses, nulls are returned instead of item collection metrics.\n\nIn DynamoDB, there is a 1 MB limit on data returned per result set. Both the DynamoDB web service and the downloadable version enforce this limit. However, when querying an index, the DynamoDB service calculates only the size of the projected key and attributes. By contrast, the downloadable version of DynamoDB calculates the size of the entire item.\n\nIf you're using DynamoDB Streams, the rate at which shards are created might differ. In the DynamoDB web service, shard-creation behavior is partially influenced by table partition activity. When you run DynamoDB locally, there is no table partitioning. In either case, shards are ephemeral, so your application should not be dependent on shard behavior.\n\nTransactionConflictExceptions aren't thrown by downloadable DynamoDB for transactional APIs. We recommend that you use a Java mocking framework to simulate TransactionConflictExceptions in the DynamoDB handler to test how your application responds to conflicting transactions.\n\nIn the DynamoDB web service, whether being accessed via the console or the AWS CLI, table names are case sensitive. A table named Authors and one named authors can both exist as separate tables. In the downloadable version, table names are case insensitive, and attempting to create these two tables would result in an error.\n\nTagging is not supported in the downloadable version of DynamoDB.\n\nThe downloadable version of DynamoDB ignores the Limit parameter in ExecuteStatement."
  },
  {
    "title": "Deploying DynamoDB locally on your computer - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.DownloadingAndRunning.html",
    "html": "Deploying DynamoDB locally on your computer\nPDF\nRSS\nImportant\n\nDynamoDB local jar can be downloaded from our AWS CloudFront distribution links referenced here. Starting January 1, 2025, the old S3 distribution buckets will no longer be active and DynamoDB local will be distributed through CloudFront distribution links only.\n\nThere are two major versions of DynamoDB local available: DynamoDB local v2.x (Current) and DynamoDB local v1.x (Legacy). Customers should use version 2.x (Current) when possible, as it supports the latest versions of the Java Runtime Environment and is compatible with the jakarta.* namespace for Maven project. DynamoDB local v1.x will reach end of standard support starting on January 1, 2025. After this date, v1.x will no longer receive updates or bug fixes.\nNote\n\nDynamoDB local AWS_ACCESS_KEY_ID can contain only letters (A–Z, a–z) and numbers (0–9).\n\nDownload DynamoDB local\nRun DynamoDB local as Docker image\nRun DynamoDB local as an Apache Maven dependency\n\nFor an example of a sample project that showcases multiple approaches to set up and use DynamoDB local, including downloading JAR files, running it as a Docker image, and using it as a Maven dependency, see DynamoDB Local Sample Java Project."
  },
  {
    "title": "Setting up DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SettingUp.html",
    "html": "Setting up DynamoDB\nPDF\nRSS\n\nIn addition to the Amazon DynamoDB web service, AWS provides a downloadable version of DynamoDB that you can run on your computer. The downloadable version is helpful for developing and testing your code. It lets you write and test applications locally without accessing the DynamoDB web service.\n\nThe topics in this section describe how to set up DynamoDB (downloadable version) and the DynamoDB web service.\n\nTopics\nSetting up DynamoDB local (downloadable version)\nSetting up DynamoDB (web service)"
  },
  {
    "title": "Reserved capacity - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/reserved-capacity.html",
    "html": "Reserved capacity\nPDF\nRSS\n\nFor provisioned capacity tables that use the Standard table class, DynamoDB offers the ability to purchase reserved capacity for your read and write capacity. A reserved capacity purchase is an agreement to pay for a minimum amount of provisioned throughput capacity, for the duration of the term of the agreement, in exchange for discounted pricing.\n\nNote\n\nYou can't purchase reserved capacity for replicated write capacity units (rWCUs). Reserved capacity is applied only to the Region in which it was purchased. Reserved capacity is also not available for tables using the DynamoDB Standard-IA table class or on-demand capacity mode.\n\nReserved capacity is purchased in allocations of 100 WCUs or 100 RCUs. The smallest reserved capacity offering is 100 capacity units (reads or writes). DynamoDB reserved capacity is offered as either a one-year commitment or in select Regions as a three-year commitment. You can save up to 54% off standard rates for a one-year term and 77% off standard rates for a three-year term. For more information about how and when you should purchase, see Amazon DynamoDB Reserved Capacity.\n\nWhen you purchase DynamoDB reserved capacity, you pay a one-time partial upfront payment and receive a discounted hourly rate for the committed provisioned usage. You pay for the entire committed provisioned usage, regardless of actual usage, so your cost savings are closely tied to use. Any capacity that you provision in excess of the purchased reserved capacity is billed at standard provisioned capacity rates. By reserving your read and write capacity units ahead of time, you realize significant cost savings on your provisioned capacity costs.\n\nYou can't sell, cancel, or transfer reserved capacity to another Region or account.\n\nNote\n\nReserved capacity isn't a capacity dedicated to your organization. It's a billing discount applied to the use of provisioned capacity for reads and/or writes on your account."
  },
  {
    "title": "Using the AWS SDK to configure auto scaling on Amazon DynamoDB tables - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.HowTo.SDK.html",
    "html": "Using the AWS SDK to configure auto scaling on Amazon DynamoDB tables\nPDF\nRSS\n\nIn addition to using the AWS Management Console and the AWS Command Line Interface (AWS CLI), you can write applications that interact with Amazon DynamoDB auto scaling. This section contains two Java programs that you can use to test this functionality:\n\nEnableDynamoDBAutoscaling.java\n\nDisableDynamoDBAutoscaling.java\n\nEnabling Application Auto Scaling for a table\n\nThe following program shows an example of setting up an auto scaling policy for a DynamoDB table (TestTable). It proceeds as follows:\n\nThe program registers write capacity units as a scalable target for TestTable. The range for this metric is between 5 and 10 write capacity units.\n\nAfter the scalable target is created, the program builds a target tracking configuration. The policy seeks to maintain a 50 percent target ratio between consumed write capacity and provisioned write capacity.\n\nThe program then creates the scaling policy, based on the target tracking configuration.\n\nNote\n\nWhen you manually remove a table or global table replica, you do not automatically remove any associated scalable targets, scaling policies, or CloudWatch alarms.\n\nThe program requires that you provide an Amazon Resource Name (ARN) for a valid Application Auto Scaling service linked role. (For example: arn:aws:iam::122517410325:role/AWSServiceRoleForApplicationAutoScaling_DynamoDBTable.) In the following program, replace SERVICE_ROLE_ARN_GOES_HERE with the actual ARN.\n\npackage com.amazonaws.codesamples.autoscaling;\n\nimport com.amazonaws.services.applicationautoscaling.AWSApplicationAutoScalingClient;\nimport com.amazonaws.services.applicationautoscaling.AWSApplicationAutoScalingClientBuilder;\nimport com.amazonaws.services.applicationautoscaling.model.DescribeScalableTargetsRequest;\nimport com.amazonaws.services.applicationautoscaling.model.DescribeScalableTargetsResult;\nimport com.amazonaws.services.applicationautoscaling.model.DescribeScalingPoliciesRequest;\nimport com.amazonaws.services.applicationautoscaling.model.DescribeScalingPoliciesResult;\nimport com.amazonaws.services.applicationautoscaling.model.MetricType;\nimport com.amazonaws.services.applicationautoscaling.model.PolicyType;\nimport com.amazonaws.services.applicationautoscaling.model.PredefinedMetricSpecification;\nimport com.amazonaws.services.applicationautoscaling.model.PutScalingPolicyRequest;\nimport com.amazonaws.services.applicationautoscaling.model.RegisterScalableTargetRequest;\nimport com.amazonaws.services.applicationautoscaling.model.ScalableDimension;\nimport com.amazonaws.services.applicationautoscaling.model.ServiceNamespace;\nimport com.amazonaws.services.applicationautoscaling.model.TargetTrackingScalingPolicyConfiguration;\n\npublic class EnableDynamoDBAutoscaling {\n\n\tstatic AWSApplicationAutoScalingClient aaClient = (AWSApplicationAutoScalingClient) AWSApplicationAutoScalingClientBuilder\n\t\t\t.standard().build();\n\n\tpublic static void main(String args[]) {\n\n\t\tServiceNamespace ns = ServiceNamespace.Dynamodb;\n\t\tScalableDimension tableWCUs = ScalableDimension.DynamodbTableWriteCapacityUnits;\n\t\tString resourceID = \"table/TestTable\";\n\n\t\t// Define the scalable target\n\t\tRegisterScalableTargetRequest rstRequest = new RegisterScalableTargetRequest()\n\t\t\t\t.withServiceNamespace(ns)\n\t\t\t\t.withResourceId(resourceID)\n\t\t\t\t.withScalableDimension(tableWCUs)\n\t\t\t\t.withMinCapacity(5)\n\t\t\t\t.withMaxCapacity(10)\n\t\t\t\t.withRoleARN(\"SERVICE_ROLE_ARN_GOES_HERE\");\n\n\t\ttry {\n\t\t\taaClient.registerScalableTarget(rstRequest);\n\t\t} catch (Exception e) {\n\t\t\tSystem.err.println(\"Unable to register scalable target: \");\n\t\t\tSystem.err.println(e.getMessage());\n\t\t}\n\n\t\t// Verify that the target was created\n\t\tDescribeScalableTargetsRequest dscRequest = new DescribeScalableTargetsRequest()\n\t\t\t\t.withServiceNamespace(ns)\n\t\t\t\t.withScalableDimension(tableWCUs)\n\t\t\t\t.withResourceIds(resourceID);\n\t\ttry {\n\t\t\tDescribeScalableTargetsResult dsaResult = aaClient.describeScalableTargets(dscRequest);\n\t\t\tSystem.out.println(\"DescribeScalableTargets result: \");\n\t\t\tSystem.out.println(dsaResult);\n\t\t\tSystem.out.println();\n\t\t} catch (Exception e) {\n\t\t\tSystem.err.println(\"Unable to describe scalable target: \");\n\t\t\tSystem.err.println(e.getMessage());\n\t\t}\n\n\t\tSystem.out.println();\n\n\t\t// Configure a scaling policy\n\t\tTargetTrackingScalingPolicyConfiguration targetTrackingScalingPolicyConfiguration = new TargetTrackingScalingPolicyConfiguration()\n\t\t\t\t.withPredefinedMetricSpecification(\n\t\t\t\t\t\tnew PredefinedMetricSpecification()\n\t\t\t\t\t\t\t\t.withPredefinedMetricType(MetricType.DynamoDBWriteCapacityUtilization))\n\t\t\t\t.withTargetValue(50.0)\n\t\t\t\t.withScaleInCooldown(60)\n\t\t\t\t.withScaleOutCooldown(60);\n\n\t\t// Create the scaling policy, based on your configuration\n\t\tPutScalingPolicyRequest pspRequest = new PutScalingPolicyRequest()\n\t\t\t\t.withServiceNamespace(ns)\n\t\t\t\t.withScalableDimension(tableWCUs)\n\t\t\t\t.withResourceId(resourceID)\n\t\t\t\t.withPolicyName(\"MyScalingPolicy\")\n\t\t\t\t.withPolicyType(PolicyType.TargetTrackingScaling)\n\t\t\t\t.withTargetTrackingScalingPolicyConfiguration(targetTrackingScalingPolicyConfiguration);\n\n\t\ttry {\n\t\t\taaClient.putScalingPolicy(pspRequest);\n\t\t} catch (Exception e) {\n\t\t\tSystem.err.println(\"Unable to put scaling policy: \");\n\t\t\tSystem.err.println(e.getMessage());\n\t\t}\n\n\t\t// Verify that the scaling policy was created\n\t\tDescribeScalingPoliciesRequest dspRequest = new DescribeScalingPoliciesRequest()\n\t\t\t\t.withServiceNamespace(ns)\n\t\t\t\t.withScalableDimension(tableWCUs)\n\t\t\t\t.withResourceId(resourceID);\n\n\t\ttry {\n\t\t\tDescribeScalingPoliciesResult dspResult = aaClient.describeScalingPolicies(dspRequest);\n\t\t\tSystem.out.println(\"DescribeScalingPolicies result: \");\n\t\t\tSystem.out.println(dspResult);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t\tSystem.err.println(\"Unable to describe scaling policy: \");\n\t\t\tSystem.err.println(e.getMessage());\n\t\t}\n\n\t}\n\n}\n\n\nDisabling Application Auto Scaling for a table\n\nThe following program reverses the previous process. It removes the auto scaling policy and then deregisters the scalable target.\n\npackage com.amazonaws.codesamples.autoscaling;\n\nimport com.amazonaws.services.applicationautoscaling.AWSApplicationAutoScalingClient;\nimport com.amazonaws.services.applicationautoscaling.model.DeleteScalingPolicyRequest;\nimport com.amazonaws.services.applicationautoscaling.model.DeregisterScalableTargetRequest;\nimport com.amazonaws.services.applicationautoscaling.model.DescribeScalableTargetsRequest;\nimport com.amazonaws.services.applicationautoscaling.model.DescribeScalableTargetsResult;\nimport com.amazonaws.services.applicationautoscaling.model.DescribeScalingPoliciesRequest;\nimport com.amazonaws.services.applicationautoscaling.model.DescribeScalingPoliciesResult;\nimport com.amazonaws.services.applicationautoscaling.model.ScalableDimension;\nimport com.amazonaws.services.applicationautoscaling.model.ServiceNamespace;\n\npublic class DisableDynamoDBAutoscaling {\n\n\tstatic AWSApplicationAutoScalingClient aaClient = new AWSApplicationAutoScalingClient();\n\n\tpublic static void main(String args[]) {\n\n\t\tServiceNamespace ns = ServiceNamespace.Dynamodb;\n\t\tScalableDimension tableWCUs = ScalableDimension.DynamodbTableWriteCapacityUnits;\n\t\tString resourceID = \"table/TestTable\";\n\n\t\t// Delete the scaling policy\n\t\tDeleteScalingPolicyRequest delSPRequest = new DeleteScalingPolicyRequest()\n\t\t\t\t.withServiceNamespace(ns)\n\t\t\t\t.withScalableDimension(tableWCUs)\n\t\t\t\t.withResourceId(resourceID)\n\t\t\t\t.withPolicyName(\"MyScalingPolicy\");\n\n\t\ttry {\n\t\t\taaClient.deleteScalingPolicy(delSPRequest);\n\t\t} catch (Exception e) {\n\t\t\tSystem.err.println(\"Unable to delete scaling policy: \");\n\t\t\tSystem.err.println(e.getMessage());\n\t\t}\n\n\t\t// Verify that the scaling policy was deleted\n\t\tDescribeScalingPoliciesRequest descSPRequest = new DescribeScalingPoliciesRequest()\n\t\t\t\t.withServiceNamespace(ns)\n\t\t\t\t.withScalableDimension(tableWCUs)\n\t\t\t\t.withResourceId(resourceID);\n\n\t\ttry {\n\t\t\tDescribeScalingPoliciesResult dspResult = aaClient.describeScalingPolicies(descSPRequest);\n\t\t\tSystem.out.println(\"DescribeScalingPolicies result: \");\n\t\t\tSystem.out.println(dspResult);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t\tSystem.err.println(\"Unable to describe scaling policy: \");\n\t\t\tSystem.err.println(e.getMessage());\n\t\t}\n\n\t\tSystem.out.println();\n\n\t\t// Remove the scalable target\n\t\tDeregisterScalableTargetRequest delSTRequest = new DeregisterScalableTargetRequest()\n\t\t\t\t.withServiceNamespace(ns)\n\t\t\t\t.withScalableDimension(tableWCUs)\n\t\t\t\t.withResourceId(resourceID);\n\n\t\ttry {\n\t\t\taaClient.deregisterScalableTarget(delSTRequest);\n\t\t} catch (Exception e) {\n\t\t\tSystem.err.println(\"Unable to deregister scalable target: \");\n\t\t\tSystem.err.println(e.getMessage());\n\t\t}\n\n\t\t// Verify that the scalable target was removed\n\t\tDescribeScalableTargetsRequest dscRequest = new DescribeScalableTargetsRequest()\n\t\t\t\t.withServiceNamespace(ns)\n\t\t\t\t.withScalableDimension(tableWCUs)\n\t\t\t\t.withResourceIds(resourceID);\n\n\t\ttry {\n\t\t\tDescribeScalableTargetsResult dsaResult = aaClient.describeScalableTargets(dscRequest);\n\t\t\tSystem.out.println(\"DescribeScalableTargets result: \");\n\t\t\tSystem.out.println(dsaResult);\n\t\t\tSystem.out.println();\n\t\t} catch (Exception e) {\n\t\t\tSystem.err.println(\"Unable to describe scalable target: \");\n\t\t\tSystem.err.println(e.getMessage());\n\t\t}\n\n\t}\n\n}\n\n"
  },
  {
    "title": "Using the AWS CLI to manage DynamoDB auto scaling - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.CLI.html",
    "html": "Using the AWS CLI to manage DynamoDB auto scaling\nPDF\nRSS\n\nInstead of using the AWS Management Console, you can use the AWS Command Line Interface (AWS CLI) to manage Amazon DynamoDB auto scaling. The tutorial in this section demonstrates how to install and configure the AWS CLI for managing DynamoDB auto scaling. In this tutorial, you do the following:\n\nCreate a DynamoDB table named TestTable. The initial throughput settings are 5 read capacity units and 5 write capacity units.\n\nCreate an Application Auto Scaling policy for TestTable. The policy seeks to maintain a 50 percent target ratio between consumed write capacity and provisioned write capacity. The range for this metric is between 5 and 10 write capacity units. (Application Auto Scaling is not allowed to adjust the throughput beyond this range.)\n\nRun a Python program to drive write traffic to TestTable. When the target ratio exceeds 50 percent for a sustained period of time, Application Auto Scaling notifies DynamoDB to adjust the throughput of TestTable upward to maintain the 50 percent target utilization.\n\nVerify that DynamoDB has successfully adjusted the provisioned write capacity for TestTable.\n\nNote\n\nYou can also schedule your DynamoDB scaling so it happens at certain times. Learn the basic steps here.\n\nTopics\nBefore you begin\nStep 1: Create a DynamoDB table\nStep 2: Register a scalable target\nStep 3: Create a scaling policy\nStep 4: Drive write traffic to TestTable\nStep 5: View Application Auto Scaling actions\n(Optional) Step 6: Clean up\nBefore you begin\n\nComplete the following tasks before starting the tutorial.\n\nInstall the AWS CLI\n\nIf you haven't already done so, you must install and configure the AWS CLI. To do this, follow these instructions in the AWS Command Line Interface User Guide:\n\nInstalling the AWS CLI\n\nConfiguring the AWS CLI\n\nInstall Python\n\nPart of this tutorial requires you to run a Python program (see Step 4: Drive write traffic to TestTable). If you don't already have it installed, you can download Python.\n\nStep 1: Create a DynamoDB table\n\nIn this step, you use the AWS CLI to create TestTable. The primary key consists of pk (partition key) and sk (sort key). Both of these attributes are of type Number. The initial throughput settings are 5 read capacity units and 5 write capacity units.\n\nUse the following AWS CLI command to create the table.\n\naws dynamodb create-table \\\n    --table-name TestTable \\\n    --attribute-definitions \\\n        AttributeName=pk,AttributeType=N \\\n        AttributeName=sk,AttributeType=N \\\n    --key-schema \\\n        AttributeName=pk,KeyType=HASH \\\n        AttributeName=sk,KeyType=RANGE \\\n    --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5\n\nTo check the status of the table, use the following command.\n\naws dynamodb describe-table \\\n    --table-name TestTable \\\n    --query \"Table.[TableName,TableStatus,ProvisionedThroughput]\"\n\nThe table is ready for use when its status is ACTIVE.\n\nStep 2: Register a scalable target\n\nNext you register the table's write capacity as a scalable target with Application Auto Scaling. This allows Application Auto Scaling to adjust the provisioned write capacity for TestTable, but only within the range of 5–10 capacity units.\n\nNote\n\nDynamoDB auto scaling requires the presence of a service linked role (AWSServiceRoleForApplicationAutoScaling_DynamoDBTable) that performs auto scaling actions on your behalf. This role is created automatically for you. For more information, see Service-linked roles for Application Auto Scaling in the Application Auto Scaling User Guide.\n\nEnter the following command to register the scalable target.\n\naws application-autoscaling register-scalable-target \\\n    --service-namespace dynamodb \\\n    --resource-id \"table/TestTable\" \\\n    --scalable-dimension \"dynamodb:table:WriteCapacityUnits\" \\\n    --min-capacity 5 \\\n    --max-capacity 10\n\nTo verify the registration, use the following command.\n\naws application-autoscaling describe-scalable-targets \\\n    --service-namespace dynamodb \\\n    --resource-id \"table/TestTable\"\nNote\n\nYou can also register a scalable target against a global secondary index. For example, for a global secondary index (\"test-index\"), the resource ID and scalable dimension arguments are updated appropriately.\n\naws application-autoscaling register-scalable-target \\\n    --service-namespace dynamodb \\\n    --resource-id \"table/TestTable/index/test-index\" \\\n    --scalable-dimension \"dynamodb:index:WriteCapacityUnits\" \\\n    --min-capacity 5 \\\n    --max-capacity 10\nStep 3: Create a scaling policy\n\nIn this step, you create a scaling policy for TestTable. The policy defines the details under which Application Auto Scaling can adjust your table's provisioned throughput, and what actions to take when it does so. You associate this policy with the scalable target that you defined in the previous step (write capacity units for the TestTable table).\n\nThe policy contains the following elements:\n\nPredefinedMetricSpecification—The metric that Application Auto Scaling is allowed to adjust. For DynamoDB, the following values are valid values for PredefinedMetricType:\n\nDynamoDBReadCapacityUtilization\n\nDynamoDBWriteCapacityUtilization\n\nScaleOutCooldown—The minimum amount of time (in seconds) between each Application Auto Scaling event that increases provisioned throughput. This parameter allows Application Auto Scaling to continuously, but not aggressively, increase the throughput in response to real-world workloads. The default setting for ScaleOutCooldown is 0.\n\nScaleInCooldown—The minimum amount of time (in seconds) between each Application Auto Scaling event that decreases provisioned throughput. This parameter allows Application Auto Scaling to decrease the throughput gradually and predictably. The default setting for ScaleInCooldown is 0.\n\nTargetValue—Application Auto Scaling ensures that the ratio of consumed capacity to provisioned capacity stays at or near this value. You define TargetValue as a percentage.\n\nNote\n\nTo further understand how TargetValue works, suppose that you have a table with a provisioned throughput setting of 200 write capacity units. You decide to create a scaling policy for this table, with a TargetValue of 70 percent.\n\nNow suppose that you begin driving write traffic to the table so that the actual write throughput is 150 capacity units. The consumed-to-provisioned ratio is now (150 / 200), or 75 percent. This ratio exceeds your target, so Application Auto Scaling increases the provisioned write capacity to 215 so that the ratio is (150 / 215), or 69.77 percent—as close to your TargetValue as possible, but not exceeding it.\n\nFor TestTable, you set TargetValue to 50 percent. Application Auto Scaling adjusts the table's provisioned throughput within the range of 5–10 capacity units (see Step 2: Register a scalable target) so that the consumed-to-provisioned ratio remains at or near 50 percent. You set the values for ScaleOutCooldown and ScaleInCooldown to 60 seconds.\n\nCreate a file named scaling-policy.json with the following contents.\n\n{\n    \"PredefinedMetricSpecification\": {\n        \"PredefinedMetricType\": \"DynamoDBWriteCapacityUtilization\"\n    },\n    \"ScaleOutCooldown\": 60,\n    \"ScaleInCooldown\": 60,\n    \"TargetValue\": 50.0\n}            \n\nUse the following AWS CLI command to create the policy.\n\naws application-autoscaling put-scaling-policy \\\n    --service-namespace dynamodb \\\n    --resource-id \"table/TestTable\" \\\n    --scalable-dimension \"dynamodb:table:WriteCapacityUnits\" \\\n    --policy-name \"MyScalingPolicy\" \\\n    --policy-type \"TargetTrackingScaling\" \\\n    --target-tracking-scaling-policy-configuration file://scaling-policy.json\n\nIn the output, note that Application Auto Scaling has created two Amazon CloudWatch alarms—one each for the upper and lower boundary of the scaling target range.\n\nUse the following AWS CLI command to view more details about the scaling policy.\n\naws application-autoscaling describe-scaling-policies \\\n    --service-namespace dynamodb \\\n    --resource-id \"table/TestTable\" \\\n    --policy-name \"MyScalingPolicy\"\n\nIn the output, verify that the policy settings match your specifications from Step 2: Register a scalable target and Step 3: Create a scaling policy.\n\nStep 4: Drive write traffic to TestTable\n\nNow you can test your scaling policy by writing data to TestTable. To do this, you run a Python program.\n\nCreate a file named bulk-load-test-table.py with the following contents.\n\nimport boto3\ndynamodb = boto3.resource('dynamodb')\n\ntable = dynamodb.Table(\"TestTable\")\n\nfiller = \"x\" * 100000\n\ni = 0\nwhile (i < 10):\n    j = 0\n    while (j < 10):\n        print (i, j)\n        \n        table.put_item(\n            Item={\n                'pk':i,\n                'sk':j,\n                'filler':{\"S\":filler}\n            }\n        )\n        j += 1\n    i += 1\n\nEnter the following command to run the program.\n\npython bulk-load-test-table.py\n\nThe provisioned write capacity for TestTable is very low (5 write capacity units), so the program stalls occasionally due to write throttling. This is expected behavior.\n\nLet the program continue running while you move on to the next step.\n\nStep 5: View Application Auto Scaling actions\n\nIn this step, you view the Application Auto Scaling actions that are initiated on your behalf. You also verify that Application Auto Scaling has updated the provisioned write capacity for TestTable.\n\nEnter the following command to view the Application Auto Scaling actions.\n\naws application-autoscaling describe-scaling-activities \\\n    --service-namespace dynamodb\n\nRerun this command occasionally, while the Python program is running. (It takes several minutes before your scaling policy is invoked.) You should eventually see the following output.\n\n...\n{\n    \"ScalableDimension\": \"dynamodb:table:WriteCapacityUnits\", \n    \"Description\": \"Setting write capacity units to 10.\", \n    \"ResourceId\": \"table/TestTable\", \n    \"ActivityId\": \"0cc6fb03-2a7c-4b51-b67f-217224c6b656\", \n    \"StartTime\": 1489088210.175, \n    \"ServiceNamespace\": \"dynamodb\", \n    \"EndTime\": 1489088246.85, \n    \"Cause\": \"monitor alarm AutoScaling-table/TestTable-AlarmHigh-1bb3c8db-1b97-4353-baf1-4def76f4e1b9 in state ALARM triggered policy MyScalingPolicy\", \n    \"StatusMessage\": \"Successfully set write capacity units to 10. Change successfully fulfilled by dynamodb.\", \n    \"StatusCode\": \"Successful\"\n}, \n...\n\nThis indicates that Application Auto Scaling has issued an UpdateTable request to DynamoDB.\n\nEnter the following command to verify that DynamoDB increased the table's write capacity.\n\naws dynamodb describe-table \\\n    --table-name TestTable \\\n    --query \"Table.[TableName,TableStatus,ProvisionedThroughput]\"\n\nThe WriteCapacityUnits should have been scaled from 5 to 10.\n\n(Optional) Step 6: Clean up\n\nIn this tutorial, you created several resources. You can delete these resources if you no longer need them.\n\nDelete the scaling policy for TestTable.\n\naws application-autoscaling delete-scaling-policy \\\n    --service-namespace dynamodb \\\n    --resource-id \"table/TestTable\" \\\n    --scalable-dimension \"dynamodb:table:WriteCapacityUnits\" \\\n    --policy-name \"MyScalingPolicy\"\n\nDeregister the scalable target.\n\naws application-autoscaling deregister-scalable-target \\\n    --service-namespace dynamodb \\\n    --resource-id \"table/TestTable\" \\\n    --scalable-dimension \"dynamodb:table:WriteCapacityUnits\"\n\nDelete the TestTable table.\n\naws dynamodb delete-table --table-name TestTable"
  },
  {
    "title": "Using the AWS Management Console with DynamoDB auto scaling - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.Console.html",
    "html": "Using the AWS Management Console with DynamoDB auto scaling\nPDF\nRSS\n\nWhen you use the AWS Management Console to create a new table, Amazon DynamoDB auto scaling is enabled for that table by default. You can also use the console to enable auto scaling for existing tables, modify auto scaling settings, or disable auto scaling.\n\nNote\n\nFor more advanced features like setting scale-in and scale-out cooldown times, use the AWS Command Line Interface (AWS CLI) to manage DynamoDB auto scaling. For more information, see Using the AWS CLI to manage DynamoDB auto scaling.\n\nTopics\nBefore you begin: Granting user permissions for DynamoDB auto scaling\nCreating a new table with auto scaling enabled\nEnabling DynamoDB auto scaling on existing tables\nViewing auto scaling activities on the console\nModifying or disabling DynamoDB auto scaling settings\nBefore you begin: Granting user permissions for DynamoDB auto scaling\n\nIn AWS Identity and Access Management (IAM), the AWS managed policy DynamoDBFullAccess provides the required permissions for using the DynamoDB console. However, for DynamoDB auto scaling, users require additional permissions.\n\nImportant\n\nTo delete an auto scaling-enabled table, application-autoscaling:* permissions are required. The AWS managed policy DynamoDBFullAccess includes such permissions.\n\nTo set up a user for DynamoDB console access and DynamoDB auto scaling, create a role and add the AmazonDynamoDBFullAccess policy to that role. Then assign the role to a user.\n\nCreating a new table with auto scaling enabled\nNote\n\nDynamoDB auto scaling requires the presence of a service-linked role (AWSServiceRoleForApplicationAutoScaling_DynamoDBTable) that performs auto scaling actions on your behalf. This role is created automatically for you. For more information, see Service-linked roles for Application Auto Scaling in the Application Auto Scaling User Guide.\n\nTo create a new table with auto scaling enabled\n\nOpen the DynamoDB console at https://console.aws.amazon.com/dynamodb/.\n\nChoose Create table.\n\nOn the Create table page, enter a Table name and primary key.\n\nIf Default settings is selected, the table will be created with auto scaling enabled.\n\nOtherwise, for custom settings:\n\nSelect Customize settings.\n\nIn the Read/write capacity settings section, select Provisioned capacity mode and set Auto scaling to On for Read capacity, Write capacity, or both. For each of these, set your desired scaling policy for the table and, optionally, all global secondary indexes of the table.\n\nMinimum capacity units – Enter your lower boundary for the auto scaling range.\n\nMaximum capacity units – Enter your upper boundary for the auto scaling range.\n\nTarget utilization – Enter your target utilization percentage for the table.\n\nNote\n\nIf you create a global secondary index for the new table, the index's capacity at time of creation will be the same as your base table's capacity. You can change the index's capacity in the table's settings after you create the table.\n\nWhen the settings are as you want them, choose Create table. Your table is created with the auto scaling parameters.\n\nEnabling DynamoDB auto scaling on existing tables\nNote\n\nDynamoDB auto scaling requires the presence of a service-linked role (AWSServiceRoleForApplicationAutoScaling_DynamoDBTable) that performs auto scaling actions on your behalf. This role is created automatically for you. For more information, see Service-linked roles for Application Auto Scaling.\n\nTo enable DynamoDB auto scaling for an existing table\n\nOpen the DynamoDB console at https://console.aws.amazon.com/dynamodb/.\n\nIn the navigation pane on the left side of the console, choose Tables.\n\nChoose the table that you want to work with and choose the Additional settings tab.\n\nIn the Read/write capacity section, choose Edit.\n\nIn the Capacity mode section, choose Provisioned.\n\nIn the Table capacity section, set Auto scaling to On for Read capacity, Write capacity, or both. For each of these, set your desired scaling policy for the table and, optionally, all global secondary indexes of the table.\n\nMinimum capacity units – Enter your lower boundary for the auto scaling range.\n\nMaximum capacity units – Enter your upper boundary for the auto scaling range.\n\nTarget utilization – Enter your target utilization percentage for the table.\n\nUse the same capacity read/write capacity settings for all global secondary indexes – Choose whether global secondary indexes should use the same auto scaling policy as the base table.\n\nNote\n\nFor best performance, we recommend that you enable Use the same read/write capacity settings for all global secondary indexes. This option allows DynamoDB auto scaling to uniformly scale all the global secondary indexes on the base table. This includes existing global secondary indexes, and any others that you create for this table in the future.\n\nWith this option enabled, you can't set a scaling policy on an individual global secondary index.\n\nWhen the settings are as you want them, choose Save.\n\nViewing auto scaling activities on the console\n\nAs your application drives read and write traffic to your table, DynamoDB auto scaling dynamically modifies the table's throughput settings. Amazon CloudWatch keeps track of provisioned and consumed capacity, throttled events, latency, and other metrics for all of your DynamoDB tables and secondary indexes.\n\nTo view these metrics in the DynamoDB console, choose the table that you want to work with and choose the Monitor tab. To create a customizable view of table metrics, select View all in CloudWatch.\n\nModifying or disabling DynamoDB auto scaling settings\n\nYou can use the AWS Management Console to modify your DynamoDB auto scaling settings. To do this, go to the Additional settings tab for your table, and choose Edit in the Read/write capacity section. For more information about these settings, see Enabling DynamoDB auto scaling on existing tables."
  },
  {
    "title": "Managing throughput capacity automatically with DynamoDB auto scaling - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html",
    "html": "Managing throughput capacity automatically with DynamoDB auto scaling\nPDF\nRSS\n\nMany database workloads are cyclical in nature, while others are difficult to predict in advance. For one example, consider a social networking app where most of the users are active during daytime hours. The database must be able to handle the daytime activity, but there's no need for the same levels of throughput at night. For another example, consider a new mobile gaming app that is experiencing unexpectedly rapid adoption. If the game becomes too popular it could exceed the available database resources, resulting in slow performance and unhappy customers. These kinds of workloads often require manual intervention to scale database resources up or down in response to varying usage levels.\n\nAmazon DynamoDB auto scaling uses the AWS Application Auto Scaling service to dynamically adjust provisioned throughput capacity on your behalf, in response to actual traffic patterns. This enables a table or a global secondary index to increase its provisioned read and write capacity to handle sudden increases in traffic, without throttling. When the workload decreases, Application Auto Scaling decreases the throughput so that you don't pay for unused provisioned capacity.\n\nNote\n\nIf you use the AWS Management Console to create a table or a global secondary index, DynamoDB auto scaling is enabled by default. You can modify your auto scaling settings at any time. For more information, see Using the AWS Management Console with DynamoDB auto scaling.\n\nWhen you delete a table or global table replica then any associated scalable targets, scaling polices, or CloudWatch alarms are not automatically deleted with it.\n\nWith Application Auto Scaling, you create a scaling policy for a table or a global secondary index. The scaling policy specifies whether you want to scale read capacity or write capacity (or both), and the minimum and maximum provisioned capacity unit settings for the table or index.\n\nThe scaling policy also contains a target utilization—the percentage of consumed provisioned throughput at a point in time. Application Auto Scaling uses a target tracking algorithm to adjust the provisioned throughput of the table (or index) upward or downward in response to actual workloads, so that the actual capacity utilization remains at or near your target utilization.\n\nAuto scaling can be triggered when two data points breach the configured target utilization value within a one-minute span. Therefore, auto scaling can take place because the consumed capacity is above target utilization for two consistent minutes. But if the spikes are more than a minute apart, auto scaling might not be triggered. Similarly, a scale down event can be triggered when 15 consecutive data points are lower than the target utilization. In either case, after auto scaling is triggered an UpdateTable call is invoked. It can then take several minutes to update the provisioned capacity for the table or the index. During this period, any requests that exceed the previous provisioned capacity of the tables will be throttled.\n\nImportant\n\nYou can't adjust the number of data points to breach to trigger the underlying alarm (though the current number could change in the future).\n\nYou can set the auto scaling target utilization values between 20 and 90 percent for your read and write capacity.\n\nNote\n\nIn addition to tables, DynamoDB auto scaling also supports global secondary indexes. Every global secondary index has its own provisioned throughput capacity, separate from that of its base table. When you create a scaling policy for a global secondary index, Application Auto Scaling adjusts the provisioned throughput settings for the index to ensure that its actual utilization stays at or near your desired utilization ratio.\n\nHow DynamoDB auto scaling works\nNote\n\nTo get started quickly with DynamoDB auto scaling, see Using the AWS Management Console with DynamoDB auto scaling.\n\nThe following diagram provides a high-level overview of how DynamoDB auto scaling manages throughput capacity for a table.\n\nThe following steps summarize the auto scaling process as shown in the previous diagram:\n\nYou create an Application Auto Scaling policy for your DynamoDB table.\n\nDynamoDB publishes consumed capacity metrics to Amazon CloudWatch.\n\nIf the table's consumed capacity exceeds your target utilization (or falls below the target) for a specific length of time, Amazon CloudWatch triggers an alarm. You can view the alarm on the console and receive notifications using Amazon Simple Notification Service (Amazon SNS).\n\nThe CloudWatch alarm invokes Application Auto Scaling to evaluate your scaling policy.\n\nApplication Auto Scaling issues an UpdateTable request to adjust your table's provisioned throughput.\n\nDynamoDB processes the UpdateTable request, dynamically increasing (or decreasing) the table's provisioned throughput capacity so that it approaches your target utilization.\n\nTo understand how DynamoDB auto scaling works, suppose that you have a table named ProductCatalog. The table is bulk-loaded with data infrequently, so it doesn't incur very much write activity. However, it does experience a high degree of read activity, which varies over time. By monitoring the Amazon CloudWatch metrics for ProductCatalog, you determine that the table requires 1,200 read capacity units (to avoid DynamoDB throttling read requests when activity is at its peak). You also determine that ProductCatalog requires 150 read capacity units at a minimum, when read traffic is at its lowest point. For more information about preventing throttling, see Throttling issues for DynamoDB tables using provisioned capacity mode.\n\nWithin the range of 150 to 1,200 read capacity units, you decide that a target utilization of 70 percent would be appropriate for the ProductCatalog table. Target utilization is the ratio of consumed capacity units to provisioned capacity units, expressed as a percentage. Application Auto Scaling uses its target tracking algorithm to ensure that the provisioned read capacity of ProductCatalog is adjusted as required so that utilization remains at or near 70 percent.\n\nNote\n\nDynamoDB auto scaling modifies provisioned throughput settings only when the actual workload stays elevated or depressed for a sustained period of several minutes. The Application Auto Scaling target tracking algorithm seeks to keep the target utilization at or near your chosen value over the long term.\n\nSudden, short-duration spikes of activity are accommodated by the table's built-in burst capacity. For more information, see Burst capacity.\n\nTo enable DynamoDB auto scaling for the ProductCatalog table, you create a scaling policy. This policy specifies the following:\n\nThe table or global secondary index that you want to manage\n\nWhich capacity type to manage (read capacity or write capacity)\n\nThe upper and lower boundaries for the provisioned throughput settings\n\nYour target utilization\n\nWhen you create a scaling policy, Application Auto Scaling creates a pair of Amazon CloudWatch alarms on your behalf. Each pair represents the upper and lower boundaries for your provisioned throughput settings. These CloudWatch alarms are triggered when the table's actual utilization deviates from your target utilization for a sustained period of time.\n\nWhen one of the CloudWatch alarms is triggered, Amazon SNS sends you a notification (if you have enabled it). The CloudWatch alarm then invokes Application Auto Scaling, which in turn notifies DynamoDB to adjust the ProductCatalog table's provisioned capacity upward or downward as appropriate.\n\nDuring a scaling event, AWS Config is charged per configuration item recorded. When a scaling event occurs, four CloudWatch alarms are created for each read and write auto-scaling event: ProvisionedCapacity alarms: ProvisionedCapacityLow, ProvisionedCapacityHigh and ConsumedCapacity alarms: AlarmHigh, AlarmLow. This results in a total of eight alarms. Therefore, AWS Config records eight configuration items for every scaling event.\n\nNote\n\nYou can also schedule your DynamoDB scaling so it happens at certain times. Learn the basic steps here.\n\nUsage notes\n\nBefore you begin using DynamoDB auto scaling, you should be aware of the following:\n\nDynamoDB auto scaling can increase read capacity or write capacity as often as necessary, in accordance with your auto scaling policy. All DynamoDB quotas remain in effect, as described in Service, account, and table quotas in Amazon DynamoDB.\n\nDynamoDB auto scaling doesn't prevent you from manually modifying provisioned throughput settings. These manual adjustments don't affect any existing CloudWatch alarms that are related to DynamoDB auto scaling.\n\nIf you enable DynamoDB auto scaling for a table that has one or more global secondary indexes, we highly recommend that you also apply auto scaling uniformly to those indexes. This will help ensure better performance for table writes and reads, and help avoid throttling. You can enable auto scaling by selecting Apply same settings to global secondary indexes in the AWS Management Console. For more information, see Enabling DynamoDB auto scaling on existing tables.\n\nWhen you delete a table or global table replica, any associated scalable targets, scaling polices or CloudWatch alarms are not automatically deleted with it.\n\nWhen creating a GSI for an existing table, auto scaling is not enabled for the GSI. You will have to manually manage the capacity while the GSI is being built. Once the backfill on the GSI completes and it reaches active status, auto scaling will operate as normal."
  },
  {
    "title": "Provisioned capacity mode - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/provisioned-capacity-mode.html",
    "html": "Provisioned capacity mode\nPDF\nRSS\n\nWhen you create a new provisioned table in DynamoDB, you must specify its provisioned throughput capacity. This is the amount of read and write throughput that the table can support. DynamoDB uses this information to ensure there are sufficient system resources to meet your throughput requirements.\n\nYou can optionally allow DynamoDB auto scaling to manage your table's throughput capacity. To use auto scaling, you must provide the initial settings for read and write capacity when you create the table. DynamoDB auto scaling uses these initial settings as a starting point and then adjusts them dynamically in response to your application's requirements. For more information, see Managing throughput capacity automatically with DynamoDB auto scaling.\n\nAs your application's data and access requirements change, you might need to adjust your table's throughput settings. If you're using DynamoDB auto scaling, the throughput settings are automatically adjusted in response to actual workloads. You can also use the UpdateTable operation to manually adjust your table's throughput capacity. You might decide to do this if you need to bulk-load data from an existing data store into your new DynamoDB table. You could create the table with a large write throughput setting and then reduce this setting after the bulk data load is complete.\n\nYou can switch tables from on-demand mode to provisioned capacity mode at any time. When you do multiple switches between capacity modes, the following conditions apply:\n\nYou can switch a newly created table in on-demand mode to provisioned capacity mode at any time. However, you can only switch it back to on-demand mode 24 hours after the table’s creation timestamp.\n\nYou can switch an existing table in on-demand mode to provisioned capacity mode at any time. However, you can only switch it back to on-demand mode 24 hours after the last timestamp indicating a switch to on-demand.\n\nFor more information about switching between read and write capacity modes, see Considerations when switching capacity modes.\n\nTopics\nRead capacity units and write capacity units\nChoosing initial throughput settings\nDynamoDB auto scaling\nManaging throughput capacity automatically with DynamoDB auto scaling\nReserved capacity\nRead capacity units and write capacity units\n\nFor provisioned mode tables, you specify throughput requirements in terms of capacity units. These units represent the amount of data your application needs to read or write per second. You can modify these settings later, if needed, or enable DynamoDB auto scaling to modify them automatically.\n\nFor an item up to 4 KB, one read capacity unit represents one strongly consistent read operation per second, or two eventually consistent read operations per second. For more information about DynamoDB read consistency models, see Read consistency.\n\nA write capacity unit represents one write per second for an item up to 1 KB. For more information about the different read and write operations, see Read and write operations.\n\nChoosing initial throughput settings\n\nEvery application has different requirements for reading from and writing to a database. When you're determining the initial throughput settings for a DynamoDB table, consider the following:\n\nExpected read and write request rates — You should estimate the number of reads and writes you need to perform per second.\n\nItem sizes — Some items are small enough that they can be read or written using a single capacity unit. Larger items require multiple capacity units. By estimating the average size of the items that will be in your table, you can specify accurate settings for your table's provisioned throughput.\n\nRead consistency requirements — Read capacity units are based on strongly consistent read operations, which consume twice as many database resources as eventually consistent reads. You should determine whether your application requires strongly consistent reads, or whether it can relax this requirement and perform eventually consistent reads instead. Read operations in DynamoDB are eventually consistent, by default. You can request strongly consistent reads for these operations, if necessary.\n\nFor example, say that you want to read 80 items per second from a table. The size of these items is 3 KB, and you want strongly consistent reads. In this case, each read requires one provisioned read capacity unit. To determine this number, divide the item size of the operation by 4 KB. Then, round up to the nearest whole number, as shown in the following example:\n\n3 KB / 4 KB = 0.75 or 1 read capacity unit\n\nTherefore, to read 80 items per second from a table, set the table's provisioned read throughput to 80 read capacity units as shown in the following example:\n\n1 read capacity unit per item × 80 reads per second = 80 read capacity units\n\nNow suppose that you want to write 100 items per second to your table and that the size of each item is 512 bytes. In this case, each write requires one provisioned write capacity unit. To determine this number, divide the item size of the operation by 1 KB. Then, round up to the nearest whole number, as shown in the following example:\n\n512 bytes / 1 KB = 0.5 or 1 write capacity unit\n\nTo write 100 items per second to your table, set the table's provisioned write throughput to 100 write capacity units:\n\n1 write capacity unit per item × 100 writes per second = 100 write capacity units\n\nDynamoDB auto scaling\n\nDynamoDB auto scaling actively manages provisioned throughput capacity for tables and global secondary indexes. With auto scaling, you define a range (upper and lower limits) for read and write capacity units. You also define a target utilization percentage within that range. DynamoDB auto scaling seeks to maintain your target utilization, even as your application workload increases or decreases.\n\nWith DynamoDB auto scaling, a table or a global secondary index can increase its provisioned read and write capacity to handle sudden increases in traffic, without request throttling. When the workload decreases, DynamoDB auto scaling can decrease the throughput so that you don't pay for unused provisioned capacity.\n\nNote\n\nIf you use the AWS Management Console to create a table or a global secondary index, DynamoDB auto scaling is enabled by default.\n\nYou can manage auto scaling settings at any time by using the console, the AWS CLI, or one of the AWS SDKs. For more information, see Managing throughput capacity automatically with DynamoDB auto scaling.\n\nUtilization rate\n\nUtilization rate can help you determine if you’re over provisioning capacity, in which case should reduce your table capacity to save costs. Conversely, it can also help you determine if you’re under provisioning capacity. In this case, you should increase table capacity to prevent potential throttling of requests during unexpected high traffic instances. For more information, see Amazon DynamoDB auto scaling: Performance and cost optimization at any scale.\n\nIf you’re using DynamoDB auto scaling, you’ll also need to set a target utilization percentage. Auto scaling will use this percentage as a target to adjust capacity upward or downward. We recommend setting target utilization to 70%. For more information, see Managing throughput capacity automatically with DynamoDB auto scaling."
  },
  {
    "title": "Pre-warming a table for on-demand capacity mode - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/pre-warming-on-demand-capacity-mode.html",
    "html": "Pre-warming a table for on-demand capacity mode\nPDF\nRSS\n\nFor on-demand tables, DynamoDB automatically allocates more capacity as your traffic volume increases. New on-demand tables will be able to sustain up to 4,000 writes per second and 12,000 reads per second. The overall table won't be throttled if the table access is distributed evenly across partitions and the table doesn't exceed twice its previous peak traffic. However, throttling can still occur if the throughput exceeds twice the previous peak within the same 30 minutes.\n\nOne solution is to pre-warm the tables to the anticipated peak capacity of the spike. Make sure to check your account limits and confirm that you can reach the desired capacity in provisioned mode. See Throughput default quotas for more information on both account-level and table-level limits.\n\nNote\n\nIf you're pre-warming an existing table, or a new table in on-demand mode, start this process at least 24 hours before the anticipated peak. There're certain conditions to the number of switches you can perform in a 24-hour period. For information about these conditions, see Considerations when switching capacity modes.\n\nTo pre-warm a table, do the following steps:\n\nBased on the capacity mode of your table, do one of the following steps:\n\nTo pre-warm a table that's currently in on-demand mode, switch it to provisioned mode.\n\nTo pre-warm a new table that is in provisioned mode, or has already been in provisioned mode, proceed to the next step without waiting.\n\nSet the table's write throughput to the desired peak value, and keep it there for several minutes. You'll incur cost from this high volume of throughput until you switch back to on-demand.\n\nSwitch to on-demand capacity mode. This should allow the table to handle a similar number of requests to the provisioned throughput capacity values."
  },
  {
    "title": "Maximum throughput for on-demand tables - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/on-demand-capacity-mode-max-throughput.html",
    "html": "Maximum throughput for on-demand tables\nPDF\nRSS\n\nFor on-demand tables, you can optionally specify maximum read or write (or both) throughput per second on individual tables and associated global secondary indexes (GSIs). Specifying a maximum on-demand throughput helps keep table-level usage and costs bounded. By default, maximum throughput settings don’t apply and your on-demand throughput rate is bounded by the AWS service quota for all tables or GSIs within a table. If needed, you can request an increase to your service quota.\n\nWhen you configure maximum throughput for an on-demand table, throughput requests that exceed the maximum amount specified will be throttled. You can modify the table-level throughput settings any time based on your application requirements.\n\nThe following are some common use cases that can benefit from using maximum throughput for on-demand tables:\n\nThroughput cost optimization – Using maximum throughput for on-demand tables provides an additional layer of cost predictability and manageability. Additionally, it offers greater flexibility to use on-demand mode to support workloads with differing traffic patterns and budget.\n\nProtection against excessive usage – By setting maximum throughput, you can prevent an accidental surge in read or write consumption, which might arise from non-optimized code or rogue processes, against an on-demand table. This table-level setting can protect organizations from consuming excessive resources within a certain time frame.\n\nSafeguarding downstream services – A customer application can include serverless and non-serverless technologies. The serverless piece of the architecture can scale rapidly to match demand. But downstream components with fixed capacities could be overwhelmed. Implementing maximum throughput settings for on-demand tables can prevent large volume of events from propagating to multiple downstream components with unexpected side effects.\n\nYou can configure maximum throughput for on-demand mode for new and existing single-Region tables and global tables and GSIs. You can also configure maximum throughput during table restore and data import from Amazon S3 workflows.\n\nYou can specify maximum throughput settings for an on-demand tables using the DynamoDB console, AWS CLI, AWS CloudFormation, or DynamoDB API.\n\nNote\n\nThe maximum throughput for an on-demand table is applied on a best-effort basis and should be thought of as targets instead of guaranteed request ceilings. Your workload might temporarily exceed the maximum throughput specified because of burst capacity. In some cases, DynamoDB uses burst capacity to accommodate reads or writes in excess of your table's maximum throughput settings. With burst capacity, unexpected read or write requests can succeed where they otherwise would be throttled.\n\nTopics\nConsiderations when using maximum throughput for on-demand mode\nRequest throttling and CloudWatch metrics\nConsiderations when using maximum throughput for on-demand mode\n\nWhen you use maximum throughput for tables in on-demand mode, the following considerations apply:\n\nYou can independently set maximum throughput for reads and writes for any on-demand table, or individual global secondary index within that table to fine-tune your approach based on specific requirements.\n\nYou can use Amazon CloudWatch to monitor and understand DynamoDB table-level usage metrics and to determine appropriate maximum throughput settings for on-demand mode. For more information, see DynamoDB Metrics and dimensions.\n\nWhen you specify the maximum read or write (or both) throughput settings on one global table replica, the same maximum throughput settings are automatically applied to all replica tables. It's important that the replica tables and secondary indexes in a global table have identical write throughput settings to ensure proper replication of data. For more information, see Best practices and requirements for managing global tables.\n\nThe smallest maximum read or write throughput that you can specify is one request unit per second.\n\nThe maximum throughput you specify must be lower than the default throughput quota that is available for any on-demand table, or individual global secondary index within that table.\n\nRequest throttling and CloudWatch metrics\n\nIf your application exceeds the maximum read or write throughput you've set on your on-demand table, DynamoDB begins to throttle those requests. When DynamoDB throttles a read or write, it returns a ThrottlingException to the caller. You can then take appropriate action, if required. For example, you can increase or disable the maximum table throughput setting, or wait for a short interval before retrying the request.\n\nTo simplify monitoring the maximum throughput configured for a table or global secondary index, CloudWatch provides the following metrics: OnDemandMaxReadRequestUnits and OnDemandMaxWriteRequestUnits."
  },
  {
    "title": "On-demand capacity mode - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/on-demand-capacity-mode.html",
    "html": "On-demand capacity mode\nPDF\nRSS\n\nAmazon DynamoDB on-demand is a serverless billing option that can serve millions of requests per second without capacity planning. DynamoDB on-demand offers pay-per-request pricing for read and write requests so that you only pay for what you use.\n\nWhen you choose on-demand mode, DynamoDB instantly accommodates your workloads as they ramp up or down to any previously reached traffic level. If a workload’s traffic level hits a new peak, DynamoDB adapts rapidly to accommodate the workload. For more information about on-demand mode's scaling properties, see Initial throughput and scaling properties.\n\nTables that use on-demand mode deliver the same single-digit millisecond latency, service-level agreement (SLA) commitment, and security that DynamoDB already offers. You can choose on-demand for both new and existing tables and you can continue using the existing DynamoDB APIs without changing code.\n\nThe on-demand throughput rate is bounded by the table-level throughput quota which applies to all tables with the account. You can request an increase for this quota. For more information, see Throughput default quotas.\n\nOptionally, you can also configure maximum read or write (or both) throughput per second for individual on-demand tables and global secondary indexes. By configuring throughput, you can keep table-level usage and costs bounded, protect against inadvertent surge in consumed resources, and prevent excessive use for predictable cost management. Throughput requests that exceed the maximum table throughput are throttled. You can modify the table-specific maximum throughput at any time based on your application requirements. For more information, see Maximum throughput for on-demand tables.\n\nTo get started, create or update a table to use on-demand mode. For more information, see Basic operations on DynamoDB tables.\n\nYou can switch tables from on-demand mode to provisioned capacity mode at any time. When you do multiple switches between capacity modes, the following conditions apply:\n\nYou can switch a newly created table in on-demand mode to provisioned capacity mode at any time. However, you can only switch it back to on-demand mode 24 hours after the table’s creation timestamp.\n\nYou can switch an existing table in on-demand mode to provisioned capacity mode at any time. However, you can only switch it back to on-demand mode 24 hours after the last timestamp indicating a switch to on-demand.\n\nFor more information about switching between read and write capacity modes, see Considerations when switching capacity modes.\n\nTopics\nRead request units and write request units\nInitial throughput and scaling properties\nMaximum throughput for on-demand tables\nPre-warming a table for on-demand capacity mode\nRead request units and write request units\n\nDynamoDB charges you for the reads and writes that your application performs on your tables in terms of read request units and write request units.\n\nOne read request unit represents one strongly consistent read operation per second, or two eventually consistent read operations per second, for an item up to 4 KB in size. For more information about DynamoDB read consistency models, see Read consistency.\n\nOne write request unit represents one write operation per second, for an item up to 1 KB in size.\n\nFor more information about how read and write units are consumed, see Read and write operations.\n\nInitial throughput and scaling properties\n\nDynamoDB tables using on-demand capacity mode automatically adapt to your application’s traffic volume. New on-demand tables will be able to sustain up to 4,000 writes per second and 12,000 reads per second. On-demand capacity mode instantly accommodates up to double the previous peak traffic on a table. For example, say that your application’s traffic pattern varies between 25,000 and 50,000 strongly consistent reads per second. 50,000 reads per second is the previous traffic peak. On-demand capacity mode instantly accommodates sustained traffic of up to 100,000 reads per second. If your application sustains traffic of 100,000 reads per second, that peak becomes your new previous peak. This previous peak enables subsequent traffic to reach up to 200,000 reads per second.\n\nIf your workload generates more than double your previous peak on a table, DynamoDB automatically allocates more capacity as your traffic volume increases. This capacity allocation helps ensure that your workload doesn't experience throttling. However, throttling can occur if you exceed double your previous peak within 30 minutes. For example, say that your application’s traffic pattern varies between 25,000 and 50,000 strongly consistent reads per second. 50,000 reads per second is the previously reached traffic peak. We recommend that you either pre-warm your table or space your traffic growth over at least 30 minutes before driving more than 100,000 reads per second. For more information about pre-warming, see Pre-warming a table for on-demand capacity mode.\n\nDynamoDB doesn’t place the 30 minute throttling restriction if your workload’s peak traffic remains within double your previous peak. If your peak traffic exceeds double the peak, make sure that this growth occurs 30 minutes after you last reached the peak."
  },
  {
    "title": "DynamoDB throughput capacity - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/capacity-mode.html",
    "html": "DynamoDB throughput capacity\nPDF\nRSS\n\nA table’s throughput capacity mode determines how the capacity of a table is managed. Throughput capacity also determines how you're charged for the read and write operations on your tables. In Amazon DynamoDB, you can choose between on-demand mode and provisioned mode for your tables to accommodate different workload requirements.\n\nTopics\nDynamoDB capacity modes overview\nOn-demand capacity mode\nProvisioned capacity mode\nBurst and adaptive capacity\nDynamoDB capacity modes overview\n\nThis section provides an overview of the two capacity modes available for your DynamoDB table and considerations in selecting the appropriate capacity mode for your application. These modes allow you to meet different needs based on requirements for responsiveness and how usage is managed.\n\nOn-demand mode\n\nAmazon DynamoDB on-demand is a serverless billing option that can serve millions of requests per second without capacity planning. DynamoDB on-demand offers pay-per-request pricing for read and write requests so that you only pay for what you use.. For on-demand mode tables, you don't need to specify how much read and write throughput you expect your application to perform.\n\nWith on-demand mode, DynamoDB handles all aspects of throughput management. You can make API calls as needed without managing throughput capacity on the table.\n\nOn-demand capacity mode might be the best for you if any of the following apply:\n\nYou’re just getting started with Amazon DynamoDB.\n\nYou’re developing, testing, prototyping, and running in production new applications where the traffic pattern is unknown.\n\nYour application has bursty, intermittent, or unpredictable traffic that is hard to forecast.\n\nYou prefer the ease of paying for only what you use.\n\nFor more information, see On-demand capacity mode.\n\nProvisioned mode\n\nIn provisioned mode, you specify the number of reads and writes per second that you require for your application. You'll be charged for the throughput capacity even if you don't fully utilize the provisioned capacity. You'll be charged based on the hourly read and write capacity you have provisioned. You can use Auto Scaling to adjust your table’s provisioned capacity automatically in response to traffic changes. This helps you govern your DynamoDB use to stay at or below a defined request rate in order to obtain cost predictability.\n\nProvisioned capacity mode might be the best for you if any of the following apply:\n\nYou have predictable or cyclical application traffic.\n\nYou run applications where the traffic is consistent or ramps gradually.\n\nYou can forecast capacity requirements to control costs.\n\nYou have limited short-term bursts of traffic.\n\nFor more information, see Provisioned capacity mode.\n\nThe following video provides an introduction to table throughput capacity. This video also describes how to select a capacity mode based on your requirements."
  },
  {
    "title": "Read and write operations - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/read-write-operations.html",
    "html": "Read and write operations\nPDF\nRSS\n\nDynamoDB read operations allow you to retrieve one or more items from a table by specifying the partition key value and, optionally, the sort key value. Using DynamoDB write operations, you can insert, update, or delete items in a table. This topic explains capacity unit consumption for these two operations.\n\nTopics\nCapacity unit consumption for read operations\nCapacity unity consumption for write operations\nCapacity unit consumption for read operations\n\nDynamoDB read requests can be either strongly consistent, eventually consistent, or transactional.\n\nA strongly consistent read request of an item up to 4 KB requires one read unit.\n\nAn eventually consistent read request of an item up to 4 KB requires one-half read unit.\n\nA transactional read request of an item up to 4 KB requires two read units.\n\nTo learn more about DynamoDB read consistency models, see Read consistency.\n\nItem sizes for reads are rounded up to the next 4 KB multiple. For example, reading a 3,500-byte item consumes the same throughput as reading a 4 KB item.\n\nIf you need to read an item that is larger than 4 KB, DynamoDB needs additional read units. The total number of read units required depends on the item size, and whether you want an eventually consistent or strongly consistent read. For example, if your item size is 8 KB, you require 2 read units to sustain one strongly consistent read. You'll require 1 read unit if you choose eventually consistent reads or 4 read units for a transactional read request.\n\nThe following list describes how DynamoDB read operations consume read units:\n\nGetItem: Reads a single item from a table. To determine the number of read units that GetItem will consume, take the item size and round it up to the next 4 KB boundary. This is the number of read units required if you specified a strongly consistent read. For an eventually consistent read, which is the default, divide this number by two.\n\nFor example, if you read an item that is 3.5 KB, DynamoDB rounds the item size to 4 KB. If you read an item of 10 KB, DynamoDB rounds the item size to 12 KB.\n\nBatchGetItem: Reads up to 100 items from one or more tables. DynamoDB processes each item in the batch as an individual GetItem request. DynamoDB first rounds up the size of each item to the next 4 KB boundary and then calculates the total size. The result isn't necessarily the same as the total size of all the items. For example, if BatchGetItem reads two items of sizes 1.5 KB and 6.5 KB, DynamoDB calculates the size as 12 KB (4 KB + 8 KB). DynamoDB doesn’t calculate the size as 8 KB (1.5 KB + 6.5 KB).\n\nQuery: Reads multiple items that have the same partition key value. All items returned are treated as a single read operation, where DynamoDB computes the total size of all items. DynamoDB then rounds up the size to the next 4 KB boundary. For example, suppose your query returns 10 items whose combined size is 40.8 KB. DynamoDB rounds the item size for the operation to 44 KB. If a query returns 1500 items of 64 bytes each, the cumulative size is 96 KB.\n\nScan: Reads all items in a table. DynamoDB considers the size of the items that are evaluated, not the size of the items returned by the scan. For more information about Scan operations, see Working with scans in DynamoDB.\n\nImportant\n\nIf you perform a read operation on an item that doesn't exist, DynamoDB will still consume read throughput as outlined above. For Query/Scan operations, you'll still be charged additional read throughput based on read consistency and the number of partitions searched to serve the request, even if no data exists.\n\nFor any operation that returns items, you can request a subset of attributes to retrieve. However, doing so has no impact on the item size calculations. In addition, Query and Scan can return item counts instead of attribute values. Getting the count of items uses the same quantity of read units and is subject to the same item size calculations. This is because DynamoDB has to read each item in order to increment the count.\n\nCapacity unity consumption for write operations\n\nOne write unit represents one write for an item up to 1 KB in size. If you need to write an item that is larger than 1 KB, DynamoDB needs to consume additional write units. Transactional write requests require 2 write units to perform one write for items up to 1 KB. The total number of write request units required depends on the item size. For example, if your item size is 2 KB, you require 2 write units to sustain one write request or 4 write units for a transactional write request.\n\nItem sizes for writes are rounded up to the next 1 KB multiple. For example, writing a 500-byte item consumes the same throughput as writing a 1 KB item.\n\nThe following list describes how DynamoDB write operations consume write units:\n\nPutItem: Writes a single item to a table. If an item with the same primary key exists in the table, the operation replaces the item. For calculating provisioned throughput consumption, the item size that matters is the larger of the two.\n\nUpdateItem: Modifies a single item in the table. DynamoDB considers the size of the item as it appears before and after the update. The provisioned throughput consumed reflects the larger of these item sizes. Even if you update a subset of the item's attributes, UpdateItem will still consume the full amount of provisioned throughput (the larger of the \"before\" and \"after\" item sizes).\n\nDeleteItem: Removes a single item from a table. The provisioned throughput consumption is based on the size of the deleted item.\n\nBatchWriteItem: Writes up to 25 items to one or more tables. DynamoDB processes each item in the batch as an individual PutItem or DeleteItem request (updates are not supported). DynamoDB first rounds up the size of each item to the next 1 KB boundary, and then calculates the total size. The result isn't necessarily the same as the total size of all the items. For example, if BatchWriteItem writes two items of sizes 500-byte and 3.5 KB, DynamoDB calculates the size as 5 KB (1 KB + 4 KB). DynamoDB doesn’t calculate the size as 4 KB (500 bytes + 3.5 KB).\n\nFor PutItem, UpdateItem, and DeleteItem operations, DynamoDB rounds the item size up to the next 1 KB. For example, if you put or delete an item of 1.6 KB, DynamoDB rounds the item size up to 2 KB.\n\nPutItem, UpdateItem, and DeleteItem operations allow conditional writes, where you specify an expression that must evaluate to true for the operation to succeed. If the expression evaluates to false, DynamoDB still consumes write capacity units from the table. The amount of consumed write capacity units depends on the size of the item. This item can be an existing item in the table or a new one you're attempting to create or update. For example, say that an existing item is 300 KB. The new item you’re trying to create or update is 310 KB. The write capacity units consumed will be 310 KB for the new item."
  },
  {
    "title": "Read consistency - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html",
    "html": "Read consistency\nPDF\nRSS\n\nAmazon DynamoDB reads data from tables, local secondary indexes (LSIs), global secondary indexes (GSIs), and streams. For more information, see Core components of Amazon DynamoDB. Both tables and LSIs provide two read consistency options: eventually consistent (default) and strongly consistent reads. All reads from GSIs and streams are eventually consistent.\n\nWhen your application writes data to a DynamoDB table and receives an HTTP 200 response (OK), that means the write completed successfully and has been durably persisted. DynamoDB provides read-committed isolation and ensures that read operations always return committed values for an item. The read will never present a view to the item from a write which did not ultimately succeed. Read-committed isolation does not prevent modifications of the item immediately after the read operation.\n\nEventually Consistent Reads\n\nEventually consistent is the default read consistent model for all read operations. When issuing eventually consistent reads to a DynamoDB table or an index, the responses may not reflect the results of a recently completed write operation. If you repeat your read request after a short time, the response should eventually return the more recent item. Eventually consistent reads are supported on tables, local secondary indexes, and global secondary indexes. Also note that all reads from a DynamoDB stream are also eventually consistent.\n\nEventually consistent reads are half the cost of strongly consistent reads. For more information, see Amazon DynamoDB pricing.\n\nStrongly Consistent Reads\n\nRead operations such as GetItem, Query, and Scan provide an optional ConsistentRead parameter. If you set ConsistentRead to true, DynamoDB returns a response with the most up-to-date data, reflecting the updates from all prior write operations that were successful. Strongly consistent reads are only supported on tables and local secondary indexes. Strongly consistent reads from a global secondary index or a DynamoDB stream are not supported.\n\nGlobal tables read consistency\n\nDynamoDB also supports global tables for multi-active and multi-Region replication. A global table is composed of multiple replica tables in different AWS Regions. Any change made to any item in any replica table is replicated to all the other replicas within the same global table, typically within a second, and are eventually consistent. For more information, see Consistency and conflict resolution."
  },
  {
    "title": "DynamoDB reads and writes - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ddb-reads-writes.html",
    "html": "DynamoDB reads and writes\nPDF\nRSS\n\nDynamoDB reads and writes refer to the operations that retrieve data from a table (reads) and insert, update, or delete data in a table (writes). When you work with DynamoDB, it's essential to understand the concepts of reads and writes, because they directly impact the performance and cost of your application.\n\nThis topic provides details about the different types of read consistency that apply to DynamoDB. This topic also describes the unit consumption for different read and write operations that you might perform.\n\nTopics\nRead consistency\nRead and write operations"
  },
  {
    "title": "Training courses - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AdditionalResources.Training.html",
    "html": "Training courses\nPDF\nRSS\n\nThere are many different training courses and educational options for learning more about DynamoDB. Here are some current examples:\n\nDeveloping with Amazon DynamoDB – Designed by AWS to take you from beginner to expert in developing real-world applications with data modeling for Amazon DynamoDB.\n\nDynamoDB deep-dive course – A course from A Cloud Guru.\n\nAmazon DynamoDB: Building NoSQL database-driven applications – A course from the AWS Training and Certification team hosted on edX."
  },
  {
    "title": "Data modeling and design pattern presentations - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AdditionalResources.DataModeling.html",
    "html": "Data modeling and design pattern presentations\nPDF\nRSS\n\nYou can use the following resources on data modeling and design patterns to help you get the most out of DynamoDB:\n\nAWS re:Invent 2019: Data modeling with DynamoDB\n\nA talk by Alex DeBrie that helps you started with the principles of DynamoDB data modeling.\n\nAWS re:Invent 2020: Data modeling with DynamoDB – Part 1\n\nAWS re:Invent 2020: Data modeling with DynamoDB – Part 2\n\nAWS re:Invent 2017: Advanced design patterns\n\nAWS re:Invent 2018: Advanced design patterns\n\nAWS re:Invent 2019: Advanced design patterns\n\nJeremy Daly shares his 12 key takeaways from this session.\n\nAWS re:Invent 2020: DynamoDB advanced design patterns – Part 1\n\nAWS re:Invent 2020: DynamoDB advanced design patterns – Part 2\n\nDynamoDB Office Hours on Twitch\n\nNote\n\nEach session covers different use cases and examples."
  },
  {
    "title": "Knowledge Center articles - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AdditionalResources.KnowledgeCenter.html",
    "html": "Knowledge Center articles\nPDF\nRSS\n\nThe AWS Knowledge Center articles and videos cover the most frequent questions and requests that we receive from AWS customers. The following are some current Knowledge Center articles on specific tasks that relate to DynamoDB:\n\nCost optimization\n\nHow do I optimize costs with Amazon DynamoDB?\n\nThrottling and latency\n\nWhy is my DynamoDB maximum latency metric high when the average latency is normal?\n\nWhy is my DynamoDB table being throttled?\n\nWhy is my on-demand DynamoDB table being throttled?\n\nPagination\n\nHow do I implement pagination in DynamoDB\n\nTransactions\n\nWhy is my TransactWriteItems API call failing in DynamoDB\n\nTroubleshooting\n\nHow do I resolve issues with DynamoDB auto scaling?\n\nHow do I troubleshoot HTTP 4XX errors in DynamoDB\n\nFor additional articles and videos for DynamoDB, see the Knowledge Center articles."
  },
  {
    "title": "Prescriptive Guidance articles - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AdditionalResources.PrescriptiveGuidance.html",
    "html": "Prescriptive Guidance articles\nPDF\nRSS\n\nAWS Prescriptive Guidance provides time-tested strategies, guides, and patterns to help accelerate your projects. These resources were developed by AWS technology experts and the global community of AWS Partners, based on their years of experience helping customers achieve their business objectives.\n\nData modeling and migration\n\nA hierarchical data model in DynamoDB\n\nModeling data with DynamoDB\n\nMigrate an Oracle database to DynamoDB using AWS DMS\n\nGlobal tables\n\nUsing Amazon DynamoDB global tables\n\nServerless\n\nImplement the serverless saga pattern with AWS Step Functions\n\nSaaS architecture\n\nManage tenants across multiple SaaS products on a single control plane\n\nTenant onboarding in SaaS architecture for the silo model using C# and AWS CDK\n\nData protection and data movement\n\nConfigure cross-account access to Amazon DynamoDB\n\nFull table copy options for DynamoDB\n\nDisaster recovery strategy for databases on AWS\n\nMiscellaneous\n\nHelp enforce tagging in DynamoDB\n\nPrescriptive guidance video walkthroughs\n\nUsing Serverless Architecture to Create Data Pipelines\n\nNovartis - Buying Engine: AI-powered Procurement Portal\n\nVeritiv: Enable Insights to Forecast Sales Demand on AWS Data Lakes\n\nmimik: Hybrid Edge Cloud Leveraging AWS to Support Edge Microservice Mesh\n\nChange Data Capture with Amazon DynamoDB\n\nFor additional Prescriptive Guidance articles and videos for DynamoDB, see Prescriptive Guidance."
  },
  {
    "title": "Tools for coding and visualization - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AdditionalResources.Tools.html",
    "html": "Tools for coding and visualization\nPDF\nRSS\n\nYou can use the following coding and visualization tools to work with DynamoDB:\n\nNoSQL Workbench for Amazon DynamoDB – A unified, visual tool that helps you design, create, query, and manage DynamoDB tables. It provides data modeling, data visualization, and query development features.\n\nDynobase – A desktop tool that makes it easy to see your DynamoDB tables and work with them, create app code, and edit records with real-time validation.\n\nDynamoDB Toolbox – A project from Jeremy Daly that provides helpful utilities for working with data modeling andJavaScript and Node.js.\n\nDynamoDB Streams Processor – A simple tool that you can use to work with DynamoDB streams."
  },
  {
    "title": "Additional resources for Amazon DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AdditionalResources.html",
    "html": "Additional resources for Amazon DynamoDB\nPDF\nRSS\n\nYou can use the following additional resources to understand and work with DynamoDB.\n\nTopics\nTools for coding and visualization\nPrescriptive Guidance articles\nKnowledge Center articles\nBlog posts, repositories, and guides\nData modeling and design pattern presentations\nTraining courses"
  },
  {
    "title": "Deleting data from a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.DeleteData.html",
    "html": "Deleting data from a table\nPDF\nRSS\n\nIn SQL, the DELETE statement removes one or more rows from a table. Amazon DynamoDB uses the DeleteItem operation to delete one item at a time.\n\nTopics\nDeleting data from a table with SQL\nDeleting data from a table in DynamoDB\nDeleting data from a table with SQL\n\nIn SQL, you use the DELETE statement to delete one or more rows. The WHERE clause determines the rows that you want to modify. The following is an example.\n\nDELETE FROM Music\nWHERE Artist = 'The Acme Band' AND SongTitle = 'Look Out, World';\n\nYou can modify the WHERE clause to delete multiple rows. For example, you could delete all of the songs by a particular artist, as shown in the following example.\n\nDELETE FROM Music WHERE Artist = 'The Acme Band'\nNote\n\nIf you omit the WHERE clause, the database attempts to delete all of the rows from the table.\n\nDeleting data from a table in DynamoDB\n\nIn DynamoDB, you can use either the DynamoDB API or PartiQL (a SQL-compatible query language) to delete a single item. If you want to modify multiple items, you must use multiple operations.\n\nDynamoDB API\nPartiQL for DynamoDB\n\nWith the DynamoDB API, you use the DeleteItem operation to delete data from a table, one item at a time. You must specify the item's primary key values.\n\n{\n    TableName: \"Music\",\n    Key: {\n        Artist: \"The Acme Band\",\n        SongTitle: \"Look Out, World\"\n    }\n}\nNote\n\nIn addition to DeleteItem, Amazon DynamoDB supports a BatchWriteItem operation for deleting multiple items at the same time.\n\nDeleteItem supports conditional writes, where the operation succeeds only if a specific ConditionExpression evaluates to true. For example, the following DeleteItem operation deletes the item only if it has a RecordLabel attribute.\n\n{\n    TableName: \"Music\",\n    Key: {\n        Artist: \"The Acme Band\",\n        SongTitle: \"Look Out, World\"\n    },\n   ConditionExpression: \"attribute_exists(RecordLabel)\"\n}\nNote\n\nFor code examples that use DeleteItem, see Getting started with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Removing a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.RemoveTable.html",
    "html": "Removing a table\nPDF\nRSS\n\nIn SQL, you use the DROP TABLE statement to remove a table. In Amazon DynamoDB, you use the DeleteTable operation.\n\nTopics\nRemoving a table with SQL\nRemoving a table in DynamoDB\nRemoving a table with SQL\n\nWhen you no longer need a table and want to discard it permanently, you would use the DROP TABLE statement in SQL.\n\nDROP TABLE Music;\n\nAfter a table is dropped, it cannot be recovered. (Some relational databases do allow you to undo a DROP TABLE operation, but this is vendor-specific functionality and it is not widely implemented.)\n\nRemoving a table in DynamoDB\n\nIn DynamoDB, DeleteTable is a similar operation. In the following example, the table is permanently deleted.\n\n{\n    TableName: \"Music\"\n}\nNote\n\nFor code examples that use DeleteTable, see Getting started with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Creating an index - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.Indexes.Creating.html",
    "html": "Creating an index\nPDF\nRSS\n\nCompare the CREATE INDEX statement in SQL with the UpdateTable operation in Amazon DynamoDB.\n\nTopics\nCreating an index with SQL\nCreating an index in DynamoDB\nCreating an index with SQL\n\nIn a relational database, an index is a data structure that lets you perform fast queries on different columns in a table. You can use the CREATE INDEX SQL statement to add an index to an existing table, specifying the columns to be indexed. After the index has been created, you can query the data in the table as usual, but now the database can use the index to quickly find the specified rows in the table instead of scanning the entire table.\n\nAfter you create an index, the database maintains it for you. Whenever you modify data in the table, the index is automatically modified to reflect changes in the table.\n\nIn MySQL, you would create an index like the following.\n\nCREATE INDEX GenreAndPriceIndex\nON Music (genre, price);\nCreating an index in DynamoDB\n\nIn DynamoDB, you can create and use a secondary index for similar purposes.\n\nIndexes in DynamoDB are different from their relational counterparts. When you create a secondary index, you must specify its key attributes—a partition key and a sort key. After you create the secondary index, you can Query it or Scan it just as you would with a table. DynamoDB does not have a query optimizer, so a secondary index is only used when you Query it or Scan it.\n\nDynamoDB supports two different kinds of indexes:\n\nGlobal secondary indexes – The primary key of the index can be any two attributes from its table.\n\nLocal secondary indexes – The partition key of the index must be the same as the partition key of its table. However, the sort key can be any other attribute.\n\nDynamoDB ensures that the data in a secondary index is eventually consistent with its table. You can request strongly consistent Query or Scan operations on a table or a local secondary index. However, global secondary indexes support only eventual consistency.\n\nYou can add a global secondary index to an existing table, using the UpdateTable operation and specifying GlobalSecondaryIndexUpdates.\n\n{\n    TableName: \"Music\",\n    AttributeDefinitions:[\n        {AttributeName: \"Genre\", AttributeType: \"S\"},\n        {AttributeName: \"Price\", AttributeType: \"N\"}\n    ],\n    GlobalSecondaryIndexUpdates: [\n        {\n            Create: {\n                IndexName: \"GenreAndPriceIndex\",\n                KeySchema: [\n                    {AttributeName: \"Genre\", KeyType: \"HASH\"}, //Partition key\n                    {AttributeName: \"Price\", KeyType: \"RANGE\"}, //Sort key\n                ],\n                Projection: {\n                    \"ProjectionType\": \"ALL\"\n                },\n                ProvisionedThroughput: {                                // Only specified if using provisioned mode\n                    \"ReadCapacityUnits\": 1,\"WriteCapacityUnits\": 1\n                }\n            }\n        }\n    ]\n}\n\nYou must provide the following parameters to UpdateTable:\n\nTableName – The table that the index will be associated with.\n\nAttributeDefinitions – The data types for the key schema attributes of the index.\n\nGlobalSecondaryIndexUpdates – Details about the index you want to create:\n\nIndexName – A name for the index.\n\nKeySchema – The attributes that are used for the index's primary key.\n\nProjection – Attributes from the table that are copied to the index. In this case, ALL means that all of the attributes are copied.\n\nProvisionedThroughput (for provisioned tables) – The number of reads and writes per second that you need for this index. (This is separate from the provisioned throughput settings of the table.)\n\nPart of this operation involves backfilling data from the table into the new index. During backfilling, the table remains available. However, the index is not ready until its Backfilling attribute changes from true to false. You can use the DescribeTable operation to view this attribute.\n\nNote\n\nFor code examples that use UpdateTable, see Getting started with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Managing indexes - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.Indexes.html",
    "html": "Managing indexes\nPDF\nRSS\n\nIndexes give you access to alternate query patterns, and can speed up queries. This section compares and contrasts index creation and usage in SQL and Amazon DynamoDB.\n\nWhether you are using a relational database or DynamoDB, you should be judicious with index creation. Whenever a write occurs on a table, all of the table's indexes must be updated. In a write-heavy environment with large tables, this can consume large amounts of system resources. In a read-only or read-mostly environment, this is not as much of a concern. However, you should ensure that the indexes are actually being used by your application, and not simply taking up space.\n\nTopics\nCreating an index\nQuerying and scanning an index"
  },
  {
    "title": "Key differences between SQL and DynamoDB when reading data from a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.ReadData.html",
    "html": "Key differences between SQL and DynamoDB when reading data from a table\nPDF\nRSS\n\nWith SQL, you use the SELECT statement to retrieve one or more rows from a table. You use the WHERE clause to determine the data that is returned to you.\n\nThis is different than using Amazon DynamoDB which provides the following operations for reading data:\n\nExecuteStatement retrieves a single or multiple items from a table. BatchExecuteStatement retrieves multiple items from different tables in a single operation. Both of these operations use PartiQL, a SQL-compatible query language.\n\nGetItem – Retrieves a single item from a table. This is the most efficient way to read a single item because it provides direct access to the physical location of the item. (DynamoDB also provides the BatchGetItem operation, allowing you to perform up to 100 GetItem calls in a single operation.)\n\nQuery – Retrieves all of the items that have a specific partition key. Within those items, you can apply a condition to the sort key and retrieve only a subset of the data. Query provides quick, efficient access to the partitions where the data is stored. (For more information, see Partitions and data distribution.)\n\nScan – Retrieves all of the items in the specified table. (This operation should not be used with large tables because it can consume large amounts of system resources.)\n\nNote\n\nWith a relational database, you can use the SELECT statement to join data from multiple tables and return the results. Joins are fundamental to the relational model. To ensure that joins run efficiently, the database and its applications should be performance-tuned on an ongoing basis. DynamoDB is a non-relational NoSQL database that does not support table joins. Instead, applications read data from one table at a time.\n\nThe following sections describe different use cases for reading data, and how to perform these tasks with a relational database and with DynamoDB.\n\nTopics\nReading an item using its primary key\nQuerying a table\nScanning a table"
  },
  {
    "title": "Getting information about a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.GetTableInfo.html",
    "html": "Getting information about a table\nPDF\nRSS\n\nYou can verify that a table has been created according to your specifications. In a relational database, all of the table's schema is shown. Amazon DynamoDB tables are schemaless, so only the primary key attributes are shown.\n\nTopics\nGetting information about a table with SQL\nGetting information about a table in DynamoDB\nGetting information about a table with SQL\n\nMost relational database management systems (RDBMS) allow you to describe a table's structure—columns, data types, primary key definition, and so on. There is no standard way to do this in SQL. However, many database systems provide a DESCRIBE command. The following is an example from MySQL.\n\nDESCRIBE Music;\n\nThis returns the structure of your table, with all of the column names, data types, and sizes.\n\n+------------+-------------+------+-----+---------+-------+\n| Field      | Type        | Null | Key | Default | Extra |\n+------------+-------------+------+-----+---------+-------+\n| Artist     | varchar(20) | NO   | PRI | NULL    |       |\n| SongTitle  | varchar(30) | NO   | PRI | NULL    |       |\n| AlbumTitle | varchar(25) | YES  |     | NULL    |       |\n| Year       | int(11)     | YES  |     | NULL    |       |\n| Price      | float       | YES  |     | NULL    |       |\n| Genre      | varchar(10) | YES  |     | NULL    |       |\n| Tags       | text        | YES  |     | NULL    |       |\n+------------+-------------+------+-----+---------+-------+\n\n\nThe primary key for this table consists of Artist and SongTitle.\n\nGetting information about a table in DynamoDB\n\nDynamoDB has a DescribeTable operation, which is similar. The only parameter is the table name.\n\n{\n    TableName : \"Music\"\n}\n\nThe reply from DescribeTable looks like the following.\n\n{\n  \"Table\": {\n    \"AttributeDefinitions\": [\n      {\n        \"AttributeName\": \"Artist\",\n        \"AttributeType\": \"S\"\n      },\n      {\n        \"AttributeName\": \"SongTitle\",\n        \"AttributeType\": \"S\"\n      }\n    ],\n    \"TableName\": \"Music\",\n    \"KeySchema\": [\n      {\n        \"AttributeName\": \"Artist\",\n        \"KeyType\": \"HASH\"  //Partition key\n      },\n      {\n        \"AttributeName\": \"SongTitle\",\n        \"KeyType\": \"RANGE\"  //Sort key\n      }\n    ],\n\n    ...\n\nDescribeTable also returns information about indexes on the table, provisioned throughput settings, an approximate item count, and other metadata."
  },
  {
    "title": "Creating a table - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.CreateTable.html",
    "html": "Creating a table\nPDF\nRSS\n\nTables are the fundamental data structures in relational databases and in Amazon DynamoDB. A relational database management system (RDBMS) requires you to define the table's schema when you create it. In contrast, DynamoDB tables are schemaless—other than the primary key, you do not need to define any extra attributes or data types when you create a table.\n\nThe following section compares how you would create a table with SQL to how you would create it with DynamoDB.\n\nTopics\nCreating a table with SQL\nCreating a table with DynamoDB\nCreating a table with SQL\n\nWith SQL you would use the CREATE TABLE statement to create a table, as shown in the following example.\n\nCREATE TABLE Music (\n    Artist VARCHAR(20) NOT NULL,\n    SongTitle VARCHAR(30) NOT NULL,\n    AlbumTitle VARCHAR(25),\n    Year INT,\n    Price FLOAT,\n    Genre VARCHAR(10),\n    Tags TEXT,\n    PRIMARY KEY(Artist, SongTitle)\n);\n\nThe primary key for this table consists of Artist and SongTitle.\n\nYou must define all of the table's columns and data types, and the table's primary key. (You can use the ALTER TABLE statement to change these definitions later, if necessary.)\n\nMany SQL implementations let you define storage specifications for your table, as part of the CREATE TABLE statement. Unless you indicate otherwise, the table is created with default storage settings. In a production environment, a database administrator can help determine the optimal storage parameters.\n\nCreating a table with DynamoDB\n\nUse the CreateTable operation to create a provisioned mode table, specifying parameters as shown following:\n\n{\n    TableName : \"Music\",\n    KeySchema: [\n        {\n            AttributeName: \"Artist\",\n            KeyType: \"HASH\" //Partition key\n        },\n        {\n            AttributeName: \"SongTitle\",\n            KeyType: \"RANGE\" //Sort key\n        }\n    ],\n    AttributeDefinitions: [\n        {\n            AttributeName: \"Artist\",\n            AttributeType: \"S\"\n        },\n        {\n            AttributeName: \"SongTitle\",\n            AttributeType: \"S\"\n        }\n    ],\n    ProvisionedThroughput: {       // Only specified if using provisioned mode\n        ReadCapacityUnits: 1,\n        WriteCapacityUnits: 1\n    }\n}\n\nThe primary key for this table consists of Artist (partition key) and SongTitle (sort key).\n\nYou must provide the following parameters to CreateTable:\n\nTableName – Name of the table.\n\nKeySchema – Attributes that are used for the primary key. For more information, see Tables, items, and attributes and Primary key.\n\nAttributeDefinitions – Data types for the key schema attributes.\n\nProvisionedThroughput (for provisioned tables) – Number of reads and writes per second that you need for this table. DynamoDB reserves sufficient storage and system resources so that your throughput requirements are always met. You can use the UpdateTable operation to change these later, if necessary. You do not need to specify a table's storage requirements because storage allocation is managed entirely by DynamoDB.\n\nNote\n\nFor code examples that use CreateTable, see Getting started with DynamoDB and the AWS SDKs."
  },
  {
    "title": "Characteristics of databases - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.Accessing.html",
    "html": "Characteristics of databases\nPDF\nRSS\n\nBefore your application can access a database, it must be authenticated to ensure that the application is allowed to use the database. It must be authorized so that the application can perform only the actions for which it has permissions.\n\nThe following diagram shows a client's interaction with a relational database and with Amazon DynamoDB.\n\nThe following table has more details about client interaction tasks.\n\nCharacteristic\tRelational database management system (RDBMS)\tAmazon DynamoDB\nTools for Accessing the Database\t\n\nMost relational databases provide a command line interface (CLI) so that you can enter ad hoc SQL statements and see the results immediately.\n\n\tIn most cases, you write application code. You can also use the AWS Management Console, the AWS Command Line Interface (AWS CLI), or NoSQL Workbench to send ad hoc requests to DynamoDB and view the results. PartiQL, a SQL-compatible query language, lets you select, insert, update, and delete data in DynamoDB.\nConnecting to the Database\tAn application program establishes and maintains a network connection with the database. When the application is finished, it terminates the connection.\tDynamoDB is a web service, and interactions with it are stateless. Applications do not need to maintain persistent network connections. Instead, interaction with DynamoDB occurs using HTTP(S) requests and responses.\nAuthentication\tAn application cannot connect to the database until it is authenticated. The RDBMS can perform the authentication itself, or it can offload this task to the host operating system or a directory service.\tEvery request to DynamoDB must be accompanied by a cryptographic signature, which authenticates that particular request. The AWS SDKs provide all of the logic necessary for creating signatures and signing requests. For more information, see Signing AWS API requests in the AWS General Reference.\nAuthorization\tApplications can perform only the actions for which they have been authorized. Database administrators or application owners can use the SQL GRANT and REVOKE statements to control access to database objects (such as tables), data (such as rows within a table), or the ability to issue certain SQL statements.\tIn DynamoDB, authorization is handled by AWS Identity and Access Management (IAM). You can write an IAM policy to grant permissions on a DynamoDB resource (such as a table), and then allow users and roles to use that policy. IAM also features fine-grained access control for individual data items in DynamoDB tables. For more information, see Identity and Access Management for Amazon DynamoDB.\nSending a Request\tThe application issues a SQL statement for every database operation that it wants to perform. Upon receipt of the SQL statement, the RDBMS checks its syntax, creates a plan for performing the operation, and then runs the plan.\tThe application sends HTTP(S) requests to DynamoDB. The requests contain the name of the DynamoDB operation to perform, along with parameters. DynamoDB runs the request immediately.\nReceiving a Response\tThe RDBMS returns the results from the SQL statement. If there is an error, the RDBMS returns an error status and message.\tDynamoDB returns an HTTP(S) response containing the results of the operation. If there is an error, DynamoDB returns an HTTP error status and messages."
  },
  {
    "title": "Relational (SQL) or NoSQL? - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.WhyDynamoDB.html",
    "html": "Relational (SQL) or NoSQL?\nPDF\nRSS\n\nToday's applications have more demanding requirements than ever before. For example, an online game might start out with just a few users and a very small amount of data. However, if the game becomes successful, it can easily outstrip the resources of the underlying database management system. It is common for web-based applications to have hundreds, thousands, or millions of concurrent users, with terabytes or more of new data generated per day. Databases for such applications must handle tens (or hundreds) of thousands of reads and writes per second.\n\nAmazon DynamoDB is well-suited for these kinds of workloads. As a developer, you can start small and gradually increase your utilization as your application becomes more popular. DynamoDB scales seamlessly to handle very large amounts of data and very large numbers of users.\n\nFor more information on traditional relational database modeling and how to adapt it for DynamoDB, see Best practices for modeling relational data in DynamoDB.\n\nThe following table shows some high-level differences between a relational database management system (RDBMS) and DynamoDB.\n\nCharacteristic\tRelational database management system (RDBMS)\tAmazon DynamoDB\nOptimal Workloads\tAd hoc queries; data warehousing; OLAP (online analytical processing).\tWeb-scale applications, including social networks, gaming, media sharing, and Internet of Things (IoT).\nData Model\tThe relational model requires a well-defined schema, where data is normalized into tables, rows, and columns. In addition, all of the relationships are defined among tables, columns, indexes, and other database elements.\tDynamoDB is schemaless. Every table must have a primary key to uniquely identify each data item, but there are no similar constraints on other non-key attributes. DynamoDB can manage structured or semistructured data, including JSON documents.\nData Access\tSQL is the standard for storing and retrieving data. Relational databases offer a rich set of tools for simplifying the development of database-driven applications, but all of these tools use SQL.\tYou can use the AWS Management Console, the AWS CLI, or NoSQL WorkBench to work with DynamoDB and perform ad hoc tasks. PartiQL, a SQL-compatible query language, lets you select, insert, update, and delete data in DynamoDB. Applications can use the AWS software development kits (SDKs) to work with DynamoDB using object-based, document-centric, or low-level interfaces.\nPerformance\tRelational databases are optimized for storage, so performance generally depends on the disk subsystem. Developers and database administrators must optimize queries, indexes, and table structures in order to achieve peak performance.\tDynamoDB is optimized for compute, so performance is mainly a function of the underlying hardware and network latency. As a managed service, DynamoDB insulates you and your applications from these implementation details, so that you can focus on designing and building robust, high-performance applications.\nScaling\tIt is easiest to scale up with faster hardware. It is also possible for database tables to span across multiple hosts in a distributed system, but this requires additional investment. Relational databases have maximum sizes for the number and size of files, which imposes upper limits on scalability.\tDynamoDB is designed to scale out using distributed clusters of hardware. This design allows increased throughput without increased latency. Customers specify their throughput requirements, and DynamoDB allocates sufficient resources to meet those requirements. There are no upper limits on the number of items per table, nor the total size of that table."
  },
  {
    "title": "Partitions and data distribution - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.Partitions.html",
    "html": "Partitions and data distribution\nPDF\nRSS\n\nAmazon DynamoDB stores data in partitions. A partition is an allocation of storage for a table, backed by solid state drives (SSDs) and automatically replicated across multiple Availability Zones within an AWS Region. Partition management is handled entirely by DynamoDB—you never have to manage partitions yourself.\n\nWhen you create a table, the initial status of the table is CREATING. During this phase, DynamoDB allocates sufficient partitions to the table so that it can handle your provisioned throughput requirements. You can begin writing and reading table data after the table status changes to ACTIVE.\n\nDynamoDB allocates additional partitions to a table in the following situations:\n\nIf you increase the table's provisioned throughput settings beyond what the existing partitions can support.\n\nIf an existing partition fills to capacity and more storage space is required.\n\nPartition management occurs automatically in the background and is transparent to your applications. Your table remains available throughout and fully supports your provisioned throughput requirements.\n\nFor more details, see Partition key design.\n\nGlobal secondary indexes in DynamoDB are also composed of partitions. The data in a global secondary index is stored separately from the data in its base table, but index partitions behave in much the same way as table partitions.\n\nData distribution: Partition key\n\nIf your table has a simple primary key (partition key only), DynamoDB stores and retrieves each item based on its partition key value.\n\nTo write an item to the table, DynamoDB uses the value of the partition key as input to an internal hash function. The output value from the hash function determines the partition in which the item will be stored.\n\nTo read an item from the table, you must specify the partition key value for the item. DynamoDB uses this value as input to its hash function, yielding the partition in which the item can be found.\n\nThe following diagram shows a table named Pets, which spans multiple partitions. The table's primary key is AnimalType (only this key attribute is shown). DynamoDB uses its hash function to determine where to store a new item, in this case based on the hash value of the string Dog. Note that the items are not stored in sorted order. Each item's location is determined by the hash value of its partition key.\n\nNote\n\nDynamoDB is optimized for uniform distribution of items across a table's partitions, no matter how many partitions there may be. We recommend that you choose a partition key that can have a large number of distinct values relative to the number of items in the table.\n\nData distribution: Partition key and sort key\n\nIf the table has a composite primary key (partition key and sort key), DynamoDB calculates the hash value of the partition key in the same way as described in Data distribution: Partition key. However, it tends to keep items which have the same value of partition key close together and in sorted order by the sort key attribute's value. The set of items which have the same value of partition key is called an item collection. Item collections are optimized for efficient retrieval of ranges of the items within the collection. If your table doesn't have local secondary indexes, DynamoDB will automatically split your item collection over as many partitions as required to store the data and to serve read and write throughput.\n\nTo write an item to the table, DynamoDB calculates the hash value of the partition key to determine which partition should contain the item. In that partition, several items could have the same partition key value. So DynamoDB stores the item among the others with the same partition key, in ascending order by sort key.\n\nTo read an item from the table, you must specify its partition key value and sort key value. DynamoDB calculates the partition key's hash value, yielding the partition in which the item can be found.\n\nYou can read multiple items from the table in a single operation (Query) if the items you want have the same partition key value. DynamoDB returns all of the items with that partition key value. Optionally, you can apply a condition to the sort key so that it returns only the items within a certain range of values.\n\nSuppose that the Pets table has a composite primary key consisting of AnimalType (partition key) and Name (sort key). The following diagram shows DynamoDB writing an item with a partition key value of Dog and a sort key value of Fido.\n\nTo read that same item from the Pets table, DynamoDB calculates the hash value of Dog, yielding the partition in which these items are stored. DynamoDB then scans the sort key attribute values until it finds Fido.\n\nTo read all of the items with an AnimalType of Dog, you can issue a Query operation without specifying a sort key condition. By default, the items are returned in the order that they are stored (that is, in ascending order by sort key). Optionally, you can request descending order instead.\n\nTo query only some of the Dog items, you can apply a condition to the sort key (for example, only the Dog items where Name begins with a letter that is within the range A through K).\n\nNote\n\nIn a DynamoDB table, there is no upper limit on the number of distinct sort key values per partition key value. If you needed to store many billions of Dog items in the Pets table, DynamoDB would allocate enough storage to handle this requirement automatically."
  },
  {
    "title": "Table classes - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.TableClasses.html",
    "html": "Table classes\nPDF\nRSS\n\nDynamoDB offers two table classes designed to help you optimize for cost. The DynamoDB Standard table class is the default, and is recommended for the vast majority of workloads. The DynamoDB Standard-Infrequent Access (DynamoDB Standard-IA) table class is optimized for tables where storage is the dominant cost. For example, tables that store infrequently accessed data, such as application logs, old social media posts, e-commerce order history, and past gaming achievements, are good candidates for the Standard-IA table class. See Amazon DynamoDB Pricing for pricing details.\n\nEvery DynamoDB table is associated with a table class (DynamoDB Standard by default). All secondary indexes associated with the table use the same table class. Each table class offers different pricing for data storage as well as for read and write requests. You can select the most cost-effective table class for your table based on its storage and throughput usage patterns.\n\nThe choice of a table class is not permanent—you can change this setting using the AWS Management Console, AWS CLI, or AWS SDK. DynamoDB also supports managing your table class using AWS CloudFormation for single-Region tables and global tables. To learn more about selecting your table class, see Considerations when choosing a table class."
  },
  {
    "title": "Supported data types and naming rules in Amazon DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.NamingRulesDataTypes.html",
    "html": "Supported data types and naming rules in Amazon DynamoDB\nPDF\nRSS\n\nThis section describes the Amazon DynamoDB naming rules and the various data types that DynamoDB supports. There are limits that apply to data types. For more information, see Data types.\n\nTopics\nNaming rules\nData types\nData type descriptors\nNaming rules\n\nTables, attributes, and other objects in DynamoDB must have names. Names should be meaningful and concise—for example, names such as Products, Books, and Authors are self-explanatory.\n\nThe following are the naming rules for DynamoDB:\n\nAll names must be encoded using UTF-8, and are case-sensitive.\n\nTable names and index names must be between 3 and 255 characters long, and can contain only the following characters:\n\na-z\n\nA-Z\n\n0-9\n\n_ (underscore)\n\n- (dash)\n\n. (dot)\n\nAttribute names must be at least one character long and less than 64 KB in size. It is considered best practice to keep your attribute names as short as possible. This helps reduce read request units consumed, as attribute names are included in metering of storage and throughput usage.\n\nThe following are the exceptions. These attribute names must be no greater than 255 characters long:\n\nSecondary index partition key names\n\nSecondary index sort key names\n\nThe names of any user-specified projected attributes (applicable only to local secondary indexes)\n\nReserved words and special characters\n\nDynamoDB has a list of reserved words and special characters. For a complete list, see Reserved words in DynamoDB. Also, the following characters have special meaning in DynamoDB: # (hash) and : (colon).\n\nAlthough DynamoDB allows you to use these reserved words and special characters for names, we recommend that you avoid doing so because you have to define placeholder variables whenever you use these names in an expression. For more information, see Expression attribute names in DynamoDB.\n\nData types\n\nDynamoDB supports many different data types for attributes within a table. They can be categorized as follows:\n\nScalar Types – A scalar type can represent exactly one value. The scalar types are number, string, binary, Boolean, and null.\n\nDocument Types – A document type can represent a complex structure with nested attributes, such as what you would find in a JSON document. The document types are list and map.\n\nSet Types – A set type can represent multiple scalar values. The set types are string set, number set, and binary set.\n\nWhen you create a table or a secondary index, you must specify the names and data types of each primary key attribute (partition key and sort key). Furthermore, each primary key attribute must be defined as type string, number, or binary.\n\nDynamoDB is a NoSQL database and is schemaless. This means that other than the primary key attributes, you don't have to define any attributes or data types when you create tables. By comparison, relational databases require you to define the names and data types of each column when you create a table.\n\nThe following are descriptions of each data type, along with examples in JSON format.\n\nScalar types\n\nThe scalar types are number, string, binary, Boolean, and null.\n\nNumber\n\nNumbers can be positive, negative, or zero. Numbers can have up to 38 digits of precision. Exceeding this results in an exception. If you need greater precision than 38 digits, you can use strings.\n\nPositive range: 1E-130 to 9.9999999999999999999999999999999999999E+125\n\nNegative range: -9.9999999999999999999999999999999999999E+125 to -1E-130\n\nIn DynamoDB, numbers are represented as variable length. Leading and trailing zeroes are trimmed.\n\nAll numbers are sent across the network to DynamoDB as strings to maximize compatibility across languages and libraries. However, DynamoDB treats them as number type attributes for mathematical operations.\n\nYou can use the number data type to represent a date or a timestamp. One way to do this is by using epoch time—the number of seconds since 00:00:00 UTC on 1 January 1970. For example, the epoch time 1437136300 represents 12:31:40 PM UTC on 17 July 2015.\n\nFor more information, see http://en.wikipedia.org/wiki/Unix_time.\n\nString\n\nStrings are Unicode with UTF-8 binary encoding. The minimum length of a string can be zero, if the attribute is not used as a key for an index or table, and is constrained by the maximum DynamoDB item size limit of 400 KB.\n\nThe following additional constraints apply to primary key attributes that are defined as type string:\n\nFor a simple primary key, the maximum length of the first attribute value (the partition key) is 2048 bytes.\n\nFor a composite primary key, the maximum length of the second attribute value (the sort key) is 1024 bytes.\n\nDynamoDB collates and compares strings using the bytes of the underlying UTF-8 string encoding. For example, \"a\" (0x61) is greater than \"A\" (0x41), and \"¿\" (0xC2BF) is greater than \"z\" (0x7A).\n\nYou can use the string data type to represent a date or a timestamp. One way to do this is by using ISO 8601 strings, as shown in these examples:\n\n2016-02-15\n\n2015-12-21T17:42:34Z\n\n20150311T122706Z\n\nFor more information, see http://en.wikipedia.org/wiki/ISO_8601.\n\nNote\n\nUnlike conventional relational databases, DynamoDB does not natively support a date and time data type. It can be useful instead to store date and time data as a number data type, using Unix epoch time.\n\nBinary\n\nBinary type attributes can store any binary data, such as compressed text, encrypted data, or images. Whenever DynamoDB compares binary values, it treats each byte of the binary data as unsigned.\n\nThe length of a binary attribute can be zero, if the attribute is not used as a key for an index or table, and is constrained by the maximum DynamoDB item size limit of 400 KB.\n\nIf you define a primary key attribute as a binary type attribute, the following additional constraints apply:\n\nFor a simple primary key, the maximum length of the first attribute value (the partition key) is 2048 bytes.\n\nFor a composite primary key, the maximum length of the second attribute value (the sort key) is 1024 bytes.\n\nYour applications must encode binary values in base64-encoded format before sending them to DynamoDB. Upon receipt of these values, DynamoDB decodes the data into an unsigned byte array and uses that as the length of the binary attribute.\n\nThe following example is a binary attribute, using base64-encoded text.\n\ndGhpcyB0ZXh0IGlzIGJhc2U2NC1lbmNvZGVk\nBoolean\n\nA Boolean type attribute can store either true or false.\n\nNull\n\nNull represents an attribute with an unknown or undefined state.\n\nDocument types\n\nThe document types are list and map. These data types can be nested within each other, to represent complex data structures up to 32 levels deep.\n\nThere is no limit on the number of values in a list or a map, as long as the item containing the values fits within the DynamoDB item size limit (400 KB).\n\nAn attribute value can be an empty string or empty binary value if the attribute is not used for a table or index key. An attribute value cannot be an empty set (string set, number set, or binary set), however, empty lists and maps are allowed. Empty string and binary values are allowed within lists and maps. For more information, see Attributes.\n\nList\n\nA list type attribute can store an ordered collection of values. Lists are enclosed in square brackets: [ ... ]\n\nA list is similar to a JSON array. There are no restrictions on the data types that can be stored in a list element, and the elements in a list element do not have to be of the same type.\n\nThe following example shows a list that contains two strings and a number.\n\nFavoriteThings: [\"Cookies\", \"Coffee\", 3.14159]\nNote\n\nDynamoDB lets you work with individual elements within lists, even if those elements are deeply nested. For more information, see Using expressions in DynamoDB.\n\nMap\n\nA map type attribute can store an unordered collection of name-value pairs. Maps are enclosed in curly braces: { ... }\n\nA map is similar to a JSON object. There are no restrictions on the data types that can be stored in a map element, and the elements in a map do not have to be of the same type.\n\nMaps are ideal for storing JSON documents in DynamoDB. The following example shows a map that contains a string, a number, and a nested list that contains another map.\n\n{\n    Day: \"Monday\",\n    UnreadEmails: 42,\n    ItemsOnMyDesk: [\n        \"Coffee Cup\",\n        \"Telephone\",\n        {\n            Pens: { Quantity : 3},\n            Pencils: { Quantity : 2},\n            Erasers: { Quantity : 1}\n        }\n    ]\n}\nNote\n\nDynamoDB lets you work with individual elements within maps, even if those elements are deeply nested. For more information, see Using expressions in DynamoDB.\n\nSets\n\nDynamoDB supports types that represent sets of number, string, or binary values. All the elements within a set must be of the same type. For example, a Number Set can only contain numbers and a String Set can only contain strings.\n\nThere is no limit on the number of values in a set, as long as the item containing the values fits within the DynamoDB item size limit (400 KB).\n\nEach value within a set must be unique. The order of the values within a set is not preserved. Therefore, your applications must not rely on any particular order of elements within the set. DynamoDB does not support empty sets, however, empty string and binary values are allowed within a set.\n\nThe following example shows a string set, a number set, and a binary set:\n\n[\"Black\", \"Green\", \"Red\"]\n\n[42.2, -19, 7.5, 3.14]\n\n[\"U3Vubnk=\", \"UmFpbnk=\", \"U25vd3k=\"]\nData type descriptors\n\nThe low-level DynamoDB API protocol uses Data type descriptors as tokens that tell DynamoDB how to interpret each attribute.\n\nThe following is a complete list of DynamoDB data type descriptors:\n\nS – String\n\nN – Number\n\nB – Binary\n\nBOOL – Boolean\n\nNULL – Null\n\nM – Map\n\nL – List\n\nSS – String Set\n\nNS – Number Set\n\nBS – Binary Set"
  },
  {
    "title": "DynamoDB API - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.API.html",
    "html": "DynamoDB API\nPDF\nRSS\n\nTo work with Amazon DynamoDB, your application must use a few simple API operations. The following is a summary of these operations, organized by category.\n\nNote\n\nFor a full list of the API operations, see the Amazon DynamoDB API Reference.\n\nTopics\nControl plane\nData plane\nDynamoDB Streams\nTransactions\nControl plane\n\nControl plane operations let you create and manage DynamoDB tables. They also let you work with indexes, streams, and other objects that are dependent on tables.\n\nCreateTable – Creates a new table. Optionally, you can create one or more secondary indexes, and enable DynamoDB Streams for the table.\n\nDescribeTable– Returns information about a table, such as its primary key schema, throughput settings, and index information.\n\nListTables – Returns the names of all of your tables in a list.\n\nUpdateTable – Modifies the settings of a table or its indexes, creates or removes new indexes on a table, or modifies DynamoDB Streams settings for a table.\n\nDeleteTable – Removes a table and all of its dependent objects from DynamoDB.\n\nData plane\n\nData plane operations let you perform create, read, update, and delete (also called CRUD) actions on data in a table. Some of the data plane operations also let you read data from a secondary index.\n\nYou can use PartiQL - a SQL-compatible query language for Amazon DynamoDB, to perform these CRUD operations or you can use DynamoDB’s classic CRUD APIs that separates each operation into a distinct API call.\n\nPartiQL - A SQL-compatible query language\n\nExecuteStatement – Reads multiple items from a table. You can also write or update a single item from a table. When writing or updating a single item, you must specify the primary key attributes.\n\nBatchExecuteStatement – Writes, updates or reads multiple items from a table. This is more efficient than ExecuteStatement because your application only needs a single network round trip to write or read the items.\n\nClassic APIs\nCreating data\n\nPutItem – Writes a single item to a table. You must specify the primary key attributes, but you don't have to specify other attributes.\n\nBatchWriteItem – Writes up to 25 items to a table. This is more efficient than calling PutItem multiple times because your application only needs a single network round trip to write the items.\n\nReading data\n\nGetItem – Retrieves a single item from a table. You must specify the primary key for the item that you want. You can retrieve the entire item, or just a subset of its attributes.\n\nBatchGetItem – Retrieves up to 100 items from one or more tables. This is more efficient than calling GetItem multiple times because your application only needs a single network round trip to read the items.\n\nQuery – Retrieves all items that have a specific partition key. You must specify the partition key value. You can retrieve entire items, or just a subset of their attributes. Optionally, you can apply a condition to the sort key values so that you only retrieve a subset of the data that has the same partition key. You can use this operation on a table, provided that the table has both a partition key and a sort key. You can also use this operation on an index, provided that the index has both a partition key and a sort key.\n\nScan – Retrieves all items in the specified table or index. You can retrieve entire items, or just a subset of their attributes. Optionally, you can apply a filtering condition to return only the values that you are interested in and discard the rest.\n\nUpdating data\n\nUpdateItem – Modifies one or more attributes in an item. You must specify the primary key for the item that you want to modify. You can add new attributes and modify or remove existing attributes. You can also perform conditional updates, so that the update is only successful when a user-defined condition is met. Optionally, you can implement an atomic counter, which increments or decrements a numeric attribute without interfering with other write requests.\n\nDeleting data\n\nDeleteItem – Deletes a single item from a table. You must specify the primary key for the item that you want to delete.\n\nBatchWriteItem – Deletes up to 25 items from one or more tables. This is more efficient than calling DeleteItem multiple times because your application only needs a single network round trip to delete the items.\n\nNote\n\nYou can use BatchWriteItem to both create data and delete data.\n\nDynamoDB Streams\n\nDynamoDB Streams operations let you enable or disable a stream on a table, and allow access to the data modification records contained in a stream.\n\nListStreams – Returns a list of all your streams, or just the stream for a specific table.\n\nDescribeStream – Returns information about a stream, such as its Amazon Resource Name (ARN) and where your application can begin reading the first few stream records.\n\nGetShardIterator – Returns a shard iterator, which is a data structure that your application uses to retrieve the records from the stream.\n\nGetRecords – Retrieves one or more stream records, using a given shard iterator.\n\nTransactions\n\nTransactions provide atomicity, consistency, isolation, and durability (ACID) enabling you to maintain data correctness in your applications more easily.\n\nYou can use PartiQL - a SQL-compatible query language for Amazon DynamoDB, to perform transactional operations or you can use DynamoDB’s classic CRUD APIs that separates each operation into a distinct API call.\n\nPartiQL - A SQL-compatible query language\n\nExecuteTransaction – A batch operation that allows CRUD operations to multiple items both within and across tables with a guaranteed all-or-nothing result.\n\nClassic APIs\n\nTransactWriteItems – A batch operation that allows Put, Update, and Delete operations to multiple items both within and across tables with a guaranteed all-or-nothing result.\n\nTransactGetItems – A batch operation that allows Get operations to retrieve multiple items from one or more tables."
  },
  {
    "title": "Core components of Amazon DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html",
    "html": "Core components of Amazon DynamoDB\nPDF\nRSS\n\nIn DynamoDB, tables, items, and attributes are the core components that you work with. A table is a collection of items, and each item is a collection of attributes. DynamoDB uses primary keys to uniquely identify each item in a table and secondary indexes to provide more querying flexibility. You can use DynamoDB Streams to capture data modification events in DynamoDB tables.\n\nThere are limits in DynamoDB. For more information, see Service, account, and table quotas in Amazon DynamoDB.\n\nThe following video will give you an introductory look at tables, items, and attributes.\n\nTables, items, and attributes\n\nTables, items, and attributes\n\nThe following are the basic DynamoDB components:\n\nTables – Similar to other database systems, DynamoDB stores data in tables. A table is a collection of data. For example, see the example table called People that you could use to store personal contact information about friends, family, or anyone else of interest. You could also have a Cars table to store information about vehicles that people drive.\n\nItems – Each table contains zero or more items. An item is a group of attributes that is uniquely identifiable among all of the other items. In a People table, each item represents a person. For a Cars table, each item represents one vehicle. Items in DynamoDB are similar in many ways to rows, records, or tuples in other database systems. In DynamoDB, there is no limit to the number of items you can store in a table.\n\nAttributes – Each item is composed of one or more attributes. An attribute is a fundamental data element, something that does not need to be broken down any further. For example, an item in a People table contains attributes called PersonID, LastName, FirstName, and so on. For a Department table, an item might have attributes such as DepartmentID, Name, Manager, and so on. Attributes in DynamoDB are similar in many ways to fields or columns in other database systems.\n\nThe following diagram shows a table named People with some example items and attributes.\n\n\nPeople\n\n{\n    \"PersonID\": 101,\n    \"LastName\": \"Smith\",\n    \"FirstName\": \"Fred\",\n    \"Phone\": \"555-4321\"\n}\n\n{\n    \"PersonID\": 102,\n    \"LastName\": \"Jones\",\n    \"FirstName\": \"Mary\",\n    \"Address\": {\n                \"Street\": \"123 Main\",\n                \"City\": \"Anytown\",\n                \"State\": \"OH\",\n                \"ZIPCode\": 12345\n    }\n}\n\n{\n    \"PersonID\": 103,\n    \"LastName\": \"Stephens\",\n    \"FirstName\": \"Howard\",\n    \"Address\": {\n                \"Street\": \"123 Main\",\n                \"City\": \"London\",                                    \n                \"PostalCode\": \"ER3 5K8\"\n    },\n    \"FavoriteColor\": \"Blue\"\n}\n\nNote the following about the People table:\n\nEach item in the table has a unique identifier, or primary key, that distinguishes the item from all of the others in the table. In the People table, the primary key consists of one attribute (PersonID).\n\nOther than the primary key, the People table is schemaless, which means that neither the attributes nor their data types need to be defined beforehand. Each item can have its own distinct attributes.\n\nMost of the attributes are scalar, which means that they can have only one value. Strings and numbers are common examples of scalars.\n\nSome of the items have a nested attribute (Address). DynamoDB supports nested attributes up to 32 levels deep.\n\nThe following is another example table named Music that you could use to keep track of your music collection.\n\n\nMusic\n\n{\n    \"Artist\": \"No One You Know\",\n    \"SongTitle\": \"My Dog Spot\",\n    \"AlbumTitle\": \"Hey Now\",\n    \"Price\": 1.98,\n    \"Genre\": \"Country\",\n    \"CriticRating\": 8.4\n}\n\n{\n    \"Artist\": \"No One You Know\",\n    \"SongTitle\": \"Somewhere Down The Road\",\n    \"AlbumTitle\": \"Somewhat Famous\",\n    \"Genre\": \"Country\",\n    \"CriticRating\": 8.4,\n    \"Year\": 1984\n}\n\n{\n    \"Artist\": \"The Acme Band\",\n    \"SongTitle\": \"Still in Love\",\n    \"AlbumTitle\": \"The Buck Starts Here\",\n    \"Price\": 2.47,\n    \"Genre\": \"Rock\",\n    \"PromotionInfo\": {\n        \"RadioStationsPlaying\": [\n            \"KHCR\",\n            \"KQBX\",\n            \"WTNR\",\n            \"WJJH\"\n        ],\n        \"TourDates\": {\n            \"Seattle\": \"20150622\",\n            \"Cleveland\": \"20150630\"\n        },\n        \"Rotation\": \"Heavy\"\n    }\n}\n\n{\n    \"Artist\": \"The Acme Band\",\n    \"SongTitle\": \"Look Out, World\",\n    \"AlbumTitle\": \"The Buck Starts Here\",\n    \"Price\": 0.99,\n    \"Genre\": \"Rock\"\n} \n\nNote the following about the Music table:\n\nThe primary key for Music consists of two attributes (Artist and SongTitle). Each item in the table must have these two attributes. The combination of Artist and SongTitle distinguishes each item in the table from all of the others.\n\nOther than the primary key, the Music table is schemaless, which means that neither the attributes nor their data types need to be defined beforehand. Each item can have its own distinct attributes.\n\nOne of the items has a nested attribute (PromotionInfo), which contains other nested attributes. DynamoDB supports nested attributes up to 32 levels deep.\n\nFor more information, see Working with tables and data in DynamoDB.\n\nPrimary key\n\nWhen you create a table, in addition to the table name, you must specify the primary key of the table. The primary key uniquely identifies each item in the table, so that no two items can have the same key.\n\nDynamoDB supports two different kinds of primary keys:\n\nPartition key – A simple primary key, composed of one attribute known as the partition key.\n\nDynamoDB uses the partition key's value as input to an internal hash function. The output from the hash function determines the partition (physical storage internal to DynamoDB) in which the item will be stored.\n\nIn a table that has only a partition key, no two items can have the same partition key value.\n\nThe People table described in Tables, items, and attributes is an example of a table with a simple primary key (PersonID). You can access any item in the People table directly by providing the PersonId value for that item.\n\nPartition key and sort key – Referred to as a composite primary key, this type of key is composed of two attributes. The first attribute is the partition key, and the second attribute is the sort key.\n\nDynamoDB uses the partition key value as input to an internal hash function. The output from the hash function determines the partition (physical storage internal to DynamoDB) in which the item will be stored. All items with the same partition key value are stored together, in sorted order by sort key value.\n\nIn a table that has a partition key and a sort key, it's possible for multiple items to have the same partition key value. However, those items must have different sort key values.\n\nThe Music table described in Tables, items, and attributes is an example of a table with a composite primary key (Artist and SongTitle). You can access any item in the Music table directly, if you provide the Artist and SongTitle values for that item.\n\nA composite primary key gives you additional flexibility when querying data. For example, if you provide only the value for Artist, DynamoDB retrieves all of the songs by that artist. To retrieve only a subset of songs by a particular artist, you can provide a value for Artist along with a range of values for SongTitle.\n\nNote\n\nThe partition key of an item is also known as its hash attribute. The term hash attribute derives from the use of an internal hash function in DynamoDB that evenly distributes data items across partitions, based on their partition key values.\n\nThe sort key of an item is also known as its range attribute. The term range attribute derives from the way DynamoDB stores items with the same partition key physically close together, in sorted order by the sort key value.\n\nEach primary key attribute must be a scalar (meaning that it can hold only a single value). The only data types allowed for primary key attributes are string, number, or binary. There are no such restrictions for other, non-key attributes.\n\nSecondary indexes\n\nYou can create one or more secondary indexes on a table. A secondary index lets you query the data in the table using an alternate key, in addition to queries against the primary key. DynamoDB doesn't require that you use indexes, but they give your applications more flexibility when querying your data. After you create a secondary index on a table, you can read data from the index in much the same way as you do from the table.\n\nDynamoDB supports two kinds of indexes:\n\nGlobal secondary index – An index with a partition key and sort key that can be different from those on the table.\n\nLocal secondary index – An index that has the same partition key as the table, but a different sort key.\n\nIn DynamoDB, global secondary indexes (GSIs) are indexes that span the entire table, allowing you to query across all partition keys. Local secondary indexes (LSIs) are indexes that have the same partition key as the base table but a different sort key.\n\nEach table in DynamoDB has a quota of 20 global secondary indexes (default quota) and 5 local secondary indexes.\n\nIn the example Music table shown previously, you can query data items by Artist (partition key) or by Artist and SongTitle (partition key and sort key). What if you also wanted to query the data by Genre and AlbumTitle? To do this, you could create an index on Genre and AlbumTitle, and then query the index in much the same way as you'd query the Music table.\n\nThe following diagram shows the example Music table, with a new index called GenreAlbumTitle. In the index, Genre is the partition key and AlbumTitle is the sort key.\n\nMusic Table\tGenreAlbumTitle\n\n\n{\n    \"Artist\": \"No One You Know\",\n    \"SongTitle\": \"My Dog Spot\",\n    \"AlbumTitle\": \"Hey Now\",\n    \"Price\": 1.98,\n    \"Genre\": \"Country\",\n    \"CriticRating\": 8.4\n}                               \n                                \n\t\n\n{\n    \"Genre\": \"Country\",\n    \"AlbumTitle\": \"Hey Now\",\n    \"Artist\": \"No One You Know\",\n    \"SongTitle\": \"My Dog Spot\"\n}\n                                \n\n\n\n{\n    \"Artist\": \"No One You Know\",\n    \"SongTitle\": \"Somewhere Down The Road\",\n    \"AlbumTitle\": \"Somewhat Famous\",\n    \"Genre\": \"Country\",\n    \"CriticRating\": 8.4,\n    \"Year\": 1984\n}\n                                \n\t\n\n{\n    \"Genre\": \"Country\",\n    \"AlbumTitle\": \"Somewhat Famous\",\n    \"Artist\": \"No One You Know\",\n    \"SongTitle\": \"Somewhere Down The Road\"\n}\n                                \n\n\n\n{\n    \"Artist\": \"The Acme Band\",\n    \"SongTitle\": \"Still in Love\",\n    \"AlbumTitle\": \"The Buck Starts Here\",\n    \"Price\": 2.47,\n    \"Genre\": \"Rock\",\n    \"PromotionInfo\": {\n        \"RadioStationsPlaying\": {\n            \"KHCR\",\n            \"KQBX\",\n            \"WTNR\",\n            \"WJJH\"\n        },\n        \"TourDates\": {\n            \"Seattle\": \"20150622\",\n            \"Cleveland\": \"20150630\"\n        },\n        \"Rotation\": \"Heavy\"\n    }\n}\n                                \n\t\n\n{\n    \"Genre\": \"Rock\",\n    \"AlbumTitle\": \"The Buck Starts Here\",\n    \"Artist\": \"The Acme Band\",\n    \"SongTitle\": \"Still In Love\"\n}\n                                \n\n\n\n{\n    \"Artist\": \"The Acme Band\",\n    \"SongTitle\": \"Look Out, World\",\n    \"AlbumTitle\": \"The Buck Starts Here\",\n    \"Price\": 0.99,\n    \"Genre\": \"Rock\"\n}\n                                \n\t\n\n{\n    \"Genre\": \"Rock\",\n    \"AlbumTitle\": \"The Buck Starts Here\",\n    \"Artist\": \"The Acme Band\",\n    \"SongTitle\": \"Look Out, World\"\n}\n                                \n\nNote the following about the GenreAlbumTitle index:\n\nEvery index belongs to a table, which is called the base table for the index. In the preceding example, Music is the base table for the GenreAlbumTitle index.\n\nDynamoDB maintains indexes automatically. When you add, update, or delete an item in the base table, DynamoDB adds, updates, or deletes the corresponding item in any indexes that belong to that table.\n\nWhen you create an index, you specify which attributes will be copied, or projected, from the base table to the index. At a minimum, DynamoDB projects the key attributes from the base table into the index. This is the case with GenreAlbumTitle, where only the key attributes from the Music table are projected into the index.\n\nYou can query the GenreAlbumTitle index to find all albums of a particular genre (for example, all Rock albums). You can also query the index to find all albums within a particular genre that have certain album titles (for example, all Country albums with titles that start with the letter H).\n\nFor more information, see Improving data access with secondary indexes.\n\nDynamoDB Streams\n\nDynamoDB Streams is an optional feature that captures data modification events in DynamoDB tables. The data about these events appear in the stream in near-real time, and in the order that the events occurred.\n\nEach event is represented by a stream record. If you enable a stream on a table, DynamoDB Streams writes a stream record whenever one of the following events occurs:\n\nA new item is added to the table: The stream captures an image of the entire item, including all of its attributes.\n\nAn item is updated: The stream captures the \"before\" and \"after\" image of any attributes that were modified in the item.\n\nAn item is deleted from the table: The stream captures an image of the entire item before it was deleted.\n\nEach stream record also contains the name of the table, the event timestamp, and other metadata. Stream records have a lifetime of 24 hours; after that, they are automatically removed from the stream.\n\nYou can use DynamoDB Streams together with AWS Lambda to create a trigger—code that runs automatically whenever an event of interest appears in a stream. For example, consider a Customers table that contains customer information for a company. Suppose that you want to send a \"welcome\" email to each new customer. You could enable a stream on that table, and then associate the stream with a Lambda function. The Lambda function would run whenever a new stream record appears, but only process new items added to the Customers table. For any item that has an EmailAddress attribute, the Lambda function would invoke Amazon Simple Email Service (Amazon SES) to send an email to that address.\n\nNote\n\nIn this example, the last customer, Craig Roe, will not receive an email because he doesn't have an EmailAddress.\n\nIn addition to triggers, DynamoDB Streams enables powerful solutions such as data replication within and across AWS Regions, materialized views of data in DynamoDB tables, data analysis using Kinesis materialized views, and much more.\n\nFor more information, see Change data capture for DynamoDB Streams."
  },
  {
    "title": "Cheat sheet for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CheatSheet.html",
    "html": "Cheat sheet for DynamoDB\nPDF\nRSS\n\nThis cheat sheet provides a quick reference for working with Amazon DynamoDB and its various AWS SDKs.\n\nInitial setup\n\nSign up for AWS.\n\nGet an AWS access key to access DynamoDB programmatically.\n\nConfigure your DynamoDB credentials.\n\nSee also:\n\nSetting up DynamoDB (web service)\n\nGetting started with DynamoDB\n\nBasic overview of core components\n\nSDK or CLI\n\nChoose your preferred SDK, or set up the AWS CLI.\n\nNote\n\nWhen you use the AWS CLI on Windows, a backslash (\\) that is not inside a quote is treated as a carriage return. Also, you must escape any quotes and braces inside other quotes. For an example, see the Windows tab in \"Create a table\" in the next section.\n\nSee also:\n\nAWS CLI with DynamoDB\n\nGetting started with DynamoDB - step 2\n\nBasic actions\n\nThis section provides code for basic DynamoDB tasks. For more information about these tasks, see Getting started with DynamoDB and the AWS SDKs.\n\nCreate a table\nDefault\nWindows\naws dynamodb create-table \\\n    --table-name Music \\\n    --attribute-definitions \\\n        AttributeName=Artist,AttributeType=S \\\n        AttributeName=SongTitle,AttributeType=S \\\n    --key-schema \\\n        AttributeName=Artist,KeyType=HASH \\\n        AttributeName=SongTitle,KeyType=RANGE \\\n    --provisioned-throughput \\\n        ReadCapacityUnits=10,WriteCapacityUnits=5\nWrite item to a table\naws dynamodb put-item \\ --table-name Music \\ --item file://item.json\nRead item from a table\naws dynamodb get-item \\ --table-name Music \\ --item file://item.json\nDelete item from a table\naws dynamodb delete-item --table-name Music --key file://key.json\nQuery a table\naws dynamodb query --table-name Music \n--key-condition-expression \"ArtistName=:Artist and SongName=:Songtitle\" \nDelete a table\naws dynamodb delete-table --table-name Music\nList table names\naws dynamodb list-tables\nNaming rules\n\nAll names must be encoded using UTF-8 and are case sensitive.\n\nTable names and index names must be between 3 and 255 characters long, and can contain only the following characters:\n\na-z\n\nA-Z\n\n0-9\n\n_(underscore)\n\n-(dash)\n\n.(dot)\n\nAttribute names must be at least one character long, and less than 64 KB in size.\n\nFor more information, see Naming rules.\n\nService quota basics\n\nRead and write units\n\nRead capacity unit (RCU) – One strongly consistent read per second, or two eventually consistent reads per second, for items up to 4 KB in size.\n\nWrite capacity unit (WCU) – One write per second, for items up to 1 KB in size.\n\nTable limits\n\nTable size – There is no practical limit on table size. Tables are unconstrained in terms of the number of items or the number of bytes.\n\nNumber of tables – For any AWS account, there is an initial quota of 2,500 tables per AWS Region.\n\nPage size limit for query and scan – There is a limit of 1 MB per page, per query or scan. If your query parameters or scan operation on a table result in more than 1 MB of data, DynamoDB returns the initial matching items. It also returns a LastEvaluatedKey property that you can use in a new request to read the next page.\n\nIndexes\n\nLocal secondary indexes (LSIs) – You can define a maximum of five local secondary indexes. LSIs are primarily useful when an index must have strong consistency with the base table.\n\nGlobal secondary indexes (GSIs) – There is a default quota of 20 global secondary indexes per table.\n\nProjected secondary index attributes per table – You can project a total of up to 100 attributes into all of a table's local and global secondary indexes. This only applies to user-specified projected attributes.\n\nPartition keys\n\nThe minimum length of a partition key value is 1 byte. The maximum length is 2048 bytes.\n\nThere is no practical limit on the number of distinct partition key values, for tables or for secondary indexes.\n\nThe minimum length of a sort key value is 1 byte. The maximum length is 1024 bytes.\n\nIn general, there is no practical limit on the number of distinct sort key values per partition key value. The exception is for tables with secondary indexes.\n\nFor more information on secondary indexes, partition key design, and sort key design, see Best practices.\n\nLimits for commonly used data types\n\nString – The length of a string is constrained by the maximum item size of 400 KB. Strings are Unicode with UTF-8 binary encoding.\n\nNumber – A number can have up to 38 digits of precision, and can be positive, negative, or zero.\n\nBinary – The length of a binary is constrained by the maximum item size of 400 KB. Applications that work with binary attributes must encode the data in base64 encoding before sending it to DynamoDB.\n\nFor a full list of supported data types, see Data types. For more information, also see Service quotas.\n\nItems, attributes, and expression parameters\n\nThe maximum item size in DynamoDB is 400 KB, which includes both attribute name binary length (UTF-8 length) and attribute value binary lengths (UTF-8 length). The attribute name counts towards the size limit.\n\nThere is no limit on the number of values in a list, map, or set, as long as the item that contains the values fits within the 400-KB item size limit.\n\nFor expression parameters, the maximum length of any expression string is 4 KB.\n\nFor more information about item size, attributes, and expression parameters, see Service quotas.\n\nMore information\n\nSecurity\n\nMonitoring and logging\n\nWorking with streams\n\nBackups and Point-in-time recovery\n\nIntegrating with other AWS services\n\nAPI reference\n\nArchitecture Center: Database Best Practices\n\nVideo tutorials\n\nDynamoDB forum"
  },
  {
    "title": "What is Amazon DynamoDB? - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html",
    "html": "What is Amazon DynamoDB?\nPDF\nRSS\n\nAmazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. DynamoDB lets you offload the administrative burdens of operating and scaling a distributed database so that you don't have to worry about hardware provisioning, setup and configuration, replication, software patching, or cluster scaling. DynamoDB also offers encryption at rest, which eliminates the operational burden and complexity involved in protecting sensitive data. For more information, see DynamoDB encryption at rest.\n\nWith DynamoDB, you can create database tables that can store and retrieve any amount of data and serve any level of request traffic. You can scale up or scale down your tables' throughput capacity without downtime or performance degradation. You can use the AWS Management Console to monitor resource utilization and performance metrics.\n\nDynamoDB provides on-demand backup capability. It allows you to create full backups of your tables for long-term retention and archival for regulatory compliance needs. For more information, see Using On-Demand backup and restore for DynamoDB.\n\nYou can create on-demand backups and enable point-in-time recovery for your Amazon DynamoDB tables. Point-in-time recovery helps protect your tables from accidental write or delete operations. With point-in-time recovery, you can restore a table to any point in time during the last 35 days. For more information, see Point-in-time recovery: How it works.\n\nDynamoDB allows you to delete expired items from tables automatically to help you reduce storage usage and the cost of storing data that is no longer relevant. For more information, see Time to Live (TTL).\n\nHigh availability and durability\n\nDynamoDB automatically spreads the data and traffic for your tables over a sufficient number of servers to handle your throughput and storage requirements, while maintaining consistent and fast performance. All of your data is stored on solid-state disks (SSDs) and is automatically replicated across multiple Availability Zones in an AWS Region, providing built-in high availability and data durability. You can use global tables to keep DynamoDB tables in sync across AWS Regions. For more information, see Global tables - multi-Region replication for DynamoDB.\n\nGetting started with DynamoDB\n\nWe recommend that you begin by reading the following sections:\n\nAmazon DynamoDB: How it works—To learn essential DynamoDB concepts.\n\nSetting up DynamoDB —To learn how to set up DynamoDB (the downloadable version or the web service).\n\nAccessing DynamoDB—To learn how to access DynamoDB using the console, AWS CLI, or API.\n\nFrom there, you have two options to quickly get started with DynamoDB:\n\nGetting started with DynamoDB\n\nGetting started with DynamoDB and the AWS SDKs\n\nTo learn more about application development, see the following:\n\nProgramming with DynamoDB and the AWS SDKs\n\nWorking with tables, items, queries, scans, and indexes\n\nTo quickly find recommendations for maximizing performance and minimizing throughput costs, see the following: Best practices for designing and architecting with DynamoDB. To learn how to tag DynamoDB resources, see Adding tags and labels to resources.\n\nFor best practices, how-to guides, and tools, see Amazon DynamoDB resources.\n\nYou can use AWS Database Migration Service (AWS DMS) to migrate data from a relational database or MongoDB to a DynamoDB table. For more information, see the AWS Database Migration Service User Guide.\n\nTo learn how to use MongoDB as a migration source, see Using MongoDB as a source for AWS Database Migration Service. To learn how to use DynamoDB as a migration target, see Using an Amazon DynamoDB database as a target for AWS Database Migration Service.\n\nDynamoDB tutorials\n\nThe following tutorials present complete end-to-end procedures to familiarize yourself with DynamoDB. These tutorials can be completed with the free tier of AWS and will give you practical experience using DynamoDB.\n\nBuild an Application Using a NoSQL Key-Value Data Store\n\nCreate and Query a NoSQL Table with Amazon DynamoDB"
  },
  {
    "title": "NoSQL design for DynamoDB - Amazon DynamoDB",
    "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-general-nosql-design.html",
    "html": "NoSQL design for DynamoDB\nPDF\nRSS\n\nNoSQL database systems like Amazon DynamoDB use alternative models for data management, such as key-value pairs or document storage. When you switch from a relational database management system to a NoSQL database system like DynamoDB, it's important to understand the key differences and specific design approaches.\n\nTopics\nDifferences between relational data design and NoSQL\nTwo key concepts for NoSQL design\nApproaching NoSQL design\nNoSQL Workbench for DynamoDB\nDifferences between relational data design and NoSQL\n\nRelational database systems (RDBMS) and NoSQL databases have different strengths and weaknesses:\n\nIn RDBMS, data can be queried flexibly, but queries are relatively expensive and don't scale well in high-traffic situations (see First steps for modeling relational data in DynamoDB).\n\nIn a NoSQL database such as DynamoDB, data can be queried efficiently in a limited number of ways, outside of which queries can be expensive and slow.\n\nThese differences make database design different between the two systems:\n\nIn RDBMS, you design for flexibility without worrying about implementation details or performance. Query optimization generally doesn't affect schema design, but normalization is important.\n\nIn DynamoDB, you design your schema specifically to make the most common and important queries as fast and as inexpensive as possible. Your data structures are tailored to the specific requirements of your business use cases.\n\nTwo key concepts for NoSQL design\n\nNoSQL design requires a different mindset than RDBMS design. For an RDBMS, you can go ahead and create a normalized data model without thinking about access patterns. You can then extend it later when new questions and query requirements arise. You can organize each type of data into its own table.\n\nHow NoSQL design is different\n\nBy contrast, you shouldn't start designing your schema for DynamoDB until you know the questions it will need to answer. Understanding the business problems and the application use cases up front is essential.\n\nYou should maintain as few tables as possible in a DynamoDB application. Having fewer tables keeps things more scalable, requires less permissions management, and reduces overhead for your DynamoDB application. It can also help keep backup costs lower overall.\n\nApproaching NoSQL design\n\nThe first step in designing your DynamoDB application is to identify the specific query patterns that the system must satisfy.\n\nIn particular, it is important to understand three fundamental properties of your application's access patterns before you begin:\n\nData size: Knowing how much data will be stored and requested at one time will help determine the most effective way to partition the data.\n\nData shape: Instead of reshaping data when a query is processed (as an RDBMS system does), a NoSQL database organizes data so that its shape in the database corresponds with what will be queried. This is a key factor in increasing speed and scalability.\n\nData velocity: DynamoDB scales by increasing the number of physical partitions that are available to process queries, and by efficiently distributing data across those partitions. Knowing in advance what the peak query loads will be might help determine how to partition data to best use I/O capacity.\n\nAfter you identify specific query requirements, you can organize data according to general principles that govern performance:\n\nKeep related data together.   Research on routing-table optimization 20 years ago found that \"locality of reference\" was the single most important factor in speeding up response time: keeping related data together in one place. This is equally true in NoSQL systems today, where keeping related data in close proximity has a major impact on cost and performance. Instead of distributing related data items across multiple tables, you should keep related items in your NoSQL system as close together as possible.\n\nAs a general rule, you should maintain as few tables as possible in a DynamoDB application.\n\nExceptions are cases where high-volume time series data are involved, or datasets that have very different access patterns. A single table with inverted indexes can usually enable simple queries to create and retrieve the complex hierarchical data structures required by your application.\n\nUse sort order.   Related items can be grouped together and queried efficiently if their key design causes them to sort together. This is an important NoSQL design strategy.\n\nDistribute queries.   It is also important that a high volume of queries not be focused on one part of the database, where they can exceed I/O capacity. Instead, you should design data keys to distribute traffic evenly across partitions as much as possible, avoiding \"hot spots.\"\n\nUse global secondary indexes.   By creating specific global secondary indexes, you can enable different queries than your main table can support, and that are still fast and relatively inexpensive.\n\nThese general principles translate into some common design patterns that you can use to model data efficiently in DynamoDB.\n\nNoSQL Workbench for DynamoDB\n\nNoSQL Workbench for DynamoDB is a cross-platform, client-side GUI application that you can use for modern database development and operations. It's available for Windows, macOS, and Linux. NoSQL Workbench is a visual development tool that provides data modeling, data visualization, sample data generation, and query development features to help you design, create, query, and manage DynamoDB tables. With NoSQL Workbench for DynamoDB, you can build new data models from, or design models based on, existing data models that satisfy your application's data access patterns. You can also import and export the designed data model at the end of the process. For more information, see Building data models with NoSQL Workbench"
  }
]